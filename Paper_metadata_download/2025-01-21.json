[
    {
        "paper": {
            "id": "2501.08325",
            "authors": [
                {
                    "_id": "678719ac5333dfbf8e206077",
                    "user": {
                        "_id": "64105a6d14215c0775dfdd14",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64105a6d14215c0775dfdd14/-VX-cUYOLjHIg7QnWhRGG.jpeg",
                        "isPro": false,
                        "fullname": "Jiwen Yu",
                        "user": "VictorYuki",
                        "type": "user"
                    },
                    "name": "Jiwen Yu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-15T08:49:01.033Z",
                    "hidden": false
                },
                {
                    "_id": "678719ac5333dfbf8e206078",
                    "name": "Yiran Qin",
                    "hidden": false
                },
                {
                    "_id": "678719ac5333dfbf8e206079",
                    "user": {
                        "_id": "60e272ca6c78a8c122b12127",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg",
                        "isPro": false,
                        "fullname": "Xintao Wang",
                        "user": "Xintao",
                        "type": "user"
                    },
                    "name": "Xintao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-21T10:08:34.083Z",
                    "hidden": false
                },
                {
                    "_id": "678719ac5333dfbf8e20607a",
                    "name": "Pengfei Wan",
                    "hidden": false
                },
                {
                    "_id": "678719ac5333dfbf8e20607b",
                    "user": {
                        "_id": "64bce15bafd1e46c5504ad38",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64bce15bafd1e46c5504ad38/bQFX1iFbXEBXcQvUNL811.png",
                        "isPro": false,
                        "fullname": "Di Zhang",
                        "user": "di-zhang-fdu",
                        "type": "user"
                    },
                    "name": "Di Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-21T10:08:59.963Z",
                    "hidden": false
                },
                {
                    "_id": "678719ac5333dfbf8e20607c",
                    "user": {
                        "_id": "65d5ec74cd05bc1eaa125040",
                        "avatarUrl": "/avatars/2de1b1539a86452c2c89570eeb02f5ab.svg",
                        "isPro": false,
                        "fullname": "Xihui Liu",
                        "user": "XihuiLiu",
                        "type": "user"
                    },
                    "name": "Xihui Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-21T10:07:46.546Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-14T18:57:21.000Z",
            "title": "GameFactory: Creating New Games with Generative Interactive Videos",
            "summary": "Generative game engines have the potential to revolutionize game development\nby autonomously creating new content and reducing manual workload. However,\nexisting video-based game generation methods fail to address the critical\nchallenge of scene generalization, limiting their applicability to existing\ngames with fixed styles and scenes. In this paper, we present GameFactory, a\nframework focused on exploring scene generalization in game video generation.\nTo enable the creation of entirely new and diverse games, we leverage\npre-trained video diffusion models trained on open-domain video data. To bridge\nthe domain gap between open-domain priors and small-scale game dataset, we\npropose a multi-phase training strategy that decouples game style learning from\naction control, preserving open-domain generalization while achieving action\ncontrollability. Using Minecraft as our data source, we release GF-Minecraft, a\nhigh-quality and diversity action-annotated video dataset for research.\nFurthermore, we extend our framework to enable autoregressive\naction-controllable game video generation, allowing the production of\nunlimited-length interactive game videos. Experimental results demonstrate that\nGameFactory effectively generates open-domain, diverse, and action-controllable\ngame videos, representing a significant step forward in AI-driven game\ngeneration. Our dataset and project page are publicly available at\nhttps://vvictoryuki.github.io/gamefactory/.",
            "upvotes": 55,
            "discussionId": "678719ae5333dfbf8e206106"
        },
        "publishedAt": "2025-01-20T22:21:50.434Z",
        "title": "GameFactory: Creating New Games with Generative Interactive Videos",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.08325.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "64105a6d14215c0775dfdd14",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64105a6d14215c0775dfdd14/-VX-cUYOLjHIg7QnWhRGG.jpeg",
            "fullname": "Jiwen Yu",
            "name": "VictorYuki",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.09781",
            "authors": [
                {
                    "_id": "678f5a57bbe3bed7b802c477",
                    "user": {
                        "_id": "64e1cabf12a5504dda7e4948",
                        "avatarUrl": "/avatars/53851eddb4e1cae773f3e3607181094b.svg",
                        "isPro": false,
                        "fullname": "rzw",
                        "user": "maverickrzw",
                        "type": "user"
                    },
                    "name": "Zhongwei Ren",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-21T10:07:03.173Z",
                    "hidden": false
                },
                {
                    "_id": "678f5a57bbe3bed7b802c478",
                    "name": "Yunchao Wei",
                    "hidden": false
                },
                {
                    "_id": "678f5a57bbe3bed7b802c479",
                    "user": {
                        "_id": "64ae7ddf407a5cae8579c171",
                        "avatarUrl": "/avatars/f78e8958db16f5f5603ece527951ac23.svg",
                        "isPro": false,
                        "fullname": "Xun Guo",
                        "user": "xunguohf",
                        "type": "user"
                    },
                    "name": "Xun Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-21T14:20:14.976Z",
                    "hidden": false
                },
                {
                    "_id": "678f5a57bbe3bed7b802c47a",
                    "name": "Yao Zhao",
                    "hidden": false
                },
                {
                    "_id": "678f5a57bbe3bed7b802c47b",
                    "user": {
                        "_id": "647b5fef6a79fbf5e996c47c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647b5fef6a79fbf5e996c47c/IkSMnDsCY_CyEFCiMDuxe.jpeg",
                        "isPro": false,
                        "fullname": "Bingyi Kang",
                        "user": "bykang",
                        "type": "user"
                    },
                    "name": "Bingyi Kang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-21T14:19:50.039Z",
                    "hidden": false
                },
                {
                    "_id": "678f5a57bbe3bed7b802c47c",
                    "user": {
                        "_id": "67298e44017b96a1d0101dc4",
                        "avatarUrl": "/avatars/1f8ed1a3e911e6a3021087b9371d284c.svg",
                        "isPro": false,
                        "fullname": "Jiashi Feng",
                        "user": "jshfeng",
                        "type": "user"
                    },
                    "name": "Jiashi Feng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-21T14:19:44.355Z",
                    "hidden": false
                },
                {
                    "_id": "678f5a57bbe3bed7b802c47d",
                    "name": "Xiaojie Jin",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-16T18:59:10.000Z",
            "title": "VideoWorld: Exploring Knowledge Learning from Unlabeled Videos",
            "summary": "This work explores whether a deep generative model can learn complex\nknowledge solely from visual input, in contrast to the prevalent focus on\ntext-based models like large language models (LLMs). We develop VideoWorld, an\nauto-regressive video generation model trained on unlabeled video data, and\ntest its knowledge acquisition abilities in video-based Go and robotic control\ntasks. Our experiments reveal two key findings: (1) video-only training\nprovides sufficient information for learning knowledge, including rules,\nreasoning and planning capabilities, and (2) the representation of visual\nchange is crucial for knowledge acquisition. To improve both the efficiency and\nefficacy of this process, we introduce the Latent Dynamics Model (LDM) as a key\ncomponent of VideoWorld. Remarkably, VideoWorld reaches a 5-dan professional\nlevel in the Video-GoBench with just a 300-million-parameter model, without\nrelying on search algorithms or reward mechanisms typical in reinforcement\nlearning. In robotic tasks, VideoWorld effectively learns diverse control\noperations and generalizes across environments, approaching the performance of\noracle models in CALVIN and RLBench. This study opens new avenues for knowledge\nacquisition from visual data, with all code, data, and models open-sourced for\nfurther research.",
            "upvotes": 17,
            "discussionId": "678f5a59bbe3bed7b802c4d6"
        },
        "publishedAt": "2025-01-21T05:10:08.409Z",
        "title": "VideoWorld: Exploring Knowledge Learning from Unlabeled Videos",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.09781.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64e1cabf12a5504dda7e4948",
            "avatarUrl": "/avatars/53851eddb4e1cae773f3e3607181094b.svg",
            "fullname": "rzw",
            "name": "maverickrzw",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.09284",
            "authors": [
                {
                    "_id": "678dfb39f002f862857e90bf",
                    "user": {
                        "_id": "63d93667255ef6add20f9272",
                        "avatarUrl": "/avatars/99a3aeadcc81ef85164cdfb6ab186b17.svg",
                        "isPro": false,
                        "fullname": "Giyeong Oh",
                        "user": "BootsofLagrangian",
                        "type": "user"
                    },
                    "name": "Giyeong Oh",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-20T09:28:57.015Z",
                    "hidden": false
                },
                {
                    "_id": "678dfb39f002f862857e90c0",
                    "user": {
                        "_id": "646d9f60eb9268aeebc55b8b",
                        "avatarUrl": "/avatars/6bf4ff17c340a622a7a847dddfe40ff2.svg",
                        "isPro": false,
                        "fullname": "SJKIM",
                        "user": "Steamout",
                        "type": "user"
                    },
                    "name": "Saejin Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-20T13:16:39.750Z",
                    "hidden": false
                },
                {
                    "_id": "678dfb39f002f862857e90c1",
                    "name": "Woohyun Cho",
                    "hidden": false
                },
                {
                    "_id": "678dfb39f002f862857e90c2",
                    "name": "Sangkyu Lee",
                    "hidden": false
                },
                {
                    "_id": "678dfb39f002f862857e90c3",
                    "user": {
                        "_id": "60d74d1affe0328e0167dc5f",
                        "avatarUrl": "/avatars/9b1a2df9402e9c26e1eb7c818af9bae0.svg",
                        "isPro": false,
                        "fullname": "Jiwan Chung",
                        "user": "jiwan-chung",
                        "type": "user"
                    },
                    "name": "Jiwan Chung",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-21T14:22:48.531Z",
                    "hidden": false
                },
                {
                    "_id": "678dfb39f002f862857e90c4",
                    "user": {
                        "_id": "65ab767ca92a64ef5b9c8423",
                        "avatarUrl": "/avatars/00abf7a05fd86a08587f72cab5b3cff3.svg",
                        "isPro": false,
                        "fullname": "Dokyung Song",
                        "user": "dokyungs",
                        "type": "user"
                    },
                    "name": "Dokyung Song",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-21T14:22:42.282Z",
                    "hidden": false
                },
                {
                    "_id": "678dfb39f002f862857e90c5",
                    "user": {
                        "_id": "6504777fb1da3747a05160c4",
                        "avatarUrl": "/avatars/b777d98a5ff971ddb4c3e1060bb3e070.svg",
                        "isPro": false,
                        "fullname": "Youngjae Yu",
                        "user": "yjyu",
                        "type": "user"
                    },
                    "name": "Youngjae Yu",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-01-20T07:28:58.615Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-16T04:17:56.000Z",
            "title": "SEAL: Entangled White-box Watermarks on Low-Rank Adaptation",
            "summary": "Recently, LoRA and its variants have become the de facto strategy for\ntraining and sharing task-specific versions of large pretrained models, thanks\nto their efficiency and simplicity. However, the issue of copyright protection\nfor LoRA weights, especially through watermark-based techniques, remains\nunderexplored. To address this gap, we propose SEAL (SEcure wAtermarking on\nLoRA weights), the universal whitebox watermarking for LoRA. SEAL embeds a\nsecret, non-trainable matrix between trainable LoRA weights, serving as a\npassport to claim ownership. SEAL then entangles the passport with the LoRA\nweights through training, without extra loss for entanglement, and distributes\nthe finetuned weights after hiding the passport. When applying SEAL, we\nobserved no performance degradation across commonsense reasoning,\ntextual/visual instruction tuning, and text-to-image synthesis tasks. We\ndemonstrate that SEAL is robust against a variety of known attacks: removal,\nobfuscation, and ambiguity attacks.",
            "upvotes": 7,
            "discussionId": "678dfb3af002f862857e912e"
        },
        "publishedAt": "2025-01-21T07:45:12.825Z",
        "title": "SEAL: Entangled White-box Watermarks on Low-Rank Adaptation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.09284.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63d93667255ef6add20f9272",
            "avatarUrl": "/avatars/99a3aeadcc81ef85164cdfb6ab186b17.svg",
            "fullname": "Giyeong Oh",
            "name": "BootsofLagrangian",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    }
]