[
    {
        "paper": {
            "id": "2501.13200",
            "authors": [
                {
                    "_id": "67933d69b843fda452c689dd",
                    "user": {
                        "_id": "65c0db0fbda79a18292dfbb7",
                        "avatarUrl": "/avatars/1201b8282664c2d8c18beaba2396c03b.svg",
                        "isPro": false,
                        "fullname": "Alsu Sagirova",
                        "user": "alsu-sagirova",
                        "type": "user"
                    },
                    "name": "Alsu Sagirova",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T09:07:49.036Z",
                    "hidden": false
                },
                {
                    "_id": "67933d69b843fda452c689de",
                    "name": "Yuri Kuratov",
                    "hidden": false
                },
                {
                    "_id": "67933d69b843fda452c689df",
                    "user": {
                        "_id": "639c6e978a34ed9a404c6a7b",
                        "avatarUrl": "/avatars/c98ca8c9f9ed8509c2f1bb6aa994fd57.svg",
                        "isPro": false,
                        "fullname": "MIKHAIL BURTSEV",
                        "user": "mbur",
                        "type": "user"
                    },
                    "name": "Mikhail Burtsev",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:07:03.954Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-22T20:08:53.000Z",
            "title": "SRMT: Shared Memory for Multi-agent Lifelong Pathfinding",
            "summary": "Multi-agent reinforcement learning (MARL) demonstrates significant progress\nin solving cooperative and competitive multi-agent problems in various\nenvironments. One of the principal challenges in MARL is the need for explicit\nprediction of the agents' behavior to achieve cooperation. To resolve this\nissue, we propose the Shared Recurrent Memory Transformer (SRMT) which extends\nmemory transformers to multi-agent settings by pooling and globally\nbroadcasting individual working memories, enabling agents to exchange\ninformation implicitly and coordinate their actions. We evaluate SRMT on the\nPartially Observable Multi-Agent Pathfinding problem in a toy Bottleneck\nnavigation task that requires agents to pass through a narrow corridor and on a\nPOGEMA benchmark set of tasks. In the Bottleneck task, SRMT consistently\noutperforms a variety of reinforcement learning baselines, especially under\nsparse rewards, and generalizes effectively to longer corridors than those seen\nduring training. On POGEMA maps, including Mazes, Random, and MovingAI, SRMT is\ncompetitive with recent MARL, hybrid, and planning-based algorithms. These\nresults suggest that incorporating shared recurrent memory into the\ntransformer-based architectures can enhance coordination in decentralized\nmulti-agent systems. The source code for training and evaluation is available\non GitHub: https://github.com/Aloriosa/srmt.",
            "upvotes": 46,
            "discussionId": "67933d6ab843fda452c68a38"
        },
        "publishedAt": "2025-01-24T02:35:35.802Z",
        "title": "SRMT: Shared Memory for Multi-agent Lifelong Pathfinding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13200.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65c0db0fbda79a18292dfbb7",
            "avatarUrl": "/avatars/1201b8282664c2d8c18beaba2396c03b.svg",
            "fullname": "Alsu Sagirova",
            "name": "alsu-sagirova",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.13629",
            "authors": [
                {
                    "_id": "6792f8ed5e3ec6035dafb06a",
                    "user": {
                        "_id": "63776f1806241efce1e7aae6",
                        "avatarUrl": "/avatars/d67d9dcd932934c630f407ac152f2ce6.svg",
                        "isPro": false,
                        "fullname": "Zhenghao Lin",
                        "user": "Lin0",
                        "type": "user"
                    },
                    "name": "Zhenghao Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T09:14:52.584Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb06b",
                    "user": {
                        "_id": "656c6bd8e0ff1cebe966aa35",
                        "avatarUrl": "/avatars/1083cb58bdb0bee72036953276d42e13.svg",
                        "isPro": false,
                        "fullname": "tangzihao",
                        "user": "tzh94588",
                        "type": "user"
                    },
                    "name": "Zihao Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T09:15:04.802Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb06c",
                    "user": {
                        "_id": "63fb6e281b4b1bd4e7ffc5be",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Xiao Liu",
                        "user": "lx865712528",
                        "type": "user"
                    },
                    "name": "Xiao Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T09:08:05.797Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb06d",
                    "user": {
                        "_id": "643f615aa16cd6d1f4c581de",
                        "avatarUrl": "/avatars/47753a3e82b44f81881600c52e1e8495.svg",
                        "isPro": false,
                        "fullname": "Yeyun Gong",
                        "user": "yegong",
                        "type": "user"
                    },
                    "name": "Yeyun Gong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T09:58:33.228Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb06e",
                    "name": "Yi Cheng",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb06f",
                    "name": "Qi Chen",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb070",
                    "user": {
                        "_id": "61342a4b488458a484dee6c4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1630808595161-noauth.png",
                        "isPro": false,
                        "fullname": "Hang Li",
                        "user": "hanglics",
                        "type": "user"
                    },
                    "name": "Hang Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:03:59.680Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb071",
                    "name": "Ying Xin",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb072",
                    "user": {
                        "_id": "62f6a9add3bdacb7eec0d4f5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660332390183-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Ziyue Yang",
                        "user": "ziyueyang37",
                        "type": "user"
                    },
                    "name": "Ziyue Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:04:09.709Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb073",
                    "user": {
                        "_id": "646fc402e9c03ba436d5e93e",
                        "avatarUrl": "/avatars/870c86dc99fb1cb6a348a7a0385b1a04.svg",
                        "isPro": false,
                        "fullname": "Kailai Yang",
                        "user": "klyang",
                        "type": "user"
                    },
                    "name": "Kailai Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:04:16.033Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb074",
                    "name": "Yu Yan",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb075",
                    "name": "Xiao Liang",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb076",
                    "name": "Shuai Lu",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb077",
                    "name": "Yiming Huang",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb078",
                    "user": {
                        "_id": "6443bb593c323e0918f61a96",
                        "avatarUrl": "/avatars/b9e1ba17f7798b5142bc0124fba95237.svg",
                        "isPro": false,
                        "fullname": "zheheng luo",
                        "user": "KenLuo",
                        "type": "user"
                    },
                    "name": "Zheheng Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:04:49.140Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb079",
                    "name": "Lei Qu",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb07a",
                    "name": "Xuan Feng",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb07b",
                    "name": "Yaoxiang Wang",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb07c",
                    "user": {
                        "_id": "6369e01864aad59d4d4501ac",
                        "avatarUrl": "/avatars/bcbd3f9d0d194eeccd061c4fa6a6e283.svg",
                        "isPro": false,
                        "fullname": "Yuqing Xia",
                        "user": "yuqxia",
                        "type": "user"
                    },
                    "name": "Yuqing Xia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:05:26.287Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb07d",
                    "user": {
                        "_id": "673fd856a45b6f21829a3bf5",
                        "avatarUrl": "/avatars/deb8c5362fad22019cccaed6d03dea09.svg",
                        "isPro": false,
                        "fullname": "Feiyang Chen",
                        "user": "PhilipChen",
                        "type": "user"
                    },
                    "name": "Feiyang Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:05:34.991Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb07e",
                    "user": {
                        "_id": "64e85f4e5ddcace745bc0a55",
                        "avatarUrl": "/avatars/e316355b913c73104db530010ceedeb4.svg",
                        "isPro": false,
                        "fullname": "Yuting Jiang",
                        "user": "Stautinger",
                        "type": "user"
                    },
                    "name": "Yuting Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:05:41.151Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb07f",
                    "name": "Yasen Hu",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb080",
                    "name": "Hao Ni",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb081",
                    "user": {
                        "_id": "6485714cfc41a0b97fe377cc",
                        "avatarUrl": "/avatars/0af8a3df9ad711a5eac739bce26c4c2a.svg",
                        "isPro": false,
                        "fullname": "Li",
                        "user": "Binyang",
                        "type": "user"
                    },
                    "name": "Binyang Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:06:03.263Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb082",
                    "user": {
                        "_id": "663de80ca920d195191807da",
                        "avatarUrl": "/avatars/2437ce3fa073a07b971d370c26c7ab65.svg",
                        "isPro": false,
                        "fullname": "Guoshuai Zhao",
                        "user": "crayonshine",
                        "type": "user"
                    },
                    "name": "Guoshuai Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:05:17.780Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb083",
                    "name": "Jui-Hao Chiang",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb084",
                    "name": "Zhongxin Guo",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb085",
                    "name": "Chen Lin",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb086",
                    "name": "Kun Kuang",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb087",
                    "user": {
                        "_id": "66a3710a4ee2a4c936315a5a",
                        "avatarUrl": "/avatars/ef8da8fb1031695d77d34a5d365aa177.svg",
                        "isPro": false,
                        "fullname": "Li",
                        "user": "WenjieLi",
                        "type": "user"
                    },
                    "name": "Wenjie Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:06:22.951Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb088",
                    "user": {
                        "_id": "6454c337a13edf669cd5d8ea",
                        "avatarUrl": "/avatars/a383a0dda7c2ef6a0d6c3c64651f42ff.svg",
                        "isPro": false,
                        "fullname": "Yelong Shen",
                        "user": "uuu6",
                        "type": "user"
                    },
                    "name": "Yelong Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:06:30.109Z",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb089",
                    "name": "Jian Jiao",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb08a",
                    "name": "Peng Cheng",
                    "hidden": false
                },
                {
                    "_id": "6792f8ed5e3ec6035dafb08b",
                    "name": "Mao Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T12:58:14.000Z",
            "title": "Sigma: Differential Rescaling of Query, Key and Value for Efficient\n  Language Models",
            "summary": "We introduce Sigma, an efficient large language model specialized for the\nsystem domain, empowered by a novel architecture including DiffQKV attention,\nand pre-trained on our meticulously collected system domain data. DiffQKV\nattention significantly enhances the inference efficiency of Sigma by\noptimizing the Query (Q), Key (K), and Value (V) components in the attention\nmechanism differentially, based on their varying impacts on the model\nperformance and efficiency indicators. Specifically, we (1) conduct extensive\nexperiments that demonstrate the model's varying sensitivity to the compression\nof K and V components, leading to the development of differentially compressed\nKV, and (2) propose augmented Q to expand the Q head dimension, which enhances\nthe model's representation capacity with minimal impacts on the inference\nspeed. Rigorous theoretical and empirical analyses reveal that DiffQKV\nattention significantly enhances efficiency, achieving up to a 33.36%\nimprovement in inference speed over the conventional grouped-query attention\n(GQA) in long-context scenarios. We pre-train Sigma on 6T tokens from various\nsources, including 19.5B system domain data that we carefully collect and 1T\ntokens of synthesized and rewritten data. In general domains, Sigma achieves\ncomparable performance to other state-of-arts models. In the system domain, we\nintroduce the first comprehensive benchmark AIMicius, where Sigma demonstrates\nremarkable performance across all tasks, significantly outperforming GPT-4 with\nan absolute improvement up to 52.5%.",
            "upvotes": 33,
            "discussionId": "6792f8f05e3ec6035dafb140"
        },
        "publishedAt": "2025-01-23T22:48:16.405Z",
        "title": "Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13629.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63fb6e281b4b1bd4e7ffc5be",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677422062937-noauth.jpeg",
            "fullname": "Xiao Liu",
            "name": "lx865712528",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 7
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.13918",
            "authors": [
                {
                    "_id": "679319848d46289f90266168",
                    "user": {
                        "_id": "639be86b59473c6ae02ef9c4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
                        "isPro": false,
                        "fullname": "Jie Liu",
                        "user": "jieliu",
                        "type": "user"
                    },
                    "name": "Jie Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T09:07:53.235Z",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266169",
                    "name": "Gongye Liu",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f9026616a",
                    "name": "Jiajun Liang",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f9026616b",
                    "name": "Ziyang Yuan",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f9026616c",
                    "name": "Xiaokun Liu",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f9026616d",
                    "name": "Mingwu Zheng",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f9026616e",
                    "name": "Xiele Wu",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f9026616f",
                    "name": "Qiulin Wang",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266170",
                    "name": "Wenyu Qin",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266171",
                    "name": "Menghan Xia",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266172",
                    "user": {
                        "_id": "60e272ca6c78a8c122b12127",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60e272ca6c78a8c122b12127/xldEGBzGrU-bX6IwAw0Ie.jpeg",
                        "isPro": false,
                        "fullname": "Xintao Wang",
                        "user": "Xintao",
                        "type": "user"
                    },
                    "name": "Xintao Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T09:07:51.248Z",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266173",
                    "name": "Xiaohong Liu",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266174",
                    "name": "Fei Yang",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266175",
                    "name": "Pengfei Wan",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266176",
                    "name": "Di Zhang",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266177",
                    "name": "Kun Gai",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266178",
                    "name": "Yujiu Yang",
                    "hidden": false
                },
                {
                    "_id": "679319848d46289f90266179",
                    "name": "Wanli Ouyang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T18:55:41.000Z",
            "title": "Improving Video Generation with Human Feedback",
            "summary": "Video generation has achieved significant advances through rectified flow\ntechniques, but issues like unsmooth motion and misalignment between videos and\nprompts persist. In this work, we develop a systematic pipeline that harnesses\nhuman feedback to mitigate these problems and refine the video generation\nmodel. Specifically, we begin by constructing a large-scale human preference\ndataset focused on modern video generation models, incorporating pairwise\nannotations across multi-dimensions. We then introduce VideoReward, a\nmulti-dimensional video reward model, and examine how annotations and various\ndesign choices impact its rewarding efficacy. From a unified reinforcement\nlearning perspective aimed at maximizing reward with KL regularization, we\nintroduce three alignment algorithms for flow-based models by extending those\nfrom diffusion models. These include two training-time strategies: direct\npreference optimization for flow (Flow-DPO) and reward weighted regression for\nflow (Flow-RWR), and an inference-time technique, Flow-NRG, which applies\nreward guidance directly to noisy videos. Experimental results indicate that\nVideoReward significantly outperforms existing reward models, and Flow-DPO\ndemonstrates superior performance compared to both Flow-RWR and standard\nsupervised fine-tuning methods. Additionally, Flow-NRG lets users assign custom\nweights to multiple objectives during inference, meeting personalized video\nquality needs. Project page: https://gongyeliu.github.io/videoalign.",
            "upvotes": 30,
            "discussionId": "679319858d46289f90266203"
        },
        "publishedAt": "2025-01-24T05:39:01.676Z",
        "title": "Improving Video Generation with Human Feedback",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13918.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "639be86b59473c6ae02ef9c4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/639be86b59473c6ae02ef9c4/gw34RBCVZCOkcAA79xUr3.png",
            "fullname": "Jie Liu",
            "name": "jieliu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 10
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.13919",
            "authors": [
                {
                    "_id": "679317f9d3ef2f790a539a28",
                    "user": {
                        "_id": "6785fc7d17a2dfa3720ec082",
                        "avatarUrl": "/avatars/73e9d715bb16f14240c733c4843dfc22.svg",
                        "isPro": false,
                        "fullname": "Rui Li",
                        "user": "ruili0",
                        "type": "user"
                    },
                    "name": "Rui Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T10:17:34.282Z",
                    "hidden": false
                },
                {
                    "_id": "679317f9d3ef2f790a539a29",
                    "user": {
                        "_id": "65703fab7f50602340d23704",
                        "avatarUrl": "/avatars/324c45f5fba9cd8c38a89b30427c06b4.svg",
                        "isPro": false,
                        "fullname": "Xiaohan Wang",
                        "user": "nicholswang",
                        "type": "user"
                    },
                    "name": "Xiaohan Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:11:30.999Z",
                    "hidden": false
                },
                {
                    "_id": "679317f9d3ef2f790a539a2a",
                    "user": {
                        "_id": "62da55164398e21bf7f0e292",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62da55164398e21bf7f0e292/xjKkG8IA2IZZqCdjApSh3.jpeg",
                        "isPro": false,
                        "fullname": "Yuhui Zhang",
                        "user": "yuhuizhang",
                        "type": "user"
                    },
                    "name": "Yuhui Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:11:46.689Z",
                    "hidden": false
                },
                {
                    "_id": "679317f9d3ef2f790a539a2b",
                    "name": "Zeyu Wang",
                    "hidden": false
                },
                {
                    "_id": "679317f9d3ef2f790a539a2c",
                    "user": {
                        "_id": "677c8b2e92550a07fcad0f50",
                        "avatarUrl": "/avatars/2be26e8f25e98cfe5b1d227ee0409cd0.svg",
                        "isPro": false,
                        "fullname": "Serena Yeung-Levy",
                        "user": "yeunglevy",
                        "type": "user"
                    },
                    "name": "Serena Yeung-Levy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:09:52.788Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T18:58:03.000Z",
            "title": "Temporal Preference Optimization for Long-Form Video Understanding",
            "summary": "Despite significant advancements in video large multimodal models\n(video-LMMs), achieving effective temporal grounding in long-form videos\nremains a challenge for existing models. To address this limitation, we propose\nTemporal Preference Optimization (TPO), a novel post-training framework\ndesigned to enhance the temporal grounding capabilities of video-LMMs through\npreference learning. TPO adopts a self-training approach that enables models to\ndifferentiate between well-grounded and less accurate temporal responses by\nleveraging curated preference datasets at two granularities: localized temporal\ngrounding, which focuses on specific video segments, and comprehensive temporal\ngrounding, which captures extended temporal dependencies across entire video\nsequences. By optimizing on these preference datasets, TPO significantly\nenhances temporal understanding while reducing reliance on manually annotated\ndata. Extensive experiments on three long-form video understanding\nbenchmarks--LongVideoBench, MLVU, and Video-MME--demonstrate the effectiveness\nof TPO across two state-of-the-art video-LMMs. Notably, LLaVA-Video-TPO\nestablishes itself as the leading 7B model on the Video-MME benchmark,\nunderscoring the potential of TPO as a scalable and efficient solution for\nadvancing temporal reasoning in long-form video understanding. Project page:\nhttps://ruili33.github.io/tpo_website.",
            "upvotes": 14,
            "discussionId": "679317fcd3ef2f790a539ad6"
        },
        "publishedAt": "2025-01-23T23:33:03.175Z",
        "title": "Temporal Preference Optimization for Long-Form Video Understanding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13919.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "645dbaa6f5760d1530d7580d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
            "fullname": "Simeon Emanuilov",
            "name": "s-emanuilov",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 16
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.13926",
            "authors": [
                {
                    "_id": "6793040ec67af4a116a25d05",
                    "user": {
                        "_id": "647d9ab61a1fcad2fdbf2d3d",
                        "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
                        "isPro": true,
                        "fullname": "Ziyu Guo",
                        "user": "ZiyuG",
                        "type": "user"
                    },
                    "name": "Ziyu Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:07:58.258Z",
                    "hidden": false
                },
                {
                    "_id": "6793040ec67af4a116a25d06",
                    "name": "Renrui Zhang",
                    "hidden": false
                },
                {
                    "_id": "6793040ec67af4a116a25d07",
                    "name": "Chengzhuo Tong",
                    "hidden": false
                },
                {
                    "_id": "6793040ec67af4a116a25d08",
                    "user": {
                        "_id": "6713a71e7dfe714b425cccfb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/95YYcbv_f6J8yWTunwn4z.png",
                        "isPro": false,
                        "fullname": "zhizhengzhao",
                        "user": "zhizhengzhao",
                        "type": "user"
                    },
                    "name": "Zhizheng Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:08:20.272Z",
                    "hidden": false
                },
                {
                    "_id": "6793040ec67af4a116a25d09",
                    "user": {
                        "_id": "6759af3eccbc8817f9169179",
                        "avatarUrl": "/avatars/49e64c7ccf71b8f25c52783b6ae93620.svg",
                        "isPro": false,
                        "fullname": "Peng Gao",
                        "user": "gaopenghigh",
                        "type": "user"
                    },
                    "name": "Peng Gao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:08:26.816Z",
                    "hidden": false
                },
                {
                    "_id": "6793040ec67af4a116a25d0a",
                    "user": {
                        "_id": "65c04e9c27a5fdca81abcbd9",
                        "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
                        "isPro": false,
                        "fullname": "Hongsheng LI",
                        "user": "hsli-cuhk",
                        "type": "user"
                    },
                    "name": "Hongsheng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:08:33.312Z",
                    "hidden": false
                },
                {
                    "_id": "6793040ec67af4a116a25d0b",
                    "name": "Pheng-Ann Heng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T18:59:43.000Z",
            "title": "Can We Generate Images with CoT? Let's Verify and Reinforce Image\n  Generation Step by Step",
            "summary": "Chain-of-Thought (CoT) reasoning has been extensively explored in large\nmodels to tackle complex understanding tasks. However, it still remains an open\nquestion whether such strategies can be applied to verifying and reinforcing\nimage generation scenarios. In this paper, we provide the first comprehensive\ninvestigation of the potential of CoT reasoning to enhance autoregressive image\ngeneration. We focus on three techniques: scaling test-time computation for\nverification, aligning model preferences with Direct Preference Optimization\n(DPO), and integrating these techniques for complementary effects. Our results\ndemonstrate that these approaches can be effectively adapted and combined to\nsignificantly improve image generation performance. Furthermore, given the\npivotal role of reward models in our findings, we propose the Potential\nAssessment Reward Model (PARM) and PARM++, specialized for autoregressive image\ngeneration. PARM adaptively assesses each generation step through a potential\nassessment approach, merging the strengths of existing reward models, and\nPARM++ further introduces a reflection mechanism to self-correct the generated\nunsatisfactory image. Using our investigated reasoning strategies, we enhance a\nbaseline model, Show-o, to achieve superior results, with a significant +24%\nimprovement on the GenEval benchmark, surpassing Stable Diffusion 3 by +15%. We\nhope our study provides unique insights and paves a new path for integrating\nCoT reasoning with autoregressive image generation. Code and models are\nreleased at https://github.com/ZiyuGuo99/Image-Generation-CoT",
            "upvotes": 11,
            "discussionId": "67930410c67af4a116a25da4"
        },
        "publishedAt": "2025-01-23T22:08:17.598Z",
        "title": "Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13926.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63468720dd6d90d82ccf3450",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
            "fullname": "YSH",
            "name": "BestWishYsh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 28
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.13826",
            "authors": [
                {
                    "_id": "67934585e4e44e2866b644f2",
                    "user": {
                        "_id": "6400ba2b261cfa61f3a00555",
                        "avatarUrl": "/avatars/1311e0b5e21b1c94d73fcaf455d3c7f7.svg",
                        "isPro": false,
                        "fullname": "Kairui",
                        "user": "KairuiHu",
                        "type": "user"
                    },
                    "name": "Kairui Hu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T09:07:46.937Z",
                    "hidden": false
                },
                {
                    "_id": "67934585e4e44e2866b644f3",
                    "user": {
                        "_id": "64101f81b27543634e377fc1",
                        "avatarUrl": "/avatars/557dd9d4707e3b38e0805dfb87c08004.svg",
                        "isPro": false,
                        "fullname": "Penghao Wu",
                        "user": "craigwu",
                        "type": "user"
                    },
                    "name": "Penghao Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:21:29.750Z",
                    "hidden": false
                },
                {
                    "_id": "67934585e4e44e2866b644f4",
                    "user": {
                        "_id": "646e1ef5075bbcc48ddf21e8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/_vJC0zeVOIvaNV2R6toqg.jpeg",
                        "isPro": false,
                        "fullname": "Pu Fanyi",
                        "user": "pufanyi",
                        "type": "user"
                    },
                    "name": "Fanyi Pu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:21:39.917Z",
                    "hidden": false
                },
                {
                    "_id": "67934585e4e44e2866b644f5",
                    "user": {
                        "_id": "647efcc945baf21ad707e10c",
                        "avatarUrl": "/avatars/e2fab1c9031eb0eec9f015a8fc237f64.svg",
                        "isPro": false,
                        "fullname": "Wang Xiao",
                        "user": "wangxiao1208",
                        "type": "user"
                    },
                    "name": "Wang Xiao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:21:46.540Z",
                    "hidden": false
                },
                {
                    "_id": "67934585e4e44e2866b644f6",
                    "user": {
                        "_id": "62a993d80472c0b7f94027df",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62a993d80472c0b7f94027df/j5vp-IwLA2YBexylUHiQU.png",
                        "isPro": false,
                        "fullname": "Zhang Yuanhan",
                        "user": "ZhangYuanhan",
                        "type": "user"
                    },
                    "name": "Yuanhan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:26:42.528Z",
                    "hidden": false
                },
                {
                    "_id": "67934585e4e44e2866b644f7",
                    "user": {
                        "_id": "6230d750d93e84e233882dbc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6230d750d93e84e233882dbc/4MGEekLW3oWzqeFWDWvIK.jpeg",
                        "isPro": false,
                        "fullname": "Xiang Yue",
                        "user": "yuexiang96",
                        "type": "user"
                    },
                    "name": "Xiang Yue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:27:14.894Z",
                    "hidden": false
                },
                {
                    "_id": "67934585e4e44e2866b644f8",
                    "name": "Bo Li",
                    "hidden": false
                },
                {
                    "_id": "67934585e4e44e2866b644f9",
                    "user": {
                        "_id": "62ab1ac1d48b4d8b048a3473",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1656826685333-62ab1ac1d48b4d8b048a3473.png",
                        "isPro": false,
                        "fullname": "Ziwei Liu",
                        "user": "liuziwei7",
                        "type": "user"
                    },
                    "name": "Ziwei Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:27:30.310Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T16:51:47.000Z",
            "title": "Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline\n  Professional Videos",
            "summary": "Humans acquire knowledge through three cognitive stages: perceiving\ninformation, comprehending knowledge, and adapting knowledge to solve novel\nproblems. Videos serve as an effective medium for this learning process,\nfacilitating a progression through these cognitive stages. However, existing\nvideo benchmarks fail to systematically evaluate the knowledge acquisition\ncapabilities in Large Multimodal Models (LMMs). To address this gap, we\nintroduce Video-MMMU, a multi-modal, multi-disciplinary benchmark designed to\nassess LMMs' ability to acquire and utilize knowledge from videos. Video-MMMU\nfeatures a curated collection of 300 expert-level videos and 900\nhuman-annotated questions across six disciplines, evaluating knowledge\nacquisition through stage-aligned question-answer pairs: Perception,\nComprehension, and Adaptation. A proposed knowledge gain metric,\n{\\Delta}knowledge, quantifies improvement in performance after video viewing.\nEvaluation of LMMs reveals a steep decline in performance as cognitive demands\nincrease and highlights a significant gap between human and model knowledge\nacquisition, underscoring the need for methods to enhance LMMs' capability to\nlearn and adapt from videos.",
            "upvotes": 8,
            "discussionId": "67934587e4e44e2866b64597"
        },
        "publishedAt": "2025-01-24T04:24:01.412Z",
        "title": "Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13826.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6400ba2b261cfa61f3a00555",
            "avatarUrl": "/avatars/1311e0b5e21b1c94d73fcaf455d3c7f7.svg",
            "fullname": "Kairui",
            "name": "KairuiHu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 5
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.13920",
            "authors": [
                {
                    "_id": "679316ff3698fd97252a8e6f",
                    "user": {
                        "_id": "64c3c72e8f31d1e6c664b052",
                        "avatarUrl": "/avatars/af1ad5048eaa9dc417837ad02f927911.svg",
                        "isPro": false,
                        "fullname": "jiayi lei",
                        "user": "jyjyjyjy",
                        "type": "user"
                    },
                    "name": "Jiayi Lei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:12:22.641Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e70",
                    "name": "Renrui Zhang",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e71",
                    "name": "Xiangfei Hu",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e72",
                    "user": {
                        "_id": "66026c9068d519ed32519e9c",
                        "avatarUrl": "/avatars/8fa051312c713772e5b8ba65989ff7f5.svg",
                        "isPro": false,
                        "fullname": "Weifeng Lin",
                        "user": "Afeng-x",
                        "type": "user"
                    },
                    "name": "Weifeng Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:13:07.303Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e73",
                    "user": {
                        "_id": "6285a9133ab6642179158944",
                        "avatarUrl": "/avatars/6e10fa07c94141fcdbe0cab02bb731ca.svg",
                        "isPro": false,
                        "fullname": "Zhen Li",
                        "user": "Paper99",
                        "type": "user"
                    },
                    "name": "Zhen Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T20:51:38.124Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e74",
                    "name": "Wenjian Sun",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e75",
                    "user": {
                        "_id": "64a54586c0f13de8e7093314",
                        "avatarUrl": "/avatars/389e43e9a32cf2fc95f8f3a23b8f0508.svg",
                        "isPro": false,
                        "fullname": "Ruoyi Du",
                        "user": "RuoyiDu",
                        "type": "user"
                    },
                    "name": "Ruoyi Du",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:13:21.861Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e76",
                    "user": {
                        "_id": "6358a167f56b03ec9147074d",
                        "avatarUrl": "/avatars/e54ea7bf0c240cf76d538296efb3976c.svg",
                        "isPro": false,
                        "fullname": "Le Zhuo",
                        "user": "JackyZhuo",
                        "type": "user"
                    },
                    "name": "Le Zhuo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:13:27.523Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e77",
                    "user": {
                        "_id": "6740a5730bb4a675446a80ad",
                        "avatarUrl": "/avatars/27c08e33df88e4f73c136da65f2b5adb.svg",
                        "isPro": false,
                        "fullname": "Zhong-Yu Li",
                        "user": "lzyhha",
                        "type": "user"
                    },
                    "name": "Zhongyu Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:13:33.108Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e78",
                    "name": "Xinyue Li",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e79",
                    "user": {
                        "_id": "62c66504031996c36c86976a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62c66504031996c36c86976a/wIq0YJhkWnEhlzsh-TGYO.png",
                        "isPro": true,
                        "fullname": "steve z",
                        "user": "stzhao",
                        "type": "user"
                    },
                    "name": "Shitian Zhao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T13:30:14.688Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e7a",
                    "user": {
                        "_id": "647d9ab61a1fcad2fdbf2d3d",
                        "avatarUrl": "/avatars/48c8aeae8979d2c87df8bde922437d62.svg",
                        "isPro": true,
                        "fullname": "Ziyu Guo",
                        "user": "ZiyuG",
                        "type": "user"
                    },
                    "name": "Ziyu Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:14:21.821Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e7b",
                    "user": {
                        "_id": "6614fb3d5aed02b298a4b469",
                        "avatarUrl": "/avatars/d0ddb4f989ad1a3f24128cc843347bde.svg",
                        "isPro": false,
                        "fullname": "yiting lu",
                        "user": "yeeeeeyy",
                        "type": "user"
                    },
                    "name": "Yiting Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:14:50.714Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e7c",
                    "user": {
                        "_id": "6759af3eccbc8817f9169179",
                        "avatarUrl": "/avatars/49e64c7ccf71b8f25c52783b6ae93620.svg",
                        "isPro": false,
                        "fullname": "Peng Gao",
                        "user": "gaopenghigh",
                        "type": "user"
                    },
                    "name": "Peng Gao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:15:04.489Z",
                    "hidden": false
                },
                {
                    "_id": "679316ff3698fd97252a8e7d",
                    "user": {
                        "_id": "65c04e9c27a5fdca81abcbd9",
                        "avatarUrl": "/avatars/12a155683c824fa23da4a9e2bed4f64e.svg",
                        "isPro": false,
                        "fullname": "Hongsheng LI",
                        "user": "hsli-cuhk",
                        "type": "user"
                    },
                    "name": "Hongsheng Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:15:11.437Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T18:58:33.000Z",
            "title": "IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art\n  Text-to-Image Models",
            "summary": "With the rapid development of diffusion models, text-to-image(T2I) models\nhave made significant progress, showcasing impressive abilities in prompt\nfollowing and image generation. Recently launched models such as FLUX.1 and\nIdeogram2.0, along with others like Dall-E3 and Stable Diffusion 3, have\ndemonstrated exceptional performance across various complex tasks, raising\nquestions about whether T2I models are moving towards general-purpose\napplicability. Beyond traditional image generation, these models exhibit\ncapabilities across a range of fields, including controllable generation, image\nediting, video, audio, 3D, and motion generation, as well as computer vision\ntasks like semantic segmentation and depth estimation. However, current\nevaluation frameworks are insufficient to comprehensively assess these models'\nperformance across expanding domains. To thoroughly evaluate these models, we\ndeveloped the IMAGINE-E and tested six prominent models: FLUX.1, Ideogram2.0,\nMidjourney, Dall-E3, Stable Diffusion 3, and Jimeng. Our evaluation is divided\ninto five key domains: structured output generation, realism, and physical\nconsistency, specific domain generation, challenging scenario generation, and\nmulti-style creation tasks. This comprehensive assessment highlights each\nmodel's strengths and limitations, particularly the outstanding performance of\nFLUX.1 and Ideogram2.0 in structured and specific domain tasks, underscoring\nthe expanding applications and potential of T2I models as foundational AI\ntools. This study provides valuable insights into the current state and future\ntrajectory of T2I models as they evolve towards general-purpose usability.\nEvaluation scripts will be released at https://github.com/jylei16/Imagine-e.",
            "upvotes": 8,
            "discussionId": "679317043698fd97252a8f6f"
        },
        "publishedAt": "2025-01-23T23:31:27.973Z",
        "title": "IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13920.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "645dbaa6f5760d1530d7580d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/645dbaa6f5760d1530d7580d/Bqob8arLZoHIgMwNZpL9I.jpeg",
            "fullname": "Simeon Emanuilov",
            "name": "s-emanuilov",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 16
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.10018",
            "authors": [
                {
                    "_id": "678e125d09dc6d3a311cc04e",
                    "user": {
                        "_id": "6497b4464a3c31df8e4148d8",
                        "avatarUrl": "/avatars/4397a380468e84bc7945fddd9a6d1066.svg",
                        "isPro": false,
                        "fullname": "Xiaowen Li",
                        "user": "asLKHFksasak",
                        "type": "user"
                    },
                    "name": "Xiaowen Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:31:02.655Z",
                    "hidden": false
                },
                {
                    "_id": "678e125d09dc6d3a311cc04f",
                    "name": "Haolan Xue",
                    "hidden": false
                },
                {
                    "_id": "678e125d09dc6d3a311cc050",
                    "user": {
                        "_id": "64b74a45f902508f0d786505",
                        "avatarUrl": "/avatars/8bc5aaa011642827e12524c4f0a56927.svg",
                        "isPro": false,
                        "fullname": "Peiran REN",
                        "user": "lyraestar",
                        "type": "user"
                    },
                    "name": "Peiran Ren",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:30:47.443Z",
                    "hidden": false
                },
                {
                    "_id": "678e125d09dc6d3a311cc051",
                    "user": {
                        "_id": "63d0cc736b985b0f25d0412c",
                        "avatarUrl": "/avatars/3eb8c79f9a7c4c819038ea7b04e323dd.svg",
                        "isPro": false,
                        "fullname": "Bo",
                        "user": "Liefeng",
                        "type": "user"
                    },
                    "name": "Liefeng Bo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:30:55.550Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-17T08:03:02.000Z",
            "title": "DiffuEraser: A Diffusion Model for Video Inpainting",
            "summary": "Recent video inpainting algorithms integrate flow-based pixel propagation\nwith transformer-based generation to leverage optical flow for restoring\ntextures and objects using information from neighboring frames, while\ncompleting masked regions through visual Transformers. However, these\napproaches often encounter blurring and temporal inconsistencies when dealing\nwith large masks, highlighting the need for models with enhanced generative\ncapabilities. Recently, diffusion models have emerged as a prominent technique\nin image and video generation due to their impressive performance. In this\npaper, we introduce DiffuEraser, a video inpainting model based on stable\ndiffusion, designed to fill masked regions with greater details and more\ncoherent structures. We incorporate prior information to provide initialization\nand weak conditioning,which helps mitigate noisy artifacts and suppress\nhallucinations. Additionally, to improve temporal consistency during\nlong-sequence inference, we expand the temporal receptive fields of both the\nprior model and DiffuEraser, and further enhance consistency by leveraging the\ntemporal smoothing property of Video Diffusion Models. Experimental results\ndemonstrate that our proposed method outperforms state-of-the-art techniques in\nboth content completeness and temporal consistency while maintaining acceptable\nefficiency.",
            "upvotes": 7,
            "discussionId": "678e125f09dc6d3a311cc0af"
        },
        "publishedAt": "2025-01-24T03:08:08.583Z",
        "title": "DiffuEraser: A Diffusion Model for Video Inpainting",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10018.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "5f1158120c833276f61f1a84",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
            "fullname": "Niels Rogge",
            "name": "nielsr",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 736
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.10799",
            "authors": [
                {
                    "_id": "679208664e521de952ca0cdc",
                    "user": {
                        "_id": "5df9c78eda6d0311fd3d541f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5df9c78eda6d0311fd3d541f/8oDFuP77l5zhvamXNVmnc.jpeg",
                        "isPro": false,
                        "fullname": "Yen-Ting Lin",
                        "user": "yentinglin",
                        "type": "user"
                    },
                    "name": "Yen-Ting Lin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-23T09:17:30.742Z",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0cdd",
                    "user": {
                        "_id": "62f690dfc58915315c504af5",
                        "avatarUrl": "/avatars/a6732dda8cd7e37d9c0e0b1dfb68c66b.svg",
                        "isPro": false,
                        "fullname": "Di Jin",
                        "user": "jindi",
                        "type": "user"
                    },
                    "name": "Di Jin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:15:36.716Z",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0cde",
                    "name": "Tengyu Xu",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0cdf",
                    "name": "Tianhao Wu",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce0",
                    "user": {
                        "_id": "66a8611eb51510d82ed54231",
                        "avatarUrl": "/avatars/ad559e774fee4914091b82c9831ae2a2.svg",
                        "isPro": false,
                        "fullname": "Sainbayar Sukhbaatar",
                        "user": "sainbar",
                        "type": "user"
                    },
                    "name": "Sainbayar Sukhbaatar",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:16:23.763Z",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce1",
                    "name": "Chen Zhu",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce2",
                    "user": {
                        "_id": "6437de5d51c7ebfc813ce68a",
                        "avatarUrl": "/avatars/144cb1c5d5a4a645080611953494f437.svg",
                        "isPro": false,
                        "fullname": "he",
                        "user": "yunhe",
                        "type": "user"
                    },
                    "name": "Yun He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:16:34.273Z",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce3",
                    "name": "Yun-Nung Chen",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce4",
                    "user": {
                        "_id": "62f023a36a027498eaa2f9cc",
                        "avatarUrl": "/avatars/8ac1c5c74d0957e3c6cc94b3a7795c37.svg",
                        "isPro": false,
                        "fullname": "Jason Weston",
                        "user": "spermwhale",
                        "type": "user"
                    },
                    "name": "Jason Weston",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:15:25.564Z",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce5",
                    "user": {
                        "_id": "6344cf73ee1504dbcd5bdfe7",
                        "avatarUrl": "/avatars/6dd2bf1f9c5679e5c8c85d62c9836aac.svg",
                        "isPro": false,
                        "fullname": "Yuandong Tian",
                        "user": "tydsh",
                        "type": "user"
                    },
                    "name": "Yuandong Tian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:16:47.602Z",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce6",
                    "name": "Arash Rahnama",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce7",
                    "user": {
                        "_id": "65b483c5ed110eb9f1ee62df",
                        "avatarUrl": "/avatars/29100098f5aed1735675d06c516a85b7.svg",
                        "isPro": false,
                        "fullname": "Sinong Wang",
                        "user": "TheronWong",
                        "type": "user"
                    },
                    "name": "Sinong Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:17:03.211Z",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce8",
                    "name": "Hao Ma",
                    "hidden": false
                },
                {
                    "_id": "679208664e521de952ca0ce9",
                    "name": "Han Fang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-18T15:38:03.000Z",
            "title": "Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary\n  Feedback",
            "summary": "Large language models (LLMs) have recently demonstrated remarkable success in\nmathematical reasoning. Despite progress in methods like chain-of-thought\nprompting and self-consistency sampling, these advances often focus on final\ncorrectness without ensuring that the underlying reasoning process is coherent\nand reliable. This paper introduces Step-KTO, a training framework that\ncombines process-level and outcome-level binary feedback to guide LLMs toward\nmore trustworthy reasoning trajectories. By providing binary evaluations for\nboth the intermediate reasoning steps and the final answer, Step-KTO encourages\nthe model to adhere to logical progressions rather than relying on superficial\nshortcuts. Our experiments on challenging mathematical benchmarks show that\nStep-KTO significantly improves both final answer accuracy and the quality of\nintermediate reasoning steps. For example, on the MATH-500 dataset, Step-KTO\nachieves a notable improvement in Pass@1 accuracy over strong baselines. These\nresults highlight the promise of integrating stepwise process feedback into LLM\ntraining, paving the way toward more interpretable and dependable reasoning\ncapabilities.",
            "upvotes": 7,
            "discussionId": "679208674e521de952ca0d2f"
        },
        "publishedAt": "2025-01-23T22:32:09.207Z",
        "title": "Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/5df9c78eda6d0311fd3d541f/VXjkUKeidLg_JO5d3RWUG.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10799.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "5df9c78eda6d0311fd3d541f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5df9c78eda6d0311fd3d541f/8oDFuP77l5zhvamXNVmnc.jpeg",
            "fullname": "Yen-Ting Lin",
            "name": "yentinglin",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 282
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.13554",
            "authors": [
                {
                    "_id": "6793900eddc6cc37fdc74928",
                    "user": {
                        "_id": "65a909fe8581aad8c97a67d3",
                        "avatarUrl": "/avatars/96570e47117e957543d9f0fe5e1d9d57.svg",
                        "isPro": false,
                        "fullname": "liutao",
                        "user": "byliutao",
                        "type": "user"
                    },
                    "name": "Tao Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T13:30:20.097Z",
                    "hidden": false
                },
                {
                    "_id": "6793900eddc6cc37fdc74929",
                    "name": "Kai Wang",
                    "hidden": false
                },
                {
                    "_id": "6793900eddc6cc37fdc7492a",
                    "name": "Senmao Li",
                    "hidden": false
                },
                {
                    "_id": "6793900eddc6cc37fdc7492b",
                    "name": "Joost van de Weijer",
                    "hidden": false
                },
                {
                    "_id": "6793900eddc6cc37fdc7492c",
                    "name": "Fahad Shahbaz Khan",
                    "hidden": false
                },
                {
                    "_id": "6793900eddc6cc37fdc7492d",
                    "name": "Shiqi Yang",
                    "hidden": false
                },
                {
                    "_id": "6793900eddc6cc37fdc7492e",
                    "name": "Yaxing Wang",
                    "hidden": false
                },
                {
                    "_id": "6793900eddc6cc37fdc7492f",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "6793900eddc6cc37fdc74930",
                    "name": "Ming-Ming Cheng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T10:57:22.000Z",
            "title": "One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation\n  Using a Single Prompt",
            "summary": "Text-to-image generation models can create high-quality images from input\nprompts. However, they struggle to support the consistent generation of\nidentity-preserving requirements for storytelling. Existing approaches to this\nproblem typically require extensive training in large datasets or additional\nmodifications to the original model architectures. This limits their\napplicability across different domains and diverse diffusion model\nconfigurations. In this paper, we first observe the inherent capability of\nlanguage models, coined context consistency, to comprehend identity through\ncontext with a single prompt. Drawing inspiration from the inherent context\nconsistency, we propose a novel training-free method for consistent\ntext-to-image (T2I) generation, termed \"One-Prompt-One-Story\" (1Prompt1Story).\nOur approach 1Prompt1Story concatenates all prompts into a single input for T2I\ndiffusion models, initially preserving character identities. We then refine the\ngeneration process using two novel techniques: Singular-Value Reweighting and\nIdentity-Preserving Cross-Attention, ensuring better alignment with the input\ndescription for each frame. In our experiments, we compare our method against\nvarious existing consistent T2I generation approaches to demonstrate its\neffectiveness through quantitative metrics and qualitative assessments. Code is\navailable at https://github.com/byliutao/1Prompt1Story.",
            "upvotes": 5,
            "discussionId": "67939013ddc6cc37fdc74a9d"
        },
        "publishedAt": "2025-01-24T08:34:50.383Z",
        "title": "One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13554.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "65a909fe8581aad8c97a67d3",
            "avatarUrl": "/avatars/96570e47117e957543d9f0fe5e1d9d57.svg",
            "fullname": "liutao",
            "name": "byliutao",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.13824",
            "authors": [
                {
                    "_id": "6793a52265c4dd63499ca548",
                    "user": {
                        "_id": "662ce44c8b8705f30371fba8",
                        "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
                        "isPro": false,
                        "fullname": "Shuzhou Yuan",
                        "user": "shuzyuan",
                        "type": "user"
                    },
                    "name": "Shuzhou Yuan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T14:52:27.570Z",
                    "hidden": false
                },
                {
                    "_id": "6793a52265c4dd63499ca549",
                    "name": "Michael Färber",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T16:45:51.000Z",
            "title": "Hallucinations Can Improve Large Language Models in Drug Discovery",
            "summary": "Concerns about hallucinations in Large Language Models (LLMs) have been\nraised by researchers, yet their potential in areas where creativity is vital,\nsuch as drug discovery, merits exploration. In this paper, we come up with the\nhypothesis that hallucinations can improve LLMs in drug discovery. To verify\nthis hypothesis, we use LLMs to describe the SMILES string of molecules in\nnatural language and then incorporate these descriptions as part of the prompt\nto address specific tasks in drug discovery. Evaluated on seven LLMs and five\nclassification tasks, our findings confirm the hypothesis: LLMs can achieve\nbetter performance with text containing hallucinations. Notably, Llama-3.1-8B\nachieves an 18.35% gain in ROC-AUC compared to the baseline without\nhallucination. Furthermore, hallucinations generated by GPT-4o provide the most\nconsistent improvements across models. Additionally, we conduct empirical\nanalyses and a case study to investigate key factors affecting performance and\nthe underlying reasons. Our research sheds light on the potential use of\nhallucinations for LLMs and offers new perspectives for future research\nleveraging LLMs in drug discovery.",
            "upvotes": 4,
            "discussionId": "6793a52465c4dd63499ca5ad"
        },
        "publishedAt": "2025-01-24T09:39:01.834Z",
        "title": "Hallucinations Can Improve Large Language Models in Drug Discovery",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13824.png",
        "numComments": 4,
        "submittedBy": {
            "_id": "662ce44c8b8705f30371fba8",
            "avatarUrl": "/avatars/b96a25a8c124e7caa9de06b7188bdc15.svg",
            "fullname": "Shuzhou Yuan",
            "name": "shuzyuan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.13452",
            "authors": [
                {
                    "_id": "6793480ec6fd669f7341cf41",
                    "name": "Jiangchuan Wei",
                    "hidden": false
                },
                {
                    "_id": "6793480ec6fd669f7341cf42",
                    "name": "Shiyue Yan",
                    "hidden": false
                },
                {
                    "_id": "6793480ec6fd669f7341cf43",
                    "user": {
                        "_id": "6676c4f86f2ac48ee6c2f4d4",
                        "avatarUrl": "/avatars/fea4e5be4da7a7047df567a4aa86de0c.svg",
                        "isPro": false,
                        "fullname": "linwenfeng",
                        "user": "linwf",
                        "type": "user"
                    },
                    "name": "Wenfeng Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:18:06.509Z",
                    "hidden": false
                },
                {
                    "_id": "6793480ec6fd669f7341cf44",
                    "name": "Boyuan Liu",
                    "hidden": false
                },
                {
                    "_id": "6793480ec6fd669f7341cf45",
                    "name": "Renjie Chen",
                    "hidden": false
                },
                {
                    "_id": "6793480ec6fd669f7341cf46",
                    "name": "Mingyu Guo",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-23T08:06:11.000Z",
            "title": "EchoVideo: Identity-Preserving Human Video Generation by Multimodal\n  Feature Fusion",
            "summary": "Recent advancements in video generation have significantly impacted various\ndownstream applications, particularly in identity-preserving video generation\n(IPT2V). However, existing methods struggle with \"copy-paste\" artifacts and low\nsimilarity issues, primarily due to their reliance on low-level facial image\ninformation. This dependence can result in rigid facial appearances and\nartifacts reflecting irrelevant details. To address these challenges, we\npropose EchoVideo, which employs two key strategies: (1) an Identity Image-Text\nFusion Module (IITF) that integrates high-level semantic features from text,\ncapturing clean facial identity representations while discarding occlusions,\nposes, and lighting variations to avoid the introduction of artifacts; (2) a\ntwo-stage training strategy, incorporating a stochastic method in the second\nphase to randomly utilize shallow facial information. The objective is to\nbalance the enhancements in fidelity provided by shallow features while\nmitigating excessive reliance on them. This strategy encourages the model to\nutilize high-level features during training, ultimately fostering a more robust\nrepresentation of facial identities. EchoVideo effectively preserves facial\nidentities and maintains full-body integrity. Extensive experiments demonstrate\nthat it achieves excellent results in generating high-quality, controllability\nand fidelity videos.",
            "upvotes": 4,
            "discussionId": "67934811c6fd669f7341cfbf"
        },
        "publishedAt": "2025-01-24T02:59:28.457Z",
        "title": "EchoVideo: Identity-Preserving Human Video Generation by Multimodal Feature Fusion",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13452.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63468720dd6d90d82ccf3450",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63468720dd6d90d82ccf3450/tVBFlmZNz8FRMkOrDaDID.jpeg",
            "fullname": "YSH",
            "name": "BestWishYsh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 28
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.13075",
            "authors": [
                {
                    "_id": "6791ae54330198cc26b72479",
                    "user": {
                        "_id": "6444241e9c1bd83bd19ea70f",
                        "avatarUrl": "/avatars/24b4e65f26f5f8dcc1465cef67fd334b.svg",
                        "isPro": false,
                        "fullname": "Joel Lehman",
                        "user": "jal278",
                        "type": "user"
                    },
                    "name": "Joel Lehman",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-01-23T02:49:57.110Z",
                    "hidden": false
                },
                {
                    "_id": "6791ae54330198cc26b7247a",
                    "user": {
                        "_id": "6514b7fde1273c28705142cc",
                        "avatarUrl": "/avatars/072bf14abd8ef17d9393338a20157cc2.svg",
                        "isPro": false,
                        "fullname": "Elliot Meyerson",
                        "user": "ekmeyerson",
                        "type": "user"
                    },
                    "name": "Elliot Meyerson",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:20:51.128Z",
                    "hidden": false
                },
                {
                    "_id": "6791ae54330198cc26b7247b",
                    "name": "Tarek El-Gaaly",
                    "hidden": false
                },
                {
                    "_id": "6791ae54330198cc26b7247c",
                    "name": "Kenneth O. Stanley",
                    "hidden": false
                },
                {
                    "_id": "6791ae54330198cc26b7247d",
                    "name": "Tarin Ziyaee",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-22T18:38:41.000Z",
            "title": "Evolution and The Knightian Blindspot of Machine Learning",
            "summary": "This paper claims that machine learning (ML) largely overlooks an important\nfacet of general intelligence: robustness to a qualitatively unknown future in\nan open world. Such robustness relates to Knightian uncertainty (KU) in\neconomics, i.e. uncertainty that cannot be quantified, which is excluded from\nconsideration in ML's key formalisms. This paper aims to identify this blind\nspot, argue its importance, and catalyze research into addressing it, which we\nbelieve is necessary to create truly robust open-world AI. To help illuminate\nthe blind spot, we contrast one area of ML, reinforcement learning (RL), with\nthe process of biological evolution. Despite staggering ongoing progress, RL\nstill struggles in open-world situations, often failing under unforeseen\nsituations. For example, the idea of zero-shot transferring a self-driving car\npolicy trained only in the US to the UK currently seems exceedingly ambitious.\nIn dramatic contrast, biological evolution routinely produces agents that\nthrive within an open world, sometimes even to situations that are remarkably\nout-of-distribution (e.g. invasive species; or humans, who do undertake such\nzero-shot international driving). Interestingly, evolution achieves such\nrobustness without explicit theory, formalisms, or mathematical gradients. We\nexplore the assumptions underlying RL's typical formalisms, showing how they\nlimit RL's engagement with the unknown unknowns characteristic of an\never-changing complex world. Further, we identify mechanisms through which\nevolutionary processes foster robustness to novel and unpredictable challenges,\nand discuss potential pathways to algorithmically embody them. The conclusion\nis that the intriguing remaining fragility of ML may result from blind spots in\nits formalisms, and that significant gains may result from direct confrontation\nwith the challenge of KU.",
            "upvotes": 3,
            "discussionId": "6791ae55330198cc26b724bc"
        },
        "publishedAt": "2025-01-24T01:17:22.150Z",
        "title": "Evolution and The Knightian Blindspot of Machine Learning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13075.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6444241e9c1bd83bd19ea70f",
            "avatarUrl": "/avatars/24b4e65f26f5f8dcc1465cef67fd334b.svg",
            "fullname": "Joel Lehman",
            "name": "jal278",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.13124",
            "authors": [
                {
                    "_id": "6793188b56f015277a9ed95c",
                    "user": {
                        "_id": "65a6131fee7aa779f5bf8329",
                        "avatarUrl": "/avatars/aa25cc3153fd7e511b51b801e8107564.svg",
                        "isPro": false,
                        "fullname": "langhao",
                        "user": "langnick",
                        "type": "user"
                    },
                    "name": "Hao Lang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:09:24.142Z",
                    "hidden": false
                },
                {
                    "_id": "6793188b56f015277a9ed95d",
                    "user": {
                        "_id": "635b8b6a37c6a2c12e2cce00",
                        "avatarUrl": "/avatars/229fb72180529141515d1df797b33709.svg",
                        "isPro": false,
                        "fullname": "Fei Huang",
                        "user": "hzhwcmhf",
                        "type": "user"
                    },
                    "name": "Fei Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:09:39.353Z",
                    "hidden": false
                },
                {
                    "_id": "6793188b56f015277a9ed95e",
                    "user": {
                        "_id": "66641b2fd8e1e34bc621e688",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66641b2fd8e1e34bc621e688/csPETwnx2zCIHSWi9uAi-.png",
                        "isPro": false,
                        "fullname": "Yongbin Li",
                        "user": "Yongbin-Li",
                        "type": "user"
                    },
                    "name": "Yongbin Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:08:59.394Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-21T05:36:13.000Z",
            "title": "Debate Helps Weak-to-Strong Generalization",
            "summary": "Common methods for aligning already-capable models with desired behavior rely\non the ability of humans to provide supervision. However, future superhuman\nmodels will surpass the capability of humans. Therefore, humans will only be\nable to weakly supervise superhuman models. This expected deficiency of human\nevaluation would weaken the safety of future AI systems. Scalable oversight and\nweak-to-strong generalization are two complementary approaches to tackle this\nissue. In this paper, we attempt to combine the strengths of these two\napproaches to further improve alignment. Specifically, we investigate ways of\nimproving human supervision with a strong pretrained model and then supervise\nthe strong model with enhanced weak human supervision. To make iterative\nempirical progress, we consider an analogy: can we use a strong model to\nimprove weak model supervision and then use it to supervise the strong model?\nWe empirically test it by finetuning a small weak model on ground truth labels\nwith the additional help from a large strong model, and then finetuning the\nstrong model on labels generated by the weak model. We find that debate can\nassist a weak model in extracting trustworthy information from an untrustworthy\nstrong model, which provides leverage as context on samples when training a\nweak model. We also show that an ensemble of weak models helps exploit long\narguments generated by strong model debaters and obtain a more robust\nsupervision estimate. Extensive experiments on the OpenAI weak-to-strong NLP\nbenchmarks show that the combination approach leads to better alignment, which\nindicates that debate has the potential to help weak-to-strong generalization.",
            "upvotes": 3,
            "discussionId": "6793188d56f015277a9ed9aa"
        },
        "publishedAt": "2025-01-23T23:35:50.957Z",
        "title": "Debate Helps Weak-to-Strong Generalization",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.13124.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "62e0ef42edb0462c8d51818d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62e0ef42edb0462c8d51818d/3YM7DUynIWiiRFM6_enpg.jpeg",
            "fullname": "Ting-En Lin",
            "name": "tnlin",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 9
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.10979",
            "authors": [
                {
                    "_id": "6792cf69627180db59a51b7c",
                    "user": {
                        "_id": "6199b1d090692f0d92388473",
                        "avatarUrl": "/avatars/72693e4d37ded1542cd2564879fd9a61.svg",
                        "isPro": false,
                        "fullname": "Haichao Wei",
                        "user": "hawei",
                        "type": "user"
                    },
                    "name": "Haichao Wei",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T09:08:11.344Z",
                    "hidden": false
                },
                {
                    "_id": "6792cf69627180db59a51b7d",
                    "name": "Yunxiang Ren",
                    "hidden": false
                },
                {
                    "_id": "6792cf69627180db59a51b7e",
                    "name": "Zhoutong Fu",
                    "hidden": false
                },
                {
                    "_id": "6792cf69627180db59a51b7f",
                    "name": "Aman Lunia",
                    "hidden": false
                },
                {
                    "_id": "6792cf69627180db59a51b80",
                    "name": "Yi-Lin Chen",
                    "hidden": false
                },
                {
                    "_id": "6792cf69627180db59a51b81",
                    "name": "Alice Leung",
                    "hidden": false
                },
                {
                    "_id": "6792cf69627180db59a51b82",
                    "name": "Ya Xu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-19T08:06:06.000Z",
            "title": "Control LLM: Controlled Evolution for Intelligence Retention in LLM",
            "summary": "Large Language Models (LLMs) demand significant computational resources,\nmaking it essential to enhance their capabilities without retraining from\nscratch. A key challenge in this domain is catastrophic forgetting\n(CF), which hampers performance during Continuous Pre-training (CPT) and\nContinuous Supervised Fine-Tuning (CSFT). We propose Control LLM, a\nnovel approach that leverages parallel pre-trained and expanded transformer\nblocks, aligning their hidden-states through interpolation strategies This\nmethod effectively preserves performance on existing tasks while seamlessly\nintegrating new knowledge.\n  Extensive experiments demonstrate the effectiveness of Control LLM in both\nCPT and CSFT. On Llama3.1-8B-Instruct, it achieves significant improvements in\nmathematical reasoning (+14.4% on Math-Hard) and coding performance (+10%\non MBPP-PLUS). On Llama3.1-8B, it enhances multilingual capabilities (+10.6%\non C-Eval, +6.8% on CMMLU, and +30.2% on CMMLU-0shot-CoT). It surpasses\nexisting methods and achieves SOTA among open-source models tuned from the same\nbase model, using substantially less data and compute. Crucially, these gains\nare realized while preserving strong original capabilities, with minimal\ndegradation (<4.3% on MMLU) compared to >35% in open-source Math\nand Coding models. This approach has been successfully deployed in LinkedIn's\nGenAI-powered job seeker and Ads unit products.\n  To support further research, we release the training and evaluation code\n(https://github.com/linkedin/ControlLLM) along with models trained on\npublic datasets ( https://huggingface.co/ControlLLM) to the community.",
            "upvotes": 2,
            "discussionId": "6792cf6c627180db59a51c28"
        },
        "publishedAt": "2025-01-24T14:50:16.765Z",
        "title": "Control LLM: Controlled Evolution for Intelligence Retention in LLM",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10979.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6199b1d090692f0d92388473",
            "avatarUrl": "/avatars/72693e4d37ded1542cd2564879fd9a61.svg",
            "fullname": "Haichao Wei",
            "name": "hawei",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.10283",
            "authors": [
                {
                    "_id": "67934e1511eb9c774dd1bfc3",
                    "user": {
                        "_id": "67936c63ddd1e487c0c6c691",
                        "avatarUrl": "/avatars/6d57469b4afdc8bedffeea9ed5f59dd4.svg",
                        "isPro": false,
                        "fullname": "Chengwei Zheng",
                        "user": "zhengcw18",
                        "type": "user"
                    },
                    "name": "Chengwei Zheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-01-24T13:30:16.388Z",
                    "hidden": false
                },
                {
                    "_id": "67934e1511eb9c774dd1bfc4",
                    "user": {
                        "_id": "645b95f8438d6cfbe1ae8256",
                        "avatarUrl": "/avatars/ac0ebb0a73569ab063c5b2f28c509d23.svg",
                        "isPro": false,
                        "fullname": "Lixin Xue",
                        "user": "lxxue",
                        "type": "user"
                    },
                    "name": "Lixin Xue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-01-24T10:27:50.665Z",
                    "hidden": false
                },
                {
                    "_id": "67934e1511eb9c774dd1bfc5",
                    "name": "Juan Zarate",
                    "hidden": false
                },
                {
                    "_id": "67934e1511eb9c774dd1bfc6",
                    "name": "Jie Song",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-17T16:26:24.000Z",
            "title": "GSTAR: Gaussian Surface Tracking and Reconstruction",
            "summary": "3D Gaussian Splatting techniques have enabled efficient photo-realistic\nrendering of static scenes. Recent works have extended these approaches to\nsupport surface reconstruction and tracking. However, tracking dynamic surfaces\nwith 3D Gaussians remains challenging due to complex topology changes, such as\nsurfaces appearing, disappearing, or splitting. To address these challenges, we\npropose GSTAR, a novel method that achieves photo-realistic rendering, accurate\nsurface reconstruction, and reliable 3D tracking for general dynamic scenes\nwith changing topology. Given multi-view captures as input, GSTAR binds\nGaussians to mesh faces to represent dynamic objects. For surfaces with\nconsistent topology, GSTAR maintains the mesh topology and tracks the meshes\nusing Gaussians. In regions where topology changes, GSTAR adaptively unbinds\nGaussians from the mesh, enabling accurate registration and the generation of\nnew surfaces based on these optimized Gaussians. Additionally, we introduce a\nsurface-based scene flow method that provides robust initialization for\ntracking between frames. Experiments demonstrate that our method effectively\ntracks and reconstructs dynamic surfaces, enabling a range of applications. Our\nproject page with the code release is available at\nhttps://eth-ait.github.io/GSTAR/.",
            "upvotes": 1,
            "discussionId": "67934e1611eb9c774dd1bffe"
        },
        "publishedAt": "2025-01-24T03:24:06.601Z",
        "title": "GSTAR: Gaussian Surface Tracking and Reconstruction",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.10283.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "5f1158120c833276f61f1a84",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
            "fullname": "Niels Rogge",
            "name": "nielsr",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 736
        },
        "isAuthorParticipating": false
    }
]