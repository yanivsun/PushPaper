[
    {
        "paper": {
            "id": "2501.19393",
            "authors": [
                {
                    "_id": "67a02dd80e751b0476a1bcc6",
                    "user": {
                        "_id": "5f1eb362eec0ad2a071ad6e2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/5f1eb362eec0ad2a071ad6e2/IXMYkYKuTwn6kBdWnQeeY.png",
                        "isPro": false,
                        "fullname": "Niklas Muennighoff",
                        "user": "Muennighoff",
                        "type": "user"
                    },
                    "name": "Niklas Muennighoff",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:07:41.451Z",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bcc7",
                    "user": {
                        "_id": "65a5b721f6cfc4b24a75732b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a5b721f6cfc4b24a75732b/Hr2AZi3uC6nVl_x3er2Hn.png",
                        "isPro": false,
                        "fullname": "Zitong Yang",
                        "user": "zitongyang",
                        "type": "user"
                    },
                    "name": "Zitong Yang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:09:05.373Z",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bcc8",
                    "user": {
                        "_id": "6400f2ed568dbe30c9161e47",
                        "avatarUrl": "/avatars/c55938df5bce82b5d96e592a1ec36a8b.svg",
                        "isPro": false,
                        "fullname": "Weijia Shi",
                        "user": "swj0419",
                        "type": "user"
                    },
                    "name": "Weijia Shi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:09:20.064Z",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bcc9",
                    "name": "Xiang Lisa Li",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bcca",
                    "name": "Li Fei-Fei",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bccb",
                    "name": "Hannaneh Hajishirzi",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bccc",
                    "name": "Luke Zettlemoyer",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bccd",
                    "user": {
                        "_id": "6409651b9e9f790c905b2335",
                        "avatarUrl": "/avatars/1fb8c80b60f21f65a0a027319101f236.svg",
                        "isPro": false,
                        "fullname": "Percy Liang",
                        "user": "percyliang",
                        "type": "user"
                    },
                    "name": "Percy Liang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:10:17.521Z",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bcce",
                    "name": "Emmanuel Cand√®s",
                    "hidden": false
                },
                {
                    "_id": "67a02dd80e751b0476a1bccf",
                    "name": "Tatsunori Hashimoto",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-31T18:48:08.000Z",
            "title": "s1: Simple test-time scaling",
            "summary": "Test-time scaling is a promising new approach to language modeling that uses\nextra test-time compute to improve performance. Recently, OpenAI's o1 model\nshowed this capability but did not publicly share its methodology, leading to\nmany replication efforts. We seek the simplest approach to achieve test-time\nscaling and strong reasoning performance. First, we curate a small dataset s1K\nof 1,000 questions paired with reasoning traces relying on three criteria we\nvalidate through ablations: difficulty, diversity, and quality. Second, we\ndevelop budget forcing to control test-time compute by forcefully terminating\nthe model's thinking process or lengthening it by appending \"Wait\" multiple\ntimes to the model's generation when it tries to end. This can lead the model\nto double-check its answer, often fixing incorrect reasoning steps. After\nsupervised finetuning the Qwen2.5-32B-Instruct language model on s1K and\nequipping it with budget forcing, our model s1 exceeds o1-preview on\ncompetition math questions by up to 27% (MATH and AIME24). Further, scaling s1\nwith budget forcing allows extrapolating beyond its performance without\ntest-time intervention: from 50% to 57% on AIME24. Our model, data, and code\nare open-source at https://github.com/simplescaling/s1.",
            "upvotes": 51,
            "discussionId": "67a02dd90e751b0476a1bd02"
        },
        "publishedAt": "2025-02-02T21:45:49.841Z",
        "title": "s1: Simple test-time scaling",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19393.png",
        "numComments": 7,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5925
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.19324",
            "authors": [
                {
                    "_id": "67a04151dd7b3a4aba880589",
                    "user": {
                        "_id": "62c414354ce7250560a1f67f",
                        "avatarUrl": "/avatars/28fd73973d1703c84f4f59644fef8a80.svg",
                        "isPro": false,
                        "fullname": "Baohao Liao",
                        "user": "baohao",
                        "type": "user"
                    },
                    "name": "Baohao Liao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:10:48.379Z",
                    "hidden": false
                },
                {
                    "_id": "67a04151dd7b3a4aba88058a",
                    "user": {
                        "_id": "6602869253a0518b2a98cafd",
                        "avatarUrl": "/avatars/c14b5953a716f42c83ad28147f8308ae.svg",
                        "isPro": false,
                        "fullname": "Yuhui Xu",
                        "user": "yuhuixu",
                        "type": "user"
                    },
                    "name": "Yuhui Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-03T11:07:52.570Z",
                    "hidden": false
                },
                {
                    "_id": "67a04151dd7b3a4aba88058b",
                    "user": {
                        "_id": "63a3ff69f91ad3ea5703841d",
                        "avatarUrl": "/avatars/69227c4bce01d33747c1377b6f9672db.svg",
                        "isPro": false,
                        "fullname": "Hanze Dong",
                        "user": "hendrydong",
                        "type": "user"
                    },
                    "name": "Hanze Dong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:10:54.880Z",
                    "hidden": false
                },
                {
                    "_id": "67a04151dd7b3a4aba88058c",
                    "user": {
                        "_id": "61f9d3b54ac99e8a1bae85f4",
                        "avatarUrl": "/avatars/ac47d13204dd22452e4bc46e280842d5.svg",
                        "isPro": false,
                        "fullname": "JunnanLi",
                        "user": "JunnanLi",
                        "type": "user"
                    },
                    "name": "Junnan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:11:08.170Z",
                    "hidden": false
                },
                {
                    "_id": "67a04151dd7b3a4aba88058d",
                    "name": "Christof Monz",
                    "hidden": false
                },
                {
                    "_id": "67a04151dd7b3a4aba88058e",
                    "name": "Silvio Savarese",
                    "hidden": false
                },
                {
                    "_id": "67a04151dd7b3a4aba88058f",
                    "user": {
                        "_id": "65f84fd980481173afd91233",
                        "avatarUrl": "/avatars/6ac7bd6beba24d1476c5179b88c9e3fa.svg",
                        "isPro": false,
                        "fullname": "Doyen",
                        "user": "doyensahoo",
                        "type": "user"
                    },
                    "name": "Doyen Sahoo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:11:23.345Z",
                    "hidden": false
                },
                {
                    "_id": "67a04151dd7b3a4aba880590",
                    "user": {
                        "_id": "649dbcc4e0fff1ed099dc80a",
                        "avatarUrl": "/avatars/c87c273ca628dbcddccbf1ee19b2ce33.svg",
                        "isPro": false,
                        "fullname": "Caiming Xiong",
                        "user": "cxiong",
                        "type": "user"
                    },
                    "name": "Caiming Xiong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:11:29.821Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-31T17:19:57.000Z",
            "title": "Reward-Guided Speculative Decoding for Efficient LLM Reasoning",
            "summary": "We introduce Reward-Guided Speculative Decoding (RSD), a novel framework\naimed at improving the efficiency of inference in large language models (LLMs).\nRSD synergistically combines a lightweight draft model with a more powerful\ntarget model, incorporating a controlled bias to prioritize high-reward\noutputs, in contrast to existing speculative decoding methods that enforce\nstrict unbiasedness. RSD employs a process reward model to evaluate\nintermediate decoding steps and dynamically decide whether to invoke the target\nmodel, optimizing the trade-off between computational cost and output quality.\nWe theoretically demonstrate that a threshold-based mixture strategy achieves\nan optimal balance between resource utilization and performance. Extensive\nevaluations on challenging reasoning benchmarks, including Olympiad-level\ntasks, show that RSD delivers significant efficiency gains against decoding\nwith the target model only (up to 4.4x fewer FLOPs), while achieving\nsignificant better accuracy than parallel decoding method on average (up to\n+3.5). These results highlight RSD as a robust and cost-effective approach for\ndeploying LLMs in resource-intensive scenarios.",
            "upvotes": 27,
            "discussionId": "67a04152dd7b3a4aba8805c0"
        },
        "publishedAt": "2025-02-02T23:10:16.068Z",
        "title": "Reward-Guided Speculative Decoding for Efficient LLM Reasoning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19324.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6602869253a0518b2a98cafd",
            "avatarUrl": "/avatars/c14b5953a716f42c83ad28147f8308ae.svg",
            "fullname": "Yuhui Xu",
            "name": "yuhuixu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.18119",
            "authors": [
                {
                    "_id": "67a0a3201d9fadf4470cb07a",
                    "user": {
                        "_id": "66ac77011cfb12c087605acb",
                        "avatarUrl": "/avatars/54c06bd1c4c9d491470ed4162c2301ae.svg",
                        "isPro": false,
                        "fullname": "Lin",
                        "user": "Qika",
                        "type": "user"
                    },
                    "name": "Qika Lin",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-03T11:06:10.149Z",
                    "hidden": false
                },
                {
                    "_id": "67a0a3201d9fadf4470cb07b",
                    "name": "Tianzhe Zhao",
                    "hidden": false
                },
                {
                    "_id": "67a0a3201d9fadf4470cb07c",
                    "name": "Kai He",
                    "hidden": false
                },
                {
                    "_id": "67a0a3201d9fadf4470cb07d",
                    "name": "Zhen Peng",
                    "hidden": false
                },
                {
                    "_id": "67a0a3201d9fadf4470cb07e",
                    "name": "Fangzhi Xu",
                    "hidden": false
                },
                {
                    "_id": "67a0a3201d9fadf4470cb07f",
                    "name": "Ling Huang",
                    "hidden": false
                },
                {
                    "_id": "67a0a3201d9fadf4470cb080",
                    "name": "Jingying Ma",
                    "hidden": false
                },
                {
                    "_id": "67a0a3201d9fadf4470cb081",
                    "name": "Mengling Feng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-30T03:40:20.000Z",
            "title": "Self-supervised Quantized Representation for Seamlessly Integrating\n  Knowledge Graphs with Large Language Models",
            "summary": "Due to the presence of the natural gap between Knowledge Graph (KG)\nstructures and the natural language, the effective integration of holistic\nstructural information of KGs with Large Language Models (LLMs) has emerged as\na significant question. To this end, we propose a two-stage framework to learn\nand apply quantized codes for each entity, aiming for the seamless integration\nof KGs with LLMs. Firstly, a self-supervised quantized representation (SSQR)\nmethod is proposed to compress both KG structural and semantic knowledge into\ndiscrete codes (\\ie, tokens) that align the format of language sentences. We\nfurther design KG instruction-following data by viewing these learned codes as\nfeatures to directly input to LLMs, thereby achieving seamless integration. The\nexperiment results demonstrate that SSQR outperforms existing unsupervised\nquantized methods, producing more distinguishable codes. Further, the\nfine-tuned LLaMA2 and LLaMA3.1 also have superior performance on KG link\nprediction and triple classification tasks, utilizing only 16 tokens per entity\ninstead of thousands in conventional prompting methods.",
            "upvotes": 12,
            "discussionId": "67a0a3221d9fadf4470cb0f8"
        },
        "publishedAt": "2025-02-03T06:06:33.957Z",
        "title": "Self-supervised Quantized Representation for Seamlessly Integrating Knowledge Graphs with Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18119.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "66ac77011cfb12c087605acb",
            "avatarUrl": "/avatars/54c06bd1c4c9d491470ed4162c2301ae.svg",
            "fullname": "Lin",
            "name": "Qika",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.19339",
            "authors": [
                {
                    "_id": "67a044d1af1b65169565354c",
                    "name": "Zhiheng Lyu",
                    "hidden": false
                },
                {
                    "_id": "67a044d1af1b65169565354d",
                    "name": "Xueguang Ma",
                    "hidden": false
                },
                {
                    "_id": "67a044d1af1b65169565354e",
                    "user": {
                        "_id": "6313a86154e6e5d9f0f94e04",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
                        "isPro": false,
                        "fullname": "Wenhu Chen",
                        "user": "wenhu",
                        "type": "user"
                    },
                    "name": "Wenhu Chen",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-03T04:23:47.571Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-31T17:39:21.000Z",
            "title": "PixelWorld: Towards Perceiving Everything as Pixels",
            "summary": "Existing foundation models typically process visual input as pixels and\ntextual input as tokens, a paradigm that contrasts with human perception, where\nboth modalities are processed in a unified manner. With the rise of embodied\nand agentic AI, where inputs primarily come from camera pixels, the need for a\nunified perception framework becomes increasingly evident. In this paper, we\npropose to unify all modalities (text, tables, code, diagrams, images, etc) as\npixel inputs, i.e. \"Perceive Everything as Pixels\" (PEAP). We introduce\nPixelWorld, a novel evaluation suite that unifies all the mentioned modalities\ninto pixel space to gauge the existing models' performance. Our findings show\nthat (1) PEAP outperforms baseline with token-based input in multimodal\ndatasets, benefiting from unified input for better disambiguation, (2)\nsignificant declines in reasoning and coding capabilities across all models\nwhen processing pixel-based input, underscoring the need to enhance foundation\nmodels' perceptual abilities, (3) larger models can maintain strong performance\non non-reasoning tasks under PEAP, while smaller models like Phi-3.5-V suffer\nsignificant performance degradation, (4) the attention pattern of PEAP is\nhighly aligned with text token input, (5) PEAP can be accelerated significantly\nby exploiting the spatial sparsity. We conclude that the existing frontier\nmodels are competent in pixel perception, however, there is still headroom for\nimprovement. Our code, dataset will be released upon acceptance.",
            "upvotes": 10,
            "discussionId": "67a044d3af1b6516956535b6"
        },
        "publishedAt": "2025-02-03T10:59:18.508Z",
        "title": "PixelWorld: Towards Perceiving Everything as Pixels",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6313a86154e6e5d9f0f94e04/NnyW-XW-vW8IqQdK1pG5e.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19339.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6313a86154e6e5d9f0f94e04",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662232951344-6313a86154e6e5d9f0f94e04.jpeg",
            "fullname": "Wenhu Chen",
            "name": "wenhu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 32
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.14677",
            "authors": [
                {
                    "_id": "679d5057ca02e3270aaada16",
                    "name": "Peiqing Yang",
                    "hidden": false
                },
                {
                    "_id": "679d5057ca02e3270aaada17",
                    "name": "Shangchen Zhou",
                    "hidden": false
                },
                {
                    "_id": "679d5057ca02e3270aaada18",
                    "name": "Jixin Zhao",
                    "hidden": false
                },
                {
                    "_id": "679d5057ca02e3270aaada19",
                    "name": "Qingyi Tao",
                    "hidden": false
                },
                {
                    "_id": "679d5057ca02e3270aaada1a",
                    "name": "Chen Change Loy",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-24T17:56:24.000Z",
            "title": "MatAnyone: Stable Video Matting with Consistent Memory Propagation",
            "summary": "Auxiliary-free human video matting methods, which rely solely on input\nframes, often struggle with complex or ambiguous backgrounds. To address this,\nwe propose MatAnyone, a robust framework tailored for target-assigned video\nmatting. Specifically, building on a memory-based paradigm, we introduce a\nconsistent memory propagation module via region-adaptive memory fusion, which\nadaptively integrates memory from the previous frame. This ensures semantic\nstability in core regions while preserving fine-grained details along object\nboundaries. For robust training, we present a larger, high-quality, and diverse\ndataset for video matting. Additionally, we incorporate a novel training\nstrategy that efficiently leverages large-scale segmentation data, boosting\nmatting stability. With this new network design, dataset, and training\nstrategy, MatAnyone delivers robust and accurate video matting results in\ndiverse real-world scenarios, outperforming existing methods.",
            "upvotes": 7,
            "discussionId": "679d505cca02e3270aaadaf6"
        },
        "publishedAt": "2025-02-03T13:15:59.743Z",
        "title": "MatAnyone: Stable Video Matting with Consistent Memory Propagation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.14677.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5925
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2411.04983",
            "authors": [
                {
                    "_id": "67a0783a1b24595484396c4d",
                    "user": {
                        "_id": "63486560e0bf88ccd36fe568",
                        "avatarUrl": "/avatars/934cffbd9f5c699abad20dcf86745382.svg",
                        "isPro": false,
                        "fullname": "Gaoyue Zhou",
                        "user": "gaoyuezhou",
                        "type": "user"
                    },
                    "name": "Gaoyue Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:58:14.740Z",
                    "hidden": false
                },
                {
                    "_id": "67a0783a1b24595484396c4e",
                    "user": {
                        "_id": "634236fc8d8089ebaefb8180",
                        "avatarUrl": "/avatars/e40518ff3f0d0a58ba4f46048c84640d.svg",
                        "isPro": false,
                        "fullname": "Hengkai Pan",
                        "user": "garyphk",
                        "type": "user"
                    },
                    "name": "Hengkai Pan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:58:20.238Z",
                    "hidden": false
                },
                {
                    "_id": "67a0783a1b24595484396c4f",
                    "user": {
                        "_id": "64ed0b8c2203a126eb1a5b9a",
                        "avatarUrl": "/avatars/9156dc406ed3f9ee62b73657ac20f5ed.svg",
                        "isPro": false,
                        "fullname": "Yann LeCun",
                        "user": "ylecun",
                        "type": "user"
                    },
                    "name": "Yann LeCun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:58:26.526Z",
                    "hidden": false
                },
                {
                    "_id": "67a0783a1b24595484396c50",
                    "user": {
                        "_id": "66fffa0766bc54f4e532e3d2",
                        "avatarUrl": "/avatars/9db8b2183097bcaddded06d1b800cf77.svg",
                        "isPro": false,
                        "fullname": "Lerrel Pinto",
                        "user": "LerrelPinto",
                        "type": "user"
                    },
                    "name": "Lerrel Pinto",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:58:41.008Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-11-07T18:54:37.000Z",
            "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot\n  Planning",
            "summary": "The ability to predict future outcomes given control actions is fundamental\nfor physical reasoning. However, such predictive models, often called world\nmodels, have proven challenging to learn and are typically developed for\ntask-specific solutions with online policy learning. We argue that the true\npotential of world models lies in their ability to reason and plan across\ndiverse problems using only passive data. Concretely, we require world models\nto have the following three properties: 1) be trainable on offline,\npre-collected trajectories, 2) support test-time behavior optimization, and 3)\nfacilitate task-agnostic reasoning. To realize this, we present DINO World\nModel (DINO-WM), a new method to model visual dynamics without reconstructing\nthe visual world. DINO-WM leverages spatial patch features pre-trained with\nDINOv2, enabling it to learn from offline behavioral trajectories by predicting\nfuture patch features. This design allows DINO-WM to achieve observational\ngoals through action sequence optimization, facilitating task-agnostic behavior\nplanning by treating desired goal patch features as prediction targets. We\nevaluate DINO-WM across various domains, including maze navigation, tabletop\npushing, and particle manipulation. Our experiments demonstrate that DINO-WM\ncan generate zero-shot behavioral solutions at test time without relying on\nexpert demonstrations, reward modeling, or pre-learned inverse models. Notably,\nDINO-WM exhibits strong generalization capabilities compared to prior\nstate-of-the-art work, adapting to diverse task families such as arbitrarily\nconfigured mazes, push manipulation with varied object shapes, and\nmulti-particle scenarios.",
            "upvotes": 7,
            "discussionId": "67a0783d1b24595484396cca"
        },
        "publishedAt": "2025-02-03T03:10:08.761Z",
        "title": "DINO-WM: World Models on Pre-trained Visual Features enable Zero-shot Planning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2411.04983.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "5f1158120c833276f61f1a84",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
            "fullname": "Niels Rogge",
            "name": "nielsr",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 743
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.19399",
            "authors": [
                {
                    "_id": "67a0e9707ddf31accd7b2510",
                    "name": "Ken M. Nakanishi",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-31T18:55:35.000Z",
            "title": "Scalable-Softmax Is Superior for Attention",
            "summary": "The maximum element of the vector output by the Softmax function approaches\nzero as the input vector size increases. Transformer-based language models rely\non Softmax to compute attention scores, causing the attention distribution to\nflatten as the context size grows. This reduces the model's ability to\nprioritize key information effectively and potentially limits its length\ngeneralization. To address this problem, we propose Scalable-Softmax (SSMax),\nwhich replaces Softmax in scenarios where the input vector size varies. SSMax\ncan be seamlessly integrated into existing Transformer-based architectures.\nExperimental results in language modeling show that models using SSMax not only\nachieve faster loss reduction during pretraining but also significantly improve\nperformance in long contexts and key information retrieval. Furthermore, an\nanalysis of attention scores reveals that SSMax enables the model to focus\nattention on key information even in long contexts. Additionally, although\nmodels that use SSMax from the beginning of pretraining achieve better length\ngeneralization, those that have already started pretraining can still gain some\nof this ability by replacing Softmax in the attention layers with SSMax, either\nduring or after pretraining.",
            "upvotes": 6,
            "discussionId": "67a0e9707ddf31accd7b254a"
        },
        "publishedAt": "2025-02-03T13:01:15.923Z",
        "title": "Scalable-Softmax Is Superior for Attention",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.19399.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60eeedbf50b60c406afc1291",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649111275459-60eeedbf50b60c406afc1291.png",
            "fullname": "Samuel Arcadinho",
            "name": "SSamDav",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.18837",
            "authors": [
                {
                    "_id": "67a04e7ab6fd93f91c65457b",
                    "name": "Mrinank Sharma",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65457c",
                    "user": {
                        "_id": "63272a638624baac667c8bdb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63272a638624baac667c8bdb/ylZ-FNT9PLhn8sBCD1wQm.png",
                        "isPro": false,
                        "fullname": "Meg Tong",
                        "user": "meg-tong",
                        "type": "user"
                    },
                    "name": "Meg Tong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:12:10.128Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65457d",
                    "user": {
                        "_id": "62301010174feb5439c42e23",
                        "avatarUrl": "/avatars/cd3c8a97823e3cbc176fef245113624f.svg",
                        "isPro": false,
                        "fullname": "Jesse Mu",
                        "user": "jayelm",
                        "type": "user"
                    },
                    "name": "Jesse Mu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:12:02.638Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65457e",
                    "name": "Jerry Wei",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65457f",
                    "name": "Jorrit Kruthoff",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654580",
                    "user": {
                        "_id": "60ef38cdd36c6e3f5e270b5c",
                        "avatarUrl": "/avatars/a6c89092322364f35eb6051178f3fbcc.svg",
                        "isPro": false,
                        "fullname": "Scott Goodfriend",
                        "user": "sgoodfriend",
                        "type": "user"
                    },
                    "name": "Scott Goodfriend",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:11:51.464Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654581",
                    "user": {
                        "_id": "64f2218f0d19f5ae05f6a807",
                        "avatarUrl": "/avatars/855d9f57b075855418e2db33a110ffed.svg",
                        "isPro": false,
                        "fullname": "Euan Ong",
                        "user": "euanong",
                        "type": "user"
                    },
                    "name": "Euan Ong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-03T11:07:50.780Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654582",
                    "user": {
                        "_id": "660ed54c6923ed21e630820d",
                        "avatarUrl": "/avatars/5c613fbff6d4d36eeaeae92296c88d2c.svg",
                        "isPro": false,
                        "fullname": "Alwin Peng",
                        "user": "Primusa",
                        "type": "user"
                    },
                    "name": "Alwin Peng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:12:18.423Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654583",
                    "user": {
                        "_id": "676158c7bedb5ba8dd41cad5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/yLEBoauB-32KlAi7arfAE.png",
                        "isPro": false,
                        "fullname": "Raj Agarwal",
                        "user": "Raj32123",
                        "type": "user"
                    },
                    "name": "Raj Agarwal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:12:26.895Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654584",
                    "user": {
                        "_id": "62f6b27d05ca68c0e0008549",
                        "avatarUrl": "/avatars/14d0075aa1b578cd7ee5f9e68d12e2f0.svg",
                        "isPro": false,
                        "fullname": "Cem Anil",
                        "user": "anilcem",
                        "type": "user"
                    },
                    "name": "Cem Anil",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:12:35.275Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654585",
                    "user": {
                        "_id": "6764dc0c7fa1ef387f891893",
                        "avatarUrl": "/avatars/eb060a92b65877ae90c1106cfa7c4314.svg",
                        "isPro": false,
                        "fullname": "Amanda askell",
                        "user": "askeii",
                        "type": "user"
                    },
                    "name": "Amanda Askell",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:12:44.345Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654586",
                    "user": {
                        "_id": "665991b987aedd2a572042e1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/665991b987aedd2a572042e1/nWbp1n_Ps_MPTmpWJcWoz.jpeg",
                        "isPro": false,
                        "fullname": "Nathan Bailey",
                        "user": "nathanbaileyw",
                        "type": "user"
                    },
                    "name": "Nathan Bailey",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:12:50.549Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654587",
                    "user": {
                        "_id": "63124bb3f568fb0098f617c7",
                        "avatarUrl": "/avatars/6109b5c05452322246843b29b4662051.svg",
                        "isPro": false,
                        "fullname": "Joe Benton",
                        "user": "JoeJBenton",
                        "type": "user"
                    },
                    "name": "Joe Benton",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:12:58.193Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654588",
                    "name": "Emma Bluemke",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654589",
                    "user": {
                        "_id": "65b7ceed0e2951626572e25d",
                        "avatarUrl": "/avatars/5d6085ca4260d663f0ddbe632c9e746c.svg",
                        "isPro": false,
                        "fullname": "Samuel Bowman",
                        "user": "samuelpbowman",
                        "type": "user"
                    },
                    "name": "Samuel R. Bowman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:13:11.959Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65458a",
                    "user": {
                        "_id": "64dd22e1c29ed0b051d1a5c4",
                        "avatarUrl": "/avatars/c8511325f6d8cb485382c0de40975b65.svg",
                        "isPro": false,
                        "fullname": "Eric Christiansen",
                        "user": "emchristiansen",
                        "type": "user"
                    },
                    "name": "Eric Christiansen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:13:19.490Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65458b",
                    "user": {
                        "_id": "636146e7472131c3bc538bd8",
                        "avatarUrl": "/avatars/9db880163cc0eea796165d8bf5e2a91f.svg",
                        "isPro": false,
                        "fullname": "Hoagy Cunningham",
                        "user": "HoagyC",
                        "type": "user"
                    },
                    "name": "Hoagy Cunningham",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:13:24.996Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65458c",
                    "user": {
                        "_id": "656f669dec366e93ca16cf98",
                        "avatarUrl": "/avatars/84e266ede3fe45d24666e1d8e03dd94d.svg",
                        "isPro": false,
                        "fullname": "Andy Dau",
                        "user": "atadau",
                        "type": "user"
                    },
                    "name": "Andy Dau",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T11:13:38.325Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65458d",
                    "name": "Anjali Gopal",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65458e",
                    "name": "Rob Gilson",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65458f",
                    "name": "Logan Graham",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654590",
                    "name": "Logan Howard",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654591",
                    "user": {
                        "_id": "66fc4c692408eb3bdeba876f",
                        "avatarUrl": "/avatars/66ba18ccb95d150e66d7b6930d4eb938.svg",
                        "isPro": false,
                        "fullname": "Nimit Kalra",
                        "user": "nimitkalra",
                        "type": "user"
                    },
                    "name": "Nimit Kalra",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-03T08:14:42.317Z",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654592",
                    "name": "Taesung Lee",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654593",
                    "name": "Kevin Lin",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654594",
                    "name": "Peter Lofgren",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654595",
                    "name": "Francesco Mosconi",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654596",
                    "name": "Clare O'Hara",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654597",
                    "name": "Catherine Olsson",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654598",
                    "name": "Linda Petrini",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c654599",
                    "name": "Samir Rajani",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65459a",
                    "name": "Nikhil Saxena",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65459b",
                    "name": "Alex Silverstein",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65459c",
                    "name": "Tanya Singh",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65459d",
                    "name": "Theodore Sumers",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65459e",
                    "name": "Leonard Tang",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c65459f",
                    "name": "Kevin K. Troy",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c6545a0",
                    "name": "Constantin Weisser",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c6545a1",
                    "name": "Ruiqi Zhong",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c6545a2",
                    "name": "Giulio Zhou",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c6545a3",
                    "name": "Jan Leike",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c6545a4",
                    "name": "Jared Kaplan",
                    "hidden": false
                },
                {
                    "_id": "67a04e7ab6fd93f91c6545a5",
                    "name": "Ethan Perez",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-31T01:09:32.000Z",
            "title": "Constitutional Classifiers: Defending against Universal Jailbreaks\n  across Thousands of Hours of Red Teaming",
            "summary": "Large language models (LLMs) are vulnerable to universal jailbreaks-prompting\nstrategies that systematically bypass model safeguards and enable users to\ncarry out harmful processes that require many model interactions, like\nmanufacturing illegal substances at scale. To defend against these attacks, we\nintroduce Constitutional Classifiers: safeguards trained on synthetic data,\ngenerated by prompting LLMs with natural language rules (i.e., a constitution)\nspecifying permitted and restricted content. In over 3,000 estimated hours of\nred teaming, no red teamer found a universal jailbreak that could extract\ninformation from an early classifier-guarded LLM at a similar level of detail\nto an unguarded model across most target queries. On automated evaluations,\nenhanced classifiers demonstrated robust defense against held-out\ndomain-specific jailbreaks. These classifiers also maintain deployment\nviability, with an absolute 0.38% increase in production-traffic refusals and a\n23.7% inference overhead. Our work demonstrates that defending against\nuniversal jailbreaks while maintaining practical deployment viability is\ntractable.",
            "upvotes": 5,
            "discussionId": "67a04e7bb6fd93f91c6545bc"
        },
        "publishedAt": "2025-02-03T00:05:21.087Z",
        "title": "Constitutional Classifiers: Defending against Universal Jailbreaks across Thousands of Hours of Red Teaming",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18837.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5925
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.18052",
            "authors": [
                {
                    "_id": "67a07bbb8e344720ae1a6008",
                    "user": {
                        "_id": "6422f416a73327caad9d1d86",
                        "avatarUrl": "/avatars/aa3639277cd1732504402fc64a57eff8.svg",
                        "isPro": false,
                        "fullname": "Bartosz Cywi≈Ñski",
                        "user": "bcywinski",
                        "type": "user"
                    },
                    "name": "Bartosz Cywi≈Ñski",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-03T11:07:48.609Z",
                    "hidden": false
                },
                {
                    "_id": "67a07bbb8e344720ae1a6009",
                    "name": "Kamil Deja",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-29T23:29:47.000Z",
            "title": "SAeUron: Interpretable Concept Unlearning in Diffusion Models with\n  Sparse Autoencoders",
            "summary": "Diffusion models, while powerful, can inadvertently generate harmful or\nundesirable content, raising significant ethical and safety concerns. Recent\nmachine unlearning approaches offer potential solutions but often lack\ntransparency, making it difficult to understand the changes they introduce to\nthe base model. In this work, we introduce SAeUron, a novel method leveraging\nfeatures learned by sparse autoencoders (SAEs) to remove unwanted concepts in\ntext-to-image diffusion models. First, we demonstrate that SAEs, trained in an\nunsupervised manner on activations from multiple denoising timesteps of the\ndiffusion model, capture sparse and interpretable features corresponding to\nspecific concepts. Building on this, we propose a feature selection method that\nenables precise interventions on model activations to block targeted content\nwhile preserving overall performance. Evaluation with the competitive\nUnlearnCanvas benchmark on object and style unlearning highlights SAeUron's\nstate-of-the-art performance. Moreover, we show that with a single SAE, we can\nremove multiple concepts simultaneously and that in contrast to other methods,\nSAeUron mitigates the possibility of generating unwanted content, even under\nadversarial attack. Code and checkpoints are available at:\nhttps://github.com/cywinski/SAeUron.",
            "upvotes": 3,
            "discussionId": "67a07bc08e344720ae1a60e9"
        },
        "publishedAt": "2025-02-03T15:09:16.653Z",
        "title": "SAeUron: Interpretable Concept Unlearning in Diffusion Models with Sparse Autoencoders",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18052.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6422f416a73327caad9d1d86",
            "avatarUrl": "/avatars/aa3639277cd1732504402fc64a57eff8.svg",
            "fullname": "Bartosz Cywi≈Ñski",
            "name": "bcywinski",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.18841",
            "authors": [
                {
                    "_id": "67a02c75221b701e4c04da7f",
                    "name": "Wojciech Zaremba",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da80",
                    "user": {
                        "_id": "6792b8359967b7f195447e43",
                        "avatarUrl": "/avatars/0fcad468c7062d003902e78975daf6ea.svg",
                        "isPro": false,
                        "fullname": "Evgenia Nitishinskaya",
                        "user": "gadzin1203",
                        "type": "user"
                    },
                    "name": "Evgenia Nitishinskaya",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:56:51.252Z",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da81",
                    "name": "Boaz Barak",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da82",
                    "name": "Stephanie Lin",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da83",
                    "user": {
                        "_id": "62952a811e87ffbe5c06e3d4",
                        "avatarUrl": "/avatars/8140d3a6cbb0f85c284a1fd388915cb2.svg",
                        "isPro": false,
                        "fullname": "Sam Toyer",
                        "user": "qxcv",
                        "type": "user"
                    },
                    "name": "Sam Toyer",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:57:23.000Z",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da84",
                    "user": {
                        "_id": "6100e69a393be1b5c4c83867",
                        "avatarUrl": "/avatars/1b87098cffb9c50345789808daea4f68.svg",
                        "isPro": false,
                        "fullname": "Yaodong Yu",
                        "user": "yaodongyu",
                        "type": "user"
                    },
                    "name": "Yaodong Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:57:28.373Z",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da85",
                    "name": "Rachel Dias",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da86",
                    "user": {
                        "_id": "63112d2431257261d20d5754",
                        "avatarUrl": "/avatars/502a68c0fb2f0c6989fe2869d0a7e3f4.svg",
                        "isPro": false,
                        "fullname": "Eric Wallace",
                        "user": "EricWallace",
                        "type": "user"
                    },
                    "name": "Eric Wallace",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:57:48.651Z",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da87",
                    "name": "Kai Xiao",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da88",
                    "name": "Johannes Heidecke",
                    "hidden": false
                },
                {
                    "_id": "67a02c75221b701e4c04da89",
                    "name": "Amelia Glaese",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-31T01:20:44.000Z",
            "title": "Trading Inference-Time Compute for Adversarial Robustness",
            "summary": "We conduct experiments on the impact of increasing inference-time compute in\nreasoning models (specifically OpenAI o1-preview and o1-mini) on their\nrobustness to adversarial attacks. We find that across a variety of attacks,\nincreased inference-time compute leads to improved robustness. In many cases\n(with important exceptions), the fraction of model samples where the attack\nsucceeds tends to zero as the amount of test-time compute grows. We perform no\nadversarial training for the tasks we study, and we increase inference-time\ncompute by simply allowing the models to spend more compute on reasoning,\nindependently of the form of attack. Our results suggest that inference-time\ncompute has the potential to improve adversarial robustness for Large Language\nModels. We also explore new attacks directed at reasoning models, as well as\nsettings where inference-time compute does not improve reliability, and\nspeculate on the reasons for these as well as ways to address them.",
            "upvotes": 3,
            "discussionId": "67a02c76221b701e4c04daf5"
        },
        "publishedAt": "2025-02-02T21:40:11.158Z",
        "title": "Trading Inference-Time Compute for Adversarial Robustness",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18841.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5925
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.18804",
            "authors": [
                {
                    "_id": "67a10b8e83c3565727b0cd68",
                    "name": "Vitor Guizilini",
                    "hidden": false
                },
                {
                    "_id": "67a10b8e83c3565727b0cd69",
                    "name": "Muhammad Zubair Irshad",
                    "hidden": false
                },
                {
                    "_id": "67a10b8e83c3565727b0cd6a",
                    "name": "Dian Chen",
                    "hidden": false
                },
                {
                    "_id": "67a10b8e83c3565727b0cd6b",
                    "name": "Greg Shakhnarovich",
                    "hidden": false
                },
                {
                    "_id": "67a10b8e83c3565727b0cd6c",
                    "name": "Rares Ambrus",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-30T23:43:06.000Z",
            "title": "Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric\n  Diffusion",
            "summary": "Current methods for 3D scene reconstruction from sparse posed images employ\nintermediate 3D representations such as neural fields, voxel grids, or 3D\nGaussians, to achieve multi-view consistent scene appearance and geometry. In\nthis paper we introduce MVGD, a diffusion-based architecture capable of direct\npixel-level generation of images and depth maps from novel viewpoints, given an\narbitrary number of input views. Our method uses raymap conditioning to both\naugment visual features with spatial information from different viewpoints, as\nwell as to guide the generation of images and depth maps from novel views. A\nkey aspect of our approach is the multi-task generation of images and depth\nmaps, using learnable task embeddings to guide the diffusion process towards\nspecific modalities. We train this model on a collection of more than 60\nmillion multi-view samples from publicly available datasets, and propose\ntechniques to enable efficient and consistent learning in such diverse\nconditions. We also propose a novel strategy that enables the efficient\ntraining of larger models by incrementally fine-tuning smaller ones, with\npromising scaling behavior. Through extensive experiments, we report\nstate-of-the-art results in multiple novel view synthesis benchmarks, as well\nas multi-view stereo and video depth estimation.",
            "upvotes": 2,
            "discussionId": "67a10b9183c3565727b0cdef"
        },
        "publishedAt": "2025-02-03T13:32:45.792Z",
        "title": "Zero-Shot Novel View and Depth Synthesis with Multi-View Geometric Diffusion",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18804.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "62e458d33051028b542be2a0",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1659131510466-noauth.jpeg",
            "fullname": "Zubair Irshad",
            "name": "mirshad7",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.18965",
            "authors": [
                {
                    "_id": "67a0e794042d0e5936db83cf",
                    "user": {
                        "_id": "64a2b68da0696e0a29739349",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a2b68da0696e0a29739349/wUtx3yCcSiN7SZP4nMSPK.png",
                        "isPro": false,
                        "fullname": "Fabian S",
                        "user": "fabian-sp",
                        "type": "user"
                    },
                    "name": "Fabian Schaipp",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-03T16:00:56.014Z",
                    "hidden": false
                },
                {
                    "_id": "67a0e794042d0e5936db83d0",
                    "user": {
                        "_id": "65785d22dddc2360b01702e1",
                        "avatarUrl": "/avatars/8e3ddf25b9c423f57484fddef4f0aafd.svg",
                        "isPro": false,
                        "fullname": "Alexander H√§gele",
                        "user": "haeggee",
                        "type": "user"
                    },
                    "name": "Alexander H√§gele",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T16:01:03.085Z",
                    "hidden": false
                },
                {
                    "_id": "67a0e794042d0e5936db83d1",
                    "name": "Adrien Taylor",
                    "hidden": false
                },
                {
                    "_id": "67a0e794042d0e5936db83d2",
                    "name": "Umut Simsekli",
                    "hidden": false
                },
                {
                    "_id": "67a0e794042d0e5936db83d3",
                    "name": "Francis Bach",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-31T08:55:56.000Z",
            "title": "The Surprising Agreement Between Convex Optimization Theory and\n  Learning-Rate Scheduling for Large Model Training",
            "summary": "We show that learning-rate schedules for large model training behave\nsurprisingly similar to a performance bound from non-smooth convex optimization\ntheory. We provide a bound for the constant schedule with linear cooldown; in\nparticular, the practical benefit of cooldown is reflected in the bound due to\nthe absence of logarithmic terms. Further, we show that this surprisingly close\nmatch between optimization theory and practice can be exploited for\nlearning-rate tuning: we achieve noticeable improvements for training 124M and\n210M Llama-type models by (i) extending the schedule for continued training\nwith optimal learning-rate, and (ii) transferring the optimal learning-rate\nacross schedules.",
            "upvotes": 2,
            "discussionId": "67a0e79e042d0e5936db858d"
        },
        "publishedAt": "2025-02-03T10:59:24.249Z",
        "title": "The Surprising Agreement Between Convex Optimization Theory and Learning-Rate Scheduling for Large Model Training",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18965.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "64a2b68da0696e0a29739349",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64a2b68da0696e0a29739349/wUtx3yCcSiN7SZP4nMSPK.png",
            "fullname": "Fabian S",
            "name": "fabian-sp",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.18753",
            "authors": [
                {
                    "_id": "67a0a09da2d6613d77a7d10e",
                    "user": {
                        "_id": "65e1b6e9501590df0173cbd3",
                        "avatarUrl": "/avatars/a73e2139700e23eff455734c99cef5ba.svg",
                        "isPro": false,
                        "fullname": "Jian Hu",
                        "user": "lwpyh",
                        "type": "user"
                    },
                    "name": "Jian Hu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:59:15.739Z",
                    "hidden": false
                },
                {
                    "_id": "67a0a09da2d6613d77a7d10f",
                    "user": {
                        "_id": "667ee096b0fad0fdee319ed4",
                        "avatarUrl": "/avatars/d9df687e8522d47f7fcefe40fd9b575b.svg",
                        "isPro": false,
                        "fullname": "Zixu Cheng",
                        "user": "Cade921",
                        "type": "user"
                    },
                    "name": "Zixu Cheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:59:22.704Z",
                    "hidden": false
                },
                {
                    "_id": "67a0a09da2d6613d77a7d110",
                    "name": "Shaogang Gong",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-30T21:07:14.000Z",
            "title": "INT: Instance-Specific Negative Mining for Task-Generic Promptable\n  Segmentation",
            "summary": "Task-generic promptable image segmentation aims to achieve segmentation of\ndiverse samples under a single task description by utilizing only one\ntask-generic prompt. Current methods leverage the generalization capabilities\nof Vision-Language Models (VLMs) to infer instance-specific prompts from these\ntask-generic prompts in order to guide the segmentation process. However, when\nVLMs struggle to generalise to some image instances, predicting\ninstance-specific prompts becomes poor. To solve this problem, we introduce\nInstance-specific Negative Mining for Task-Generic\nPromptable Segmentation (INT). The key idea of INT is to adaptively\nreduce the influence of irrelevant (negative) prior knowledge whilst to\nincrease the use the most plausible prior knowledge, selected by negative\nmining with higher contrast, in order to optimise instance-specific prompts\ngeneration. Specifically, INT consists of two components: (1) instance-specific\nprompt generation, which progressively fliters out incorrect information in\nprompt generation; (2) semantic mask generation, which ensures each image\ninstance segmentation matches correctly the semantics of the instance-specific\nprompts. INT is validated on six datasets, including camouflaged objects and\nmedical images, demonstrating its effectiveness, robustness and scalability.",
            "upvotes": 2,
            "discussionId": "67a0a09fa2d6613d77a7d174"
        },
        "publishedAt": "2025-02-03T05:59:36.106Z",
        "title": "INT: Instance-Specific Negative Mining for Task-Generic Promptable Segmentation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18753.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "65e1b6e9501590df0173cbd3",
            "avatarUrl": "/avatars/a73e2139700e23eff455734c99cef5ba.svg",
            "fullname": "Jian Hu",
            "name": "lwpyh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.18128",
            "authors": [
                {
                    "_id": "679e04b792d873dfa23d0ba6",
                    "user": {
                        "_id": "647d79a736e109abce419102",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647d79a736e109abce419102/S8Hby6eO4WdPQrct0Ix3c.png",
                        "isPro": false,
                        "fullname": "Abdurrahman Odaba≈üƒ±",
                        "user": "odabashi",
                        "type": "user"
                    },
                    "name": "Abdurrahman Odaba≈üƒ±",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-03T08:14:51.873Z",
                    "hidden": false
                },
                {
                    "_id": "679e04b792d873dfa23d0ba7",
                    "name": "G√∂ksel Biricik",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-30T04:20:16.000Z",
            "title": "Unraveling the Capabilities of Language Models in News Summarization",
            "summary": "Given the recent introduction of multiple language models and the ongoing\ndemand for improved Natural Language Processing tasks, particularly\nsummarization, this work provides a comprehensive benchmarking of 20 recent\nlanguage models, focusing on smaller ones for the news summarization task. In\nthis work, we systematically test the capabilities and effectiveness of these\nmodels in summarizing news article texts which are written in different styles\nand presented in three distinct datasets. Specifically, we focus in this study\non zero-shot and few-shot learning settings and we apply a robust evaluation\nmethodology that combines different evaluation concepts including automatic\nmetrics, human evaluation, and LLM-as-a-judge. Interestingly, including\ndemonstration examples in the few-shot learning setting did not enhance models'\nperformance and, in some cases, even led to worse quality of the generated\nsummaries. This issue arises mainly due to the poor quality of the gold\nsummaries that have been used as reference summaries, which negatively impacts\nthe models' performance. Furthermore, our study's results highlight the\nexceptional performance of GPT-3.5-Turbo and GPT-4, which generally dominate\ndue to their advanced capabilities. However, among the public models evaluated,\ncertain models such as Qwen1.5-7B, SOLAR-10.7B-Instruct-v1.0, Meta-Llama-3-8B\nand Zephyr-7B-Beta demonstrated promising results. These models showed\nsignificant potential, positioning them as competitive alternatives to large\nmodels for the task of news summarization.",
            "upvotes": 2,
            "discussionId": "679e04b892d873dfa23d0bd3"
        },
        "publishedAt": "2025-02-03T04:01:13.509Z",
        "title": "Unraveling the Capabilities of Language Models in News Summarization",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18128.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "647d79a736e109abce419102",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647d79a736e109abce419102/S8Hby6eO4WdPQrct0Ix3c.png",
            "fullname": "Abdurrahman Odaba≈üƒ±",
            "name": "odabashi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2404.07097",
            "authors": [
                {
                    "_id": "67a07a4b605a6c919dea84ec",
                    "user": {
                        "_id": "642294c112b4b51aae368d30",
                        "avatarUrl": "/avatars/017c19910ba01d6bd9cd864132652448.svg",
                        "isPro": false,
                        "fullname": "Yoni Kasten",
                        "user": "ykasten",
                        "type": "user"
                    },
                    "name": "Yoni Kasten",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:59:44.973Z",
                    "hidden": false
                },
                {
                    "_id": "67a07a4b605a6c919dea84ed",
                    "user": {
                        "_id": "65fbd280b0068def429d426f",
                        "avatarUrl": "/avatars/1c9caccbb08ce3c9fa3bd60fecab10b5.svg",
                        "isPro": false,
                        "fullname": "Wuyue Lu",
                        "user": "Woo-wy",
                        "type": "user"
                    },
                    "name": "Wuyue Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-03T12:59:51.676Z",
                    "hidden": false
                },
                {
                    "_id": "67a07a4b605a6c919dea84ee",
                    "name": "Haggai Maron",
                    "hidden": false
                }
            ],
            "publishedAt": "2024-04-10T15:37:00.000Z",
            "title": "Fast Encoder-Based 3D from Casual Videos via Point Track Processing",
            "summary": "This paper addresses the long-standing challenge of reconstructing 3D\nstructures from videos with dynamic content. Current approaches to this problem\nwere not designed to operate on casual videos recorded by standard cameras or\nrequire a long optimization time.\n  Aiming to significantly improve the efficiency of previous approaches, we\npresent TracksTo4D, a learning-based approach that enables inferring 3D\nstructure and camera positions from dynamic content originating from casual\nvideos using a single efficient feed-forward pass. To achieve this, we propose\noperating directly over 2D point tracks as input and designing an architecture\ntailored for processing 2D point tracks. Our proposed architecture is designed\nwith two key principles in mind: (1) it takes into account the inherent\nsymmetries present in the input point tracks data, and (2) it assumes that the\nmovement patterns can be effectively represented using a low-rank\napproximation. TracksTo4D is trained in an unsupervised way on a dataset of\ncasual videos utilizing only the 2D point tracks extracted from the videos,\nwithout any 3D supervision. Our experiments show that TracksTo4D can\nreconstruct a temporal point cloud and camera positions of the underlying video\nwith accuracy comparable to state-of-the-art methods, while drastically\nreducing runtime by up to 95\\%. We further show that TracksTo4D generalizes\nwell to unseen videos of unseen semantic categories at inference time.",
            "upvotes": 1,
            "discussionId": "67a07a4d605a6c919dea8555"
        },
        "publishedAt": "2025-02-03T03:12:19.292Z",
        "title": "Fast Encoder-Based 3D from Casual Videos via Point Track Processing",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2404.07097.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "5f1158120c833276f61f1a84",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
            "fullname": "Niels Rogge",
            "name": "nielsr",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 743
        },
        "isAuthorParticipating": false
    }
]