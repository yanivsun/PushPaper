[
    {
        "paper": {
            "id": "2502.01237",
            "authors": [
                {
                    "_id": "67a1c1428747511e7b9a1965",
                    "user": {
                        "_id": "62897fce5d9e25c10e4f319d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62897fce5d9e25c10e4f319d/bMlfAyzkNNZlkQ5mCW6Vc.jpeg",
                        "isPro": false,
                        "fullname": "Alexey Gorbatovski",
                        "user": "Myashka",
                        "type": "user"
                    },
                    "name": "Alexey Gorbatovski",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:00.767Z",
                    "hidden": false
                },
                {
                    "_id": "67a1c1428747511e7b9a1966",
                    "user": {
                        "_id": "637dd11dcbad6e62a5e39743",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637dd11dcbad6e62a5e39743/DG3rM8cy8inqbCoG4qizO.jpeg",
                        "isPro": false,
                        "fullname": "Boris Shaposhnikov",
                        "user": "borisshapa",
                        "type": "user"
                    },
                    "name": "Boris Shaposhnikov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T14:48:32.720Z",
                    "hidden": false
                },
                {
                    "_id": "67a1c1428747511e7b9a1967",
                    "user": {
                        "_id": "6416272d986557e8cac64ece",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6416272d986557e8cac64ece/s3CLjNN_pGj-vJDcENFD2.jpeg",
                        "isPro": false,
                        "fullname": "Viacheslav",
                        "user": "ummagumm-a",
                        "type": "user"
                    },
                    "name": "Viacheslav Sinii",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:38:52.039Z",
                    "hidden": false
                },
                {
                    "_id": "67a1c1428747511e7b9a1968",
                    "user": {
                        "_id": "636e71b2b0ebc04888157b71",
                        "avatarUrl": "/avatars/957ba705d470e3a01792741d7f0ff038.svg",
                        "isPro": false,
                        "fullname": "Alexey Malakhov",
                        "user": "ZeL1k7",
                        "type": "user"
                    },
                    "name": "Alexey Malakhov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:38:54.121Z",
                    "hidden": false
                },
                {
                    "_id": "67a1c1428747511e7b9a1969",
                    "user": {
                        "_id": "62a9c8edc19f92ae443ab37f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669110208492-62a9c8edc19f92ae443ab37f.png",
                        "isPro": false,
                        "fullname": "Daniil Gavrilov",
                        "user": "kefirski",
                        "type": "user"
                    },
                    "name": "Daniil Gavrilov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:38:57.087Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T10:54:14.000Z",
            "title": "The Differences Between Direct Alignment Algorithms are a Blur",
            "summary": "Direct Alignment Algorithms (DAAs) simplify language model alignment by\nreplacing reinforcement learning (RL) and reward modeling (RM) in Reinforcement\nLearning from Human Feedback (RLHF) with direct policy optimization. DAAs can\nbe classified by their ranking losses (pairwise vs. pointwise), by the rewards\nused in those losses (e.g., likelihood ratios of policy and reference policy,\nor odds ratios), or by whether a Supervised Fine-Tuning (SFT) phase is required\n(two-stage vs. one-stage). We first show that one-stage methods underperform\ntwo-stage methods. To address this, we incorporate an explicit SFT phase and\nintroduce the beta parameter, controlling the strength of preference\noptimization, into single-stage ORPO and ASFT. These modifications improve\ntheir performance in Alpaca Eval 2 by +3.46 (ORPO) and +8.27 (ASFT),\nmatching two-stage methods like DPO. Further analysis reveals that the key\nfactor is whether the approach uses pairwise or pointwise objectives, rather\nthan the specific implicit reward or loss function. These results highlight the\nimportance of careful evaluation to avoid premature claims of performance gains\nor overall superiority in alignment algorithms.",
            "upvotes": 84,
            "discussionId": "67a1c1438747511e7b9a19ae"
        },
        "publishedAt": "2025-02-04T03:10:49.348Z",
        "title": "The Differences Between Direct Alignment Algorithms are a Blur",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62897fce5d9e25c10e4f319d/ndKErkZSfT5LvqKfIrC7f.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01237.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "62897fce5d9e25c10e4f319d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62897fce5d9e25c10e4f319d/bMlfAyzkNNZlkQ5mCW6Vc.jpeg",
            "fullname": "Alexey Gorbatovski",
            "name": "Myashka",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 7
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.01061",
            "authors": [
                {
                    "_id": "67a1a7a166a8a88726963ef4",
                    "user": {
                        "_id": "64802fcdcc9e514b3b031244",
                        "avatarUrl": "/avatars/cc5979008bdb21a2be9575865dce909b.svg",
                        "isPro": false,
                        "fullname": "Gaojie Lin",
                        "user": "lingaojie",
                        "type": "user"
                    },
                    "name": "Gaojie Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:49:22.604Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a7a166a8a88726963ef5",
                    "user": {
                        "_id": "666c1c980bc5acf176808bcf",
                        "avatarUrl": "/avatars/3930b46046565dab7685704ddb428e14.svg",
                        "isPro": false,
                        "fullname": "jianwen jiang",
                        "user": "janphu",
                        "type": "user"
                    },
                    "name": "Jianwen Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:49:28.420Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a7a166a8a88726963ef6",
                    "name": "Jiaqi Yang",
                    "hidden": false
                },
                {
                    "_id": "67a1a7a166a8a88726963ef7",
                    "user": {
                        "_id": "65b0b6d00648e8d10b609066",
                        "avatarUrl": "/avatars/071d2a99f6d7a4e37d338e58d46c4bc2.svg",
                        "isPro": false,
                        "fullname": "ZZerong",
                        "user": "zerong2",
                        "type": "user"
                    },
                    "name": "Zerong Zheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:50:10.474Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a7a166a8a88726963ef8",
                    "name": "Chao Liang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T05:17:32.000Z",
            "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human\n  Animation Models",
            "summary": "End-to-end human animation, such as audio-driven talking human generation,\nhas undergone notable advancements in the recent few years. However, existing\nmethods still struggle to scale up as large general video generation models,\nlimiting their potential in real applications. In this paper, we propose\nOmniHuman, a Diffusion Transformer-based framework that scales up data by\nmixing motion-related conditions into the training phase. To this end, we\nintroduce two training principles for these mixed conditions, along with the\ncorresponding model architecture and inference strategy. These designs enable\nOmniHuman to fully leverage data-driven motion generation, ultimately achieving\nhighly realistic human video generation. More importantly, OmniHuman supports\nvarious portrait contents (face close-up, portrait, half-body, full-body),\nsupports both talking and singing, handles human-object interactions and\nchallenging body poses, and accommodates different image styles. Compared to\nexisting end-to-end audio-driven methods, OmniHuman not only produces more\nrealistic videos, but also offers greater flexibility in inputs. It also\nsupports multiple driving modalities (audio-driven, video-driven and combined\ndriving signals). Video samples are provided on the ttfamily project page\n(https://omnihuman-lab.github.io)",
            "upvotes": 78,
            "discussionId": "67a1a7a466a8a88726963f90"
        },
        "publishedAt": "2025-02-04T00:37:57.949Z",
        "title": "OmniHuman-1: Rethinking the Scaling-Up of One-Stage Conditioned Human Animation Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01061.png",
        "numComments": 5,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5941
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01456",
            "authors": [
                {
                    "_id": "67a19d705efa4fab15497775",
                    "user": {
                        "_id": "650eba9555dc1e841746f132",
                        "avatarUrl": "/avatars/af6f5ee78f161d25ec0afc45d2def8eb.svg",
                        "isPro": false,
                        "fullname": "Ganqu Cui",
                        "user": "ganqu",
                        "type": "user"
                    },
                    "name": "Ganqu Cui",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:23.889Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497776",
                    "name": "Lifan Yuan",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497777",
                    "name": "Zefan Wang",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497778",
                    "user": {
                        "_id": "6321152b8c0da827c72c7c16",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678783813705-6321152b8c0da827c72c7c16.jpeg",
                        "isPro": false,
                        "fullname": "Hanbin Wang",
                        "user": "hanbin",
                        "type": "user"
                    },
                    "name": "Hanbin Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:25.869Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497779",
                    "user": {
                        "_id": "671bfaa29e5e675c7f5c4307",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/PwDA6OSSAmg6k4LliEQkZ.png",
                        "isPro": false,
                        "fullname": "Wendi Li",
                        "user": "wendili",
                        "type": "user"
                    },
                    "name": "Wendi Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:51:24.261Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab1549777a",
                    "user": {
                        "_id": "64c5e944979493279b700cb2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/vjFuPWw8Vl7b7gXB19Sk-.jpeg",
                        "isPro": false,
                        "fullname": "Bingxiang He",
                        "user": "hbx",
                        "type": "user"
                    },
                    "name": "Bingxiang He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:51:31.090Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab1549777b",
                    "user": {
                        "_id": "672c2d7816766a76a747b7b5",
                        "avatarUrl": "/avatars/12c7b26d2b81721ccac3a5c71e32a1a1.svg",
                        "isPro": false,
                        "fullname": "Yuchen Fan",
                        "user": "yuchenFan",
                        "type": "user"
                    },
                    "name": "Yuchen Fan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:51:56.597Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab1549777c",
                    "user": {
                        "_id": "64abc4aa6cadc7aca585dddf",
                        "avatarUrl": "/avatars/736afea979cd0021c7a37f68731524ea.svg",
                        "isPro": false,
                        "fullname": "Tianyu Yu",
                        "user": "Yirany",
                        "type": "user"
                    },
                    "name": "Tianyu Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:52:26.615Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab1549777d",
                    "name": "Qixin Xu",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab1549777e",
                    "user": {
                        "_id": "648312243b7fe59c876c0dca",
                        "avatarUrl": "/avatars/c26ad76cd213529e4670bb599b8199bb.svg",
                        "isPro": false,
                        "fullname": "weize",
                        "user": "weizechen",
                        "type": "user"
                    },
                    "name": "Weize Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:52:46.343Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab1549777f",
                    "name": "Jiarui Yuan",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497780",
                    "user": {
                        "_id": "6630f87ee53fcb71c3887df0",
                        "avatarUrl": "/avatars/50191a3d45bebf90cf08df09477e95db.svg",
                        "isPro": false,
                        "fullname": "HuayuChen",
                        "user": "HuayuChen",
                        "type": "user"
                    },
                    "name": "Huayu Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:53:06.620Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497781",
                    "user": {
                        "_id": "6621f365313c12da6713d336",
                        "avatarUrl": "/avatars/bb1d7e0369a279c4d33408c8a1ae67bb.svg",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "Kaiyanzhang",
                        "type": "user"
                    },
                    "name": "Kaiyan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:53:14.100Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497782",
                    "user": {
                        "_id": "663f07d029be04778ba97871",
                        "avatarUrl": "/avatars/fb7c9d4a2c537d918a3267e7cbc03f04.svg",
                        "isPro": false,
                        "fullname": "Xingtai Lv",
                        "user": "XingtaiHF",
                        "type": "user"
                    },
                    "name": "Xingtai Lv",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:53:21.172Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497783",
                    "name": "Shuo Wang",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497784",
                    "name": "Yuan Yao",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497785",
                    "name": "Xu Han",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497786",
                    "name": "Hao Peng",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497787",
                    "user": {
                        "_id": "67017abfe4d49b157ac534d9",
                        "avatarUrl": "/avatars/997e1b9f54b27a7728a9d4abfee4ba91.svg",
                        "isPro": false,
                        "fullname": "Yu Cheng",
                        "user": "ych133",
                        "type": "user"
                    },
                    "name": "Yu Cheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T14:48:37.956Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497788",
                    "user": {
                        "_id": "6310a3cd531cc21f9e06de6a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6310a3cd531cc21f9e06de6a/aTGMx3O41lUARK9s3dAik.jpeg",
                        "isPro": false,
                        "fullname": "Zhiyuan Liu",
                        "user": "acharkq",
                        "type": "user"
                    },
                    "name": "Zhiyuan Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:53:42.497Z",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab15497789",
                    "name": "Maosong Sun",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab1549778a",
                    "name": "Bowen Zhou",
                    "hidden": false
                },
                {
                    "_id": "67a19d705efa4fab1549778b",
                    "name": "Ning Ding",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T15:43:48.000Z",
            "title": "Process Reinforcement through Implicit Rewards",
            "summary": "Dense process rewards have proven a more effective alternative to the sparse\noutcome-level rewards in the inference-time scaling of large language models\n(LLMs), particularly in tasks requiring complex multi-step reasoning. While\ndense rewards also offer an appealing choice for the reinforcement learning\n(RL) of LLMs since their fine-grained rewards have the potential to address\nsome inherent issues of outcome rewards, such as training efficiency and credit\nassignment, this potential remains largely unrealized. This can be primarily\nattributed to the challenges of training process reward models (PRMs) online,\nwhere collecting high-quality process labels is prohibitively expensive, making\nthem particularly vulnerable to reward hacking. To address these challenges, we\npropose PRIME (Process Reinforcement through IMplicit rEwards), which enables\nonline PRM updates using only policy rollouts and outcome labels through\nimplict process rewards. PRIME combines well with various advantage functions\nand forgoes the dedicated reward model training phrase that existing approaches\nrequire, substantially reducing the development overhead. We demonstrate\nPRIME's effectiveness on competitional math and coding. Starting from\nQwen2.5-Math-7B-Base, PRIME achieves a 15.1% average improvement across several\nkey reasoning benchmarks over the SFT model. Notably, our resulting model,\nEurus-2-7B-PRIME, surpasses Qwen2.5-Math-7B-Instruct on seven reasoning\nbenchmarks with 10% of its training data.",
            "upvotes": 44,
            "discussionId": "67a19d705efa4fab154977d0"
        },
        "publishedAt": "2025-02-04T00:02:39.922Z",
        "title": "Process Reinforcement through Implicit Rewards",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01456.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6321152b8c0da827c72c7c16",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678783813705-6321152b8c0da827c72c7c16.jpeg",
            "fullname": "Hanbin Wang",
            "name": "hanbin",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 13
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01341",
            "authors": [
                {
                    "_id": "67a236ba5f63ce00e8402d56",
                    "user": {
                        "_id": "63efd75a5c2ceb16fc6e98fc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63efd75a5c2ceb16fc6e98fc/qoA4LKuLTEr7hx90i90UK.jpeg",
                        "isPro": true,
                        "fullname": "Ahmed Masry",
                        "user": "ahmed-masry",
                        "type": "user"
                    },
                    "name": "Ahmed Masry",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T16:54:31.623Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d57",
                    "user": {
                        "_id": "63507c18aef7e7f6cf476017",
                        "avatarUrl": "/avatars/183a74624b9daec613a57d405fa577bf.svg",
                        "isPro": false,
                        "fullname": "Juan A. Rodriguez",
                        "user": "joanrod",
                        "type": "user"
                    },
                    "name": "Juan A. Rodriguez",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:15:38.988Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d58",
                    "user": {
                        "_id": "6452d79149b6b9a2383b5775",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/T28lP0kE7PZIGzJjhSpSx.jpeg",
                        "isPro": false,
                        "fullname": "Tianyu Zhang",
                        "user": "TianyuZhang",
                        "type": "user"
                    },
                    "name": "Tianyu Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:15:45.137Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d59",
                    "user": {
                        "_id": "62bb1e0f3ff437e49a3088e5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62bb1e0f3ff437e49a3088e5/bcUQmH8tKfI6DIWH9IcYp.jpeg",
                        "isPro": false,
                        "fullname": "Suyuchen Wang",
                        "user": "sheryc",
                        "type": "user"
                    },
                    "name": "Suyuchen Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T16:54:29.585Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d5a",
                    "name": "Chao Wang",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d5b",
                    "user": {
                        "_id": "6752203d99b478caa1e85a79",
                        "avatarUrl": "/avatars/29284c6cb11d45a640bf3871954007ed.svg",
                        "isPro": false,
                        "fullname": "Aarash Feizi",
                        "user": "feiziaarash",
                        "type": "user"
                    },
                    "name": "Aarash Feizi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:33:25.590Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d5c",
                    "name": "Akshay Kalkunte Suresh",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d5d",
                    "user": {
                        "_id": "65830af2a1707aa10effcc32",
                        "avatarUrl": "/avatars/0626454399b711fca7fb2b66fcecaca8.svg",
                        "isPro": false,
                        "fullname": "Abhay Puri",
                        "user": "abhaypuri",
                        "type": "user"
                    },
                    "name": "Abhay Puri",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:33:52.015Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d5e",
                    "user": {
                        "_id": "66155491f1214e73d69074b5",
                        "avatarUrl": "/avatars/00572ab695a4188422e8ee38fc87680b.svg",
                        "isPro": false,
                        "fullname": "Xiangru Jian",
                        "user": "EdwardXJ",
                        "type": "user"
                    },
                    "name": "Xiangru Jian",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:33:57.470Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d5f",
                    "user": {
                        "_id": "646cc16b94eb019a96e1fb2e",
                        "avatarUrl": "/avatars/31f168a6c1ec45eb0c784d9119c1b9bf.svg",
                        "isPro": false,
                        "fullname": "Pierre-Andre Noel",
                        "user": "PierreAndreNoel",
                        "type": "user"
                    },
                    "name": "Pierre-André Noël",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:34:03.702Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d60",
                    "user": {
                        "_id": "63d3095c2727d7888cbb54e2",
                        "avatarUrl": "/avatars/51fd37f4216eec309cd439e56626d6ad.svg",
                        "isPro": false,
                        "fullname": "Sathwik Tejaswi Madhusudhan",
                        "user": "stm4",
                        "type": "user"
                    },
                    "name": "Sathwik Tejaswi Madhusudhan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:34:10.257Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d61",
                    "user": {
                        "_id": "64b829042fccad9f5ff20cc7",
                        "avatarUrl": "/avatars/92cca111ddd0db5d998615c2257a0894.svg",
                        "isPro": false,
                        "fullname": "Marco Pedersoli",
                        "user": "Marcopede",
                        "type": "user"
                    },
                    "name": "Marco Pedersoli",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:34:16.472Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d62",
                    "name": "Bang Liu",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d63",
                    "user": {
                        "_id": "631f54aa5ba8c026340b13cf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631f54aa5ba8c026340b13cf/2jI0VUDG5cKkdf2C5KJuy.png",
                        "isPro": false,
                        "fullname": "Nicolas Chapados",
                        "user": "nicolaschapados",
                        "type": "user"
                    },
                    "name": "Nicolas Chapados",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:34:23.259Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d64",
                    "name": "Yoshua Bengio",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d65",
                    "user": {
                        "_id": "6706c57876c98ec236f2f090",
                        "avatarUrl": "/avatars/d45543b65b70f03a71dcd378a6ce931b.svg",
                        "isPro": false,
                        "fullname": "Enamul Hoque",
                        "user": "enamulhoque1",
                        "type": "user"
                    },
                    "name": "Enamul Hoque",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:34:32.793Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d66",
                    "name": "Christopher Pal",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d67",
                    "user": {
                        "_id": "64062855692855e65ae31688",
                        "avatarUrl": "/avatars/e35d22a037b8b35422d3ee982f133076.svg",
                        "isPro": false,
                        "fullname": "Issam Laradji",
                        "user": "issamlaradji",
                        "type": "user"
                    },
                    "name": "Issam H. Laradji",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:34:48.589Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d68",
                    "user": {
                        "_id": "646edffecb6ea6e6b6e1be4c",
                        "avatarUrl": "/avatars/8e1b0312c935ff1338c9fb74046fce02.svg",
                        "isPro": false,
                        "fullname": "David Vazquez",
                        "user": "DavidVazquez",
                        "type": "user"
                    },
                    "name": "David Vazquez",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:35:01.844Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d69",
                    "name": "Perouz Taslakian",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d6a",
                    "user": {
                        "_id": "65ca8745d64d82c92fa7c71f",
                        "avatarUrl": "/avatars/4f475609f1573cd671e82122c7097f45.svg",
                        "isPro": false,
                        "fullname": "G",
                        "user": "spandanagella",
                        "type": "user"
                    },
                    "name": "Spandana Gella",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:35:14.497Z",
                    "hidden": false
                },
                {
                    "_id": "67a236ba5f63ce00e8402d6b",
                    "name": "Sai Rajeswar",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T13:34:51.000Z",
            "title": "AlignVLM: Bridging Vision and Language Latent Spaces for Multimodal\n  Understanding",
            "summary": "Aligning visual features with language embeddings is a key challenge in\nvision-language models (VLMs). The performance of such models hinges on having\na good connector that maps visual features generated by a vision encoder to a\nshared embedding space with the LLM while preserving semantic similarity.\nExisting connectors, such as multilayer perceptrons (MLPs), often produce\nout-of-distribution or noisy inputs, leading to misalignment between the\nmodalities. In this work, we propose a novel vision-text alignment method,\nAlignVLM, that maps visual features to a weighted average of LLM text\nembeddings. Our approach leverages the linguistic priors encoded by the LLM to\nensure that visual features are mapped to regions of the space that the LLM can\neffectively interpret. AlignVLM is particularly effective for document\nunderstanding tasks, where scanned document images must be accurately mapped to\ntheir textual content. Our extensive experiments show that AlignVLM achieves\nstate-of-the-art performance compared to prior alignment methods. We provide\nfurther analysis demonstrating improved vision-text feature alignment and\nrobustness to noise.",
            "upvotes": 25,
            "discussionId": "67a236bb5f63ce00e8402ddc"
        },
        "publishedAt": "2025-02-04T10:51:54.103Z",
        "title": "AlignVLM: Bridging Vision and Language Latent Spaces for Multimodal Understanding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01341.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63efd75a5c2ceb16fc6e98fc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63efd75a5c2ceb16fc6e98fc/qoA4LKuLTEr7hx90i90UK.jpeg",
            "fullname": "Ahmed Masry",
            "name": "ahmed-masry",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 52
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2501.18636",
            "authors": [
                {
                    "_id": "67a1bfc314cba2eba6da4b2b",
                    "name": "Xun Liang",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b2c",
                    "user": {
                        "_id": "66daea8776dbaaa372eabec5",
                        "avatarUrl": "/avatars/1e5fbe4ff06bb6121c7029253b76b79f.svg",
                        "isPro": false,
                        "fullname": "siminniu",
                        "user": "siminniu",
                        "type": "user"
                    },
                    "name": "Simin Niu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:11:40.648Z",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b2d",
                    "user": {
                        "_id": "661ef43ff65a7cf84e2291e1",
                        "avatarUrl": "/avatars/cf90dba5934763693c800b3708ce4771.svg",
                        "isPro": false,
                        "fullname": "Zhiyu (Drew) Li",
                        "user": "zhiyuli",
                        "type": "user"
                    },
                    "name": "Zhiyu Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:11:52.391Z",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b2e",
                    "name": "Sensen Zhang",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b2f",
                    "user": {
                        "_id": "669e0b93c7cb0568dac6e92e",
                        "avatarUrl": "/avatars/a39ea77d7391f164af8a80f94f85f2ca.svg",
                        "isPro": false,
                        "fullname": "hanyu Wang",
                        "user": "UglyToilet",
                        "type": "user"
                    },
                    "name": "Hanyu Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:04.452Z",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b30",
                    "name": "Feiyu Xiong",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b31",
                    "name": "Jason Zhaoxin Fan",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b32",
                    "name": "Bo Tang",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b33",
                    "name": "Shichao Song",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b34",
                    "name": "Mengwei Wang",
                    "hidden": false
                },
                {
                    "_id": "67a1bfc314cba2eba6da4b35",
                    "name": "Jiawei Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-28T17:01:31.000Z",
            "title": "SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of\n  Large Language Model",
            "summary": "The indexing-retrieval-generation paradigm of retrieval-augmented generation\n(RAG) has been highly successful in solving knowledge-intensive tasks by\nintegrating external knowledge into large language models (LLMs). However, the\nincorporation of external and unverified knowledge increases the vulnerability\nof LLMs because attackers can perform attack tasks by manipulating knowledge.\nIn this paper, we introduce a benchmark named SafeRAG designed to evaluate the\nRAG security. First, we classify attack tasks into silver noise, inter-context\nconflict, soft ad, and white Denial-of-Service. Next, we construct RAG security\nevaluation dataset (i.e., SafeRAG dataset) primarily manually for each task. We\nthen utilize the SafeRAG dataset to simulate various attack scenarios that RAG\nmay encounter. Experiments conducted on 14 representative RAG components\ndemonstrate that RAG exhibits significant vulnerability to all attack tasks and\neven the most apparent attack task can easily bypass existing retrievers,\nfilters, or advanced LLMs, resulting in the degradation of RAG service quality.\nCode is available at: https://github.com/IAAR-Shanghai/SafeRAG.",
            "upvotes": 25,
            "discussionId": "67a1bfc414cba2eba6da4b63"
        },
        "publishedAt": "2025-02-04T03:22:06.520Z",
        "title": "SafeRAG: Benchmarking Security in Retrieval-Augmented Generation of Large Language Model",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18636.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "62a155e615eeab266b2f2243",
            "avatarUrl": "/avatars/e89ef156e73af028e3ce3664e6cb4e62.svg",
            "fullname": "Zhiyu Li",
            "name": "jimi888",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.01534",
            "authors": [
                {
                    "_id": "67a1ad77d797fac51fa80770",
                    "name": "Dawei Li",
                    "hidden": false
                },
                {
                    "_id": "67a1ad77d797fac51fa80771",
                    "user": {
                        "_id": "653a195b0da86d726c9c580c",
                        "avatarUrl": "/avatars/61649e1d600fdc1edc50ead0dfa99fdd.svg",
                        "isPro": false,
                        "fullname": "Renliang Sun",
                        "user": "RLSNLP",
                        "type": "user"
                    },
                    "name": "Renliang Sun",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:11.035Z",
                    "hidden": false
                },
                {
                    "_id": "67a1ad77d797fac51fa80772",
                    "name": "Yue Huang",
                    "hidden": false
                },
                {
                    "_id": "67a1ad77d797fac51fa80773",
                    "user": {
                        "_id": "61d53df2062444ea769d3b79",
                        "avatarUrl": "/avatars/fa771202368b6b2626a8fdf1c4369239.svg",
                        "isPro": false,
                        "fullname": "Ming Zhong",
                        "user": "MingZhong",
                        "type": "user"
                    },
                    "name": "Ming Zhong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T14:54:39.212Z",
                    "hidden": false
                },
                {
                    "_id": "67a1ad77d797fac51fa80774",
                    "name": "Bohan Jiang",
                    "hidden": false
                },
                {
                    "_id": "67a1ad77d797fac51fa80775",
                    "name": "Jiawei Han",
                    "hidden": false
                },
                {
                    "_id": "67a1ad77d797fac51fa80776",
                    "user": {
                        "_id": "605a97d9b54d35bc67a4ff12",
                        "avatarUrl": "/avatars/7a48a2dac4e6ebb9e775022e15ddc5a7.svg",
                        "isPro": false,
                        "fullname": "zhangxiangliang",
                        "user": "ZhangXiangliang",
                        "type": "user"
                    },
                    "name": "Xiangliang Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:14:47.621Z",
                    "hidden": false
                },
                {
                    "_id": "67a1ad77d797fac51fa80777",
                    "user": {
                        "_id": "62fa0ffe0697d224219a0cb7",
                        "avatarUrl": "/avatars/f0ef59e1c0cf4ab4fe5cee08d488bd03.svg",
                        "isPro": false,
                        "fullname": "Wei Wang",
                        "user": "WeiWang",
                        "type": "user"
                    },
                    "name": "Wei Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:14:54.615Z",
                    "hidden": false
                },
                {
                    "_id": "67a1ad77d797fac51fa80778",
                    "name": "Huan Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T17:13:03.000Z",
            "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
            "summary": "Large Language Models (LLMs) as judges and LLM-based data synthesis have\nemerged as two fundamental LLM-driven data annotation methods in model\ndevelopment. While their combination significantly enhances the efficiency of\nmodel training and evaluation, little attention has been given to the potential\ncontamination brought by this new model development paradigm. In this work, we\nexpose preference leakage, a contamination problem in LLM-as-a-judge caused by\nthe relatedness between the synthetic data generators and LLM-based evaluators.\nTo study this issue, we first define three common relatednesses between data\ngenerator LLM and judge LLM: being the same model, having an inheritance\nrelationship, and belonging to the same model family. Through extensive\nexperiments, we empirically confirm the bias of judges towards their related\nstudent models caused by preference leakage across multiple LLM baselines and\nbenchmarks. Further analysis suggests that preference leakage is a pervasive\nissue that is harder to detect compared to previously identified biases in\nLLM-as-a-judge scenarios. All of these findings imply that preference leakage\nis a widespread and challenging problem in the area of LLM-as-a-judge. We\nrelease all codes and data at:\nhttps://github.com/David-Li0406/Preference-Leakage.",
            "upvotes": 25,
            "discussionId": "67a1ad78d797fac51fa807c1"
        },
        "publishedAt": "2025-02-04T01:04:33.630Z",
        "title": "Preference Leakage: A Contamination Problem in LLM-as-a-judge",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01534.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6474e1afb68461d5cf7c41cc",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6474e1afb68461d5cf7c41cc/bcoiD_qPrjHUBlB259djg.png",
            "fullname": "Dawei Li",
            "name": "wjldw",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.01639",
            "authors": [
                {
                    "_id": "67a20a822cf1b98052d941d1",
                    "user": {
                        "_id": "636daf1b56c0762cfda074b5",
                        "avatarUrl": "/avatars/f44be5eb110acfa2efbd09de6b416239.svg",
                        "isPro": false,
                        "fullname": "Rohit Gandikota",
                        "user": "RohitGandikota",
                        "type": "user"
                    },
                    "name": "Rohit Gandikota",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T17:11:21.938Z",
                    "hidden": false
                },
                {
                    "_id": "67a20a822cf1b98052d941d2",
                    "user": {
                        "_id": "62f923adebd15ad7b5b22141",
                        "avatarUrl": "/avatars/3454aa0bbbe4f119c551f7e9b522afa8.svg",
                        "isPro": false,
                        "fullname": "Zongze Wu",
                        "user": "ZongzeWu",
                        "type": "user"
                    },
                    "name": "Zongze Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:38:03.547Z",
                    "hidden": false
                },
                {
                    "_id": "67a20a822cf1b98052d941d3",
                    "name": "Richard Zhang",
                    "hidden": false
                },
                {
                    "_id": "67a20a822cf1b98052d941d4",
                    "user": {
                        "_id": "6214d6c01e35c843d42d1f77",
                        "avatarUrl": "/avatars/ac208cd180b4f3ed1ec367e581facfcf.svg",
                        "isPro": false,
                        "fullname": "David Bau",
                        "user": "davidbau",
                        "type": "user"
                    },
                    "name": "David Bau",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:38:13.109Z",
                    "hidden": false
                },
                {
                    "_id": "67a20a822cf1b98052d941d5",
                    "name": "Eli Shechtman",
                    "hidden": false
                },
                {
                    "_id": "67a20a822cf1b98052d941d6",
                    "name": "Nick Kolkin",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T18:59:55.000Z",
            "title": "SliderSpace: Decomposing the Visual Capabilities of Diffusion Models",
            "summary": "We present SliderSpace, a framework for automatically decomposing the visual\ncapabilities of diffusion models into controllable and human-understandable\ndirections. Unlike existing control methods that require a user to specify\nattributes for each edit direction individually, SliderSpace discovers multiple\ninterpretable and diverse directions simultaneously from a single text prompt.\nEach direction is trained as a low-rank adaptor, enabling compositional control\nand the discovery of surprising possibilities in the model's latent space.\nThrough extensive experiments on state-of-the-art diffusion models, we\ndemonstrate SliderSpace's effectiveness across three applications: concept\ndecomposition, artistic style exploration, and diversity enhancement. Our\nquantitative evaluation shows that SliderSpace-discovered directions decompose\nthe visual structure of model's knowledge effectively, offering insights into\nthe latent capabilities encoded within diffusion models. User studies further\nvalidate that our method produces more diverse and useful variations compared\nto baselines. Our code, data and trained weights are available at\nhttps://sliderspace.baulab.info",
            "upvotes": 17,
            "discussionId": "67a20a892cf1b98052d943dd"
        },
        "publishedAt": "2025-02-04T07:40:38.331Z",
        "title": "SliderSpace: Decomposing the Visual Capabilities of Diffusion Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01639.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "636daf1b56c0762cfda074b5",
            "avatarUrl": "/avatars/f44be5eb110acfa2efbd09de6b416239.svg",
            "fullname": "Rohit Gandikota",
            "name": "RohitGandikota",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 6
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.00698",
            "authors": [
                {
                    "_id": "67a1b8afe03dbbbbb51bb5c1",
                    "user": {
                        "_id": "633b99cfc9b44f5c6ac8fe03",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633b99cfc9b44f5c6ac8fe03/sFmpPlWwo07ttcWWuV1Iw.jpeg",
                        "isPro": false,
                        "fullname": "huanqiacai",
                        "user": "huanqia",
                        "type": "user"
                    },
                    "name": "Huanqia Cai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:06.531Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b8afe03dbbbbb51bb5c2",
                    "user": {
                        "_id": "645e553c3b6d85c65e8b0e54",
                        "avatarUrl": "/avatars/1fffc6499b9d65b21a895ca96f03b781.svg",
                        "isPro": false,
                        "fullname": "Steven",
                        "user": "yijunyang",
                        "type": "user"
                    },
                    "name": "Yijun Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T14:48:36.068Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b8afe03dbbbbb51bb5c3",
                    "name": "Winston Hu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-02T07:12:03.000Z",
            "title": "MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal\n  Models",
            "summary": "IQ testing has served as a foundational methodology for evaluating human\ncognitive capabilities, deliberately decoupling assessment from linguistic\nbackground, language proficiency, or domain-specific knowledge to isolate core\ncompetencies in abstraction and reasoning. Yet, artificial intelligence\nresearch currently lacks systematic benchmarks to quantify these critical\ncognitive dimensions in multimodal systems. To address this critical gap, we\npropose MM-IQ, a comprehensive evaluation framework comprising 2,710\nmeticulously curated test items spanning 8 distinct reasoning paradigms.\n  Through systematic evaluation of leading open-source and proprietary\nmultimodal models, our benchmark reveals striking limitations: even\nstate-of-the-art architectures achieve only marginally superior performance to\nrandom chance (27.49% vs. 25% baseline accuracy). This substantial performance\nchasm highlights the inadequacy of current multimodal systems in approximating\nfundamental human reasoning capacities, underscoring the need for\nparadigm-shifting advancements to bridge this cognitive divide.",
            "upvotes": 15,
            "discussionId": "67a1b8b1e03dbbbbb51bb613"
        },
        "publishedAt": "2025-02-04T07:50:53.886Z",
        "title": "MM-IQ: Benchmarking Human-Like Abstraction and Reasoning in Multimodal Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00698.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "633b99cfc9b44f5c6ac8fe03",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633b99cfc9b44f5c6ac8fe03/sFmpPlWwo07ttcWWuV1Iw.jpeg",
            "fullname": "huanqiacai",
            "name": "huanqia",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01068",
            "authors": [
                {
                    "_id": "67a1a75f6aa8429da4945eeb",
                    "user": {
                        "_id": "639ffbc6beb95d698de9640d",
                        "avatarUrl": "/avatars/7ef1aaadd5b378d00e17dc548e42cb7e.svg",
                        "isPro": false,
                        "fullname": "Dongwon Jo",
                        "user": "dongwonjo",
                        "type": "user"
                    },
                    "name": "Dongwon Jo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:16.125Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a75f6aa8429da4945eec",
                    "user": {
                        "_id": "662672eaebdfec5cfdf1d034",
                        "avatarUrl": "/avatars/61bc7add693c555e29ad3c1112215684.svg",
                        "isPro": false,
                        "fullname": "Jiwon Song",
                        "user": "jiwonsong",
                        "type": "user"
                    },
                    "name": "Jiwon Song",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:14.253Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a75f6aa8429da4945eed",
                    "user": {
                        "_id": "6566ddb96af53c602f80b1e2",
                        "avatarUrl": "/avatars/403c8e486115920e50867b6462ddfd99.svg",
                        "isPro": false,
                        "fullname": "Yulhwa Kim",
                        "user": "YulhwaKim",
                        "type": "user"
                    },
                    "name": "Yulhwa Kim",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:35:45.706Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a75f6aa8429da4945eee",
                    "name": "Jae-Joon Kim",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T05:25:09.000Z",
            "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with\n  Token-Selective Propagation",
            "summary": "While large language models (LLMs) excel at handling long-context sequences,\nthey require substantial key-value (KV) caches to store contextual information,\nwhich can heavily burden computational efficiency and memory usage. Previous\nefforts to compress these KV caches primarily focused on reducing memory\ndemands but were limited in enhancing latency. To address this issue, we\nintroduce FastKV, a KV cache compression method designed to enhance latency for\nlong-context sequences. To enhance processing speeds while maintaining\naccuracy, FastKV adopts a novel Token-Selective Propagation (TSP) approach that\nretains the full context information in the initial layers of LLMs and\nselectively propagates only a portion of this information in deeper layers even\nin the prefill stage. Additionally, FastKV incorporates grouped-query attention\n(GQA)-aware KV cache compression to exploit the advantages of GQA in both\nmemory and computational efficiency. Our experimental results show that FastKV\nachieves 2.00times and 1.40times improvements in time-to-first-token\n(TTFT) and throughput, respectively, compared to HeadKV, the state-of-the-art\nKV cache compression method. Moreover, FastKV successfully maintains accuracy\non long-context benchmarks at levels comparable to the baselines. Our code is\navailable at https://github.com/dongwonjo/FastKV.",
            "upvotes": 12,
            "discussionId": "67a1a7616aa8429da4945f95"
        },
        "publishedAt": "2025-02-04T00:45:45.545Z",
        "title": "FastKV: KV Cache Compression for Fast Long-Context Processing with Token-Selective Propagation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01068.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "639ffbc6beb95d698de9640d",
            "avatarUrl": "/avatars/7ef1aaadd5b378d00e17dc548e42cb7e.svg",
            "fullname": "Dongwon Jo",
            "name": "dongwonjo",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.00094",
            "authors": [
                {
                    "_id": "67a185ab908f4534beb94b8c",
                    "user": {
                        "_id": "656864e12d73834278a8dea7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
                        "isPro": true,
                        "fullname": "Ahmed Heakl",
                        "user": "ahmedheakl",
                        "type": "user"
                    },
                    "name": "Ahmed Heakl",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:32.712Z",
                    "hidden": false
                },
                {
                    "_id": "67a185ab908f4534beb94b8d",
                    "name": "Sara Ghaboura",
                    "hidden": false
                },
                {
                    "_id": "67a185ab908f4534beb94b8e",
                    "name": "Omkar Thawkar",
                    "hidden": false
                },
                {
                    "_id": "67a185ab908f4534beb94b8f",
                    "name": "Fahad Shahbaz Khan",
                    "hidden": false
                },
                {
                    "_id": "67a185ab908f4534beb94b90",
                    "user": {
                        "_id": "654a5f4f9b8bd6406d45bb46",
                        "avatarUrl": "/avatars/ac0d7eef62cd98a280b162cf7896b1a2.svg",
                        "isPro": false,
                        "fullname": "Hisham Cholakkal",
                        "user": "hishamcholakkal",
                        "type": "user"
                    },
                    "name": "Hisham Cholakkal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:36:17.368Z",
                    "hidden": false
                },
                {
                    "_id": "67a185ab908f4534beb94b91",
                    "name": "Rao Muhammad Anwer",
                    "hidden": false
                },
                {
                    "_id": "67a185ab908f4534beb94b92",
                    "user": {
                        "_id": "65337cfbbadc49780755d1d1",
                        "avatarUrl": "/avatars/527f456a6a95e0b3a143be130b9b9258.svg",
                        "isPro": false,
                        "fullname": "Salman Khan",
                        "user": "SalmanKhan",
                        "type": "user"
                    },
                    "name": "Salman Khan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:36:30.190Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-31T18:58:20.000Z",
            "title": "AIN: The Arabic INclusive Large Multimodal Model",
            "summary": "Amid the swift progress of large language models (LLMs) and their evolution\ninto large multimodal models (LMMs), significant strides have been made in\nhigh-resource languages such as English and Chinese. While Arabic LLMs have\nseen notable progress, Arabic LMMs remain largely unexplored, often narrowly\nfocusing on a few specific aspects of the language and visual understanding. To\nbridge this gap, we introduce AIN-the Arabic Inclusive Multimodal\nModel-designed to excel across diverse domains. AIN is an English-Arabic\nbilingual LMM designed to excel in English and Arabic, leveraging carefully\nconstructed 3.6 million high-quality Arabic-English multimodal data samples.\nAIN demonstrates state-of-the-art Arabic performance, while also possessing\nstrong English-language visual capabilities. On the recent CAMEL-Bench\nbenchmark comprising 38 sub-domains including, multi-image understanding,\ncomplex visual perception, handwritten document understanding, video\nunderstanding, medical imaging, plant diseases, and remote sensing-based land\nuse understanding, our AIN demonstrates strong performance with the 7B model\noutperforming GPT-4o by an absolute gain of 3.4% averaged over eight domains\nand 38 sub-domains. AIN's superior capabilities position it as a significant\nstep toward empowering Arabic speakers with advanced multimodal generative AI\ntools across diverse applications.",
            "upvotes": 12,
            "discussionId": "67a185b0908f4534beb94c49"
        },
        "publishedAt": "2025-02-03T22:22:44.375Z",
        "title": "AIN: The Arabic INclusive Large Multimodal Model",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/mmf9V_8rdsi9hN-QdFZV8.png",
            "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/uLq0E1qq75-P4P1KV4xWF.png",
            "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/1eixiKjHGNVm6RaJpdWeq.png",
            "https://cdn-uploads.huggingface.co/production/uploads/656864e12d73834278a8dea7/XVJSPAgIQcQn8Zi4gUVwi.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00094.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "656864e12d73834278a8dea7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/656864e12d73834278a8dea7/sfAWS2eyPtFHb_2GZIypp.jpeg",
            "fullname": "Ahmed Heakl",
            "name": "ahmedheakl",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 18
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01637",
            "authors": [
                {
                    "_id": "67a1a51e6aa8429da493d0b5",
                    "name": "Da Yu",
                    "hidden": false
                },
                {
                    "_id": "67a1a51e6aa8429da493d0b6",
                    "name": "Edith Cohen",
                    "hidden": false
                },
                {
                    "_id": "67a1a51e6aa8429da493d0b7",
                    "name": "Badih Ghazi",
                    "hidden": false
                },
                {
                    "_id": "67a1a51e6aa8429da493d0b8",
                    "user": {
                        "_id": "645949e7ecf89b6a375ff129",
                        "avatarUrl": "/avatars/93f167fe70c43328b95ed597b6dfa51b.svg",
                        "isPro": true,
                        "fullname": "Yangsibo Huang",
                        "user": "yangsibo",
                        "type": "user"
                    },
                    "name": "Yangsibo Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:04:05.965Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a51e6aa8429da493d0b9",
                    "user": {
                        "_id": "64c0d2f8d76592ba8996036c",
                        "avatarUrl": "/avatars/7b7720ad2060ac5c36651fee8d43ba69.svg",
                        "isPro": false,
                        "fullname": "Pritish Kamath",
                        "user": "pritishkamath",
                        "type": "user"
                    },
                    "name": "Pritish Kamath",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:04:12.118Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a51e6aa8429da493d0ba",
                    "name": "Ravi Kumar",
                    "hidden": false
                },
                {
                    "_id": "67a1a51e6aa8429da493d0bb",
                    "user": {
                        "_id": "667a19869f78b2d01bc402b1",
                        "avatarUrl": "/avatars/b7fb00826a62e70d2dae5f978b7366f3.svg",
                        "isPro": false,
                        "fullname": "Daogao Liu",
                        "user": "ShyShowmaker",
                        "type": "user"
                    },
                    "name": "Daogao Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T20:58:14.948Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a51e6aa8429da493d0bc",
                    "user": {
                        "_id": "65c65a2ef2d7e1eb92256d1f",
                        "avatarUrl": "/avatars/b02979bc1549a16515c880ce836c3023.svg",
                        "isPro": false,
                        "fullname": "Chiyuan Zhang",
                        "user": "pluspluskid",
                        "type": "user"
                    },
                    "name": "Chiyuan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T20:58:08.569Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T18:59:32.000Z",
            "title": "Scaling Embedding Layers in Language Models",
            "summary": "We propose SCONE (Scalable, Contextualized,\nOffloaded, N-gram Embedding), a method for\nextending input embedding layers to enhance language model performance as layer\nsize scales. To avoid increased decoding costs, SCONE retains the original\nvocabulary while introducing embeddings for a set of frequent n-grams. These\nembeddings provide contextualized representation for each input token and are\nlearned with a separate model during training. During inference, they are\nprecomputed and stored in off-accelerator memory with minimal impact on\ninference speed. SCONE enables two new scaling strategies: increasing the\nnumber of cached n-gram embeddings and scaling the model used to learn them,\nall while maintaining fixed inference-time FLOPS. We show that scaling both\naspects allows SCONE to outperform a 1.9B parameter baseline across diverse\ncorpora, while using only half the inference-time FLOPS.",
            "upvotes": 10,
            "discussionId": "67a1a51e6aa8429da493d0d5"
        },
        "publishedAt": "2025-02-04T00:27:13.960Z",
        "title": "Scaling Embedding Layers in Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01637.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5941
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.01142",
            "authors": [
                {
                    "_id": "67a1b4630e9634919de9bc52",
                    "user": {
                        "_id": "643407dd4b34368fdb0149e8",
                        "avatarUrl": "/avatars/9477b9267d5692a4fe59e30590e9639d.svg",
                        "isPro": false,
                        "fullname": "Xinyan Guan",
                        "user": "xinyan233333",
                        "type": "user"
                    },
                    "name": "Xinyan Guan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:08.849Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b4630e9634919de9bc53",
                    "user": {
                        "_id": "657bef0fff16eeb2ee40ed9c",
                        "avatarUrl": "/avatars/2a436b1d9b04c611a795f10363150aca.svg",
                        "isPro": false,
                        "fullname": "zeng",
                        "user": "zengjiali",
                        "type": "user"
                    },
                    "name": "Jiali Zeng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:36:59.186Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b4630e9634919de9bc54",
                    "user": {
                        "_id": "64cb254871a7bbb60c17d5fa",
                        "avatarUrl": "/avatars/5121fd5b7b55d275eba3947f3f4c034d.svg",
                        "isPro": false,
                        "fullname": "Fandong Meng",
                        "user": "fandong",
                        "type": "user"
                    },
                    "name": "Fandong Meng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:36:44.284Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b4630e9634919de9bc55",
                    "user": {
                        "_id": "667b74b9279199a7c610687f",
                        "avatarUrl": "/avatars/9834e9971579655a4c387a306c610f57.svg",
                        "isPro": false,
                        "fullname": "Chunlei Xin",
                        "user": "meow77",
                        "type": "user"
                    },
                    "name": "Chunlei Xin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:37:04.877Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b4630e9634919de9bc56",
                    "user": {
                        "_id": "6216496a9b34d2fb49144599",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6216496a9b34d2fb49144599/41CKA_h1Ffj3RzVabSAkm.jpeg",
                        "isPro": false,
                        "fullname": "Yaojie Lu",
                        "user": "luyaojie",
                        "type": "user"
                    },
                    "name": "Yaojie Lu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:37:11.297Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b4630e9634919de9bc57",
                    "user": {
                        "_id": "6711c702f858a456b4b9f3a4",
                        "avatarUrl": "/avatars/178e9567c3111ab22717c3c0dd003a6a.svg",
                        "isPro": false,
                        "fullname": "Hongyu  Lin",
                        "user": "sanmusunrise",
                        "type": "user"
                    },
                    "name": "Hongyu Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:37:20.338Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b4630e9634919de9bc58",
                    "user": {
                        "_id": "65e99a77e71555ed193609cf",
                        "avatarUrl": "/avatars/38ceb127883944677665da967d17dd18.svg",
                        "isPro": false,
                        "fullname": "Xianpei Han",
                        "user": "xphan",
                        "type": "user"
                    },
                    "name": "Xianpei Han",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:37:26.589Z",
                    "hidden": false
                },
                {
                    "_id": "67a1b4630e9634919de9bc59",
                    "name": "Le Sun",
                    "hidden": false
                },
                {
                    "_id": "67a1b4630e9634919de9bc5a",
                    "name": "Jie Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T08:22:45.000Z",
            "title": "DeepRAG: Thinking to Retrieval Step by Step for Large Language Models",
            "summary": "Large Language Models (LLMs) have shown remarkable potential in reasoning\nwhile they still suffer from severe factual hallucinations due to timeliness,\naccuracy, and coverage of parametric knowledge. Meanwhile, integrating\nreasoning with retrieval-augmented generation (RAG) remains challenging due to\nineffective task decomposition and redundant retrieval, which can introduce\nnoise and degrade response quality. In this paper, we propose DeepRAG, a\nframework that models retrieval-augmented reasoning as a Markov Decision\nProcess (MDP), enabling strategic and adaptive retrieval. By iteratively\ndecomposing queries, DeepRAG dynamically determines whether to retrieve\nexternal knowledge or rely on parametric reasoning at each step. Experiments\nshow that DeepRAG improves retrieval efficiency while improving answer accuracy\nby 21.99%, demonstrating its effectiveness in optimizing retrieval-augmented\nreasoning.",
            "upvotes": 9,
            "discussionId": "67a1b4640e9634919de9bc8b"
        },
        "publishedAt": "2025-02-04T04:35:57.149Z",
        "title": "DeepRAG: Thinking to Retrieval Step by Step for Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01142.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "643407dd4b34368fdb0149e8",
            "avatarUrl": "/avatars/9477b9267d5692a4fe59e30590e9639d.svg",
            "fullname": "Xinyan Guan",
            "name": "xinyan233333",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01100",
            "authors": [
                {
                    "_id": "67a1a649f4aecd0dfc96ebf4",
                    "user": {
                        "_id": "607f666a4ad99100d63ce35c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/607f666a4ad99100d63ce35c/QxhxnvfeV6efkxwUFHwjI.png",
                        "isPro": false,
                        "fullname": "Bill Yuchen Lin",
                        "user": "yuchenlin",
                        "type": "user"
                    },
                    "name": "Bill Yuchen Lin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:17.972Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a649f4aecd0dfc96ebf5",
                    "user": {
                        "_id": "635049104e753c9940fefd71",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/635049104e753c9940fefd71/HgR43XIFw3dneY5ufrAE8.jpeg",
                        "isPro": false,
                        "fullname": "Ronan Le Bras",
                        "user": "ronanlb",
                        "type": "user"
                    },
                    "name": "Ronan Le Bras",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-04T05:31:56.722Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a649f4aecd0dfc96ebf6",
                    "name": "Kyle Richardson",
                    "hidden": false
                },
                {
                    "_id": "67a1a649f4aecd0dfc96ebf7",
                    "name": "Ashish Sabharwal",
                    "hidden": false
                },
                {
                    "_id": "67a1a649f4aecd0dfc96ebf8",
                    "name": "Radha Poovendran",
                    "hidden": false
                },
                {
                    "_id": "67a1a649f4aecd0dfc96ebf9",
                    "user": {
                        "_id": "64d265cfbe712cda5ab7cc3f",
                        "avatarUrl": "/avatars/caab6fa5764a0271552ae589d352b592.svg",
                        "isPro": false,
                        "fullname": "Peter Clarke",
                        "user": "PeterClarke",
                        "type": "user"
                    },
                    "name": "Peter Clark",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:38:40.973Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a649f4aecd0dfc96ebfa",
                    "user": {
                        "_id": "64d42729f63b01b7f676b176",
                        "avatarUrl": "/avatars/52e54bdd6a1fb6c774a40cd70f3d7925.svg",
                        "isPro": false,
                        "fullname": "Yejin Choi",
                        "user": "yejinchoinka",
                        "type": "user"
                    },
                    "name": "Yejin Choi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:38:53.950Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T06:44:49.000Z",
            "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
            "summary": "We investigate the logical reasoning capabilities of large language models\n(LLMs) and their scalability in complex non-monotonic reasoning. To this end,\nwe introduce ZebraLogic, a comprehensive evaluation framework for assessing LLM\nreasoning performance on logic grid puzzles derived from constraint\nsatisfaction problems (CSPs). ZebraLogic enables the generation of puzzles with\ncontrollable and quantifiable complexity, facilitating a systematic study of\nthe scaling limits of models such as Llama, o1 models, and DeepSeek-R1. By\nencompassing a broad range of search space complexities and diverse logical\nconstraints, ZebraLogic provides a structured environment to evaluate reasoning\nunder increasing difficulty.\n  Our results reveal a significant decline in accuracy as problem complexity\ngrows -- a phenomenon we term the curse of complexity. This limitation persists\neven with larger models and increased inference-time computation, suggesting\ninherent constraints in current LLM reasoning capabilities. Additionally, we\nexplore strategies to enhance logical reasoning, including Best-of-N sampling,\nbacktracking mechanisms, and self-verification prompts. Our findings offer\ncritical insights into the scalability of LLM reasoning, highlight fundamental\nlimitations, and outline potential directions for improvement.",
            "upvotes": 8,
            "discussionId": "67a1a64cf4aecd0dfc96ecb8"
        },
        "publishedAt": "2025-02-04T00:32:03.929Z",
        "title": "ZebraLogic: On the Scaling Limits of LLMs for Logical Reasoning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01100.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5941
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.01081",
            "authors": [
                {
                    "_id": "67a1a56d83c3565727d22f0c",
                    "name": "Vernon Y. H. Toh",
                    "hidden": false
                },
                {
                    "_id": "67a1a56d83c3565727d22f0d",
                    "name": "Yew Ken Chia",
                    "hidden": false
                },
                {
                    "_id": "67a1a56d83c3565727d22f0e",
                    "user": {
                        "_id": "62eced5e7e89e8d34df1a1ea",
                        "avatarUrl": "/avatars/99c9d8ba7e7722b7524d5d687cf96a25.svg",
                        "isPro": false,
                        "fullname": "Deepanway Ghosal",
                        "user": "dghosal",
                        "type": "user"
                    },
                    "name": "Deepanway Ghosal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:40:36.537Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a56d83c3565727d22f0f",
                    "user": {
                        "_id": "626b626405fe1cb65725aca1",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626b626405fe1cb65725aca1/aa-Lata46I3fXOmMetvXH.jpeg",
                        "isPro": false,
                        "fullname": "Soujanya Poria",
                        "user": "soujanyaporia",
                        "type": "user"
                    },
                    "name": "Soujanya Poria",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:40:30.882Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T05:47:04.000Z",
            "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning\n  Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
            "summary": "The releases of OpenAI's o1 and o3 mark a significant paradigm shift in Large\nLanguage Models towards advanced reasoning capabilities. Notably, o3\noutperformed humans in novel problem-solving and skill acquisition on the\nAbstraction and Reasoning Corpus for Artificial General Intelligence (ARC-AGI).\nHowever, this benchmark is limited to symbolic patterns, whereas humans often\nperceive and reason about multimodal scenarios involving both vision and\nlanguage data. Thus, there is an urgent need to investigate advanced reasoning\ncapabilities in multimodal tasks. To this end, we track the evolution of the\nGPT-[n] and o-[n] series models on challenging multimodal puzzles, requiring\nfine-grained visual perception with abstract or algorithmic reasoning. The\nsuperior performance of o1 comes at nearly 750 times the computational cost of\nGPT-4o, raising concerns about its efficiency. Our results reveal a clear\nupward trend in reasoning capabilities across model iterations, with notable\nperformance jumps across GPT-series models and subsequently to o1. Nonetheless,\nwe observe that the o1 model still struggles with simple multimodal puzzles\nrequiring abstract reasoning. Furthermore, its performance in algorithmic\npuzzles remains poor. We plan to continuously track new models in the series\nand update our results in this paper accordingly. All resources used in this\nevaluation are openly available https://github.com/declare-lab/LLM-PuzzleTest.",
            "upvotes": 7,
            "discussionId": "67a1a57083c3565727d22fc6"
        },
        "publishedAt": "2025-02-04T00:28:35.436Z",
        "title": "The Jumping Reasoning Curve? Tracking the Evolution of Reasoning Performance in GPT-[n] and o-[n] Models on Multimodal Puzzles",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01081.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5941
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.01591",
            "authors": [
                {
                    "_id": "67a1a4b72bf092a7612b36eb",
                    "name": "Antoine Dedieu",
                    "hidden": false
                },
                {
                    "_id": "67a1a4b72bf092a7612b36ec",
                    "name": "Joseph Ortiz",
                    "hidden": false
                },
                {
                    "_id": "67a1a4b72bf092a7612b36ed",
                    "user": {
                        "_id": "665c8e13a1ff38df9706379e",
                        "avatarUrl": "/avatars/e0aecfac58ff98c628fd57afee53f791.svg",
                        "isPro": false,
                        "fullname": "xinghua Lou",
                        "user": "nickname-xingxing",
                        "type": "user"
                    },
                    "name": "Xinghua Lou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:08:45.474Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a4b72bf092a7612b36ee",
                    "name": "Carter Wendelken",
                    "hidden": false
                },
                {
                    "_id": "67a1a4b72bf092a7612b36ef",
                    "user": {
                        "_id": "6310ec5d64939fabc00aea54",
                        "avatarUrl": "/avatars/d3fde9392fd30a6d80e2e7989ed4db17.svg",
                        "isPro": false,
                        "fullname": "Wolfgang Lehrach",
                        "user": "wpl",
                        "type": "user"
                    },
                    "name": "Wolfgang Lehrach",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:08:36.618Z",
                    "hidden": false
                },
                {
                    "_id": "67a1a4b72bf092a7612b36f0",
                    "name": "J Swaroop Guntupalli",
                    "hidden": false
                },
                {
                    "_id": "67a1a4b72bf092a7612b36f1",
                    "name": "Miguel Lazaro-Gredilla",
                    "hidden": false
                },
                {
                    "_id": "67a1a4b72bf092a7612b36f2",
                    "name": "Kevin Patrick Murphy",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T18:25:17.000Z",
            "title": "Improving Transformer World Models for Data-Efficient RL",
            "summary": "We present an approach to model-based RL that achieves a new state of the art\nperformance on the challenging Craftax-classic benchmark, an open-world 2D\nsurvival game that requires agents to exhibit a wide range of general abilities\n-- such as strong generalization, deep exploration, and long-term reasoning.\nWith a series of careful design choices aimed at improving sample efficiency,\nour MBRL algorithm achieves a reward of 67.4% after only 1M environment steps,\nsignificantly outperforming DreamerV3, which achieves 53.2%, and, for the first\ntime, exceeds human performance of 65.0%. Our method starts by constructing a\nSOTA model-free baseline, using a novel policy architecture that combines CNNs\nand RNNs. We then add three improvements to the standard MBRL setup: (a) \"Dyna\nwith warmup\", which trains the policy on real and imaginary data, (b) \"nearest\nneighbor tokenizer\" on image patches, which improves the scheme to create the\ntransformer world model (TWM) inputs, and (c) \"block teacher forcing\", which\nallows the TWM to reason jointly about the future tokens of the next timestep.",
            "upvotes": 7,
            "discussionId": "67a1a4b82bf092a7612b371b"
        },
        "publishedAt": "2025-02-04T00:25:52.071Z",
        "title": "Improving Transformer World Models for Data-Efficient RL",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01591.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 5941
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.01208",
            "authors": [
                {
                    "_id": "67a1e729a6c7d65cad72b3d7",
                    "user": {
                        "_id": "6682989afc0e69f80acf2845",
                        "avatarUrl": "/avatars/35d48738965fe21fdd79198a17d6c8cc.svg",
                        "isPro": false,
                        "fullname": "jixiaotong",
                        "user": "xiaotong9515",
                        "type": "user"
                    },
                    "name": "Xiaotong Ji",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:40:16.111Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e729a6c7d65cad72b3d8",
                    "name": "Shyam Sundhar Ramesh",
                    "hidden": false
                },
                {
                    "_id": "67a1e729a6c7d65cad72b3d9",
                    "name": "Matthieu Zimmer",
                    "hidden": false
                },
                {
                    "_id": "67a1e729a6c7d65cad72b3da",
                    "user": {
                        "_id": "65fd58a41a58717c800d3650",
                        "avatarUrl": "/avatars/9dce361a0417465116c816abdf53e916.svg",
                        "isPro": false,
                        "fullname": "Bogunovic",
                        "user": "ilijabogunovic",
                        "type": "user"
                    },
                    "name": "Ilija Bogunovic",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:39:45.148Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e729a6c7d65cad72b3db",
                    "name": "Jun Wang",
                    "hidden": false
                },
                {
                    "_id": "67a1e729a6c7d65cad72b3dc",
                    "user": {
                        "_id": "631c375768f7da9ad2496bf6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631c375768f7da9ad2496bf6/1sDOoecA6e1v_hn_VAgUq.jpeg",
                        "isPro": false,
                        "fullname": "Haitham Bou Ammar",
                        "user": "hba123",
                        "type": "user"
                    },
                    "name": "Haitham Bou Ammar",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T17:39:59.356Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T09:59:32.000Z",
            "title": "Almost Surely Safe Alignment of Large Language Models at Inference-Time",
            "summary": "Even highly capable large language models (LLMs) can produce biased or unsafe\nresponses, and alignment techniques, such as RLHF, aimed at mitigating this\nissue, are expensive and prone to overfitting as they retrain the LLM. This\npaper introduces a novel inference-time alignment approach that ensures LLMs\ngenerate safe responses almost surely, i.e., with a probability approaching\none. We achieve this by framing the safe generation of inference-time responses\nas a constrained Markov decision process within the LLM's latent space.\nCrucially, we augment a safety state that tracks the evolution of safety\nconstraints and enables us to demonstrate formal safety guarantees upon solving\nthe MDP in the latent space. Building on this foundation, we propose\nInferenceGuard, a practical implementation that safely aligns LLMs without\nmodifying the model weights. Empirically, we demonstrate InferenceGuard\neffectively balances safety and task performance, outperforming existing\ninference-time alignment methods in generating safe and aligned responses.",
            "upvotes": 6,
            "discussionId": "67a1e72aa6c7d65cad72b40f"
        },
        "publishedAt": "2025-02-04T05:09:45.473Z",
        "title": "Almost Surely Safe Alignment of Large Language Models at Inference-Time",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/631c375768f7da9ad2496bf6/jINeBtMoT2NBNmd9kSK9g.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01208.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "631c375768f7da9ad2496bf6",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631c375768f7da9ad2496bf6/1sDOoecA6e1v_hn_VAgUq.jpeg",
            "fullname": "Haitham Bou Ammar",
            "name": "hba123",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 13
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01441",
            "authors": [
                {
                    "_id": "67a189e8fbbab3ce03462fb3",
                    "user": {
                        "_id": "63e083e6f351dc0745745d17",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e083e6f351dc0745745d17/N0GE4uLrkm14blAQMnm2E.jpeg",
                        "isPro": false,
                        "fullname": "Quan Dao",
                        "user": "quandao10",
                        "type": "user"
                    },
                    "name": "Quan Dao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:30.529Z",
                    "hidden": false
                },
                {
                    "_id": "67a189e8fbbab3ce03462fb4",
                    "name": "Khanh Doan",
                    "hidden": false
                },
                {
                    "_id": "67a189e8fbbab3ce03462fb5",
                    "name": "Di Liu",
                    "hidden": false
                },
                {
                    "_id": "67a189e8fbbab3ce03462fb6",
                    "user": {
                        "_id": "66db7db231e772c5ec4c5576",
                        "avatarUrl": "/avatars/aa0eb054bd6c881054431a22daf1aea1.svg",
                        "isPro": false,
                        "fullname": "Trung Le",
                        "user": "trungleuc",
                        "type": "user"
                    },
                    "name": "Trung Le",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-04T03:30:50.175Z",
                    "hidden": false
                },
                {
                    "_id": "67a189e8fbbab3ce03462fb7",
                    "name": "Dimitris Metaxas",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T15:25:58.000Z",
            "title": "Improved Training Technique for Latent Consistency Models",
            "summary": "Consistency models are a new family of generative models capable of producing\nhigh-quality samples in either a single step or multiple steps. Recently,\nconsistency models have demonstrated impressive performance, achieving results\non par with diffusion models in the pixel space. However, the success of\nscaling consistency training to large-scale datasets, particularly for\ntext-to-image and video generation tasks, is determined by performance in the\nlatent space. In this work, we analyze the statistical differences between\npixel and latent spaces, discovering that latent data often contains highly\nimpulsive outliers, which significantly degrade the performance of iCT in the\nlatent space. To address this, we replace Pseudo-Huber losses with Cauchy\nlosses, effectively mitigating the impact of outliers. Additionally, we\nintroduce a diffusion loss at early timesteps and employ optimal transport (OT)\ncoupling to further enhance performance. Lastly, we introduce the adaptive\nscaling-c scheduler to manage the robust training process and adopt\nNon-scaling LayerNorm in the architecture to better capture the statistics of\nthe features and reduce outlier impact. With these strategies, we successfully\ntrain latent consistency models capable of high-quality sampling with one or\ntwo steps, significantly narrowing the performance gap between latent\nconsistency and diffusion models. The implementation is released here:\nhttps://github.com/quandao10/sLCT/",
            "upvotes": 6,
            "discussionId": "67a189eafbbab3ce0346300b"
        },
        "publishedAt": "2025-02-03T22:32:23.956Z",
        "title": "Improved Training Technique for Latent Consistency Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01441.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63e083e6f351dc0745745d17",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e083e6f351dc0745745d17/N0GE4uLrkm14blAQMnm2E.jpeg",
            "fullname": "Quan Dao",
            "name": "quandao10",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01584",
            "authors": [
                {
                    "_id": "67a1e658a68ad21bcdffead6",
                    "user": {
                        "_id": "6243199444c9c3b21be74c50",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6243199444c9c3b21be74c50/uxnj03NBcV_TeC3eV2U-Q.jpeg",
                        "isPro": false,
                        "fullname": "Carolyn Anderson",
                        "user": "canders1",
                        "type": "user"
                    },
                    "name": "Carolyn Jane Anderson",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:09:21.263Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e658a68ad21bcdffead7",
                    "user": {
                        "_id": "641e5fd25f274a0a92c30b7a",
                        "avatarUrl": "/avatars/192ef72795a032f3c73950143a13f6b9.svg",
                        "isPro": false,
                        "fullname": "Joydeep Biswas",
                        "user": "joydeep-b",
                        "type": "user"
                    },
                    "name": "Joydeep Biswas",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:09:28.567Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e658a68ad21bcdffead8",
                    "user": {
                        "_id": "67508d980b12dc1a51ea5e59",
                        "avatarUrl": "/avatars/ec29de1d231a93af18c279fcd2ebbd0b.svg",
                        "isPro": false,
                        "fullname": "Aleksander Boruch-Gruszecki",
                        "user": "abgruszecki",
                        "type": "user"
                    },
                    "name": "Aleksander Boruch-Gruszecki",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:09:34.032Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e658a68ad21bcdffead9",
                    "user": {
                        "_id": "642ca13cc3684e5a4e806661",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/642ca13cc3684e5a4e806661/ELhdKsK429zi4wZkVkx9Y.jpeg",
                        "isPro": false,
                        "fullname": "Federico Cassano",
                        "user": "cassanof",
                        "type": "user"
                    },
                    "name": "Federico Cassano",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:09:39.635Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e658a68ad21bcdffeada",
                    "user": {
                        "_id": "644c34858c51ddbe0ea78cb9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/644c34858c51ddbe0ea78cb9/7BREj4M1LR4LAGk4-WS4G.jpeg",
                        "isPro": false,
                        "fullname": "Molly Feldman",
                        "user": "feldmanmolly",
                        "type": "user"
                    },
                    "name": "Molly Q Feldman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:09:48.494Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e658a68ad21bcdffeadb",
                    "user": {
                        "_id": "62d8315bad693a1a962864b3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1664332914111-62d8315bad693a1a962864b3.png",
                        "isPro": false,
                        "fullname": "Arjun Guha",
                        "user": "arjunguha",
                        "type": "user"
                    },
                    "name": "Arjun Guha",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:09:54.609Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e658a68ad21bcdffeadc",
                    "user": {
                        "_id": "64025d945caf6d21d67cdad2",
                        "avatarUrl": "/avatars/17227ea5bd07c820f4f3fd29ffa5853e.svg",
                        "isPro": false,
                        "fullname": "Francesca Lucchetti",
                        "user": "franlucc",
                        "type": "user"
                    },
                    "name": "Francesca Lucchetti",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:10:03.253Z",
                    "hidden": false
                },
                {
                    "_id": "67a1e658a68ad21bcdffeadd",
                    "user": {
                        "_id": "6634fdc967cbac200e103bd7",
                        "avatarUrl": "/avatars/47bbdbc066055f25736d7e1cca928b1f.svg",
                        "isPro": false,
                        "fullname": "Zixuan Wu",
                        "user": "AryaWu",
                        "type": "user"
                    },
                    "name": "Zixuan Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:10:34.894Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T18:10:38.000Z",
            "title": "PhD Knowledge Not Required: A Reasoning Challenge for Large Language\n  Models",
            "summary": "Existing benchmarks for frontier models often test specialized, ``PhD-level''\nknowledge that is difficult for non-experts to grasp. In contrast, we present a\nbenchmark based on the NPR Sunday Puzzle Challenge that requires only general\nknowledge. Our benchmark is challenging for both humans and models, however\ncorrect solutions are easy to verify, and models' mistakes are easy to spot.\n  Our work reveals capability gaps that are not evident in existing benchmarks:\nOpenAI o1 significantly outperforms other reasoning models that are on par on\nbenchmarks that test specialized knowledge. Furthermore, our analysis of\nreasoning outputs uncovers new kinds of failures. DeepSeek R1, for instance,\noften concedes with ``I give up'' before providing an answer that it knows is\nwrong. R1 can also be remarkably ``uncertain'' in its output and in rare cases,\nit does not ``finish thinking,'' which suggests the need for an inference-time\ntechnique to ``wrap up'' before the context window limit is reached. We also\nquantify the effectiveness of reasoning longer with R1 and Gemini Thinking to\nidentify the point beyond which more reasoning is unlikely to improve accuracy\non our benchmark.",
            "upvotes": 5,
            "discussionId": "67a1e659a68ad21bcdffeb04"
        },
        "publishedAt": "2025-02-04T05:06:50.415Z",
        "title": "PhD Knowledge Not Required: A Reasoning Challenge for Large Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01584.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "62d8315bad693a1a962864b3",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1664332914111-62d8315bad693a1a962864b3.png",
            "fullname": "Arjun Guha",
            "name": "arjunguha",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 12
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01636",
            "authors": [
                {
                    "_id": "67a1aa5dc7fa0ccf0a32ceb1",
                    "user": {
                        "_id": "64e8f4a24f3f7b0b84834315",
                        "avatarUrl": "/avatars/242bb68c7ccffe5061c2d1c229ea3b0b.svg",
                        "isPro": false,
                        "fullname": "Akshat Gupta",
                        "user": "akshat57",
                        "type": "user"
                    },
                    "name": "Akshat Gupta",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2025-02-04T05:53:11.213Z",
                    "hidden": false
                },
                {
                    "_id": "67a1aa5dc7fa0ccf0a32ceb2",
                    "name": "Phudish Prateepamornkul",
                    "hidden": false
                },
                {
                    "_id": "67a1aa5dc7fa0ccf0a32ceb3",
                    "name": "Maochuan Lu",
                    "hidden": false
                },
                {
                    "_id": "67a1aa5dc7fa0ccf0a32ceb4",
                    "name": "Ahmed Alaa",
                    "hidden": false
                },
                {
                    "_id": "67a1aa5dc7fa0ccf0a32ceb5",
                    "name": "Thomas Hartvigsen",
                    "hidden": false
                },
                {
                    "_id": "67a1aa5dc7fa0ccf0a32ceb6",
                    "user": {
                        "_id": "60523e4aa7226b25aaeea2b8",
                        "avatarUrl": "/avatars/316ca348da91ebced86991f36150c959.svg",
                        "isPro": false,
                        "fullname": "Gopala Anumanchipalli",
                        "user": "gopalakr",
                        "type": "user"
                    },
                    "name": "Gopala Anumanchipalli",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:11:09.416Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T18:59:14.000Z",
            "title": "Lifelong Sequential Knowledge Editing without Model Degradation",
            "summary": "Prior work in parameter-modifying knowledge editing has shown that\nlarge-scale sequential editing leads to significant model degradation. In this\npaper, we study the reasons behind this and scale sequential knowledge editing\nto 10,000 sequential edits, while maintaining the downstream performance of the\noriginal model. We first show that locate-then-edit knowledge editing methods\nlead to overfitting on the edited facts. We also show that continuous knowledge\nediting using these methods leads to disproportionate growth in the norm of the\nedited matrix. We then provide a crucial insight into the inner workings of\nlocate-then-edit methods. We show that norm-growth is a hidden trick employed\nby these methods that gives larger importance to the output activations\nproduced from the edited layers. With this \"importance hacking\", the edited\nlayers provide a much larger contributions to the model's output. To mitigate\nthese issues, we present ENCORE - Early stopping and Norm-Constrained Robust\nknowledge Editing. ENCORE controls for overfitting and the disproportionate\nnorm-growth to enable long-term sequential editing, where we are able to\nperform up to 10,000 sequential edits without loss of downstream performance.\nENCORE is also 61% faster than MEMIT and 64% faster than AlphaEdit on\nLlama3-8B.",
            "upvotes": 4,
            "discussionId": "67a1aa5fc7fa0ccf0a32cf90"
        },
        "publishedAt": "2025-02-04T00:50:46.370Z",
        "title": "Lifelong Sequential Knowledge Editing without Model Degradation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01636.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "64e8f4a24f3f7b0b84834315",
            "avatarUrl": "/avatars/242bb68c7ccffe5061c2d1c229ea3b0b.svg",
            "fullname": "Akshat Gupta",
            "name": "akshat57",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01619",
            "authors": [
                {
                    "_id": "67a280644fdf4d9187507d74",
                    "user": {
                        "_id": "607aeae5d2cd8c150e6ae074",
                        "avatarUrl": "/avatars/a087743b98b6fe2181283a9610db4ec4.svg",
                        "isPro": false,
                        "fullname": "Archiki Prasad",
                        "user": "archiki",
                        "type": "user"
                    },
                    "name": "Archiki Prasad",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:11:22.710Z",
                    "hidden": false
                },
                {
                    "_id": "67a280644fdf4d9187507d75",
                    "user": {
                        "_id": "61781c4caf41befe8ff060e8",
                        "avatarUrl": "/avatars/8871d7b046fc28cbc8638228da8e9737.svg",
                        "isPro": false,
                        "fullname": "Elias Stengel-Eskin",
                        "user": "esteng",
                        "type": "user"
                    },
                    "name": "Elias Stengel-Eskin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:11:36.824Z",
                    "hidden": false
                },
                {
                    "_id": "67a280644fdf4d9187507d76",
                    "name": "Justin Chih-Yao Chen",
                    "hidden": false
                },
                {
                    "_id": "67a280644fdf4d9187507d77",
                    "name": "Zaid Khan",
                    "hidden": false
                },
                {
                    "_id": "67a280644fdf4d9187507d78",
                    "user": {
                        "_id": "665d9d3a057f7c508f98c625",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/665d9d3a057f7c508f98c625/u1R9P9sJoAl4zEIcetbPy.jpeg",
                        "isPro": false,
                        "fullname": "Mohit Bansal",
                        "user": "mohitbansal",
                        "type": "user"
                    },
                    "name": "Mohit Bansal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:12:17.347Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T18:51:43.000Z",
            "title": "Learning to Generate Unit Tests for Automated Debugging",
            "summary": "Unit tests (UTs) play an instrumental role in assessing code correctness as\nwell as providing feedback to a large language model (LLM) as it iteratively\ndebugs faulty code, motivating automated test generation. However, we uncover a\ntrade-off between generating unit test inputs that reveal errors when given a\nfaulty code and correctly predicting the unit test output without access to the\ngold solution. To address this trade-off, we propose UTGen, which teaches LLMs\nto generate unit test inputs that reveal errors along with their correct\nexpected outputs based on task descriptions and candidate code. We integrate\nUTGen into UTDebug, a robust debugging pipeline that uses generated tests to\nhelp LLMs debug effectively. Since model-generated tests can provide noisy\nsignals (e.g., from incorrectly predicted outputs), UTDebug (i) scales UTGen\nvia test-time compute to improve UT output prediction, and (ii) validates and\nback-tracks edits based on multiple generated UTs to avoid overfitting. We show\nthat UTGen outperforms UT generation baselines by 7.59% based on a metric\nmeasuring the presence of both error-revealing UT inputs and correct UT\noutputs. When used with UTDebug, we find that feedback from UTGen's unit tests\nimproves pass@1 accuracy of Qwen-2.5 7B on HumanEvalFix and our own harder\ndebugging split of MBPP+ by over 3% and 12.35% (respectively) over other\nLLM-based UT generation baselines.",
            "upvotes": 2,
            "discussionId": "67a280654fdf4d9187507dd2"
        },
        "publishedAt": "2025-02-04T16:10:18.388Z",
        "title": "Learning to Generate Unit Tests for Automated Debugging",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01619.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "607aeae5d2cd8c150e6ae074",
            "avatarUrl": "/avatars/a087743b98b6fe2181283a9610db4ec4.svg",
            "fullname": "Archiki Prasad",
            "name": "archiki",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.00314",
            "authors": [
                {
                    "_id": "67a1d1ca167bea74d520eb59",
                    "user": {
                        "_id": "61ba19bf6122a4fd29049371",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1639586194527-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Moein Heidari",
                        "user": "moein99",
                        "type": "user"
                    },
                    "name": "Moein Heidari",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:12:31.574Z",
                    "hidden": false
                },
                {
                    "_id": "67a1d1ca167bea74d520eb5a",
                    "name": "Ehsan Khodapanah Aghdam",
                    "hidden": false
                },
                {
                    "_id": "67a1d1ca167bea74d520eb5b",
                    "name": "Alexander Manzella",
                    "hidden": false
                },
                {
                    "_id": "67a1d1ca167bea74d520eb5c",
                    "name": "Daniel Hsu",
                    "hidden": false
                },
                {
                    "_id": "67a1d1ca167bea74d520eb5d",
                    "name": "Rebecca Scalabrino",
                    "hidden": false
                },
                {
                    "_id": "67a1d1ca167bea74d520eb5e",
                    "user": {
                        "_id": "6793160813ed9a38f3c214ef",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/qVy6X8N_ckK5Z-y2ger_2.png",
                        "isPro": false,
                        "fullname": "wenjin chen",
                        "user": "cwjbks",
                        "type": "user"
                    },
                    "name": "Wenjin Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:13:15.403Z",
                    "hidden": false
                },
                {
                    "_id": "67a1d1ca167bea74d520eb5f",
                    "user": {
                        "_id": "675c4b8633402f946da6ff4d",
                        "avatarUrl": "/avatars/1aba24c10f9dc02f0be27e70c7b14c82.svg",
                        "isPro": false,
                        "fullname": "David Foran",
                        "user": "technoprimitive",
                        "type": "user"
                    },
                    "name": "David J. Foran",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:13:30.389Z",
                    "hidden": false
                },
                {
                    "_id": "67a1d1ca167bea74d520eb60",
                    "name": "Ilker Hacihaliloglu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-01T04:25:28.000Z",
            "title": "A Study on the Performance of U-Net Modifications in Retroperitoneal\n  Tumor Segmentation",
            "summary": "The retroperitoneum hosts a variety of tumors, including rare benign and\nmalignant types, which pose diagnostic and treatment challenges due to their\ninfrequency and proximity to vital structures. Estimating tumor volume is\ndifficult due to their irregular shapes, and manual segmentation is\ntime-consuming. Automatic segmentation using U-Net and its variants,\nincorporating Vision Transformer (ViT) elements, has shown promising results\nbut struggles with high computational demands. To address this, architectures\nlike the Mamba State Space Model (SSM) and Extended Long-Short Term Memory\n(xLSTM) offer efficient solutions by handling long-range dependencies with\nlower resource consumption. This study evaluates U-Net enhancements, including\nCNN, ViT, Mamba, and xLSTM, on a new in-house CT dataset and a public organ\nsegmentation dataset. The proposed ViLU-Net model integrates Vi-blocks for\nimproved segmentation. Results highlight xLSTM's efficiency in the U-Net\nframework. The code is publicly accessible on GitHub.",
            "upvotes": 2,
            "discussionId": "67a1d1cd167bea74d520ebf6"
        },
        "publishedAt": "2025-02-04T03:38:34.899Z",
        "title": "A Study on the Performance of U-Net Modifications in Retroperitoneal Tumor Segmentation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00314.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "61ba19bf6122a4fd29049371",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1639586194527-noauth.jpeg",
            "fullname": "Moein Heidari",
            "name": "moein99",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.00987",
            "authors": [
                {
                    "_id": "67a1a4278b6584b24ff98eaf",
                    "name": "Paul Albert",
                    "hidden": false
                },
                {
                    "_id": "67a1a4278b6584b24ff98eb0",
                    "name": "Frederic Z. Zhang",
                    "hidden": false
                },
                {
                    "_id": "67a1a4278b6584b24ff98eb1",
                    "name": "Hemanth Saratchandran",
                    "hidden": false
                },
                {
                    "_id": "67a1a4278b6584b24ff98eb2",
                    "name": "Cristian Rodriguez-Opazo",
                    "hidden": false
                },
                {
                    "_id": "67a1a4278b6584b24ff98eb3",
                    "name": "Anton van den Hengel",
                    "hidden": false
                },
                {
                    "_id": "67a1a4278b6584b24ff98eb4",
                    "name": "Ehsan Abbasnejad",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T01:59:45.000Z",
            "title": "RandLoRA: Full-rank parameter-efficient fine-tuning of large models",
            "summary": "Low-Rank Adaptation (LoRA) and its variants have shown impressive results in\nreducing the number of trainable parameters and memory requirements of large\ntransformer networks while maintaining fine-tuning performance. However, the\nlow-rank nature of the weight update inherently limits the representation power\nof fine-tuned models, potentially compromising performance on complex tasks.\nThis raises a critical question: when a performance gap between LoRA and\nstandard fine-tuning is observed, is it due to the reduced number of trainable\nparameters or the rank deficiency? This paper aims to answer this question by\nintroducing RandLoRA, a parameter-efficient method that performs full-rank\nupdates using a learned linear combinations of low-rank, non-trainable random\nmatrices. Our method limits the number of trainable parameters by restricting\noptimization to diagonal scaling matrices applied to the fixed random matrices.\nThis allows us to effectively overcome the low-rank limitations while\nmaintaining parameter and memory efficiency during training. Through extensive\nexperimentation across vision, language, and vision-language benchmarks, we\nsystematically evaluate the limitations of LoRA and existing random basis\nmethods. Our findings reveal that full-rank updates are beneficial across\nvision and language tasks individually, and even more so for vision-language\ntasks, where RandLoRA significantly reduces -- and sometimes eliminates -- the\nperformance gap between standard fine-tuning and LoRA, demonstrating its\nefficacy.",
            "upvotes": 1,
            "discussionId": "67a1a4288b6584b24ff98ee8"
        },
        "publishedAt": "2025-02-04T20:34:37.638Z",
        "title": "RandLoRA: Full-rank parameter-efficient fine-tuning of large models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/65f26ed18404ac0e4cfe7d83/E72WPhEmfC8brtLv3Ez5X.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.00987.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "65f26ed18404ac0e4cfe7d83",
            "avatarUrl": "/avatars/9c72744836f86a8e355a45700b10e393.svg",
            "fullname": "Paul Albert",
            "name": "PAlbert31",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2501.18055",
            "authors": [
                {
                    "_id": "67a197099b2f48315e74dcde",
                    "user": {
                        "_id": "67225dd94201755d88e104c4",
                        "avatarUrl": "/avatars/6da69788ce0cd41c86f9dd0bf8d092aa.svg",
                        "isPro": false,
                        "fullname": "Edwin D. de Jong",
                        "user": "EdwinDdeJong",
                        "type": "user"
                    },
                    "name": "Edwin D. de Jong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-04T09:39:28.120Z",
                    "hidden": false
                },
                {
                    "_id": "67a197099b2f48315e74dcdf",
                    "name": "Eric Marcus",
                    "hidden": false
                },
                {
                    "_id": "67a197099b2f48315e74dce0",
                    "name": "Jonas Teuwen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-01-29T23:38:14.000Z",
            "title": "Current Pathology Foundation Models are unrobust to Medical Center\n  Differences",
            "summary": "Pathology Foundation Models (FMs) hold great promise for healthcare. Before\nthey can be used in clinical practice, it is essential to ensure they are\nrobust to variations between medical centers. We measure whether pathology FMs\nfocus on biological features like tissue and cancer type, or on the well known\nconfounding medical center signatures introduced by staining procedure and\nother differences. We introduce the Robustness Index. This novel robustness\nmetric reflects to what degree biological features dominate confounding\nfeatures. Ten current publicly available pathology FMs are evaluated. We find\nthat all current pathology foundation models evaluated represent the medical\ncenter to a strong degree. Significant differences in the robustness index are\nobserved. Only one model so far has a robustness index greater than one,\nmeaning biological features dominate confounding features, but only slightly. A\nquantitative approach to measure the influence of medical center differences on\nFM-based prediction performance is described. We analyze the impact of\nunrobustness on classification performance of downstream models, and find that\ncancer-type classification errors are not random, but specifically attributable\nto same-center confounders: images of other classes from the same medical\ncenter. We visualize FM embedding spaces, and find these are more strongly\norganized by medical centers than by biological factors. As a consequence, the\nmedical center of origin is predicted more accurately than the tissue source\nand cancer type. The robustness index introduced here is provided with the aim\nof advancing progress towards clinical adoption of robust and reliable\npathology FMs.",
            "upvotes": 1,
            "discussionId": "67a1970b9b2f48315e74dd5d"
        },
        "publishedAt": "2025-02-04T04:59:22.696Z",
        "title": "Current Pathology Foundation Models are unrobust to Medical Center Differences",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/67225dd94201755d88e104c4/oD8gcxl4D9G3FPXWGVGiz.png",
            "https://cdn-uploads.huggingface.co/production/uploads/67225dd94201755d88e104c4/_jrPyZDKwbr3K9-Q4_sCH.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2501.18055.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "67225dd94201755d88e104c4",
            "avatarUrl": "/avatars/6da69788ce0cd41c86f9dd0bf8d092aa.svg",
            "fullname": "Edwin D. de Jong",
            "name": "EdwinDdeJong",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.01126",
            "authors": [
                {
                    "_id": "67a27eb5d6a1524a1a6f048c",
                    "user": {
                        "_id": "63b75a016fc56e43c3c15980",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672960383634-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Vaishnavi Shrivastava",
                        "user": "vshrivas",
                        "type": "user"
                    },
                    "name": "Vaishnavi Shrivastava",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:14:18.633Z",
                    "hidden": false
                },
                {
                    "_id": "67a27eb5d6a1524a1a6f048d",
                    "name": "Ananya Kumar",
                    "hidden": false
                },
                {
                    "_id": "67a27eb5d6a1524a1a6f048e",
                    "user": {
                        "_id": "6409651b9e9f790c905b2335",
                        "avatarUrl": "/avatars/1fb8c80b60f21f65a0a027319101f236.svg",
                        "isPro": false,
                        "fullname": "Percy Liang",
                        "user": "percyliang",
                        "type": "user"
                    },
                    "name": "Percy Liang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-04T21:14:47.149Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-03T07:43:27.000Z",
            "title": "Language Models Prefer What They Know: Relative Confidence Estimation\n  via Confidence Preferences",
            "summary": "Language models (LMs) should provide reliable confidence estimates to help\nusers detect mistakes in their outputs and defer to human experts when\nnecessary. Asking a language model to assess its confidence (\"Score your\nconfidence from 0-1.\") is a natural way of evaluating its uncertainty. However,\nmodels struggle to provide absolute assessments of confidence (i.e. judging\nconfidence in answering a question independent of other questions) and the\ncoarse-grained scores they produce are not useful for evaluating the\ncorrectness of their answers. We propose relative confidence estimation, where\nwe match up questions against each other and ask the model to make relative\njudgments of confidence (\"Which question are you more confident in answering\ncorrectly?\"). Treating each question as a \"player\" in a series of matchups\nagainst other questions and the model's preferences as match outcomes, we can\nuse rank aggregation methods like Elo rating and Bradley-Terry to translate the\nmodel's confidence preferences into confidence scores. We evaluate relative\nconfidence estimation against absolute confidence estimation and\nself-consistency confidence methods on five state-of-the-art LMs -- GPT-4,\nGPT-4o, Gemini 1.5 Pro, Claude 3.5 Sonnet, and Llama 3.1 405B -- across 14\nchallenging STEM, social science, and commonsense reasoning question answering\ntasks. Our results demonstrate that relative confidence estimation consistently\nprovides more reliable confidence scores than absolute confidence estimation,\nwith average gains of 3.5% in selective classification AUC over direct absolute\nconfidence estimation methods and 1.7% over self-consistency approaches across\nall models and datasets.",
            "upvotes": 0,
            "discussionId": "67a27eb9d6a1524a1a6f0591"
        },
        "publishedAt": "2025-02-04T15:56:40.599Z",
        "title": "Language Models Prefer What They Know: Relative Confidence Estimation via Confidence Preferences",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.01126.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63b75a016fc56e43c3c15980",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1672960383634-noauth.jpeg",
            "fullname": "Vaishnavi Shrivastava",
            "name": "vshrivas",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    }
]