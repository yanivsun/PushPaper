[
    {
        "paper": {
            "id": "2502.12900",
            "authors": [
                {
                    "_id": "67b54851b986e35c41e063da",
                    "user": {
                        "_id": "66975b9f8031bf92b428e138",
                        "avatarUrl": "/avatars/3254281a7bac1c8ddde1d6bc7e518b2f.svg",
                        "isPro": false,
                        "fullname": "Yuhao Zhang",
                        "user": "Yoohao",
                        "type": "user"
                    },
                    "name": "Yuhao Zhang",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-19T02:56:18.848Z",
                    "hidden": false
                },
                {
                    "_id": "67b54851b986e35c41e063db",
                    "user": {
                        "_id": "66597f2cf769c3c443b7cf41",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/WkZBh7hwlD9wVqCEMQtGX.png",
                        "isPro": false,
                        "fullname": "Chihang Lau",
                        "user": "puccho",
                        "type": "user"
                    },
                    "name": "Zhiheng Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:05.678Z",
                    "hidden": false
                },
                {
                    "_id": "67b54851b986e35c41e063dc",
                    "user": {
                        "_id": "668e7f46c243a12604035758",
                        "avatarUrl": "/avatars/35bd20032fafb7d7603266cf9a72d1e0.svg",
                        "isPro": false,
                        "fullname": "Fan Bu",
                        "user": "FanBuCUHK",
                        "type": "user"
                    },
                    "name": "Fan Bu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:42:08.544Z",
                    "hidden": false
                },
                {
                    "_id": "67b54851b986e35c41e063dd",
                    "user": {
                        "_id": "67b587c8882e49771f610b51",
                        "avatarUrl": "/avatars/aecfb38b44141b8284416fc261692909.svg",
                        "isPro": false,
                        "fullname": "Ruiyu Zhang",
                        "user": "PhoenixAxis",
                        "type": "user"
                    },
                    "name": "Ruiyu Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:42:14.866Z",
                    "hidden": false
                },
                {
                    "_id": "67b54851b986e35c41e063de",
                    "user": {
                        "_id": "637c6703ca8542a0ba900ccb",
                        "avatarUrl": "/avatars/288ed63a1efa566c3f01e850c6ba5dd5.svg",
                        "isPro": false,
                        "fullname": "Wang",
                        "user": "Benyou",
                        "type": "user"
                    },
                    "name": "Benyou Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:42:23.845Z",
                    "hidden": false
                },
                {
                    "_id": "67b54851b986e35c41e063df",
                    "name": "Haizhou Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T14:36:39.000Z",
            "title": "Soundwave: Less is More for Speech-Text Alignment in LLMs",
            "summary": "Existing end-to-end speech large language models (LLMs) usually rely on\nlarge-scale annotated data for training, while data-efficient training has not\nbeen discussed in depth. We focus on two fundamental problems between speech\nand text: the representation space gap and sequence length inconsistency. We\npropose Soundwave, which utilizes an efficient training strategy and a novel\narchitecture to address these issues. Results show that Soundwave outperforms\nthe advanced Qwen2-Audio in speech translation and AIR-Bench speech tasks,\nusing only one-fiftieth of the training data. Further analysis shows that\nSoundwave still retains its intelligence during conversation. The project is\navailable at https://github.com/FreedomIntelligence/Soundwave.",
            "upvotes": 63,
            "discussionId": "67b54852b986e35c41e06426"
        },
        "publishedAt": "2025-02-19T00:22:36.628Z",
        "title": "Soundwave: Less is More for Speech-Text Alignment in LLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12900.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "66975b9f8031bf92b428e138",
            "avatarUrl": "/avatars/3254281a7bac1c8ddde1d6bc7e518b2f.svg",
            "fullname": "Yuhao Zhang",
            "name": "Yoohao",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.13063",
            "authors": [
                {
                    "_id": "67b5a7896f72266cb765e744",
                    "user": {
                        "_id": "618b9540682ec1c38327e586",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/618b9540682ec1c38327e586/v_ZBkfh8O9Zh6C2YQpuBX.jpeg",
                        "isPro": false,
                        "fullname": "Yury Kuratov",
                        "user": "yurakuratov",
                        "type": "user"
                    },
                    "name": "Yuri Kuratov",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-19T09:42:34.422Z",
                    "hidden": false
                },
                {
                    "_id": "67b5a7896f72266cb765e745",
                    "name": "Mikhail Arkhipov",
                    "hidden": false
                },
                {
                    "_id": "67b5a7896f72266cb765e746",
                    "name": "Aydar Bulatov",
                    "hidden": false
                },
                {
                    "_id": "67b5a7896f72266cb765e747",
                    "user": {
                        "_id": "639c6e978a34ed9a404c6a7b",
                        "avatarUrl": "/avatars/c98ca8c9f9ed8509c2f1bb6aa994fd57.svg",
                        "isPro": false,
                        "fullname": "MIKHAIL BURTSEV",
                        "user": "mbur",
                        "type": "user"
                    },
                    "name": "Mikhail Burtsev",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:56:59.080Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T17:08:45.000Z",
            "title": "Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the\n  Limits of Embedding Space Capacity",
            "summary": "A range of recent works addresses the problem of compression of sequence of\ntokens into a shorter sequence of real-valued vectors to be used as inputs\ninstead of token embeddings or key-value cache. These approaches allow to\nreduce the amount of compute in existing language models. Despite relying on\npowerful models as encoders, the maximum attainable lossless compression ratio\nis typically not higher than x10. This fact is highly intriguing because, in\ntheory, the maximum information capacity of large real-valued vectors is far\nbeyond the presented rates even for 16-bit precision and a modest vector size.\nIn this work, we explore the limits of compression by replacing the encoder\nwith a per-sample optimization procedure. We show that vectors with compression\nratios up to x1500 exist, which highlights two orders of magnitude gap between\nexisting and practically attainable solutions. Furthermore, we empirically show\nthat the compression limits are determined not by the length of the input but\nby the amount of uncertainty to be reduced, namely, the cross-entropy loss on\nthis sequence without any conditioning. The obtained limits highlight the\nsubstantial gap between the theoretical capacity of input embeddings and their\npractical utilization, suggesting significant room for optimization in model\ndesign.",
            "upvotes": 51,
            "discussionId": "67b5a78a6f72266cb765e779"
        },
        "publishedAt": "2025-02-19T04:43:42.973Z",
        "title": "Cramming 1568 Tokens into a Single Vector and Back Again: Exploring the Limits of Embedding Space Capacity",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13063.png",
        "numComments": 4,
        "submittedBy": {
            "_id": "639c6e978a34ed9a404c6a7b",
            "avatarUrl": "/avatars/c98ca8c9f9ed8509c2f1bb6aa994fd57.svg",
            "fullname": "MIKHAIL BURTSEV",
            "name": "mbur",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 7
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.11564",
            "authors": [
                {
                    "_id": "67b40f93aba9e111862052ab",
                    "user": {
                        "_id": "65e5bd4568234ef5d6decadc",
                        "avatarUrl": "/avatars/c41095a946c0176b949c0b3566136c05.svg",
                        "isPro": false,
                        "fullname": "Jaehyeong Jo",
                        "user": "harryjo97",
                        "type": "user"
                    },
                    "name": "Jaehyeong Jo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-18T09:31:27.544Z",
                    "hidden": false
                },
                {
                    "_id": "67b40f93aba9e111862052ac",
                    "name": "Sung Ju Hwang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-17T08:54:29.000Z",
            "title": "Continuous Diffusion Model for Language Modeling",
            "summary": "Diffusion models have emerged as a promising alternative to autoregressive\nmodels in modeling discrete categorical data. Yet diffusion models that\ndirectly work on discrete data space do not fully exploit the power of\niterative refinement, as the signals are lost during the transition between\ndiscrete states. Existing continuous diffusion models for discrete data have\nlimited performance compared to discrete approaches, and the unclear link\nbetween them restricts the development of diffusion models for discrete data.\nIn this work, we propose a continuous diffusion model for language modeling\nthat incorporates the geometry of the underlying categorical distribution. We\nestablish a connection between the discrete diffusion and continuous flow on\nthe statistical manifold, and building on the analogy, we introduce a simple\ndesign for the diffusion process that generalizes previous discrete diffusion\nmodels. We further propose a simulation-free training framework based on radial\nsymmetry and a simple technique to address the high dimensionality of the\nmanifold. Comprehensive experiments on language modeling benchmarks and other\nmodalities show that our method outperforms existing discrete diffusion models\nand approaches the performance of autoregressive models. Codes available at\nhttps://github.com/harryjo97/RDLM{https://github.com/harryjo97/RDLM}.",
            "upvotes": 42,
            "discussionId": "67b40f94aba9e111862052d5"
        },
        "publishedAt": "2025-02-18T22:43:02.567Z",
        "title": "Continuous Diffusion Model for Language Modeling",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11564.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "65e5bd4568234ef5d6decadc",
            "avatarUrl": "/avatars/c41095a946c0176b949c0b3566136c05.svg",
            "fullname": "Jaehyeong Jo",
            "name": "harryjo97",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.11079",
            "authors": [
                {
                    "_id": "67b40141ad717fe02e188c1a",
                    "user": {
                        "_id": "63a950ac3453852ef5394178",
                        "avatarUrl": "/avatars/48a5e537b10e2247a17e63502e3201a6.svg",
                        "isPro": false,
                        "fullname": "Lijie Liu",
                        "user": "liulj13",
                        "type": "user"
                    },
                    "name": "Lijie Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-18T09:31:42.570Z",
                    "hidden": false
                },
                {
                    "_id": "67b40141ad717fe02e188c1b",
                    "user": {
                        "_id": "657ab4705e1c941f4c2f7877",
                        "avatarUrl": "/avatars/c450f81f83dd0436ae120ab15616c4f7.svg",
                        "isPro": false,
                        "fullname": "Tianxiang Ma",
                        "user": "Grayson111",
                        "type": "user"
                    },
                    "name": "Tianxiang Ma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:45:00.117Z",
                    "hidden": false
                },
                {
                    "_id": "67b40141ad717fe02e188c1c",
                    "user": {
                        "_id": "63b415037af2e415f2599c18",
                        "avatarUrl": "/avatars/4afbe7d6d05a702f1beeed9c53e78153.svg",
                        "isPro": false,
                        "fullname": "Bingchuan Li",
                        "user": "lbc402",
                        "type": "user"
                    },
                    "name": "Bingchuan Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:47:57.441Z",
                    "hidden": false
                },
                {
                    "_id": "67b40141ad717fe02e188c1d",
                    "user": {
                        "_id": "6304e2dabad6ce7fc0287d57",
                        "avatarUrl": "/avatars/3fd4a9a62b0ef98db2573411463a9247.svg",
                        "isPro": false,
                        "fullname": "Zhuowei_Chen",
                        "user": "ZhuoweiChen",
                        "type": "user"
                    },
                    "name": "Zhuowei Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:47:50.995Z",
                    "hidden": false
                },
                {
                    "_id": "67b40141ad717fe02e188c1e",
                    "name": "Jiawei Liu",
                    "hidden": false
                },
                {
                    "_id": "67b40141ad717fe02e188c1f",
                    "name": "Qian He",
                    "hidden": false
                },
                {
                    "_id": "67b40141ad717fe02e188c20",
                    "name": "Xinglong Wu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-16T11:02:50.000Z",
            "title": "Phantom: Subject-consistent video generation via cross-modal alignment",
            "summary": "The continuous development of foundational models for video generation is\nevolving into various applications, with subject-consistent video generation\nstill in the exploratory stage. We refer to this as Subject-to-Video, which\nextracts subject elements from reference images and generates\nsubject-consistent video through textual instructions. We believe that the\nessence of subject-to-video lies in balancing the dual-modal prompts of text\nand image, thereby deeply and simultaneously aligning both text and visual\ncontent. To this end, we propose Phantom, a unified video generation framework\nfor both single and multi-subject references. Building on existing\ntext-to-video and image-to-video architectures, we redesign the joint\ntext-image injection model and drive it to learn cross-modal alignment via\ntext-image-video triplet data. In particular, we emphasize subject consistency\nin human generation, covering existing ID-preserving video generation while\noffering enhanced advantages. The project homepage is here\nhttps://phantom-video.github.io/Phantom/.",
            "upvotes": 41,
            "discussionId": "67b40144ad717fe02e188cb2"
        },
        "publishedAt": "2025-02-18T21:56:39.407Z",
        "title": "Phantom: Subject-consistent video generation via cross-modal alignment",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63a950ac3453852ef5394178/HuVZ5d9xTlI4R1onRv_F5.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11079.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63a950ac3453852ef5394178",
            "avatarUrl": "/avatars/48a5e537b10e2247a17e63502e3201a6.svg",
            "fullname": "Lijie Liu",
            "name": "liulj13",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.13131",
            "authors": [
                {
                    "_id": "67b5461d29cc269e5a4eb823",
                    "name": "Feng Luo",
                    "hidden": false
                },
                {
                    "_id": "67b5461d29cc269e5a4eb824",
                    "user": {
                        "_id": "64d45451c34a346181b130dd",
                        "avatarUrl": "/avatars/9bb8205b889337df5d321539c9b5d69d.svg",
                        "isPro": false,
                        "fullname": "Rui Yang",
                        "user": "Ray2333",
                        "type": "user"
                    },
                    "name": "Rui Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:23.095Z",
                    "hidden": true
                },
                {
                    "_id": "67b5461d29cc269e5a4eb825",
                    "name": "Hao Sun",
                    "hidden": false
                },
                {
                    "_id": "67b5461d29cc269e5a4eb826",
                    "user": {
                        "_id": "634b9914dcf125e4da02498b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/634b9914dcf125e4da02498b/crRgFroWq5U6XWtvlTXSZ.jpeg",
                        "isPro": false,
                        "fullname": "Chunyuan Deng",
                        "user": "CharlesDDDD",
                        "type": "user"
                    },
                    "name": "Chunyuan Deng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:56:33.053Z",
                    "hidden": false
                },
                {
                    "_id": "67b5461d29cc269e5a4eb827",
                    "name": "Jiarui Yao",
                    "hidden": false
                },
                {
                    "_id": "67b5461d29cc269e5a4eb828",
                    "name": "Jingyan Shen",
                    "hidden": false
                },
                {
                    "_id": "67b5461d29cc269e5a4eb829",
                    "user": {
                        "_id": "6719d581a6cad13741b8bc7f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6719d581a6cad13741b8bc7f/w4EttqfXRgWZJc6HpYOS9.jpeg",
                        "isPro": false,
                        "fullname": "Huan Zhang",
                        "user": "huanzhang12",
                        "type": "user"
                    },
                    "name": "Huan Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:52:47.329Z",
                    "hidden": false
                },
                {
                    "_id": "67b5461d29cc269e5a4eb82a",
                    "name": "Hanjie Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T18:55:26.000Z",
            "title": "Rethinking Diverse Human Preference Learning through Principal Component\n  Analysis",
            "summary": "Understanding human preferences is crucial for improving foundation models\nand building personalized AI systems. However, preferences are inherently\ndiverse and complex, making it difficult for traditional reward models to\ncapture their full range. While fine-grained preference data can help,\ncollecting it is expensive and hard to scale. In this paper, we introduce\nDecomposed Reward Models (DRMs), a novel approach that extracts diverse human\npreferences from binary comparisons without requiring fine-grained annotations.\nOur key insight is to represent human preferences as vectors and analyze them\nusing Principal Component Analysis (PCA). By constructing a dataset of\nembedding differences between preferred and rejected responses, DRMs identify\northogonal basis vectors that capture distinct aspects of preference. These\ndecomposed rewards can be flexibly combined to align with different user needs,\noffering an interpretable and scalable alternative to traditional reward\nmodels. We demonstrate that DRMs effectively extract meaningful preference\ndimensions (e.g., helpfulness, safety, humor) and adapt to new users without\nadditional training. Our results highlight DRMs as a powerful framework for\npersonalized and interpretable LLM alignment.",
            "upvotes": 32,
            "discussionId": "67b5461f29cc269e5a4eb8bc"
        },
        "publishedAt": "2025-02-18T21:59:45.466Z",
        "title": "Rethinking Diverse Human Preference Learning through Principal Component Analysis",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13131.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "64d45451c34a346181b130dd",
            "avatarUrl": "/avatars/9bb8205b889337df5d321539c9b5d69d.svg",
            "fullname": "Rui Yang",
            "name": "Ray2333",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 5
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.13130",
            "authors": [
                {
                    "_id": "67b5625fb27eb6046b2ceec5",
                    "name": "Jianwei Yang",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceec6",
                    "user": {
                        "_id": "674774e8eb8fb5ea40877838",
                        "avatarUrl": "/avatars/7ee8599cb1f7bb4402bc8512faf6ca12.svg",
                        "isPro": false,
                        "fullname": "Reuben Tan",
                        "user": "tanreuben",
                        "type": "user"
                    },
                    "name": "Reuben Tan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:19:01.753Z",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceec7",
                    "user": {
                        "_id": "63ef330b1e695b35aa484e11",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63ef330b1e695b35aa484e11/bXwpGy0dl8JXeJwJ--ilr.jpeg",
                        "isPro": false,
                        "fullname": "Qianhui WU",
                        "user": "qianhuiwu",
                        "type": "user"
                    },
                    "name": "Qianhui Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:18:38.510Z",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceec8",
                    "user": {
                        "_id": "653b24ef8f8d60f204872f0a",
                        "avatarUrl": "/avatars/45a55219e8a78be53fd32e96ba460282.svg",
                        "isPro": false,
                        "fullname": "Ruijie Zheng",
                        "user": "rzheng12",
                        "type": "user"
                    },
                    "name": "Ruijie Zheng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:18:32.761Z",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceec9",
                    "user": {
                        "_id": "61942296d5c2ba6daa290357",
                        "avatarUrl": "/avatars/594021cc183c4922d48b46f43772a062.svg",
                        "isPro": false,
                        "fullname": "Baolin Peng",
                        "user": "Baolin",
                        "type": "user"
                    },
                    "name": "Baolin Peng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:18:25.610Z",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceeca",
                    "user": {
                        "_id": "6646d5819bb34d2b6b7455d3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/JFH3ZTPvlaVSg4RJJBb6L.jpeg",
                        "isPro": false,
                        "fullname": "Yongyuan Liang",
                        "user": "cheryyunl",
                        "type": "user"
                    },
                    "name": "Yongyuan Liang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:18:00.072Z",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceecb",
                    "name": "Yu Gu",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceecc",
                    "name": "Mu Cai",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceecd",
                    "user": {
                        "_id": "62551f7767f0b85962624047",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1664552038624-62551f7767f0b85962624047.png",
                        "isPro": false,
                        "fullname": "Seonghyeon Ye",
                        "user": "seonghyeonye",
                        "type": "user"
                    },
                    "name": "Seonghyeon Ye",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:17:47.576Z",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceece",
                    "user": {
                        "_id": "613e1a9267835521a6816b04",
                        "avatarUrl": "/avatars/49edaa425bbce04dff92bbfb12a6b41c.svg",
                        "isPro": true,
                        "fullname": "Joel Jang",
                        "user": "wkddydpf",
                        "type": "user"
                    },
                    "name": "Joel Jang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:17:40.305Z",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceecf",
                    "name": "Yuquan Deng",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceed0",
                    "user": {
                        "_id": "65bc13c7719492167d777718",
                        "avatarUrl": "/avatars/d1a3dc52c130b84a47c8a4ddd2e74be8.svg",
                        "isPro": false,
                        "fullname": "Lars Liden",
                        "user": "larsliden",
                        "type": "user"
                    },
                    "name": "Lars Liden",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:17:09.378Z",
                    "hidden": false
                },
                {
                    "_id": "67b5625fb27eb6046b2ceed1",
                    "user": {
                        "_id": "641904caf9d6f1d772ec7af7",
                        "avatarUrl": "/avatars/4a63eac71eb30f70b1a0e9d4708f26c1.svg",
                        "isPro": false,
                        "fullname": "Jianfeng Gao",
                        "user": "wyngjf",
                        "type": "user"
                    },
                    "name": "Jianfeng Gao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:17:03.043Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T18:55:21.000Z",
            "title": "Magma: A Foundation Model for Multimodal AI Agents",
            "summary": "We present Magma, a foundation model that serves multimodal AI agentic tasks\nin both the digital and physical worlds. Magma is a significant extension of\nvision-language (VL) models in that it not only retains the VL understanding\nability (verbal intelligence) of the latter, but is also equipped with the\nability to plan and act in the visual-spatial world (spatial-temporal\nintelligence) and complete agentic tasks ranging from UI navigation to robot\nmanipulation. To endow the agentic capabilities, Magma is pretrained on large\namounts of heterogeneous datasets spanning from images, videos to robotics\ndata, where the actionable visual objects (e.g., clickable buttons in GUI) in\nimages are labeled by Set-of-Mark (SoM) for action grounding, and the object\nmovements (e.g., the trace of human hands or robotic arms) in videos are\nlabeled by Trace-of-Mark (ToM) for action planning. Extensive experiments show\nthat SoM and ToM reach great synergy and facilitate the acquisition of\nspatial-temporal intelligence for our Magma model, which is fundamental to a\nwide range of tasks as shown in Fig.1. In particular, Magma creates new\nstate-of-the-art results on UI navigation and robotic manipulation tasks,\noutperforming previous models that are specifically tailored to these tasks. On\nimage and video-related multimodal tasks, Magma also compares favorably to\npopular large multimodal models that are trained on much larger datasets. We\nmake our model and code public for reproducibility at\nhttps://microsoft.github.io/Magma.",
            "upvotes": 27,
            "discussionId": "67b56265b27eb6046b2cf08f"
        },
        "publishedAt": "2025-02-18T23:51:36.910Z",
        "title": "Magma: A Foundation Model for Multimodal AI Agents",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13130.png",
        "numComments": 4,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 6144
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.13145",
            "authors": [
                {
                    "_id": "67b54b04bd51b4e46e39d287",
                    "user": {
                        "_id": "6577073fc2bf55b1f6bafb49",
                        "avatarUrl": "/avatars/58803398b1a918b7570db17893e65122.svg",
                        "isPro": false,
                        "fullname": "liao",
                        "user": "LegendBC",
                        "type": "user"
                    },
                    "name": "Bencheng Liao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:00.934Z",
                    "hidden": false
                },
                {
                    "_id": "67b54b04bd51b4e46e39d288",
                    "user": {
                        "_id": "66a105bb456284adf458d656",
                        "avatarUrl": "/avatars/b543a324f7e159d6e84bc68915e93d24.svg",
                        "isPro": false,
                        "fullname": "Tao Hongyuan",
                        "user": "HongyuanTao",
                        "type": "user"
                    },
                    "name": "Hongyuan Tao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:13:43.349Z",
                    "hidden": false
                },
                {
                    "_id": "67b54b04bd51b4e46e39d289",
                    "name": "Qian Zhang",
                    "hidden": false
                },
                {
                    "_id": "67b54b04bd51b4e46e39d28a",
                    "user": {
                        "_id": "646b3db131968a60a01e4cf5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/646b3db131968a60a01e4cf5/DhfdqUYQaD1Qa8Svw996J.jpeg",
                        "isPro": false,
                        "fullname": "Tianheng Cheng",
                        "user": "wondervictor",
                        "type": "user"
                    },
                    "name": "Tianheng Cheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:00:58.351Z",
                    "hidden": false
                },
                {
                    "_id": "67b54b04bd51b4e46e39d28b",
                    "name": "Yingyue Li",
                    "hidden": false
                },
                {
                    "_id": "67b54b04bd51b4e46e39d28c",
                    "name": "Haoran Yin",
                    "hidden": false
                },
                {
                    "_id": "67b54b04bd51b4e46e39d28d",
                    "user": {
                        "_id": "66c2e7fc934e2f07753542ac",
                        "avatarUrl": "/avatars/f6fa3f94435cf1c1d06daa6c925d07d0.svg",
                        "isPro": false,
                        "fullname": "LWY",
                        "user": "wenyuliu",
                        "type": "user"
                    },
                    "name": "Wenyu Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:12:36.866Z",
                    "hidden": false
                },
                {
                    "_id": "67b54b04bd51b4e46e39d28e",
                    "name": "Xinggang Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T18:59:57.000Z",
            "title": "Multimodal Mamba: Decoder-only Multimodal State Space Model via\n  Quadratic to Linear Distillation",
            "summary": "Recent Multimodal Large Language Models (MLLMs) have achieved remarkable\nperformance but face deployment challenges due to their quadratic computational\ncomplexity, growing Key-Value cache requirements, and reliance on separate\nvision encoders. We propose mmMamba, a framework for developing\nlinear-complexity native multimodal state space models through progressive\ndistillation from existing MLLMs using moderate academic computational\nresources. Our approach enables the direct conversion of trained decoder-only\nMLLMs to linear-complexity architectures without requiring pre-trained\nRNN-based LLM or vision encoders. We propose an seeding strategy to carve Mamba\nfrom trained Transformer and a three-stage distillation recipe, which can\neffectively transfer the knowledge from Transformer to Mamba while preserving\nmultimodal capabilities. Our method also supports flexible hybrid architectures\nthat combine Transformer and Mamba layers for customizable\nefficiency-performance trade-offs. Distilled from the Transformer-based\ndecoder-only HoVLE, mmMamba-linear achieves competitive performance against\nexisting linear and quadratic-complexity VLMs, while mmMamba-hybrid further\nimproves performance significantly, approaching HoVLE's capabilities. At 103K\ntokens, mmMamba-linear demonstrates 20.6times speedup and 75.8% GPU memory\nreduction compared to HoVLE, while mmMamba-hybrid achieves 13.5times speedup\nand 60.2% memory savings. Code and models are released at\nhttps://github.com/hustvl/mmMamba",
            "upvotes": 27,
            "discussionId": "67b54b05bd51b4e46e39d2bb"
        },
        "publishedAt": "2025-02-18T22:08:27.750Z",
        "title": "Multimodal Mamba: Decoder-only Multimodal State Space Model via Quadratic to Linear Distillation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13145.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6577073fc2bf55b1f6bafb49",
            "avatarUrl": "/avatars/58803398b1a918b7570db17893e65122.svg",
            "fullname": "liao",
            "name": "LegendBC",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.13143",
            "authors": [
                {
                    "_id": "67b546c0d8a1eac02c605f6a",
                    "user": {
                        "_id": "63c3e8abc7d7f4c63a515a02",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63c3e8abc7d7f4c63a515a02/npMHnVP2hHLbvoUGe7C4O.jpeg",
                        "isPro": false,
                        "fullname": "Zekun Qi",
                        "user": "qizekun",
                        "type": "user"
                    },
                    "name": "Zekun Qi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:21.001Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f6b",
                    "user": {
                        "_id": "65f9533b136fb8ddbd14e1fa",
                        "avatarUrl": "/avatars/d88f75da0448093ccd1babba2a37d73f.svg",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "WenyaoZhang",
                        "type": "user"
                    },
                    "name": "Wenyao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:08:31.789Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f6c",
                    "user": {
                        "_id": "66bde456198f9d79f2be2d17",
                        "avatarUrl": "/avatars/8c349aecb8a3a7cd7ef9d69e94eca8bd.svg",
                        "isPro": false,
                        "fullname": "Yufei Ding",
                        "user": "YufeiD",
                        "type": "user"
                    },
                    "name": "Yufei Ding",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:08:57.294Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f6d",
                    "user": {
                        "_id": "6201fc5d91d53938a6432fbf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6201fc5d91d53938a6432fbf/VLs8ZYaZrop4KBpZn53fH.jpeg",
                        "isPro": false,
                        "fullname": "Runpei Dong",
                        "user": "RunpeiDong",
                        "type": "user"
                    },
                    "name": "Runpei Dong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:18.622Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f6e",
                    "name": "Xinqiang Yu",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f6f",
                    "name": "Jingwen Li",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f70",
                    "user": {
                        "_id": "6745c4a80739b09408862ac9",
                        "avatarUrl": "/avatars/8bc082fcbbf933b150a252c78d1bb3be.svg",
                        "isPro": false,
                        "fullname": "lingyun xu",
                        "user": "codered010",
                        "type": "user"
                    },
                    "name": "Lingyun Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:09:41.570Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f71",
                    "user": {
                        "_id": "67302fa362930cbc461511a8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/L9x68oxL8Ot88pyeU6w7Z.png",
                        "isPro": false,
                        "fullname": "Baoyu Li",
                        "user": "boeyyyy",
                        "type": "user"
                    },
                    "name": "Baoyu Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:09:48.223Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f72",
                    "user": {
                        "_id": "67b42039cca7aff798979e80",
                        "avatarUrl": "/avatars/d410b3617395cd7e2a9c0c89ff12f23d.svg",
                        "isPro": false,
                        "fullname": "Xialin He",
                        "user": "XialinHe",
                        "type": "user"
                    },
                    "name": "Xialin He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:10:04.207Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f73",
                    "name": "Guofan Fan",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f74",
                    "user": {
                        "_id": "65658233d35fc55406e8b00d",
                        "avatarUrl": "/avatars/660eaa1923cd3e3478cec8197936a75c.svg",
                        "isPro": false,
                        "fullname": "Jiazhao Zhang",
                        "user": "Jzzhang",
                        "type": "user"
                    },
                    "name": "Jiazhao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:11:41.498Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f75",
                    "user": {
                        "_id": "649cd8deccfa6c1a3c4d05ec",
                        "avatarUrl": "/avatars/2b8f72a0643dfd74bc08fba5ed98ce95.svg",
                        "isPro": false,
                        "fullname": "Jiawei",
                        "user": "jiaweihe",
                        "type": "user"
                    },
                    "name": "Jiawei He",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T14:37:41.045Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f76",
                    "user": {
                        "_id": "638aa283cebef0d13aa2ec2e",
                        "avatarUrl": "/avatars/3b67e6a6073033864a817230e97c27ca.svg",
                        "isPro": false,
                        "fullname": "Jiayuan Gu",
                        "user": "jigu",
                        "type": "user"
                    },
                    "name": "Jiayuan Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:11:49.058Z",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f77",
                    "name": "Xin Jin",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f78",
                    "name": "Kaisheng Ma",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f79",
                    "name": "Zhizheng Zhang",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f7a",
                    "name": "He Wang",
                    "hidden": false
                },
                {
                    "_id": "67b546c0d8a1eac02c605f7b",
                    "name": "Li Yi",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T18:59:02.000Z",
            "title": "SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and\n  Object Manipulation",
            "summary": "Spatial intelligence is a critical component of embodied AI, promoting robots\nto understand and interact with their environments. While recent advances have\nenhanced the ability of VLMs to perceive object locations and positional\nrelationships, they still lack the capability to precisely understand object\norientations-a key requirement for tasks involving fine-grained manipulations.\nAddressing this limitation not only requires geometric reasoning but also an\nexpressive and intuitive way to represent orientation. In this context, we\npropose that natural language offers a more flexible representation space than\ncanonical frames, making it particularly suitable for instruction-following\nrobotic systems. In this paper, we introduce the concept of semantic\norientation, which defines object orientations using natural language in a\nreference-frame-free manner (e.g., the ''plug-in'' direction of a USB or the\n''handle'' direction of a knife). To support this, we construct OrienText300K,\na large-scale dataset of 3D models annotated with semantic orientations that\nlink geometric understanding to functional semantics. By integrating semantic\norientation into a VLM system, we enable robots to generate manipulation\nactions with both positional and orientational constraints. Extensive\nexperiments in simulation and real world demonstrate that our approach\nsignificantly enhances robotic manipulation capabilities, e.g., 48.7% accuracy\non Open6DOR and 74.9% accuracy on SIMPLER.",
            "upvotes": 26,
            "discussionId": "67b546c5d8a1eac02c606090"
        },
        "publishedAt": "2025-02-18T21:51:33.957Z",
        "title": "SoFar: Language-Grounded Orientation Bridges Spatial Reasoning and Object Manipulation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13143.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63c3e8abc7d7f4c63a515a02",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63c3e8abc7d7f4c63a515a02/npMHnVP2hHLbvoUGe7C4O.jpeg",
            "fullname": "Zekun Qi",
            "name": "qizekun",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12464",
            "authors": [
                {
                    "_id": "67b55b2cc92c4aa82c13562d",
                    "user": {
                        "_id": "64ad5f59b7e4b2c1ce47eb43",
                        "avatarUrl": "/avatars/1f13ebe21a90d8c99920aa2c8cd9ac45.svg",
                        "isPro": false,
                        "fullname": "Seanie Lee",
                        "user": "Seanie-lee",
                        "type": "user"
                    },
                    "name": "Seanie Lee",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:00:53.341Z",
                    "hidden": false
                },
                {
                    "_id": "67b55b2cc92c4aa82c13562e",
                    "name": "Dong Bok Lee",
                    "hidden": false
                },
                {
                    "_id": "67b55b2cc92c4aa82c13562f",
                    "user": {
                        "_id": "6311ba6f05cc08a1408d910a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1662997515866-6311ba6f05cc08a1408d910a.png",
                        "isPro": false,
                        "fullname": "Dominik Wagner",
                        "user": "dwgnr",
                        "type": "user"
                    },
                    "name": "Dominik Wagner",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T11:12:27.148Z",
                    "hidden": false
                },
                {
                    "_id": "67b55b2cc92c4aa82c135630",
                    "name": "Minki Kang",
                    "hidden": false
                },
                {
                    "_id": "67b55b2cc92c4aa82c135631",
                    "user": {
                        "_id": "63a9379e2e05ca32e352d93b",
                        "avatarUrl": "/avatars/6cda37befc873a92ed6d5dcba507954a.svg",
                        "isPro": false,
                        "fullname": "Haebin Seong",
                        "user": "hbseong",
                        "type": "user"
                    },
                    "name": "Haebin Seong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:51:37.783Z",
                    "hidden": false
                },
                {
                    "_id": "67b55b2cc92c4aa82c135632",
                    "name": "Tobias Bocklet",
                    "hidden": false
                },
                {
                    "_id": "67b55b2cc92c4aa82c135633",
                    "name": "Juho Lee",
                    "hidden": false
                },
                {
                    "_id": "67b55b2cc92c4aa82c135634",
                    "name": "Sung Ju Hwang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T02:51:17.000Z",
            "title": "SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety\n  Guardrails in Large Language Models",
            "summary": "Deploying large language models (LLMs) in real-world applications requires\nrobust safety guard models to detect and block harmful user prompts. While\nlarge safety guard models achieve strong performance, their computational cost\nis substantial. To mitigate this, smaller distilled models are used, but they\noften underperform on \"hard\" examples where the larger model provides accurate\npredictions. We observe that many inputs can be reliably handled by the smaller\nmodel, while only a small fraction require the larger model's capacity.\nMotivated by this, we propose SafeRoute, a binary router that distinguishes\nhard examples from easy ones. Our method selectively applies the larger safety\nguard model to the data that the router considers hard, improving efficiency\nwhile maintaining accuracy compared to solely using the larger safety guard\nmodel. Experimental results on multiple benchmark datasets demonstrate that our\nadaptive model selection significantly enhances the trade-off between\ncomputational cost and safety performance, outperforming relevant baselines.",
            "upvotes": 25,
            "discussionId": "67b55b2dc92c4aa82c13568b"
        },
        "publishedAt": "2025-02-18T23:23:34.214Z",
        "title": "SafeRoute: Adaptive Model Selection for Efficient and Accurate Safety Guardrails in Large Language Models",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64ad5f59b7e4b2c1ce47eb43/ZEq_vSLjsXuPX3O-TWIpE.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12464.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64ad5f59b7e4b2c1ce47eb43",
            "avatarUrl": "/avatars/1f13ebe21a90d8c99920aa2c8cd9ac45.svg",
            "fullname": "Seanie Lee",
            "name": "Seanie-lee",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.09245",
            "authors": [
                {
                    "_id": "67b57a993d4f319f1fa9424b",
                    "user": {
                        "_id": "65db0871ab2f64915ce05e73",
                        "avatarUrl": "/avatars/77e03f493196c5413cd2a02270e93660.svg",
                        "isPro": false,
                        "fullname": "Gleb Gerasimov",
                        "user": "gudleifrr",
                        "type": "user"
                    },
                    "name": "Gleb Gerasimov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T10:10:30.547Z",
                    "hidden": false
                },
                {
                    "_id": "67b57a993d4f319f1fa9424c",
                    "user": {
                        "_id": "63ed5676684767daecac6f8a",
                        "avatarUrl": "/avatars/d0e4a715f9c3fb6d74c183bab751ec35.svg",
                        "isPro": false,
                        "fullname": "Yaroslav Aksenov",
                        "user": "yaraksen",
                        "type": "user"
                    },
                    "name": "Yaroslav Aksenov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:00:41.123Z",
                    "hidden": false
                },
                {
                    "_id": "67b57a993d4f319f1fa9424d",
                    "user": {
                        "_id": "60b364e7f88532cd79eaff7b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654185363389-60b364e7f88532cd79eaff7b.jpeg",
                        "isPro": false,
                        "fullname": "Nikita Balagansky",
                        "user": "elephantmipt",
                        "type": "user"
                    },
                    "name": "Nikita Balagansky",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:33:26.858Z",
                    "hidden": false
                },
                {
                    "_id": "67b57a993d4f319f1fa9424e",
                    "user": {
                        "_id": "6416272d986557e8cac64ece",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6416272d986557e8cac64ece/s3CLjNN_pGj-vJDcENFD2.jpeg",
                        "isPro": false,
                        "fullname": "Viacheslav",
                        "user": "ummagumm-a",
                        "type": "user"
                    },
                    "name": "Viacheslav Sinii",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T11:12:28.927Z",
                    "hidden": false
                },
                {
                    "_id": "67b57a993d4f319f1fa9424f",
                    "user": {
                        "_id": "62a9c8edc19f92ae443ab37f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1669110208492-62a9c8edc19f92ae443ab37f.png",
                        "isPro": false,
                        "fullname": "Daniil Gavrilov",
                        "user": "kefirski",
                        "type": "user"
                    },
                    "name": "Daniil Gavrilov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:00:43.143Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-13T12:00:50.000Z",
            "title": "You Do Not Fully Utilize Transformer's Representation Capacity",
            "summary": "In contrast to RNNs, which compress previous tokens into a single hidden\nstate, Transformers can attend to all previous tokens directly. However,\nstandard Transformers only use representations from the immediately preceding\nlayer. In this paper, we show that this design choice causes representation\ncollapse and leads to suboptimal performance. To address this issue, we\nintroduce Layer-Integrated Memory (LIMe), a simple yet powerful approach that\npreserves the model's overall memory footprint while expanding its\nrepresentational capacity by allowing access to hidden states from earlier\nlayers. Through extensive experiments across various architectures and\ndifferent lookup mechanisms, we demonstrate consistent performance improvements\non a wide range of tasks. Moreover, our analysis of the learned representation\ndynamics and our exploration of depthwise circuits reveal how LIMe integrates\ninformation across layers, pointing to promising directions for future\nresearch.",
            "upvotes": 24,
            "discussionId": "67b57a9a3d4f319f1fa94274"
        },
        "publishedAt": "2025-02-19T03:03:51.930Z",
        "title": "You Do Not Fully Utilize Transformer's Representation Capacity",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63ed5676684767daecac6f8a/tZDsnW0gjHoYCpbZ-wwJi.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09245.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "63ed5676684767daecac6f8a",
            "avatarUrl": "/avatars/d0e4a715f9c3fb6d74c183bab751ec35.svg",
            "fullname": "Yaroslav Aksenov",
            "name": "yaraksen",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.11433",
            "authors": [
                {
                    "_id": "67b54a644508bd0617598c21",
                    "user": {
                        "_id": "67b54cbcd9f66be7f6f3f7de",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/RZwRfp6AcseTCDVXW_eUb.png",
                        "isPro": false,
                        "fullname": "Guojun Xiong",
                        "user": "xionggj001",
                        "type": "user"
                    },
                    "name": "Guojun Xiong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:14:19.641Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c22",
                    "user": {
                        "_id": "668dedbdf278aa900ce400c9",
                        "avatarUrl": "/avatars/b38e29c6b5092f5892bc2e9a7e625c88.svg",
                        "isPro": false,
                        "fullname": "Zhiyang Deng",
                        "user": "zdeng10",
                        "type": "user"
                    },
                    "name": "Zhiyang Deng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:14:39.220Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c23",
                    "name": "Keyi Wang",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c24",
                    "user": {
                        "_id": "62dd8f328456396d4f8aa894",
                        "avatarUrl": "/avatars/af8f5dc7ff937e3e849ecdfd9ca4750b.svg",
                        "isPro": false,
                        "fullname": "Yupeng Cao",
                        "user": "YupengCao",
                        "type": "user"
                    },
                    "name": "Yupeng Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:15:07.509Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c25",
                    "user": {
                        "_id": "634cabd104491d9f7111eea3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1665969099097-noauth.jpeg",
                        "isPro": true,
                        "fullname": "Haohang Li",
                        "user": "Acatsama",
                        "type": "user"
                    },
                    "name": "Haohang Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:15:15.689Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c26",
                    "user": {
                        "_id": "64f757c6016d60f3199ef5e6",
                        "avatarUrl": "/avatars/2659ba698081265d0480b08161718013.svg",
                        "isPro": false,
                        "fullname": "Yangyang Yu",
                        "user": "ShirleyY",
                        "type": "user"
                    },
                    "name": "Yangyang Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:15:22.050Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c27",
                    "user": {
                        "_id": "63a0c0803c8841cfe2cd1f15",
                        "avatarUrl": "/avatars/bbe216db7a33612f23d23ce4ed4ba3f9.svg",
                        "isPro": false,
                        "fullname": "Xueqing Peng",
                        "user": "Xueqing",
                        "type": "user"
                    },
                    "name": "Xueqing Peng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:15:29.692Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c28",
                    "user": {
                        "_id": "6650e0a99ccb17d9679653c5",
                        "avatarUrl": "/avatars/ed08188e64bdebf58329304742f9ac16.svg",
                        "isPro": false,
                        "fullname": "Mingquan Lin",
                        "user": "mq0051",
                        "type": "user"
                    },
                    "name": "Mingquan Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:15:52.483Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c29",
                    "name": "Kaleb E Smith",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c2a",
                    "name": "Xiao-Yang Liu",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c2b",
                    "user": {
                        "_id": "63b58ed5889aa6707f0bb0f4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/9-6SJBOLdqUoc2LrKsI6y.jpeg",
                        "isPro": true,
                        "fullname": "Jimin Huang",
                        "user": "jiminHuang",
                        "type": "user"
                    },
                    "name": "Jimin Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:03.181Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c2c",
                    "user": {
                        "_id": "66f6cb352c5d4ef3578a9c3f",
                        "avatarUrl": "/avatars/0a70c94072bc5e1d018cf12da0904ff0.svg",
                        "isPro": false,
                        "fullname": "Sophia Ananiadou",
                        "user": "Effoula",
                        "type": "user"
                    },
                    "name": "Sophia Ananiadou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:16:09.788Z",
                    "hidden": false
                },
                {
                    "_id": "67b54a644508bd0617598c2d",
                    "user": {
                        "_id": "6479f4317c18dca75e9a9324",
                        "avatarUrl": "/avatars/9aa709230b057f57ee4415c04a622c63.svg",
                        "isPro": false,
                        "fullname": "Xie",
                        "user": "QianqianXie1994",
                        "type": "user"
                    },
                    "name": "Qianqian Xie",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:16:24.340Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-17T04:45:53.000Z",
            "title": "FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning\n  for Financial Trading",
            "summary": "Large language models (LLMs) fine-tuned on multimodal financial data have\ndemonstrated impressive reasoning capabilities in various financial tasks.\nHowever, they often struggle with multi-step, goal-oriented scenarios in\ninteractive financial markets, such as trading, where complex agentic\napproaches are required to improve decision-making. To address this, we propose\nFLAG-Trader, a unified architecture integrating linguistic processing\n(via LLMs) with gradient-driven reinforcement learning (RL) policy\noptimization, in which a partially fine-tuned LLM acts as the policy network,\nleveraging pre-trained knowledge while adapting to the financial domain through\nparameter-efficient fine-tuning. Through policy gradient optimization driven by\ntrading rewards, our framework not only enhances LLM performance in trading but\nalso improves results on other financial-domain tasks. We present extensive\nempirical evidence to validate these enhancements.",
            "upvotes": 24,
            "discussionId": "67b54a654508bd0617598c7e"
        },
        "publishedAt": "2025-02-18T22:06:19.200Z",
        "title": "FLAG-Trader: Fusion LLM-Agent with Gradient-based Reinforcement Learning for Financial Trading",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63b58ed5889aa6707f0bb0f4/2C9mhT-1Qz14hik7sxjf2.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11433.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63b58ed5889aa6707f0bb0f4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/9-6SJBOLdqUoc2LrKsI6y.jpeg",
            "fullname": "Jimin Huang",
            "name": "jiminHuang",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 14
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12513",
            "authors": [
                {
                    "_id": "67b545fd88527668fa8bcc14",
                    "user": {
                        "_id": "6508712e7ee07e274b0f4c94",
                        "avatarUrl": "/avatars/23fe5593b0bce36c2167c3142e57e0e9.svg",
                        "isPro": false,
                        "fullname": "Tiancheng Gu",
                        "user": "GaryGuuu",
                        "type": "user"
                    },
                    "name": "Tiancheng Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:19:15.243Z",
                    "hidden": false
                },
                {
                    "_id": "67b545fd88527668fa8bcc15",
                    "user": {
                        "_id": "63e202f352b7578dba448ab5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e202f352b7578dba448ab5/8itVBLcv14m7OVsoF8h1o.jpeg",
                        "isPro": false,
                        "fullname": "Yang",
                        "user": "Kaichengalex",
                        "type": "user"
                    },
                    "name": "Kaicheng Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T14:37:43.180Z",
                    "hidden": false
                },
                {
                    "_id": "67b545fd88527668fa8bcc16",
                    "name": "Chaoyi Zhang",
                    "hidden": false
                },
                {
                    "_id": "67b545fd88527668fa8bcc17",
                    "name": "Yin Xie",
                    "hidden": false
                },
                {
                    "_id": "67b545fd88527668fa8bcc18",
                    "name": "Xiang An",
                    "hidden": false
                },
                {
                    "_id": "67b545fd88527668fa8bcc19",
                    "name": "Ziyong Feng",
                    "hidden": false
                },
                {
                    "_id": "67b545fd88527668fa8bcc1a",
                    "user": {
                        "_id": "65e7f19e14856e8859fd8adc",
                        "avatarUrl": "/avatars/203e919c361db94028a1b3c6ea52f0c2.svg",
                        "isPro": false,
                        "fullname": "Dongnan Liu",
                        "user": "Nina0607",
                        "type": "user"
                    },
                    "name": "Dongnan Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:20:00.745Z",
                    "hidden": false
                },
                {
                    "_id": "67b545fd88527668fa8bcc1b",
                    "user": {
                        "_id": "6760a8f5e4b55ba1b2b0a7b4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/NddUMmwmZFbS25v1q8KyS.png",
                        "isPro": false,
                        "fullname": "Weidong Cai",
                        "user": "SeriousBro",
                        "type": "user"
                    },
                    "name": "Weidong Cai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:20:18.377Z",
                    "hidden": false
                },
                {
                    "_id": "67b545fd88527668fa8bcc1c",
                    "user": {
                        "_id": "62cc7a38376917c0223dd24b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1657566065867-noauth.png",
                        "isPro": false,
                        "fullname": "JiankangDeng",
                        "user": "JiankangDeng",
                        "type": "user"
                    },
                    "name": "Jiankang Deng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:20:25.455Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T03:58:38.000Z",
            "title": "RealSyn: An Effective and Scalable Multimodal Interleaved Document\n  Transformation Paradigm",
            "summary": "After pre-training on extensive image-text pairs, Contrastive Language-Image\nPre-training (CLIP) demonstrates promising performance on a wide variety of\nbenchmarks. However, a substantial volume of non-paired data, such as\nmultimodal interleaved documents, remains underutilized for vision-language\nrepresentation learning. To fully leverage these unpaired documents, we\ninitially establish a Real-World Data Extraction pipeline to extract\nhigh-quality images and texts. Then we design a hierarchical retrieval method\nto efficiently associate each image with multiple semantically relevant\nrealistic texts. To further enhance fine-grained visual information, we propose\nan image semantic augmented generation module for synthetic text production.\nFurthermore, we employ a semantic balance sampling strategy to improve dataset\ndiversity, enabling better learning of long-tail concepts. Based on these\ninnovations, we construct RealSyn, a dataset combining realistic and synthetic\ntexts, available in three scales: 15M, 30M, and 100M. Extensive experiments\ndemonstrate that RealSyn effectively advances vision-language representation\nlearning and exhibits strong scalability. Models pre-trained on RealSyn achieve\nstate-of-the-art performance on multiple downstream tasks. To facilitate future\nresearch, the RealSyn dataset and pre-trained model weights are released at\nhttps://github.com/deepglint/RealSyn.",
            "upvotes": 14,
            "discussionId": "67b545fe88527668fa8bcc65"
        },
        "publishedAt": "2025-02-18T21:52:22.326Z",
        "title": "RealSyn: An Effective and Scalable Multimodal Interleaved Document Transformation Paradigm",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12513.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63e202f352b7578dba448ab5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63e202f352b7578dba448ab5/8itVBLcv14m7OVsoF8h1o.jpeg",
            "fullname": "Yang",
            "name": "Kaichengalex",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.11271",
            "authors": [
                {
                    "_id": "67b4322c217ec18a40587bec",
                    "user": {
                        "_id": "60f5f68fa7fd83d025749234",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60f5f68fa7fd83d025749234/gCeJAZfzaANAcEvI6v5-P.jpeg",
                        "isPro": false,
                        "fullname": "Pan Lu",
                        "user": "lupantech",
                        "type": "user"
                    },
                    "name": "Pan Lu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:04:43.677Z",
                    "hidden": false
                },
                {
                    "_id": "67b4322c217ec18a40587bed",
                    "name": "Bowen Chen",
                    "hidden": false
                },
                {
                    "_id": "67b4322c217ec18a40587bee",
                    "name": "Sheng Liu",
                    "hidden": false
                },
                {
                    "_id": "67b4322c217ec18a40587bef",
                    "name": "Rahul Thapa",
                    "hidden": false
                },
                {
                    "_id": "67b4322c217ec18a40587bf0",
                    "user": {
                        "_id": "66846f30f53c83742c117277",
                        "avatarUrl": "/avatars/31a2434297a6c194d57f2a0234f1ca2c.svg",
                        "isPro": false,
                        "fullname": "Joseph Boen",
                        "user": "tboen1",
                        "type": "user"
                    },
                    "name": "Joseph Boen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:39:08.417Z",
                    "hidden": false
                },
                {
                    "_id": "67b4322c217ec18a40587bf1",
                    "name": "James Zou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-16T21:18:47.000Z",
            "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex\n  Reasoning",
            "summary": "Solving complex reasoning tasks may involve visual understanding, domain\nknowledge retrieval, numerical calculation, and multi-step reasoning. Existing\nmethods augment large language models (LLMs) with external tools but are\nrestricted to specialized domains, limited tool types, or require additional\ntraining data. In this paper, we introduce OctoTools, a training-free,\nuser-friendly, and easily extensible open-source agentic framework designed to\ntackle complex reasoning across diverse domains. OctoTools introduces\nstandardized tool cards to encapsulate tool functionality, a planner for both\nhigh-level and low-level planning, and an executor to carry out tool usage. We\nvalidate OctoTools' generality across 16 diverse tasks (including MathVista,\nMMLU-Pro, MedQA, and GAIA-Text), achieving substantial average accuracy gains\nof 9.3% over GPT-4o. Furthermore, OctoTools outperforms AutoGen, GPT-Functions\nand LangChain by up to 10.6% when given the same set of tools. Through\ncomprehensive analysis and ablations, OctoTools demonstrates advantages in task\nplanning, effective tool usage, and multi-step problem solving.",
            "upvotes": 10,
            "discussionId": "67b4322d217ec18a40587c27"
        },
        "publishedAt": "2025-02-19T02:27:36.940Z",
        "title": "OctoTools: An Agentic Framework with Extensible Tools for Complex Reasoning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.11271.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "60f5f68fa7fd83d025749234",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60f5f68fa7fd83d025749234/gCeJAZfzaANAcEvI6v5-P.jpeg",
            "fullname": "Pan Lu",
            "name": "lupantech",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 5
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12859",
            "authors": [
                {
                    "_id": "67b576aa489d68b981e086ad",
                    "user": {
                        "_id": "65ed3051492a7f35db21fea2",
                        "avatarUrl": "/avatars/4fc0ccc21aa88e4e8ff74a6f850570b8.svg",
                        "isPro": false,
                        "fullname": "Chenxing Wei",
                        "user": "kittttttt",
                        "type": "user"
                    },
                    "name": "Chenxing Wei",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:23:00.016Z",
                    "hidden": false
                },
                {
                    "_id": "67b576aa489d68b981e086ae",
                    "user": {
                        "_id": "66123816d7dfcea8ae55a751",
                        "avatarUrl": "/avatars/3f24468b63e4babd7d9a0c926ca01b23.svg",
                        "isPro": false,
                        "fullname": "Shu Yao",
                        "user": "ZCODE0",
                        "type": "user"
                    },
                    "name": "Yao Shu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T14:37:34.696Z",
                    "hidden": false
                },
                {
                    "_id": "67b576aa489d68b981e086af",
                    "name": "Mingwen Ou",
                    "hidden": false
                },
                {
                    "_id": "67b576aa489d68b981e086b0",
                    "name": "Ying Tiffany He",
                    "hidden": false
                },
                {
                    "_id": "67b576aa489d68b981e086b1",
                    "name": "Fei Richard Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T13:46:47.000Z",
            "title": "PAFT: Prompt-Agnostic Fine-Tuning",
            "summary": "While Large Language Models (LLMs) adapt well to downstream tasks after\nfine-tuning, this adaptability often compromises prompt robustness, as even\nminor prompt variations can significantly degrade performance. To address this,\nwe propose Prompt-Agnostic Fine-Tuning(PAFT), a simple yet effective approach\nthat dynamically adjusts prompts during fine-tuning. This encourages the model\nto learn underlying task principles rather than overfitting to specific prompt\nformulations. PAFT operates in two stages: First, a diverse set of meaningful,\nsynthetic candidate prompts is constructed. Second, during fine-tuning, prompts\nare randomly sampled from this set to create dynamic training inputs. Extensive\nexperiments across diverse datasets and LLMs demonstrate that models trained\nwith PAFT exhibit strong robustness and generalization across a wide range of\nprompts, including unseen ones. This enhanced robustness improves both model\nperformance and inference speed while maintaining training efficiency. Ablation\nstudies further confirm the effectiveness of PAFT.",
            "upvotes": 10,
            "discussionId": "67b576aa489d68b981e08708"
        },
        "publishedAt": "2025-02-19T01:21:54.836Z",
        "title": "PAFT: Prompt-Agnostic Fine-Tuning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12859.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65ed3051492a7f35db21fea2",
            "avatarUrl": "/avatars/4fc0ccc21aa88e4e8ff74a6f850570b8.svg",
            "fullname": "Chenxing Wei",
            "name": "kittttttt",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12170",
            "authors": [
                {
                    "_id": "67b5434f2b2ec6908fffe75e",
                    "name": "Da Xiao",
                    "hidden": false
                },
                {
                    "_id": "67b5434f2b2ec6908fffe75f",
                    "user": {
                        "_id": "634f9c94cdc89e42cc7b194a",
                        "avatarUrl": "/avatars/42376474afe9b68dc44184c71e210529.svg",
                        "isPro": false,
                        "fullname": "Qingye Meng",
                        "user": "Hilbertmeng",
                        "type": "user"
                    },
                    "name": "Qingye Meng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:23:45.040Z",
                    "hidden": false
                },
                {
                    "_id": "67b5434f2b2ec6908fffe760",
                    "user": {
                        "_id": "6706a37cca9b1a88fc3951ea",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/Y4GvpKiVgqm_2Kod52_B8.png",
                        "isPro": false,
                        "fullname": "lishengping",
                        "user": "lishengping",
                        "type": "user"
                    },
                    "name": "Shengping Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T10:23:38.331Z",
                    "hidden": false
                },
                {
                    "_id": "67b5434f2b2ec6908fffe761",
                    "name": "Xingyuan Yuan",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-13T10:26:27.000Z",
            "title": "MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway\n  Dynamic Dense Connections",
            "summary": "We propose MUltiway Dynamic Dense (MUDD) connections, a simple yet effective\nmethod to address the limitations of residual connections and enhance\ncross-layer information flow in Transformers. Unlike existing dense connection\napproaches with static and shared connection weights, MUDD generates connection\nweights dynamically depending on hidden states at each sequence position and\nfor each decoupled input stream (the query, key, value or residual) of a\nTransformer block. MUDD connections can be seamlessly integrated into any\nTransformer architecture to create MUDDFormer. Extensive experiments show that\nMUDDFormer significantly outperforms Transformers across various model\narchitectures and scales in language modeling, achieving the performance of\nTransformers trained with 1.8X-2.4X compute. Notably, MUDDPythia-2.8B matches\nPythia-6.9B in pretraining ppl and downstream tasks and even rivals Pythia-12B\nin five-shot settings, while adding only 0.23% parameters and 0.4% computation.\nCode in JAX and PyTorch and pre-trained models are available at\nhttps://github.com/Caiyun-AI/MUDDFormer .",
            "upvotes": 10,
            "discussionId": "67b543502b2ec6908fffe788"
        },
        "publishedAt": "2025-02-18T22:59:16.530Z",
        "title": "MUDDFormer: Breaking Residual Bottlenecks in Transformers via Multiway Dynamic Dense Connections",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12170.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "62d77440bad37ef354028365",
            "avatarUrl": "/avatars/df0dea879e06fa814867e9aad03d1e68.svg",
            "fullname": "Da Xiao",
            "name": "xiaoda99",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.12215",
            "authors": [
                {
                    "_id": "67b56007fa141a55e51d9d78",
                    "name": "Zhiyuan Zeng",
                    "hidden": false
                },
                {
                    "_id": "67b56007fa141a55e51d9d79",
                    "name": "Qinyuan Cheng",
                    "hidden": false
                },
                {
                    "_id": "67b56007fa141a55e51d9d7a",
                    "user": {
                        "_id": "628c5da32f09ccf530204dbe",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1653366416287-628c5da32f09ccf530204dbe.jpeg",
                        "isPro": false,
                        "fullname": "Zhangyue Yin",
                        "user": "yinzhangyue",
                        "type": "user"
                    },
                    "name": "Zhangyue Yin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T11:50:17.993Z",
                    "hidden": false
                },
                {
                    "_id": "67b56007fa141a55e51d9d7b",
                    "name": "Yunhua Zhou",
                    "hidden": false
                },
                {
                    "_id": "67b56007fa141a55e51d9d7c",
                    "user": {
                        "_id": "61457b8deff2c9fdb4de4988",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1632381702899-61457b8deff2c9fdb4de4988.jpeg",
                        "isPro": false,
                        "fullname": "Xipeng Qiu",
                        "user": "xpqiu",
                        "type": "user"
                    },
                    "name": "Xipeng Qiu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T11:50:29.919Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-17T07:21:11.000Z",
            "title": "Revisiting the Test-Time Scaling of o1-like Models: Do they Truly\n  Possess Test-Time Scaling Capabilities?",
            "summary": "The advent of test-time scaling in large language models (LLMs), exemplified\nby OpenAI's o1 series, has advanced reasoning capabilities by scaling\ncomputational resource allocation during inference. While successors like QwQ,\nDeepseek-R1 (R1) and LIMO replicate these advancements, whether these models\ntruly possess test-time scaling capabilities remains underexplored. This study\nfound that longer CoTs of these o1-like models do not consistently enhance\naccuracy; in fact, correct solutions are often shorter than incorrect ones for\nthe same questions. Further investigation shows this phenomenon is closely\nrelated to models' self-revision capabilities - longer CoTs contain more\nself-revisions, which often lead to performance degradation. We then compare\nsequential and parallel scaling strategies on QwQ, R1 and LIMO, finding that\nparallel scaling achieves better coverage and scalability. Based on these\ninsights, we propose Shortest Majority Vote, a method that combines parallel\nscaling strategies with CoT length characteristics, significantly improving\nmodels' test-time scalability compared to conventional majority voting\napproaches.",
            "upvotes": 9,
            "discussionId": "67b56007fa141a55e51d9da7"
        },
        "publishedAt": "2025-02-18T23:37:46.756Z",
        "title": "Revisiting the Test-Time Scaling of o1-like Models: Do they Truly Possess Test-Time Scaling Capabilities?",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12215.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 6144
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.13092",
            "authors": [
                {
                    "_id": "67b5473109afe1f3029835cb",
                    "user": {
                        "_id": "6237df4a5ab9df625fb70c1a",
                        "avatarUrl": "/avatars/c5d1a52895cb6515f28019a8e7e3e855.svg",
                        "isPro": false,
                        "fullname": "Mengkang Hu",
                        "user": "MengkangHu",
                        "type": "user"
                    },
                    "name": "Mengkang Hu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:15.592Z",
                    "hidden": false
                },
                {
                    "_id": "67b5473109afe1f3029835cc",
                    "name": "Tianxing Chen",
                    "hidden": false
                },
                {
                    "_id": "67b5473109afe1f3029835cd",
                    "name": "Yude Zou",
                    "hidden": false
                },
                {
                    "_id": "67b5473109afe1f3029835ce",
                    "name": "Yuheng Lei",
                    "hidden": false
                },
                {
                    "_id": "67b5473109afe1f3029835cf",
                    "user": {
                        "_id": "636f526a6cd69d9a36ff2b53",
                        "avatarUrl": "/avatars/8f2271a193fcac609d9be270552b5afa.svg",
                        "isPro": false,
                        "fullname": "Qiguang Chen",
                        "user": "LightChen2333",
                        "type": "user"
                    },
                    "name": "Qiguang Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:12.095Z",
                    "hidden": false
                },
                {
                    "_id": "67b5473109afe1f3029835d0",
                    "name": "Ming Li",
                    "hidden": false
                },
                {
                    "_id": "67b5473109afe1f3029835d1",
                    "name": "Hongyuan Zhang",
                    "hidden": false
                },
                {
                    "_id": "67b5473109afe1f3029835d2",
                    "name": "Wenqi Shao",
                    "hidden": false
                },
                {
                    "_id": "67b5473109afe1f3029835d3",
                    "name": "Ping Luo",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T17:59:48.000Z",
            "title": "Text2World: Benchmarking Large Language Models for Symbolic World Model\n  Generation",
            "summary": "Recently, there has been growing interest in leveraging large language models\n(LLMs) to generate symbolic world models from textual descriptions. Although\nLLMs have been extensively explored in the context of world modeling, prior\nstudies encountered several challenges, including evaluation randomness,\ndependence on indirect metrics, and a limited domain scope. To address these\nlimitations, we introduce a novel benchmark, Text2World, based on planning\ndomain definition language (PDDL), featuring hundreds of diverse domains and\nemploying multi-criteria, execution-based metrics for a more robust evaluation.\nWe benchmark current LLMs using Text2World and find that reasoning models\ntrained with large-scale reinforcement learning outperform others. However,\neven the best-performing model still demonstrates limited capabilities in world\nmodeling. Building on these insights, we examine several promising strategies\nto enhance the world modeling capabilities of LLMs, including test-time\nscaling, agent training, and more. We hope that Text2World can serve as a\ncrucial resource, laying the groundwork for future research in leveraging LLMs\nas world models. The project page is available at\nhttps://text-to-world.github.io/.",
            "upvotes": 8,
            "discussionId": "67b5473209afe1f302983600"
        },
        "publishedAt": "2025-02-19T07:53:04.918Z",
        "title": "Text2World: Benchmarking Large Language Models for Symbolic World Model Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13092.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6237df4a5ab9df625fb70c1a",
            "avatarUrl": "/avatars/c5d1a52895cb6515f28019a8e7e3e855.svg",
            "fullname": "Mengkang Hu",
            "name": "MengkangHu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12996",
            "authors": [
                {
                    "_id": "67b5bcd091132877cf330179",
                    "name": "Satyen Kale",
                    "hidden": false
                },
                {
                    "_id": "67b5bcd091132877cf33017a",
                    "user": {
                        "_id": "622792366303bf1dc304f49f",
                        "avatarUrl": "/avatars/975c1cc3eb2f97cf8e848162056d5bea.svg",
                        "isPro": false,
                        "fullname": "Arthur Douillard",
                        "user": "ArthurDouillard",
                        "type": "user"
                    },
                    "name": "Arthur Douillard",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:42:51.668Z",
                    "hidden": false
                },
                {
                    "_id": "67b5bcd091132877cf33017b",
                    "user": {
                        "_id": "61796df92357d28cdf952511",
                        "avatarUrl": "/avatars/01821f364cf78c95aed1986d91d40610.svg",
                        "isPro": false,
                        "fullname": "Yanislav Donchev",
                        "user": "yannidd",
                        "type": "user"
                    },
                    "name": "Yanislav Donchev",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:42:57.488Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T16:16:14.000Z",
            "title": "Eager Updates For Overlapped Communication and Computation in DiLoCo",
            "summary": "Distributed optimization methods such as DiLoCo have been shown to be\neffective in training very large models across multiple distributed workers,\nsuch as datacenters. These methods split updates into two parts: an inner\noptimization phase, where the workers independently execute multiple\noptimization steps on their own local data, and an outer optimization step,\nwhere the inner updates are synchronized. While such approaches require orders\nof magnitude less communication than standard data-parallel training, in\nsettings where the workers are datacenters, even the limited communication\nrequirements of these approaches can still cause significant slow downs due to\nthe blocking necessary at each outer optimization step. In this paper, we\ninvestigate techniques to mitigate this issue by overlapping communication with\ncomputation in a manner that allows the outer optimization step to fully\noverlap with the inner optimization phase. We show that a particular variant,\ndubbed eager updates, provides competitive performance with standard DiLoCo in\nsettings with low bandwidth between workers.",
            "upvotes": 7,
            "discussionId": "67b5bcd191132877cf3301aa"
        },
        "publishedAt": "2025-02-19T06:13:51.101Z",
        "title": "Eager Updates For Overlapped Communication and Computation in DiLoCo",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12996.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "622792366303bf1dc304f49f",
            "avatarUrl": "/avatars/975c1cc3eb2f97cf8e848162056d5bea.svg",
            "fullname": "Arthur Douillard",
            "name": "ArthurDouillard",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.09838",
            "authors": [
                {
                    "_id": "67b55078a64445f58c771d84",
                    "user": {
                        "_id": "677606a43e33dab24a102ea2",
                        "avatarUrl": "/avatars/8270ae83d58dfc55fd435664d143eb6e.svg",
                        "isPro": false,
                        "fullname": "Tianwei Lin",
                        "user": "TianweiLin",
                        "type": "user"
                    },
                    "name": "Tianwei Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:39:34.771Z",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d85",
                    "user": {
                        "_id": "65fc18edfb66882aba4d548e",
                        "avatarUrl": "/avatars/f70d47fe4aba98b5a5cd64f7e002dfd2.svg",
                        "isPro": false,
                        "fullname": "wenqiao",
                        "user": "wannature",
                        "type": "user"
                    },
                    "name": "Wenqiao Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:40:41.324Z",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d86",
                    "name": "Sijing Li",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d87",
                    "name": "Yuqian Yuan",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d88",
                    "user": {
                        "_id": "648ad056dc6a5b4b88306ae2",
                        "avatarUrl": "/avatars/66a47a11626c05b706de33a3184182e9.svg",
                        "isPro": false,
                        "fullname": "yu",
                        "user": "binheyu1991",
                        "type": "user"
                    },
                    "name": "Binhe Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:41:15.907Z",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d89",
                    "name": "Haoyuan Li",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d8a",
                    "name": "Wanggui He",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d8b",
                    "name": "Hao Jiang",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d8c",
                    "name": "Mengze Li",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d8d",
                    "user": {
                        "_id": "635156f1f74cdcca6f7acf70",
                        "avatarUrl": "/avatars/133e88b30255425f6da7777737f91e81.svg",
                        "isPro": false,
                        "fullname": "Xiaohui Song",
                        "user": "fpcsong",
                        "type": "user"
                    },
                    "name": "Xiaohui Song",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:42:09.080Z",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d8e",
                    "name": "Siliang Tang",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d8f",
                    "name": "Jun Xiao",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d90",
                    "name": "Hui Lin",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d91",
                    "name": "Yueting Zhuang",
                    "hidden": false
                },
                {
                    "_id": "67b55078a64445f58c771d92",
                    "name": "Beng Chin Ooi",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-14T00:42:36.000Z",
            "title": "HealthGPT: A Medical Large Vision-Language Model for Unifying\n  Comprehension and Generation via Heterogeneous Knowledge Adaptation",
            "summary": "We present HealthGPT, a powerful Medical Large Vision-Language Model\n(Med-LVLM) that integrates medical visual comprehension and generation\ncapabilities within a unified autoregressive paradigm. Our bootstrapping\nphilosophy is to progressively adapt heterogeneous comprehension and generation\nknowledge to pre-trained large language models (LLMs). This is achieved through\na novel heterogeneous low-rank adaptation (H-LoRA) technique, which is\ncomplemented by a tailored hierarchical visual perception approach and a\nthree-stage learning strategy. To effectively learn the HealthGPT, we devise a\ncomprehensive medical domain-specific comprehension and generation dataset\ncalled VL-Health. Experimental results demonstrate exceptional performance and\nscalability of HealthGPT in medical visual unified tasks. Our project can be\naccessed at https://github.com/DCDmllm/HealthGPT.",
            "upvotes": 7,
            "discussionId": "67b5507aa64445f58c771df9"
        },
        "publishedAt": "2025-02-18T22:35:23.066Z",
        "title": "HealthGPT: A Medical Large Vision-Language Model for Unifying Comprehension and Generation via Heterogeneous Knowledge Adaptation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.09838.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65fc18edfb66882aba4d548e",
            "avatarUrl": "/avatars/f70d47fe4aba98b5a5cd64f7e002dfd2.svg",
            "fullname": "wenqiao",
            "name": "wannature",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12018",
            "authors": [
                {
                    "_id": "67b5c4ed85107d20148ae710",
                    "user": {
                        "_id": "6402e8fb06c715b93407442d",
                        "avatarUrl": "/avatars/12b67f0632be5a53b56d8a68586a7f98.svg",
                        "isPro": false,
                        "fullname": "Fengwei Teng",
                        "user": "leavendough",
                        "type": "user"
                    },
                    "name": "Fengwei Teng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T11:49:34.612Z",
                    "hidden": false
                },
                {
                    "_id": "67b5c4ed85107d20148ae711",
                    "user": {
                        "_id": "640dc84b474aa6f89554d518",
                        "avatarUrl": "/avatars/64f47f76d97c5e91b7ab8380bcada61c.svg",
                        "isPro": false,
                        "fullname": "Zhaoyang Yu",
                        "user": "MoshiQAQ",
                        "type": "user"
                    },
                    "name": "Zhaoyang Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:43:14.422Z",
                    "hidden": false
                },
                {
                    "_id": "67b5c4ed85107d20148ae712",
                    "name": "Quan Shi",
                    "hidden": false
                },
                {
                    "_id": "67b5c4ed85107d20148ae713",
                    "user": {
                        "_id": "66071c8b013a0afdf40fbfd1",
                        "avatarUrl": "/avatars/683e4ba5991059110631759a5975eacc.svg",
                        "isPro": false,
                        "fullname": "JiaYi Zhang",
                        "user": "Bbedd",
                        "type": "user"
                    },
                    "name": "Jiayi Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T14:43:54.773Z",
                    "hidden": false
                },
                {
                    "_id": "67b5c4ed85107d20148ae714",
                    "name": "Chenglin Wu",
                    "hidden": false
                },
                {
                    "_id": "67b5c4ed85107d20148ae715",
                    "name": "Yuyu Luo",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-17T16:52:42.000Z",
            "title": "Atom of Thoughts for Markov LLM Test-Time Scaling",
            "summary": "Large Language Models (LLMs) achieve superior performance through\ntraining-time scaling, and test-time scaling further enhances their\ncapabilities by conducting effective reasoning during inference. However, as\nthe scale of reasoning increases, existing test-time scaling methods suffer\nfrom accumulated historical information, which not only wastes computational\nresources but also interferes with effective reasoning. To address this issue,\nwe observe that complex reasoning progress is often achieved by solving a\nsequence of independent subquestions, each being self-contained and verifiable.\nThese subquestions are essentially atomic questions, relying primarily on their\ncurrent state rather than accumulated history, similar to the memoryless\ntransitions in a Markov process. Based on this observation, we propose Atom of\nThoughts (AoT), where each state transition in the reasoning process consists\nof decomposing the current question into a dependency-based directed acyclic\ngraph and contracting its subquestions, forming a new atomic question state.\nThis iterative decomposition-contraction process continues until reaching\ndirectly solvable atomic questions, naturally realizing Markov transitions\nbetween question states. Furthermore, these atomic questions can be seamlessly\nintegrated into existing test-time scaling methods, enabling AoT to serve as a\nplug-in enhancement for improving reasoning capabilities. Experiments across\nsix benchmarks demonstrate the effectiveness of AoT both as a standalone\nframework and a plug-in enhancement. Notably, on HotpotQA, when applied to\ngpt-4o-mini, AoT achieves an 80.6% F1 score, surpassing o3-mini by 3.4% and\nDeepSeek-R1 by 10.6%. The code will be available at\nhttps://github.com/qixucen/atom.",
            "upvotes": 6,
            "discussionId": "67b5c4ee85107d20148ae73d"
        },
        "publishedAt": "2025-02-19T06:51:04.672Z",
        "title": "Atom of Thoughts for Markov LLM Test-Time Scaling",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12018.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6402e8fb06c715b93407442d",
            "avatarUrl": "/avatars/12b67f0632be5a53b56d8a68586a7f98.svg",
            "fullname": "Fengwei Teng",
            "name": "leavendough",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12574",
            "authors": [
                {
                    "_id": "67b547f555d0424a31b9c384",
                    "user": {
                        "_id": "64cb48f7667f4f808535107e",
                        "avatarUrl": "/avatars/8f77f378ad665b246e1ea3aaba2153ae.svg",
                        "isPro": false,
                        "fullname": "chengluo",
                        "user": "wdlctc",
                        "type": "user"
                    },
                    "name": "Cheng Luo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:40:25.130Z",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c385",
                    "user": {
                        "_id": "64b15284372d4340772a3dca",
                        "avatarUrl": "/avatars/417d5f1bc1bcb5e4d5de6169673c2cf7.svg",
                        "isPro": false,
                        "fullname": "Zefan Cai",
                        "user": "ZefanCai",
                        "type": "user"
                    },
                    "name": "Zefan Cai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:40:47.077Z",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c386",
                    "name": "Hanshi Sun",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c387",
                    "user": {
                        "_id": "64c15c5bea792b1950e302e4",
                        "avatarUrl": "/avatars/51f84365cc08a1dcd5da70968389aed2.svg",
                        "isPro": false,
                        "fullname": "Jinqi Xiao",
                        "user": "jinqixiao",
                        "type": "user"
                    },
                    "name": "Jinqi Xiao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:41:01.931Z",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c388",
                    "name": "Bo Yuan",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c389",
                    "name": "Wen Xiao",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c38a",
                    "user": {
                        "_id": "675f8271a63fff7b5bcbc478",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/9tJn7NyzLMreCJVH4wRho.png",
                        "isPro": false,
                        "fullname": "Junjie Hu",
                        "user": "junjiehu",
                        "type": "user"
                    },
                    "name": "Junjie Hu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:41:18.304Z",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c38b",
                    "name": "Jiawei Zhao",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c38c",
                    "user": {
                        "_id": "64b732f832403871593e082c",
                        "avatarUrl": "/avatars/dd21932b0c167131ee7545a622c46c3c.svg",
                        "isPro": false,
                        "fullname": "Beidi Chen",
                        "user": "beidic",
                        "type": "user"
                    },
                    "name": "Beidi Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:39:20.563Z",
                    "hidden": false
                },
                {
                    "_id": "67b547f555d0424a31b9c38d",
                    "user": {
                        "_id": "6532920b3e385cfc6002938d",
                        "avatarUrl": "/avatars/cb9cc6d2733031582c83f56dc6cd1dd5.svg",
                        "isPro": false,
                        "fullname": "Anima Anandkumar",
                        "user": "animakumar",
                        "type": "user"
                    },
                    "name": "Anima Anandkumar",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:39:15.091Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T06:26:05.000Z",
            "title": "HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading",
            "summary": "Transformer-based large language models (LLMs) demonstrate impressive\nperformance in long context generation. Extending the context length has\ndisproportionately shifted the memory footprint of LLMs during inference to the\nkey-value cache (KV cache). In this paper, we propose HEADINFER, which offloads\nthe KV cache to CPU RAM while avoiding the need to fully store the KV cache for\nany transformer layer on the GPU. HEADINFER employs a fine-grained, head-wise\noffloading strategy, maintaining only selective attention heads KV cache on the\nGPU while computing attention output dynamically. Through roofline analysis, we\ndemonstrate that HEADINFER maintains computational efficiency while\nsignificantly reducing memory footprint. We evaluate HEADINFER on the\nLlama-3-8B model with a 1-million-token sequence, reducing the GPU memory\nfootprint of the KV cache from 128 GB to 1 GB and the total GPU memory usage\nfrom 207 GB to 17 GB, achieving a 92% reduction compared to BF16 baseline\ninference. Notably, HEADINFER enables 4-million-token inference with an 8B\nmodel on a single consumer GPU with 24GB memory (e.g., NVIDIA RTX 4090) without\napproximation methods.",
            "upvotes": 6,
            "discussionId": "67b547f755d0424a31b9c3e5"
        },
        "publishedAt": "2025-02-18T21:57:00.289Z",
        "title": "HeadInfer: Memory-Efficient LLM Inference by Head-wise Offloading",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12574.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64cb48f7667f4f808535107e",
            "avatarUrl": "/avatars/8f77f378ad665b246e1ea3aaba2153ae.svg",
            "fullname": "chengluo",
            "name": "wdlctc",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12501",
            "authors": [
                {
                    "_id": "67b547ffc9071a3e97139532",
                    "user": {
                        "_id": "62a42f22c683d02f5b63320c",
                        "avatarUrl": "/avatars/bc611abe9c4ef8d378123cb8ac9fdbf2.svg",
                        "isPro": false,
                        "fullname": "Qiyuan Zhang",
                        "user": "DonJoey",
                        "type": "user"
                    },
                    "name": "Qiyuan Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:10.215Z",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e97139533",
                    "name": "Yufei Wang",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e97139534",
                    "user": {
                        "_id": "63c20105726f62e411fbe882",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63c20105726f62e411fbe882/2UsU9O2psbDjJzz-sAmGH.jpeg",
                        "isPro": false,
                        "fullname": "Yuxin Jiang",
                        "user": "YuxinJiang",
                        "type": "user"
                    },
                    "name": "Yuxin Jiang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:01:08.101Z",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e97139535",
                    "name": "Liangyou Li",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e97139536",
                    "name": "Chuhan Wu",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e97139537",
                    "name": "Yasheng Wang",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e97139538",
                    "user": {
                        "_id": "647415007afa69c3c7a98f1f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647415007afa69c3c7a98f1f/pEl0PozmzNK8_PwUMiikd.jpeg",
                        "isPro": false,
                        "fullname": "Xin Jiang",
                        "user": "horiz94",
                        "type": "user"
                    },
                    "name": "Xin Jiang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T11:54:48.156Z",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e97139539",
                    "user": {
                        "_id": "655b1360c11dee7f7e7cf794",
                        "avatarUrl": "/avatars/efb4b91e9bb8ab531331c8e4296f754c.svg",
                        "isPro": false,
                        "fullname": "lifengshang",
                        "user": "lifengshang",
                        "type": "user"
                    },
                    "name": "Lifeng Shang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T11:54:33.330Z",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e9713953a",
                    "user": {
                        "_id": "6728c3b8d5ceae39aa1d2fdd",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/VV4-DjhxzEVceNLmsokn2.png",
                        "isPro": false,
                        "fullname": "tang ruiming",
                        "user": "zhangsan5421",
                        "type": "user"
                    },
                    "name": "Ruiming Tang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T11:54:25.814Z",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e9713953b",
                    "user": {
                        "_id": "65d2bb5c6130ef7be012d235",
                        "avatarUrl": "/avatars/1c1e3bbb2c683a5c9d1f792a2c13fc4a.svg",
                        "isPro": false,
                        "fullname": "Fuyuan Lyu",
                        "user": "silentspring2",
                        "type": "user"
                    },
                    "name": "Fuyuan Lyu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T11:54:14.440Z",
                    "hidden": false
                },
                {
                    "_id": "67b547ffc9071a3e9713953c",
                    "name": "Chen Ma",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T03:31:06.000Z",
            "title": "Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for\n  LLM-as-a-Judge",
            "summary": "LLM-as-a-Judge, which generates chain-of-thought (CoT) judgments, has become\na widely adopted auto-evaluation method. However, its reliability is\ncompromised by the CoT reasoning's inability to capture comprehensive and\ndeeper details, often leading to incomplete outcomes. Existing methods mainly\nrely on majority voting or criteria expansion, which is insufficient to address\nthe limitation in CoT. We propose Crowd-based Comparative Evaluation, which\nintroduces additional crowd responses to compare with the candidate responses,\nthereby exposing deeper and more comprehensive details within the candidate\nresponses. This process effectively guides LLM-as-a-Judge to provide a more\ndetailed CoT judgment. Extensive experiments demonstrate that our approach\nenhances evaluation reliability, achieving an average accuracy gain of 6.7%\nacross five benchmarks. Moreover, our method produces higher-quality CoTs that\nfacilitate judge distillation and exhibit superior performance in rejection\nsampling for supervised fine-tuning (SFT), referred to as crowd rejection\nsampling, thereby enabling more efficient SFT. Our analysis confirms that CoTs\ngenerated by ours are more comprehensive and of higher quality, and evaluation\naccuracy improves as inference scales.",
            "upvotes": 5,
            "discussionId": "67b54800c9071a3e9713956c"
        },
        "publishedAt": "2025-02-18T21:55:26.822Z",
        "title": "Crowd Comparative Reasoning: Unlocking Comprehensive Evaluations for LLM-as-a-Judge",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12501.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "62a42f22c683d02f5b63320c",
            "avatarUrl": "/avatars/bc611abe9c4ef8d378123cb8ac9fdbf2.svg",
            "fullname": "Qiyuan Zhang",
            "name": "DonJoey",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12929",
            "authors": [
                {
                    "_id": "67b546dc2b2ec6908f00c771",
                    "user": {
                        "_id": "643837ef581e6bf0fa9c72f8",
                        "avatarUrl": "/avatars/5b95d2509d1c7640d77a3405ebd53eaf.svg",
                        "isPro": false,
                        "fullname": "Lakshmi Nair",
                        "user": "lnair",
                        "type": "user"
                    },
                    "name": "Lakshmi Nair",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T14:37:39.033Z",
                    "hidden": false
                },
                {
                    "_id": "67b546dc2b2ec6908f00c772",
                    "name": "Ian Trase",
                    "hidden": false
                },
                {
                    "_id": "67b546dc2b2ec6908f00c773",
                    "name": "Mark Kim",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T15:11:46.000Z",
            "title": "Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking\n  Through Options",
            "summary": "We present a novel reasoning approach called Flow-of-Options (FoO), designed\nto address intrinsic biases in Large Language Models (LLMs). FoO enables LLMs\nto systematically explore a diverse range of possibilities in their reasoning,\nas demonstrated by an FoO-based agentic system for autonomously solving Machine\nLearning tasks (AutoML). Our framework outperforms state-of-the-art baselines,\nachieving improvements of 38.2% - 69.2% on standard data science tasks, and\n37.4% - 47.9% on therapeutic chemistry tasks. With an overall operation cost\nunder $1 per task, our framework is well-suited for cost-sensitive\napplications. Beyond classification and regression, we illustrate the broader\napplicability of our FoO-based agentic system to tasks such as reinforcement\nlearning and image generation. Our framework presents significant advancements\ncompared to current state-of-the-art agentic systems for AutoML, due to the\nbenefits of FoO in enforcing diversity in LLM solutions through compressed,\nexplainable representations that also support long-term memory when combined\nwith case-based reasoning.",
            "upvotes": 4,
            "discussionId": "67b546dd2b2ec6908f00c7f6"
        },
        "publishedAt": "2025-02-19T08:03:59.885Z",
        "title": "Flow-of-Options: Diversified and Improved LLM Reasoning by Thinking Through Options",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/643837ef581e6bf0fa9c72f8/HhevzVLx8wGDy7sD0zSAj.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12929.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "643837ef581e6bf0fa9c72f8",
            "avatarUrl": "/avatars/5b95d2509d1c7640d77a3405ebd53eaf.svg",
            "fullname": "Lakshmi Nair",
            "name": "lnair",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.10708",
            "authors": [
                {
                    "_id": "67b58e32e972a2806a9a0451",
                    "user": {
                        "_id": "65407ba7a38390065750233f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65407ba7a38390065750233f/1_IPMZbk-S9u2t18PQgMp.jpeg",
                        "isPro": false,
                        "fullname": "Zirui Song",
                        "user": "Ziruibest",
                        "type": "user"
                    },
                    "name": "Zirui Song",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:00:38.943Z",
                    "hidden": false
                },
                {
                    "_id": "67b58e32e972a2806a9a0452",
                    "name": "Bin Yan",
                    "hidden": false
                },
                {
                    "_id": "67b58e32e972a2806a9a0453",
                    "name": "Yuhan Liu",
                    "hidden": false
                },
                {
                    "_id": "67b58e32e972a2806a9a0454",
                    "name": "Miao Fang",
                    "hidden": false
                },
                {
                    "_id": "67b58e32e972a2806a9a0455",
                    "name": "Mingzhe Li",
                    "hidden": false
                },
                {
                    "_id": "67b58e32e972a2806a9a0456",
                    "name": "Rui Yan",
                    "hidden": false
                },
                {
                    "_id": "67b58e32e972a2806a9a0457",
                    "name": "Xiuying Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-15T07:43:43.000Z",
            "title": "Injecting Domain-Specific Knowledge into Large Language Models: A\n  Comprehensive Survey",
            "summary": "Large Language Models (LLMs) have demonstrated remarkable success in various\ntasks such as natural language understanding, text summarization, and machine\ntranslation. However, their general-purpose nature often limits their\neffectiveness in domain-specific applications that require specialized\nknowledge, such as healthcare, chemistry, or legal analysis. To address this,\nresearchers have explored diverse methods to enhance LLMs by integrating\ndomain-specific knowledge. In this survey, we provide a comprehensive overview\nof these methods, which we categorize into four key approaches: dynamic\nknowledge injection, static knowledge embedding, modular adapters, and prompt\noptimization. Each approach offers unique mechanisms to equip LLMs with domain\nexpertise, balancing trade-offs between flexibility, scalability, and\nefficiency. We discuss how these methods enable LLMs to tackle specialized\ntasks, compare their advantages and disadvantages, evaluate domain-specific\nLLMs against general LLMs, and highlight the challenges and opportunities in\nthis emerging field. For those interested in delving deeper into this area, we\nalso summarize the commonly used datasets and benchmarks. To keep researchers\nupdated on the latest studies, we maintain an open-source at:\nhttps://github.com/abilliyb/Knowledge_Injection_Survey_Papers, dedicated to\ndocumenting research in the field of specialized LLM.",
            "upvotes": 3,
            "discussionId": "67b58e33e972a2806a9a04b8"
        },
        "publishedAt": "2025-02-19T02:56:09.510Z",
        "title": "Injecting Domain-Specific Knowledge into Large Language Models: A Comprehensive Survey",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.10708.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65407ba7a38390065750233f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65407ba7a38390065750233f/1_IPMZbk-S9u2t18PQgMp.jpeg",
            "fullname": "Zirui Song",
            "name": "Ziruibest",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.08869",
            "authors": [
                {
                    "_id": "67b5f3e30e7fed1190f29f80",
                    "user": {
                        "_id": "67b5efbe38c175486e2869b9",
                        "avatarUrl": "/avatars/64a698259033bb8ac324e57c557a9aa9.svg",
                        "isPro": false,
                        "fullname": "Jingchao Ni",
                        "user": "nijingchao",
                        "type": "user"
                    },
                    "name": "Jingchao Ni",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T15:14:31.563Z",
                    "hidden": false
                },
                {
                    "_id": "67b5f3e30e7fed1190f29f81",
                    "name": "Ziming Zhao",
                    "hidden": false
                },
                {
                    "_id": "67b5f3e30e7fed1190f29f82",
                    "name": "ChengAo Shen",
                    "hidden": false
                },
                {
                    "_id": "67b5f3e30e7fed1190f29f83",
                    "name": "Hanghang Tong",
                    "hidden": false
                },
                {
                    "_id": "67b5f3e30e7fed1190f29f84",
                    "name": "Dongjin Song",
                    "hidden": false
                },
                {
                    "_id": "67b5f3e30e7fed1190f29f85",
                    "name": "Wei Cheng",
                    "hidden": false
                },
                {
                    "_id": "67b5f3e30e7fed1190f29f86",
                    "name": "Dongsheng Luo",
                    "hidden": false
                },
                {
                    "_id": "67b5f3e30e7fed1190f29f87",
                    "name": "Haifeng Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-13T00:42:11.000Z",
            "title": "Harnessing Vision Models for Time Series Analysis: A Survey",
            "summary": "Time series analysis has witnessed the inspiring development from traditional\nautoregressive models, deep learning models, to recent Transformers and Large\nLanguage Models (LLMs). Efforts in leveraging vision models for time series\nanalysis have also been made along the way but are less visible to the\ncommunity due to the predominant research on sequence modeling in this domain.\nHowever, the discrepancy between continuous time series and the discrete token\nspace of LLMs, and the challenges in explicitly modeling the correlations of\nvariates in multivariate time series have shifted some research attentions to\nthe equally successful Large Vision Models (LVMs) and Vision Language Models\n(VLMs). To fill the blank in the existing literature, this survey discusses the\nadvantages of vision models over LLMs in time series analysis. It provides a\ncomprehensive and in-depth overview of the existing methods, with dual views of\ndetailed taxonomy that answer the key research questions including how to\nencode time series as images and how to model the imaged time series for\nvarious tasks. Additionally, we address the challenges in the pre- and\npost-processing steps involved in this framework and outline future directions\nto further advance time series analysis with vision models.",
            "upvotes": 2,
            "discussionId": "67b5f3e30e7fed1190f29fb7"
        },
        "publishedAt": "2025-02-19T10:33:08.946Z",
        "title": "Harnessing Vision Models for Time Series Analysis: A Survey",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/67b5efbe38c175486e2869b9/iBIxlNXQX2KDabTTeqWL0.png",
            "https://cdn-uploads.huggingface.co/production/uploads/67b5efbe38c175486e2869b9/cGTQawzFrVI21iLfRjpFt.png",
            "https://cdn-uploads.huggingface.co/production/uploads/67b5efbe38c175486e2869b9/j-lNPZ3OqCUHj6vhnQS5v.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.08869.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "67b5efbe38c175486e2869b9",
            "avatarUrl": "/avatars/64a698259033bb8ac324e57c557a9aa9.svg",
            "fullname": "Jingchao Ni",
            "name": "nijingchao",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12669",
            "authors": [
                {
                    "_id": "67b58c806e53744c2a373351",
                    "user": {
                        "_id": "63024676056ec3a2a8714b24",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661093436322-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Xiang Liu",
                        "user": "Dominic789654",
                        "type": "user"
                    },
                    "name": "Xiang Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:34:03.429Z",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a373352",
                    "user": {
                        "_id": "64eded5fdfe0a679d840bc98",
                        "avatarUrl": "/avatars/4d4c67c13e547a4d296a301e8694e79e.svg",
                        "isPro": false,
                        "fullname": "sunpenglei",
                        "user": "sunpenglei",
                        "type": "user"
                    },
                    "name": "Penglei Sun",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:34:15.889Z",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a373353",
                    "name": "Shuyan Chen",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a373354",
                    "name": "Longhan Zhang",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a373355",
                    "name": "Peijie Dong",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a373356",
                    "user": {
                        "_id": "660937dff7373477d86501b8",
                        "avatarUrl": "/avatars/1edbe8c92b41bf496b962f71b306ea7b.svg",
                        "isPro": false,
                        "fullname": "Huajie You",
                        "user": "FrankYOU",
                        "type": "user"
                    },
                    "name": "Huajie You",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T18:16:35.805Z",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a373357",
                    "user": {
                        "_id": "64473221dcbe1333b64b2db2",
                        "avatarUrl": "/avatars/5e4495d3581ad3e6ea3c47650f20b993.svg",
                        "isPro": false,
                        "fullname": "yongqi zhang",
                        "user": "yongqi2023",
                        "type": "user"
                    },
                    "name": "Yongqi Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:35:12.059Z",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a373358",
                    "name": "Chang Yan",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a373359",
                    "user": {
                        "_id": "6676935fcd0b89a0115174b0",
                        "avatarUrl": "/avatars/4caca1b672d29e787814f9a30bf20bcc.svg",
                        "isPro": false,
                        "fullname": "Xiaowen Chu",
                        "user": "wenxinsiju",
                        "type": "user"
                    },
                    "name": "Xiaowen Chu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:35:20.611Z",
                    "hidden": false
                },
                {
                    "_id": "67b58c806e53744c2a37335a",
                    "name": "Tong-yi Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T09:19:24.000Z",
            "title": "Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite\n  Solar Cell Research",
            "summary": "The rapid advancement of perovskite solar cells (PSCs) has led to an\nexponential growth in research publications, creating an urgent need for\nefficient knowledge management and reasoning systems in this domain. We present\na comprehensive knowledge-enhanced system for PSCs that integrates three key\ncomponents. First, we develop Perovskite-KG, a domain-specific knowledge graph\nconstructed from 1,517 research papers, containing 23,789 entities and 22,272\nrelationships. Second, we create two complementary datasets: Perovskite-Chat,\ncomprising 55,101 high-quality question-answer pairs generated through a novel\nmulti-agent framework, and Perovskite-Reasoning, containing 2,217 carefully\ncurated materials science problems. Third, we introduce two specialized large\nlanguage models: Perovskite-Chat-LLM for domain-specific knowledge assistance\nand Perovskite-Reasoning-LLM for scientific reasoning tasks. Experimental\nresults demonstrate that our system significantly outperforms existing models\nin both domain-specific knowledge retrieval and scientific reasoning tasks,\nproviding researchers with effective tools for literature review, experimental\ndesign, and complex problem-solving in PSC research.",
            "upvotes": 2,
            "discussionId": "67b58c826e53744c2a3733c2"
        },
        "publishedAt": "2025-02-19T02:47:33.654Z",
        "title": "Perovskite-LLM: Knowledge-Enhanced Large Language Models for Perovskite Solar Cell Research",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12669.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63024676056ec3a2a8714b24",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1661093436322-noauth.jpeg",
            "fullname": "Xiang Liu",
            "name": "Dominic789654",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.13142",
            "authors": [
                {
                    "_id": "67b5790132be608036ee94e5",
                    "user": {
                        "_id": "65c3fdf79d062be813813e45",
                        "avatarUrl": "/avatars/52528a61abe5bbbef4a4a431944973cd.svg",
                        "isPro": false,
                        "fullname": "Dantong Niu",
                        "user": "NdtSoCool",
                        "type": "user"
                    },
                    "name": "Dantong Niu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:12:28.457Z",
                    "hidden": false
                },
                {
                    "_id": "67b5790132be608036ee94e6",
                    "user": {
                        "_id": "65406e82deee4716f1c29271",
                        "avatarUrl": "/avatars/25331a773f8125f9ad1c3d6ac3375586.svg",
                        "isPro": false,
                        "fullname": "Yuvan Sharma",
                        "user": "yuvansharma",
                        "type": "user"
                    },
                    "name": "Yuvan Sharma",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:12:35.531Z",
                    "hidden": false
                },
                {
                    "_id": "67b5790132be608036ee94e7",
                    "name": "Haoru Xue",
                    "hidden": false
                },
                {
                    "_id": "67b5790132be608036ee94e8",
                    "user": {
                        "_id": "650bd36a7c99ca283e58e973",
                        "avatarUrl": "/avatars/606d24b2dac190ebcbb4b2a2e4671380.svg",
                        "isPro": false,
                        "fullname": "Giscard Biamby",
                        "user": "gbiamby",
                        "type": "user"
                    },
                    "name": "Giscard Biamby",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:12:49.219Z",
                    "hidden": false
                },
                {
                    "_id": "67b5790132be608036ee94e9",
                    "name": "Junyi Zhang",
                    "hidden": false
                },
                {
                    "_id": "67b5790132be608036ee94ea",
                    "user": {
                        "_id": "66a09aec369dd38cf2113070",
                        "avatarUrl": "/avatars/cc13bdd3dc1271d33b083b61e12f1a05.svg",
                        "isPro": false,
                        "fullname": "Ziteng Ji",
                        "user": "zitengj0618",
                        "type": "user"
                    },
                    "name": "Ziteng Ji",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:13:13.907Z",
                    "hidden": false
                },
                {
                    "_id": "67b5790132be608036ee94eb",
                    "user": {
                        "_id": "64cbdf02f103036e23d1c7f3",
                        "avatarUrl": "/avatars/496069463900dea20929b57381182d39.svg",
                        "isPro": false,
                        "fullname": "Trevor Darrell",
                        "user": "trevordarrell",
                        "type": "user"
                    },
                    "name": "Trevor Darrell",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:13:20.379Z",
                    "hidden": false
                },
                {
                    "_id": "67b5790132be608036ee94ec",
                    "user": {
                        "_id": "667c5764186b27ef806636d3",
                        "avatarUrl": "/avatars/5c08f0109bc0e350624112c0aff544f6.svg",
                        "isPro": false,
                        "fullname": "Roei Herzig",
                        "user": "roeiherz",
                        "type": "user"
                    },
                    "name": "Roei Herzig",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T09:13:26.134Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T18:59:01.000Z",
            "title": "Pre-training Auto-regressive Robotic Models with 4D Representations",
            "summary": "Foundation models pre-trained on massive unlabeled datasets have\nrevolutionized natural language and computer vision, exhibiting remarkable\ngeneralization capabilities, thus highlighting the importance of pre-training.\nYet, efforts in robotics have struggled to achieve similar success, limited by\neither the need for costly robotic annotations or the lack of representations\nthat effectively model the physical world. In this paper, we introduce ARM4R,\nan Auto-regressive Robotic Model that leverages low-level 4D Representations\nlearned from human video data to yield a better pre-trained robotic model.\nSpecifically, we focus on utilizing 3D point tracking representations from\nvideos derived by lifting 2D representations into 3D space via monocular depth\nestimation across time. These 4D representations maintain a shared geometric\nstructure between the points and robot state representations up to a linear\ntransformation, enabling efficient transfer learning from human video data to\nlow-level robotic control. Our experiments show that ARM4R can transfer\nefficiently from human video data to robotics and consistently improves\nperformance on tasks across various robot environments and configurations.",
            "upvotes": 2,
            "discussionId": "67b5790832be608036ee9638"
        },
        "publishedAt": "2025-02-19T01:24:26.365Z",
        "title": "Pre-training Auto-regressive Robotic Models with 4D Representations",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.13142.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "667c5764186b27ef806636d3",
            "avatarUrl": "/avatars/5c08f0109bc0e350624112c0aff544f6.svg",
            "fullname": "Roei Herzig",
            "name": "roeiherz",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.10852",
            "authors": [
                {
                    "_id": "67b55321f703732d151de666",
                    "name": "Zeli Su",
                    "hidden": false
                },
                {
                    "_id": "67b55321f703732d151de667",
                    "user": {
                        "_id": "6430bdd8cd31d174a9f900fb",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/Y9SPnRfpKSbYc7MhNdP-H.jpeg",
                        "isPro": false,
                        "fullname": "Ziyin Zhang",
                        "user": "Geralt-Targaryen",
                        "type": "user"
                    },
                    "name": "Ziyin Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T15:10:05.400Z",
                    "hidden": false
                },
                {
                    "_id": "67b55321f703732d151de668",
                    "user": {
                        "_id": "6747329d228a652d5707e094",
                        "avatarUrl": "/avatars/f33e118950e329ce5612877413806e49.svg",
                        "isPro": false,
                        "fullname": "GUIXIAN XU",
                        "user": "Stuart-Xu",
                        "type": "user"
                    },
                    "name": "Guixian Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-19T15:09:59.600Z",
                    "hidden": false
                },
                {
                    "_id": "67b55321f703732d151de669",
                    "name": "Jianing Liu",
                    "hidden": false
                },
                {
                    "_id": "67b55321f703732d151de66a",
                    "name": "XU Han",
                    "hidden": false
                },
                {
                    "_id": "67b55321f703732d151de66b",
                    "name": "Ting Zhang",
                    "hidden": false
                },
                {
                    "_id": "67b55321f703732d151de66c",
                    "name": "Yushuang Dong",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-15T16:53:10.000Z",
            "title": "Multilingual Encoder Knows more than You Realize: Shared Weights\n  Pretraining for Extremely Low-Resource Languages",
            "summary": "While multilingual language models like XLM-R have advanced multilingualism\nin NLP, they still perform poorly in extremely low-resource languages. This\nsituation is exacerbated by the fact that modern LLMs such as LLaMA and Qwen\nsupport far fewer languages than XLM-R, making text generation models\nnon-existent for many languages in the world. To tackle this challenge, we\npropose a novel framework for adapting multilingual encoders to text generation\nin extremely low-resource languages. By reusing the weights between the encoder\nand the decoder, our framework allows the model to leverage the learned\nsemantic space of the encoder, enabling efficient learning and effective\ngeneralization in low-resource languages. Applying this framework to four\nChinese minority languages, we present XLM-SWCM, and demonstrate its superior\nperformance on various downstream tasks even when compared with much larger\nmodels.",
            "upvotes": 2,
            "discussionId": "67b55322f703732d151de69d"
        },
        "publishedAt": "2025-02-18T22:46:16.586Z",
        "title": "Multilingual Encoder Knows more than You Realize: Shared Weights Pretraining for Extremely Low-Resource Languages",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.10852.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6430bdd8cd31d174a9f900fb",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/Y9SPnRfpKSbYc7MhNdP-H.jpeg",
            "fullname": "Ziyin Zhang",
            "name": "Geralt-Targaryen",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.12130",
            "authors": [
                {
                    "_id": "67b657d6a267b1a747a7fed6",
                    "name": "Zhenfang Chen",
                    "hidden": false
                },
                {
                    "_id": "67b657d6a267b1a747a7fed7",
                    "name": "Delin Chen",
                    "hidden": false
                },
                {
                    "_id": "67b657d6a267b1a747a7fed8",
                    "name": "Rui Sun",
                    "hidden": false
                },
                {
                    "_id": "67b657d6a267b1a747a7fed9",
                    "name": "Wenjun Liu",
                    "hidden": false
                },
                {
                    "_id": "67b657d6a267b1a747a7feda",
                    "name": "Chuang Gan",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-17T18:49:25.000Z",
            "title": "Scaling Autonomous Agents via Automatic Reward Modeling And Planning",
            "summary": "Large language models (LLMs) have demonstrated remarkable capabilities across\na range of text-generation tasks. However, LLMs still struggle with problems\nrequiring multi-step decision-making and environmental feedback, such as online\nshopping, scientific reasoning, and mathematical problem-solving. Unlike pure\ntext data, collecting large-scale decision-making data is challenging.\nMoreover, many powerful LLMs are only accessible through APIs, which hinders\ntheir fine-tuning for agent tasks due to cost and complexity. To address LLM\nagents' limitations, we propose a framework that can automatically learn a\nreward model from the environment without human annotations. This model can be\nused to evaluate the action trajectories of LLM agents and provide heuristics\nfor task planning. Specifically, our approach involves employing one LLM-based\nagent to navigate an environment randomly, generating diverse action\ntrajectories. Subsequently, a separate LLM is leveraged to assign a task intent\nand synthesize a negative response alongside the correct response for each\ntrajectory. These triplets (task intent, positive response, and negative\nresponse) are then utilized as training data to optimize a reward model capable\nof scoring action trajectories. The effectiveness and generalizability of our\nframework are demonstrated through evaluations conducted on different agent\nbenchmarks. In conclusion, our proposed framework represents a significant\nadvancement in enhancing LLM agents' decision-making capabilities. By\nautomating the learning of reward models, we overcome the challenges of data\nscarcity and API limitations, potentially revolutionizing the application of\nLLMs in complex and interactive environments. This research paves the way for\nmore sophisticated AI agents capable of tackling a wide range of real-world\nproblems requiring multi-step decision-making.",
            "upvotes": 1,
            "discussionId": "67b657d7a267b1a747a7ff1a"
        },
        "publishedAt": "2025-02-19T18:20:05.946Z",
        "title": "Scaling Autonomous Agents via Automatic Reward Modeling And Planning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12130.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "654e024de113b04ba5c71e2f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/654e024de113b04ba5c71e2f/WH6S_gpQU6OXqDaiPpheK.jpeg",
            "fullname": "Rui Sun",
            "name": "ThreeSR",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.12524",
            "authors": [
                {
                    "_id": "67b608ca13df25808fbc22ae",
                    "name": "Yunjie Tian",
                    "hidden": false
                },
                {
                    "_id": "67b608ca13df25808fbc22af",
                    "name": "Qixiang Ye",
                    "hidden": false
                },
                {
                    "_id": "67b608ca13df25808fbc22b0",
                    "name": "David Doermann",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-18T04:20:14.000Z",
            "title": "YOLOv12: Attention-Centric Real-Time Object Detectors",
            "summary": "Enhancing the network architecture of the YOLO framework has been crucial for\na long time, but has focused on CNN-based improvements despite the proven\nsuperiority of attention mechanisms in modeling capabilities. This is because\nattention-based models cannot match the speed of CNN-based models. This paper\nproposes an attention-centric YOLO framework, namely YOLOv12, that matches the\nspeed of previous CNN-based ones while harnessing the performance benefits of\nattention mechanisms. YOLOv12 surpasses all popular real-time object detectors\nin accuracy with competitive speed. For example, YOLOv12-N achieves 40.6% mAP\nwith an inference latency of 1.64 ms on a T4 GPU, outperforming advanced\nYOLOv10-N / YOLOv11-N by 2.1%/1.2% mAP with a comparable speed. This advantage\nextends to other model scales. YOLOv12 also surpasses end-to-end real-time\ndetectors that improve DETR, such as RT-DETR / RT-DETRv2: YOLOv12-S beats\nRT-DETR-R18 / RT-DETRv2-R18 while running 42% faster, using only 36% of the\ncomputation and 45% of the parameters. More comparisons are shown in Figure 1.",
            "upvotes": 1,
            "discussionId": "67b608cb13df25808fbc2308"
        },
        "publishedAt": "2025-02-19T13:39:32.672Z",
        "title": "YOLOv12: Attention-Centric Real-Time Object Detectors",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.12524.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "5f1158120c833276f61f1a84",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
            "fullname": "Niels Rogge",
            "name": "nielsr",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 766
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.10990",
            "authors": [
                {
                    "_id": "67b3ee6c1e80a69e79c3155a",
                    "user": {
                        "_id": "647d834618274bce03013cc2",
                        "avatarUrl": "/avatars/a95c7df96dc4fb6a96193f6dd5068227.svg",
                        "isPro": true,
                        "fullname": "yixuan",
                        "user": "yixuantt",
                        "type": "user"
                    },
                    "name": "Yixuan Tang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-19T09:04:50.969Z",
                    "hidden": false
                },
                {
                    "_id": "67b3ee6c1e80a69e79c3155b",
                    "name": "Yi Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-16T04:23:52.000Z",
            "title": "FinMTEB: Finance Massive Text Embedding Benchmark",
            "summary": "Embedding models play a crucial role in representing and retrieving\ninformation across various NLP applications. Recent advances in large language\nmodels (LLMs) have further enhanced the performance of embedding models. While\nthese models are often benchmarked on general-purpose datasets, real-world\napplications demand domain-specific evaluation. In this work, we introduce the\nFinance Massive Text Embedding Benchmark (FinMTEB), a specialized counterpart\nto MTEB designed for the financial domain. FinMTEB comprises 64 financial\ndomain-specific embedding datasets across 7 tasks that cover diverse textual\ntypes in both Chinese and English, such as financial news articles, corporate\nannual reports, ESG reports, regulatory filings, and earnings call transcripts.\nWe also develop a finance-adapted model, FinPersona-E5, using a persona-based\ndata synthetic method to cover diverse financial embedding tasks for training.\nThrough extensive evaluation of 15 embedding models, including FinPersona-E5,\nwe show three key findings: (1) performance on general-purpose benchmarks shows\nlimited correlation with financial domain tasks; (2) domain-adapted models\nconsistently outperform their general-purpose counterparts; and (3)\nsurprisingly, a simple Bag-of-Words (BoW) approach outperforms sophisticated\ndense embeddings in financial Semantic Textual Similarity (STS) tasks,\nunderscoring current limitations in dense embedding techniques. Our work\nestablishes a robust evaluation framework for financial NLP applications and\nprovides crucial insights for developing domain-specific embedding models.",
            "upvotes": 1,
            "discussionId": "67b3ee6d1e80a69e79c3158f"
        },
        "publishedAt": "2025-02-19T04:54:27.788Z",
        "title": "FinMTEB: Finance Massive Text Embedding Benchmark",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.10990.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "647d834618274bce03013cc2",
            "avatarUrl": "/avatars/a95c7df96dc4fb6a96193f6dd5068227.svg",
            "fullname": "yixuan",
            "name": "yixuantt",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    }
]