[
    {
        "paper": {
            "id": "2502.18417",
            "authors": [
                {
                    "_id": "67c02b2eb14cf3cbc800c292",
                    "name": "Alexander Groshev",
                    "hidden": false
                },
                {
                    "_id": "67c02b2eb14cf3cbc800c293",
                    "user": {
                        "_id": "67aafccd7517c92ba71142f2",
                        "avatarUrl": "/avatars/ef4b5c6867250b8b7af2c995dd7ad740.svg",
                        "isPro": false,
                        "fullname": "Anastasiia Iashchenko",
                        "user": "nastasia-y",
                        "type": "user"
                    },
                    "name": "Anastasiia Iashchenko",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:13:49.896Z",
                    "hidden": false
                },
                {
                    "_id": "67c02b2eb14cf3cbc800c294",
                    "name": "Pavel Paramonov",
                    "hidden": false
                },
                {
                    "_id": "67c02b2eb14cf3cbc800c295",
                    "user": {
                        "_id": "6669a678465d1d802181e456",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6669a678465d1d802181e456/ZCthBBhDFQnh0bBkgUQUU.png",
                        "isPro": false,
                        "fullname": "Denis Dimitrov",
                        "user": "dendimitrov",
                        "type": "user"
                    },
                    "name": "Denis Dimitrov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T12:54:35.272Z",
                    "hidden": false
                },
                {
                    "_id": "67c02b2eb14cf3cbc800c296",
                    "user": {
                        "_id": "643984dceb7c5616ef3f5d54",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/643984dceb7c5616ef3f5d54/10JRkblrRIEVci6UJwvPz.jpeg",
                        "isPro": false,
                        "fullname": "Andrey Kuznetsov",
                        "user": "kuznetsoffandrey",
                        "type": "user"
                    },
                    "name": "Andrey Kuznetsov",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T12:54:37.211Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-25T18:13:55.000Z",
            "title": "GHOST 2.0: generative high-fidelity one shot transfer of heads",
            "summary": "While the task of face swapping has recently gained attention in the research\ncommunity, a related problem of head swapping remains largely unexplored. In\naddition to skin color transfer, head swap poses extra challenges, such as the\nneed to preserve structural information of the whole head during synthesis and\ninpaint gaps between swapped head and background. In this paper, we address\nthese concerns with GHOST 2.0, which consists of two problem-specific modules.\nFirst, we introduce enhanced Aligner model for head reenactment, which\npreserves identity information at multiple scales and is robust to extreme pose\nvariations. Secondly, we use a Blender module that seamlessly integrates the\nreenacted head into the target background by transferring skin color and\ninpainting mismatched regions. Both modules outperform the baselines on the\ncorresponding tasks, allowing to achieve state of the art results in head\nswapping. We also tackle complex cases, such as large difference in hair styles\nof source and target. Code is available at\nhttps://github.com/ai-forever/ghost-2.0",
            "upvotes": 49,
            "discussionId": "67c02b31b14cf3cbc800c34b"
        },
        "publishedAt": "2025-02-27T04:15:43.126Z",
        "title": "GHOST 2.0: generative high-fidelity one shot transfer of heads",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18417.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "67aafccd7517c92ba71142f2",
            "avatarUrl": "/avatars/ef4b5c6867250b8b7af2c995dd7ad740.svg",
            "fullname": "Anastasiia Iashchenko",
            "name": "nastasia-y",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.18934",
            "authors": [
                {
                    "_id": "67bfe1bf4426925c82fe5953",
                    "name": "Kanana LLM Team",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5954",
                    "user": {
                        "_id": "64d08bd75de9e1e911b24226",
                        "avatarUrl": "/avatars/e572bb47659393573a0c1fb3d333dd7b.svg",
                        "isPro": false,
                        "fullname": "Yunju Bak",
                        "user": "yunjubak63",
                        "type": "user"
                    },
                    "name": "Yunju Bak",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-27T12:55:35.505Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5955",
                    "name": "Hojin Lee",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5956",
                    "user": {
                        "_id": "60436d159e905013ae8715d7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
                        "isPro": false,
                        "fullname": "Minho Ryu",
                        "user": "bzantium",
                        "type": "user"
                    },
                    "name": "Minho Ryu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:17.979Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5957",
                    "user": {
                        "_id": "66ebb4fdc5b2c25450fd17de",
                        "avatarUrl": "/avatars/e6b40dcbe2eba838ba21be9221758a3c.svg",
                        "isPro": false,
                        "fullname": "Jiyeon Ham",
                        "user": "jiyeonham",
                        "type": "user"
                    },
                    "name": "Jiyeon Ham",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:11.786Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5958",
                    "name": "Seungjae Jung",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5959",
                    "user": {
                        "_id": "66c82a50c1b3c03c61aea140",
                        "avatarUrl": "/avatars/3c508f96bdca2f2ce9746d3decd4718e.svg",
                        "isPro": false,
                        "fullname": "daniel nam",
                        "user": "daniel-rl2",
                        "type": "user"
                    },
                    "name": "Daniel Wontae Nam",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:09.613Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe595a",
                    "name": "Taegyeong Eo",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe595b",
                    "name": "Donghun Lee",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe595c",
                    "user": {
                        "_id": "6142e17fe9e656d4459121e4",
                        "avatarUrl": "/avatars/6baebd4598a845ec7fdb735eb0d53139.svg",
                        "isPro": false,
                        "fullname": "Doohae Jung",
                        "user": "Doohae",
                        "type": "user"
                    },
                    "name": "Doohae Jung",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:06.858Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe595d",
                    "user": {
                        "_id": "60f559be68ee3ef098e407cf",
                        "avatarUrl": "/avatars/e1f00ff1c1c9fa7f591535d39c7d5e44.svg",
                        "isPro": false,
                        "fullname": "Boseop Kim",
                        "user": "seopbo",
                        "type": "user"
                    },
                    "name": "Boseop Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:01.989Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe595e",
                    "user": {
                        "_id": "6605028007a154c768e1c4c7",
                        "avatarUrl": "/avatars/88678edb83fdb466067e38acd22d07de.svg",
                        "isPro": false,
                        "fullname": "Nayeon Kim",
                        "user": "lana-ny",
                        "type": "user"
                    },
                    "name": "Nayeon Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:13.867Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe595f",
                    "user": {
                        "_id": "6136f65440e43b8f748a0833",
                        "avatarUrl": "/avatars/f72a5ae3d3e94485de8aed8df94abdad.svg",
                        "isPro": false,
                        "fullname": "Jaesun Park",
                        "user": "jaesun",
                        "type": "user"
                    },
                    "name": "Jaesun Park",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:15.898Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5960",
                    "name": "Hyunho Kim",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5961",
                    "user": {
                        "_id": "5fd888cf61e46993190ce543",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1634604273263-5fd888cf61e46993190ce543.jpeg",
                        "isPro": false,
                        "fullname": "Hyunwoong Ko",
                        "user": "hyunwoongko",
                        "type": "user"
                    },
                    "name": "Hyunwoong Ko",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-27T12:58:05.546Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5962",
                    "user": {
                        "_id": "63d268bb57ab367124ea7b75",
                        "avatarUrl": "/avatars/11312cde1e9f077aa9e5103b48be5de6.svg",
                        "isPro": false,
                        "fullname": "Changmin Lee",
                        "user": "changminlee",
                        "type": "user"
                    },
                    "name": "Changmin Lee",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:04.506Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5963",
                    "user": {
                        "_id": "62bd31e1d2c8a6542f53fcba",
                        "avatarUrl": "/avatars/4ac18a7bcaf9dd3885b0478dea90818f.svg",
                        "isPro": false,
                        "fullname": "Kyoung-Woon On",
                        "user": "kloud",
                        "type": "user"
                    },
                    "name": "Kyoung-Woon On",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-27T12:58:11.269Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5964",
                    "name": "Seulye Baeg",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5965",
                    "name": "Junrae Cho",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5966",
                    "name": "Sunghee Jung",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5967",
                    "name": "Jieun Kang",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5968",
                    "name": "EungGyun Kim",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe5969",
                    "name": "Eunhwa Kim",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe596a",
                    "name": "Byeongil Ko",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe596b",
                    "name": "Daniel Lee",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe596c",
                    "name": "Minchul Lee",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe596d",
                    "name": "Miok Lee",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe596e",
                    "name": "Shinbok Lee",
                    "hidden": false
                },
                {
                    "_id": "67bfe1bf4426925c82fe596f",
                    "user": {
                        "_id": "63148a8f5f47a18962765802",
                        "avatarUrl": "/avatars/bc58a863727794006dddf758efa09411.svg",
                        "isPro": true,
                        "fullname": "gaeunseo",
                        "user": "gaeunseo",
                        "type": "user"
                    },
                    "name": "Gaeun Seo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-02-27T12:59:39.670Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T08:36:20.000Z",
            "title": "Kanana: Compute-efficient Bilingual Language Models",
            "summary": "We introduce Kanana, a series of bilingual language models that demonstrate\nexceeding performance in Korean and competitive performance in English. The\ncomputational cost of Kanana is significantly lower than that of\nstate-of-the-art models of similar size. The report details the techniques\nemployed during pre-training to achieve compute-efficient yet competitive\nmodels, including high quality data filtering, staged pre-training, depth\nup-scaling, and pruning and distillation. Furthermore, the report outlines the\nmethodologies utilized during the post-training of the Kanana models,\nencompassing supervised fine-tuning and preference optimization, aimed at\nenhancing their capability for seamless interaction with users. Lastly, the\nreport elaborates on plausible approaches used for language model adaptation to\nspecific scenarios, such as embedding, retrieval augmented generation, and\nfunction calling. The Kanana model series spans from 2.1B to 32.5B parameters\nwith 2.1B models (base, instruct, embedding) publicly released to promote\nresearch on Korean language models.",
            "upvotes": 46,
            "discussionId": "67bfe1c04426925c82fe59a1"
        },
        "publishedAt": "2025-02-26T23:05:13.440Z",
        "title": "Kanana: Compute-efficient Bilingual Language Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18934.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60436d159e905013ae8715d7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1623809612769-60436d159e905013ae8715d7.jpeg",
            "fullname": "Minho Ryu",
            "name": "bzantium",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 5
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.19400",
            "authors": [
                {
                    "_id": "67bfd6f15db054ee3c5a766b",
                    "user": {
                        "_id": "631d760344503b7227837242",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/631d760344503b7227837242/3b6JRusFX6GKJpsN9ZdeJ.png",
                        "isPro": false,
                        "fullname": "Max Ku",
                        "user": "vinesmsuic",
                        "type": "user"
                    },
                    "name": "Max Ku",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:55.238Z",
                    "hidden": false
                },
                {
                    "_id": "67bfd6f15db054ee3c5a766c",
                    "user": {
                        "_id": "6365d5baa7a1324ccd5ecdb9",
                        "avatarUrl": "/avatars/636d3f410b878e451a878a6cf171dd53.svg",
                        "isPro": false,
                        "fullname": "Thomas Chong",
                        "user": "chongcht",
                        "type": "user"
                    },
                    "name": "Thomas Chong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:49.567Z",
                    "hidden": false
                },
                {
                    "_id": "67bfd6f15db054ee3c5a766d",
                    "name": "Jonathan Leung",
                    "hidden": false
                },
                {
                    "_id": "67bfd6f15db054ee3c5a766e",
                    "user": {
                        "_id": "67bfdfdbf856fd8ddbb7e0f0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/rIR0QnVM3wxMCulG2R9SJ.png",
                        "isPro": false,
                        "fullname": "Krish Shah",
                        "user": "KrishKrosh",
                        "type": "user"
                    },
                    "name": "Krish Shah",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:47.269Z",
                    "hidden": false
                },
                {
                    "_id": "67bfd6f15db054ee3c5a766f",
                    "user": {
                        "_id": "6696061aa8dbb9a9997dfff6",
                        "avatarUrl": "/avatars/d8f0bbff362fd630e6e60aab141076d3.svg",
                        "isPro": false,
                        "fullname": "Alvin Yu",
                        "user": "AlvinYuVotee",
                        "type": "user"
                    },
                    "name": "Alvin Yu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:52.146Z",
                    "hidden": false
                },
                {
                    "_id": "67bfd6f15db054ee3c5a7670",
                    "name": "Wenhu Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T18:50:09.000Z",
            "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem\n  Understanding",
            "summary": "Understanding domain-specific theorems often requires more than just\ntext-based reasoning; effective communication through structured visual\nexplanations is crucial for deeper comprehension. While large language models\n(LLMs) demonstrate strong performance in text-based theorem reasoning, their\nability to generate coherent and pedagogically meaningful visual explanations\nremains an open challenge. In this work, we introduce TheoremExplainAgent, an\nagentic approach for generating long-form theorem explanation videos (over 5\nminutes) using Manim animations. To systematically evaluate multimodal theorem\nexplanations, we propose TheoremExplainBench, a benchmark covering 240 theorems\nacross multiple STEM disciplines, along with 5 automated evaluation metrics.\nOur results reveal that agentic planning is essential for generating detailed\nlong-form videos, and the o3-mini agent achieves a success rate of 93.8% and an\noverall score of 0.77. However, our quantitative and qualitative studies show\nthat most of the videos produced exhibit minor issues with visual element\nlayout. Furthermore, multimodal explanations expose deeper reasoning flaws that\ntext-based explanations fail to reveal, highlighting the importance of\nmultimodal explanations.",
            "upvotes": 30,
            "discussionId": "67bfd6f25db054ee3c5a7699"
        },
        "publishedAt": "2025-02-26T22:07:49.438Z",
        "title": "TheoremExplainAgent: Towards Multimodal Explanations for LLM Theorem Understanding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19400.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 6243
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.18772",
            "authors": [
                {
                    "_id": "67bfc297ca6e3c22b6d99c78",
                    "name": "Xueqing Peng",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c79",
                    "name": "Triantafillos Papadopoulos",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c7a",
                    "name": "Efstathia Soufleri",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c7b",
                    "name": "Polydoros Giannouris",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c7c",
                    "name": "Ruoyu Xiang",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c7d",
                    "name": "Yan Wang",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c7e",
                    "name": "Lingfei Qian",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c7f",
                    "user": {
                        "_id": "63b58ed5889aa6707f0bb0f4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
                        "isPro": true,
                        "fullname": "Jimin Huang",
                        "user": "jiminHuang",
                        "type": "user"
                    },
                    "name": "Jimin Huang",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-27T01:40:40.189Z",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c80",
                    "name": "Qianqian Xie",
                    "hidden": false
                },
                {
                    "_id": "67bfc297ca6e3c22b6d99c81",
                    "name": "Sophia Ananiadou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T03:04:01.000Z",
            "title": "Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance",
            "summary": "Despite Greece's pivotal role in the global economy, large language models\n(LLMs) remain underexplored for Greek financial context due to the linguistic\ncomplexity of Greek and the scarcity of domain-specific datasets. Previous\nefforts in multilingual financial natural language processing (NLP) have\nexposed considerable performance disparities, yet no dedicated Greek financial\nbenchmarks or Greek-specific financial LLMs have been developed until now. To\nbridge this gap, we introduce Plutus-ben, the first Greek Financial Evaluation\nBenchmark, and Plutus-8B, the pioneering Greek Financial LLM, fine-tuned with\nGreek domain-specific data. Plutus-ben addresses five core financial NLP tasks\nin Greek: numeric and textual named entity recognition, question answering,\nabstractive summarization, and topic classification, thereby facilitating\nsystematic and reproducible LLM assessments. To underpin these tasks, we\npresent three novel, high-quality Greek financial datasets, thoroughly\nannotated by expert native Greek speakers, augmented by two existing resources.\nOur comprehensive evaluation of 22 LLMs on Plutus-ben reveals that Greek\nfinancial NLP remains challenging due to linguistic complexity, domain-specific\nterminology, and financial reasoning gaps. These findings underscore the\nlimitations of cross-lingual transfer, the necessity for financial expertise in\nGreek-trained models, and the challenges of adapting financial LLMs to Greek\ntext. We release Plutus-ben, Plutus-8B, and all associated datasets publicly to\npromote reproducible research and advance Greek financial NLP, fostering\nbroader multilingual inclusivity in finance.",
            "upvotes": 24,
            "discussionId": "67bfc298ca6e3c22b6d99caa"
        },
        "publishedAt": "2025-02-27T00:08:09.082Z",
        "title": "Plutus: Benchmarking Large Language Models in Low-Resource Greek Finance",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18772.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63b58ed5889aa6707f0bb0f4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63b58ed5889aa6707f0bb0f4/znl74_aMswlV8VtHrfj3G.jpeg",
            "fullname": "Jimin Huang",
            "name": "jiminHuang",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 15
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.17955",
            "authors": [
                {
                    "_id": "67bff526ca6e3c22b6e89d71",
                    "user": {
                        "_id": "65d2f1e0fe21569868393411",
                        "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
                        "isPro": false,
                        "fullname": "Tushar Aggarwal",
                        "user": "AggarwalTushar",
                        "type": "user"
                    },
                    "name": "Tushar Aggarwal",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2025-02-27T18:59:26.826Z",
                    "hidden": false
                },
                {
                    "_id": "67bff526ca6e3c22b6e89d72",
                    "name": "Kumar Tanmay",
                    "hidden": false
                },
                {
                    "_id": "67bff526ca6e3c22b6e89d73",
                    "user": {
                        "_id": "61a7cbb0fcbbebe775bf17fd",
                        "avatarUrl": "/avatars/8b54907c6a1ea90a1242f26e03e117af.svg",
                        "isPro": false,
                        "fullname": "Ayush Agrawal",
                        "user": "ayush1801",
                        "type": "user"
                    },
                    "name": "Ayush Agrawal",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:13:56.625Z",
                    "hidden": false
                },
                {
                    "_id": "67bff526ca6e3c22b6e89d74",
                    "name": "Kumar Ayush",
                    "hidden": false
                },
                {
                    "_id": "67bff526ca6e3c22b6e89d75",
                    "name": "Hamid Palangi",
                    "hidden": false
                },
                {
                    "_id": "67bff526ca6e3c22b6e89d76",
                    "name": "Paul Pu Liang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-25T08:27:18.000Z",
            "title": "Language Models' Factuality Depends on the Language of Inquiry",
            "summary": "Multilingual language models (LMs) are expected to recall factual knowledge\nconsistently across languages, yet they often fail to transfer knowledge\nbetween languages even when they possess the correct information in one of the\nlanguages. For example, we find that an LM may correctly identify Rashed Al\nShashai as being from Saudi Arabia when asked in Arabic, but consistently fails\nto do so when asked in English or Swahili. To systematically investigate this\nlimitation, we introduce a benchmark of 10,000 country-related facts across 13\nlanguages and propose three novel metrics: Factual Recall Score, Knowledge\nTransferability Score, and Cross-Lingual Factual Knowledge Transferability\nScore-to quantify factual recall and knowledge transferability in LMs across\ndifferent languages. Our results reveal fundamental weaknesses in today's\nstate-of-the-art LMs, particularly in cross-lingual generalization where models\nfail to transfer knowledge effectively across different languages, leading to\ninconsistent performance sensitive to the language used. Our findings emphasize\nthe need for LMs to recognize language-specific factual reliability and\nleverage the most trustworthy information across languages. We release our\nbenchmark and evaluation framework to drive future research in multilingual\nknowledge transfer.",
            "upvotes": 19,
            "discussionId": "67bff528ca6e3c22b6e89ddd"
        },
        "publishedAt": "2025-02-27T00:17:58.262Z",
        "title": "Language Models' Factuality Depends on the Language of Inquiry",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17955.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65d2f1e0fe21569868393411",
            "avatarUrl": "/avatars/1401020e76d958bef3f33e7449773694.svg",
            "fullname": "Tushar Aggarwal",
            "name": "AggarwalTushar",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.19361",
            "authors": [
                {
                    "_id": "67bfe435ca6e3c22b6e29442",
                    "name": "Yancheng He",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e29443",
                    "name": "Shilong Li",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e29444",
                    "name": "Jiaheng Liu",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e29445",
                    "name": "Weixun Wang",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e29446",
                    "name": "Xingyuan Bu",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e29447",
                    "user": {
                        "_id": "638efcf4c67af472d316d424",
                        "avatarUrl": "/avatars/97a57859d7d87a3a8f1bb41d32a72bc2.svg",
                        "isPro": false,
                        "fullname": "Ge Zhang",
                        "user": "zhangysk",
                        "type": "user"
                    },
                    "name": "Ge Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:13:58.959Z",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e29448",
                    "name": "Zhongyuan Peng",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e29449",
                    "name": "Zhaoxiang Zhang",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e2944a",
                    "name": "Wenbo Su",
                    "hidden": false
                },
                {
                    "_id": "67bfe435ca6e3c22b6e2944b",
                    "name": "Bo Zheng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T17:59:27.000Z",
            "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought\n  Reasoning?",
            "summary": "Recently, o1-like models have drawn significant attention, where these models\nproduce the long Chain-of-Thought (CoT) reasoning steps to improve the\nreasoning abilities of existing Large Language Models (LLMs). In this paper, to\nunderstand the qualities of these long CoTs and measure the critique abilities\nof existing LLMs on these long CoTs, we introduce the DeltaBench, including the\ngenerated long CoTs from different o1-like models (e.g., QwQ, DeepSeek-R1) for\ndifferent reasoning tasks (e.g., Math, Code, General Reasoning), to measure the\nability to detect errors in long CoT reasoning. Based on DeltaBench, we first\nperform fine-grained analysis of the generated long CoTs to discover the\neffectiveness and efficiency of different o1-like models. Then, we conduct\nextensive evaluations of existing process reward models (PRMs) and critic\nmodels to detect the errors of each annotated process, which aims to\ninvestigate the boundaries and limitations of existing PRMs and critic models.\nFinally, we hope that DeltaBench could guide developers to better understand\nthe long CoT reasoning abilities of their models.",
            "upvotes": 15,
            "discussionId": "67bfe438ca6e3c22b6e2948e"
        },
        "publishedAt": "2025-02-26T23:04:47.406Z",
        "title": "Can Large Language Models Detect Errors in Long Chain-of-Thought Reasoning?",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19361.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65377c30e48353201e6fdda0",
            "avatarUrl": "/avatars/a8f803b6f2e598eaee9c52c0d2ddfc16.svg",
            "fullname": "Jiaheng Liu",
            "name": "CheeryLJH",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 7
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.19328",
            "authors": [
                {
                    "_id": "67bfcb774d22a9379b29334c",
                    "name": "Hao Peng",
                    "hidden": false
                },
                {
                    "_id": "67bfcb774d22a9379b29334d",
                    "name": "Yunjia Qi",
                    "hidden": false
                },
                {
                    "_id": "67bfcb774d22a9379b29334e",
                    "name": "Xiaozhi Wang",
                    "hidden": false
                },
                {
                    "_id": "67bfcb774d22a9379b29334f",
                    "name": "Zijun Yao",
                    "hidden": false
                },
                {
                    "_id": "67bfcb774d22a9379b293350",
                    "name": "Bin Xu",
                    "hidden": false
                },
                {
                    "_id": "67bfcb774d22a9379b293351",
                    "name": "Lei Hou",
                    "hidden": false
                },
                {
                    "_id": "67bfcb774d22a9379b293352",
                    "name": "Juanzi Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T17:19:12.000Z",
            "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable\n  Correctness Signals for Reliable Reward Systems",
            "summary": "Reward models (RMs) are crucial for the training and inference-time scaling\nup of large language models (LLMs). However, existing reward models primarily\nfocus on human preferences, neglecting verifiable correctness signals which\nhave shown strong potential in training LLMs. In this paper, we propose agentic\nreward modeling, a reward system that combines reward models with verifiable\ncorrectness signals from different aspects to provide reliable rewards. We\nempirically implement a reward agent, named RewardAgent, that combines human\npreference rewards with two verifiable signals: factuality and instruction\nfollowing, to provide more reliable rewards. We conduct comprehensive\nexperiments on existing reward model benchmarks and inference time best-of-n\nsearches on real-world downstream tasks. RewardAgent significantly outperforms\nvanilla reward models, demonstrating its effectiveness. We further construct\ntraining preference pairs using RewardAgent and train an LLM with the DPO\nobjective, achieving superior performance on various NLP benchmarks compared to\nconventional reward models. Our codes are publicly released to facilitate\nfurther research (https://github.com/THU-KEG/Agentic-Reward-Modeling).",
            "upvotes": 14,
            "discussionId": "67bfcb784d22a9379b29338f"
        },
        "publishedAt": "2025-02-26T22:05:16.150Z",
        "title": "Agentic Reward Modeling: Integrating Human Preferences with Verifiable Correctness Signals for Reliable Reward Systems",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19328.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "625a5446f1063e7085d5178a",
            "avatarUrl": "/avatars/5e78186f13f74b14e01583e06ff6c4dc.svg",
            "fullname": "Hao Peng",
            "name": "Wesleythu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.18864",
            "authors": [
                {
                    "_id": "67bfd957c2a9b64ab3f97aa7",
                    "name": "Juraj Gottweis",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aa8",
                    "name": "Wei-Hung Weng",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aa9",
                    "name": "Alexander Daryin",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aaa",
                    "name": "Tao Tu",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aab",
                    "name": "Anil Palepu",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aac",
                    "name": "Petar Sirkovic",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aad",
                    "name": "Artiom Myaskovsky",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aae",
                    "name": "Felix Weissenberger",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aaf",
                    "name": "Keran Rong",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab0",
                    "name": "Ryutaro Tanno",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab1",
                    "name": "Khaled Saab",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab2",
                    "name": "Dan Popovici",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab3",
                    "name": "Jacob Blum",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab4",
                    "name": "Fan Zhang",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab5",
                    "name": "Katherine Chou",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab6",
                    "name": "Avinatan Hassidim",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab7",
                    "name": "Burak Gokturk",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab8",
                    "name": "Amin Vahdat",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ab9",
                    "name": "Pushmeet Kohli",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97aba",
                    "name": "Yossi Matias",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97abb",
                    "name": "Andrew Carroll",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97abc",
                    "name": "Kavita Kulkarni",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97abd",
                    "name": "Nenad Tomasev",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97abe",
                    "name": "Yuan Guan",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97abf",
                    "name": "Vikram Dhillon",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac0",
                    "name": "Eeshit Dhaval Vaishnav",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac1",
                    "name": "Byron Lee",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac2",
                    "name": "Tiago R D Costa",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac3",
                    "name": "José R Penadés",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac4",
                    "name": "Gary Peltz",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac5",
                    "name": "Yunhan Xu",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac6",
                    "name": "Annalisa Pawlosky",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac7",
                    "name": "Alan Karthikesalingam",
                    "hidden": false
                },
                {
                    "_id": "67bfd957c2a9b64ab3f97ac8",
                    "name": "Vivek Natarajan",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T06:17:13.000Z",
            "title": "Towards an AI co-scientist",
            "summary": "Scientific discovery relies on scientists generating novel hypotheses that\nundergo rigorous experimental validation. To augment this process, we introduce\nan AI co-scientist, a multi-agent system built on Gemini 2.0. The AI\nco-scientist is intended to help uncover new, original knowledge and to\nformulate demonstrably novel research hypotheses and proposals, building upon\nprior evidence and aligned to scientist-provided research objectives and\nguidance. The system's design incorporates a generate, debate, and evolve\napproach to hypothesis generation, inspired by the scientific method and\naccelerated by scaling test-time compute. Key contributions include: (1) a\nmulti-agent architecture with an asynchronous task execution framework for\nflexible compute scaling; (2) a tournament evolution process for self-improving\nhypotheses generation. Automated evaluations show continued benefits of\ntest-time compute, improving hypothesis quality. While general purpose, we\nfocus development and validation in three biomedical areas: drug repurposing,\nnovel target discovery, and explaining mechanisms of bacterial evolution and\nanti-microbial resistance. For drug repurposing, the system proposes candidates\nwith promising validation findings, including candidates for acute myeloid\nleukemia that show tumor inhibition in vitro at clinically applicable\nconcentrations. For novel target discovery, the AI co-scientist proposed new\nepigenetic targets for liver fibrosis, validated by anti-fibrotic activity and\nliver cell regeneration in human hepatic organoids. Finally, the AI\nco-scientist recapitulated unpublished experimental results via a parallel in\nsilico discovery of a novel gene transfer mechanism in bacterial evolution.\nThese results, detailed in separate, co-timed reports, demonstrate the\npotential to augment biomedical and scientific discovery and usher an era of AI\nempowered scientists.",
            "upvotes": 13,
            "discussionId": "67bfd958c2a9b64ab3f97afa"
        },
        "publishedAt": "2025-02-26T22:18:06.494Z",
        "title": "Towards an AI co-scientist",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18864.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60f1abe7544c2adfd699860c",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1674929746905-60f1abe7544c2adfd699860c.jpeg",
            "fullname": "AK",
            "name": "akhaliq",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 6243
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.19414",
            "authors": [
                {
                    "_id": "67c01587925b73feaf61ac41",
                    "user": {
                        "_id": "66325cc59292069aed610056",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66325cc59292069aed610056/acL_eIdQsBoeDiG9OAvvv.jpeg",
                        "isPro": false,
                        "fullname": "Shiven Sinha",
                        "user": "shivensinha4",
                        "type": "user"
                    },
                    "name": "Shiven Sinha",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T12:54:41.540Z",
                    "hidden": false
                },
                {
                    "_id": "67c01587925b73feaf61ac42",
                    "user": {
                        "_id": "6506832221ac448013f94995",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6506832221ac448013f94995/sVUI1JV4Dxan5l-MqNze4.jpeg",
                        "isPro": false,
                        "fullname": "Shashwat Goel",
                        "user": "shash42",
                        "type": "user"
                    },
                    "name": "Shashwat Goel",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T22:09:13.498Z",
                    "hidden": false
                },
                {
                    "_id": "67c01587925b73feaf61ac43",
                    "name": "Ponnurangam Kumaraguru",
                    "hidden": false
                },
                {
                    "_id": "67c01587925b73feaf61ac44",
                    "name": "Jonas Geiping",
                    "hidden": false
                },
                {
                    "_id": "67c01587925b73feaf61ac45",
                    "name": "Matthias Bethge",
                    "hidden": false
                },
                {
                    "_id": "67c01587925b73feaf61ac46",
                    "user": {
                        "_id": "6464a0d41683d3c81f51924a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6464a0d41683d3c81f51924a/s7yYVwfUB4WOhVFJS6A6T.jpeg",
                        "isPro": false,
                        "fullname": "Ameya Prabhu",
                        "user": "AmeyaPrabhu",
                        "type": "user"
                    },
                    "name": "Ameya Prabhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T12:54:39.585Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T18:58:13.000Z",
            "title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with\n  Counterexample Creation",
            "summary": "There is growing excitement about the potential of Language Models (LMs) to\naccelerate scientific discovery. Falsifying hypotheses is key to scientific\nprogress, as it allows claims to be iteratively refined over time. This process\nrequires significant researcher effort, reasoning, and ingenuity. Yet current\nbenchmarks for LMs predominantly assess their ability to generate solutions\nrather than challenge them. We advocate for developing benchmarks that evaluate\nthis inverse capability - creating counterexamples for subtly incorrect\nsolutions. To demonstrate this approach, we start with the domain of\nalgorithmic problem solving, where counterexamples can be evaluated\nautomatically using code execution. Specifically, we introduce REFUTE, a\ndynamically updating benchmark that includes recent problems and incorrect\nsubmissions from programming competitions, where human experts successfully\nidentified counterexamples. Our analysis finds that the best reasoning agents,\neven OpenAI o3-mini (high) with code execution feedback, can create\ncounterexamples for only <9% of incorrect solutions in REFUTE, even though\nratings indicate its ability to solve up to 48% of these problems from scratch.\nWe hope our work spurs progress in evaluating and enhancing LMs' ability to\nfalsify incorrect solutions - a capability that is crucial for both\naccelerating research and making models self-improve through reliable\nreflective reasoning.",
            "upvotes": 12,
            "discussionId": "67c01588925b73feaf61ad2c"
        },
        "publishedAt": "2025-02-27T02:36:29.037Z",
        "title": "Can Language Models Falsify? Evaluating Algorithmic Reasoning with Counterexample Creation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19414.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6506832221ac448013f94995",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6506832221ac448013f94995/sVUI1JV4Dxan5l-MqNze4.jpeg",
            "fullname": "Shashwat Goel",
            "name": "shash42",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.19413",
            "authors": [
                {
                    "_id": "67c02d6aa15ac71dcf1c754e",
                    "name": "Christoph Schuhmann",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c754f",
                    "user": {
                        "_id": "64ac21f11cacea8d4b8f2b3f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ac21f11cacea8d4b8f2b3f/asQOf8wFZ4vmqIeyxfvUR.jpeg",
                        "isPro": false,
                        "fullname": "Gollam Rabby",
                        "user": "tourist800",
                        "type": "user"
                    },
                    "name": "Gollam Rabby",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T12:54:33.105Z",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7550",
                    "user": {
                        "_id": "6464a0d41683d3c81f51924a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6464a0d41683d3c81f51924a/s7yYVwfUB4WOhVFJS6A6T.jpeg",
                        "isPro": false,
                        "fullname": "Ameya Prabhu",
                        "user": "AmeyaPrabhu",
                        "type": "user"
                    },
                    "name": "Ameya Prabhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T12:54:05.760Z",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7551",
                    "user": {
                        "_id": "635b9bc5cb0f36a40bb43ee3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/635b9bc5cb0f36a40bb43ee3/SVe1ZvCIfNlYdpWJ35Nu0.jpeg",
                        "isPro": false,
                        "fullname": "tawsif",
                        "user": "sleeping4cat",
                        "type": "user"
                    },
                    "name": "Tawsif Ahmed",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T22:09:11.253Z",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7552",
                    "user": {
                        "_id": "64ff3944f0d65cca9b867ed2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ff3944f0d65cca9b867ed2/jWnHkF4AUzh51MkC0UT6b.png",
                        "isPro": false,
                        "fullname": "Andreas Hochlehnert",
                        "user": "libeanim",
                        "type": "user"
                    },
                    "name": "Andreas Hochlehnert",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T22:09:08.923Z",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7553",
                    "name": "Huu Nguyen",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7554",
                    "name": "Nick Akinci Heidrich",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7555",
                    "name": "Ludwig Schmidt",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7556",
                    "name": "Robert Kaczmarczyk",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7557",
                    "name": "Sören Auer",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7558",
                    "name": "Jenia Jitsev",
                    "hidden": false
                },
                {
                    "_id": "67c02d6aa15ac71dcf1c7559",
                    "name": "Matthias Bethge",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T18:56:52.000Z",
            "title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright\n  Burdens via LLMs",
            "summary": "Paywalls, licenses and copyright rules often restrict the broad dissemination\nand reuse of scientific knowledge. We take the position that it is both legally\nand technically feasible to extract the scientific knowledge in scholarly\ntexts. Current methods, like text embeddings, fail to reliably preserve factual\ncontent, and simple paraphrasing may not be legally sound. We urge the\ncommunity to adopt a new idea: convert scholarly documents into Knowledge Units\nusing LLMs. These units use structured data capturing entities, attributes and\nrelationships without stylistic content. We provide evidence that Knowledge\nUnits: (1) form a legally defensible framework for sharing knowledge from\ncopyrighted research texts, based on legal analyses of German copyright law and\nU.S. Fair Use doctrine, and (2) preserve most (~95%) factual knowledge from\noriginal text, measured by MCQ performance on facts from the original\ncopyrighted text across four research domains. Freeing scientific knowledge\nfrom copyright promises transformative benefits for scientific research and\neducation by allowing language models to reuse important facts from copyrighted\ntext. To support this, we share open-source tools for converting research\ndocuments into Knowledge Units. Overall, our work posits the feasibility of\ndemocratizing access to scientific knowledge while respecting copyright.",
            "upvotes": 11,
            "discussionId": "67c02d6ba15ac71dcf1c7596"
        },
        "publishedAt": "2025-02-27T04:18:26.724Z",
        "title": "Project Alexandria: Towards Freeing Scientific Knowledge from Copyright Burdens via LLMs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19413.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6464a0d41683d3c81f51924a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6464a0d41683d3c81f51924a/s7yYVwfUB4WOhVFJS6A6T.jpeg",
            "fullname": "Ameya Prabhu",
            "name": "AmeyaPrabhu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 5
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.18418",
            "authors": [
                {
                    "_id": "67bf17b23f838c1e33ac7c4d",
                    "name": "Orion Weller",
                    "hidden": false
                },
                {
                    "_id": "67bf17b23f838c1e33ac7c4e",
                    "name": "Kathryn Ricci",
                    "hidden": false
                },
                {
                    "_id": "67bf17b23f838c1e33ac7c4f",
                    "name": "Eugene Yang",
                    "hidden": false
                },
                {
                    "_id": "67bf17b23f838c1e33ac7c50",
                    "name": "Andrew Yates",
                    "hidden": false
                },
                {
                    "_id": "67bf17b23f838c1e33ac7c51",
                    "name": "Dawn Lawrie",
                    "hidden": false
                },
                {
                    "_id": "67bf17b23f838c1e33ac7c52",
                    "name": "Benjamin Van Durme",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-25T18:14:06.000Z",
            "title": "Rank1: Test-Time Compute for Reranking in Information Retrieval",
            "summary": "We introduce Rank1, the first reranking model trained to take advantage of\ntest-time compute. Rank1 demonstrates the applicability within retrieval of\nusing a reasoning language model (i.e. OpenAI's o1, Deepseek's R1, etc.) for\ndistillation in order to rapidly improve the performance of a smaller model. We\ngather and open-source a dataset of more than 600,000 examples of R1 reasoning\ntraces from queries and passages in MS MARCO. Models trained on this dataset\nshow: (1) state-of-the-art performance on advanced reasoning and instruction\nfollowing datasets; (2) work remarkably well out of distribution due to the\nability to respond to user-input prompts; and (3) have explainable reasoning\nchains that can be given to users or RAG-based systems. Further, we demonstrate\nthat quantized versions of these models retain strong performance while using\nless compute/memory. Overall, Rank1 shows that test-time compute allows for a\nfundamentally new type of explainable and performant reranker model for search.",
            "upvotes": 10,
            "discussionId": "67bf17b33f838c1e33ac7c8e"
        },
        "publishedAt": "2025-02-27T09:41:49.469Z",
        "title": "Rank1: Test-Time Compute for Reranking in Information Retrieval",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18418.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6362d9712691058b19de1ba4",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6362d9712691058b19de1ba4/c9QrA2oE6lcs_46ShaTY1.jpeg",
            "fullname": "Orion Weller",
            "name": "orionweller",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 15
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.18906",
            "authors": [
                {
                    "_id": "67bfd5d2381f8fcb67e5ad36",
                    "name": "Jiani Zheng",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad37",
                    "name": "Lu Wang",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad38",
                    "user": {
                        "_id": "669dcf6200970c3b27aafa5d",
                        "avatarUrl": "/avatars/bb9ed5ff86326fdaeb184c6b0e40f74f.svg",
                        "isPro": false,
                        "fullname": "kaikai yang",
                        "user": "keanudicap",
                        "type": "user"
                    },
                    "name": "Fangkai Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:57.452Z",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad39",
                    "user": {
                        "_id": "654dbac9938fbf1e696be8aa",
                        "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
                        "isPro": false,
                        "fullname": "Chaoyun Zhang",
                        "user": "vyokky",
                        "type": "user"
                    },
                    "name": "Chaoyun Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:59.653Z",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad3a",
                    "name": "Lingrui Mei",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad3b",
                    "name": "Wenjie Yin",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad3c",
                    "name": "Qingwei Lin",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad3d",
                    "name": "Dongmei Zhang",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad3e",
                    "name": "Saravan Rajmohan",
                    "hidden": false
                },
                {
                    "_id": "67bfd5d2381f8fcb67e5ad3f",
                    "name": "Qi Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T07:52:02.000Z",
            "title": "VEM: Environment-Free Exploration for Training GUI Agent with Value\n  Environment Model",
            "summary": "Training Vision-Language Models (VLMs) for Graphical User Interfaces (GUI)\nagents via Reinforcement Learning (RL) faces critical challenges:\nenvironment-based RL requires costly interactions, while environment-free\nmethods struggle with distribution shift and reward generalization. We propose\nan environment-free RL framework that decouples value estimation from policy\noptimization by leveraging a pretrained Value Environment Model (VEM). VEM\npredicts state-action values directly from offline data, distilling human-like\npriors about GUI interaction outcomes without requiring next-state prediction\nor environmental feedback. This avoids compounding errors and enhances\nresilience to UI changes by focusing on semantic reasoning (e.g., Does this\naction advance the user's goal?). The framework operates in two stages: (1)\npretraining VEM to estimate long-term action utilities and (2) guiding policy\nexploration with frozen VEM signals, enabling layout-agnostic GUI automation.\nEvaluated on Android-in-the-Wild benchmarks, VEM achieves state-of-the-art\nperformance in both offline and online settings, outperforming environment-free\nbaselines significantly and matching environment-based approaches without\ninteraction costs. Importantly, VEM demonstrates that semantic-aware value\nestimation can achieve comparable performance with online-trained methods.",
            "upvotes": 7,
            "discussionId": "67bfd5d7381f8fcb67e5ae3d"
        },
        "publishedAt": "2025-02-26T22:02:50.690Z",
        "title": "VEM: Environment-Free Exploration for Training GUI Agent with Value Environment Model",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18906.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "654dbac9938fbf1e696be8aa",
            "avatarUrl": "/avatars/b3c4035c48169c1bfb04a439fce3499f.svg",
            "fullname": "Chaoyun Zhang",
            "name": "vyokky",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.19204",
            "authors": [
                {
                    "_id": "67bfd735ca6e3c22b6de43c7",
                    "name": "Xiankang He",
                    "hidden": false
                },
                {
                    "_id": "67bfd735ca6e3c22b6de43c8",
                    "name": "Dongyan Guo",
                    "hidden": false
                },
                {
                    "_id": "67bfd735ca6e3c22b6de43c9",
                    "name": "Hongji Li",
                    "hidden": false
                },
                {
                    "_id": "67bfd735ca6e3c22b6de43ca",
                    "name": "Ruibo Li",
                    "hidden": false
                },
                {
                    "_id": "67bfd735ca6e3c22b6de43cb",
                    "name": "Ying Cui",
                    "hidden": false
                },
                {
                    "_id": "67bfd735ca6e3c22b6de43cc",
                    "name": "Chi Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T15:10:05.000Z",
            "title": "Distill Any Depth: Distillation Creates a Stronger Monocular Depth\n  Estimator",
            "summary": "Monocular depth estimation (MDE) aims to predict scene depth from a single\nRGB image and plays a crucial role in 3D scene understanding. Recent advances\nin zero-shot MDE leverage normalized depth representations and\ndistillation-based learning to improve generalization across diverse scenes.\nHowever, current depth normalization methods for distillation, relying on\nglobal normalization, can amplify noisy pseudo-labels, reducing distillation\neffectiveness. In this paper, we systematically analyze the impact of different\ndepth normalization strategies on pseudo-label distillation. Based on our\nfindings, we propose Cross-Context Distillation, which integrates global and\nlocal depth cues to enhance pseudo-label quality. Additionally, we introduce a\nmulti-teacher distillation framework that leverages complementary strengths of\ndifferent depth estimation models, leading to more robust and accurate depth\npredictions. Extensive experiments on benchmark datasets demonstrate that our\napproach significantly outperforms state-of-the-art methods, both\nquantitatively and qualitatively.",
            "upvotes": 6,
            "discussionId": "67bfd736ca6e3c22b6de441e"
        },
        "publishedAt": "2025-02-26T22:10:20.646Z",
        "title": "Distill Any Depth: Distillation Creates a Stronger Monocular Depth Estimator",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64196320ed725fef64419c2a/k13rSuJPlDkMtzwdHXCXm.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19204.png",
        "numComments": 4,
        "submittedBy": {
            "_id": "64196320ed725fef64419c2a",
            "avatarUrl": "/avatars/96feb22fb5e8931d6c9e0ea06148266f.svg",
            "fullname": "Chi Zhang",
            "name": "DrChiZhang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.19187",
            "authors": [
                {
                    "_id": "67c01747e8c7d56a8e0cbdc3",
                    "name": "Mehran Kazemi",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdc4",
                    "user": {
                        "_id": "654e97ef5da3196a78409341",
                        "avatarUrl": "/avatars/1a5ea7351ca21960891cf9721b9f4667.svg",
                        "isPro": false,
                        "fullname": "Bahare Fatemi",
                        "user": "baharefatemi",
                        "type": "user"
                    },
                    "name": "Bahare Fatemi",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-27T07:42:00.525Z",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdc5",
                    "name": "Hritik Bansal",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdc6",
                    "name": "John Palowitch",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdc7",
                    "name": "Chrysovalantis Anastasiou",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdc8",
                    "name": "Sanket Vaibhav Mehta",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdc9",
                    "name": "Lalit K. Jain",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdca",
                    "name": "Virginia Aglietti",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdcb",
                    "name": "Disha Jindal",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdcc",
                    "name": "Peter Chen",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdcd",
                    "name": "Nishanth Dikkala",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdce",
                    "name": "Gladys Tyen",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdcf",
                    "name": "Xin Liu",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdd0",
                    "name": "Uri Shalit",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdd1",
                    "name": "Silvia Chiappa",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdd2",
                    "name": "Kate Olszewska",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdd3",
                    "name": "Yi Tay",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdd4",
                    "name": "Vinh Q. Tran",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdd5",
                    "name": "Quoc V. Le",
                    "hidden": false
                },
                {
                    "_id": "67c01747e8c7d56a8e0cbdd6",
                    "name": "Orhan Firat",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T14:50:50.000Z",
            "title": "BIG-Bench Extra Hard",
            "summary": "Large language models (LLMs) are increasingly deployed in everyday\napplications, demanding robust general reasoning capabilities and diverse\nreasoning skillset. However, current LLM reasoning benchmarks predominantly\nfocus on mathematical and coding abilities, leaving a gap in evaluating broader\nreasoning proficiencies. One particular exception is the BIG-Bench dataset,\nwhich has served as a crucial benchmark for evaluating the general reasoning\ncapabilities of LLMs, thanks to its diverse set of challenging tasks that\nallowed for a comprehensive assessment of general reasoning across various\nskills within a unified framework. However, recent advances in LLMs have led to\nsaturation on BIG-Bench, and its harder version BIG-Bench Hard (BBH).\nState-of-the-art models achieve near-perfect scores on many tasks in BBH, thus\ndiminishing its utility. To address this limitation, we introduce BIG-Bench\nExtra Hard (BBEH), a new benchmark designed to push the boundaries of LLM\nreasoning evaluation. BBEH replaces each task in BBH with a novel task that\nprobes a similar reasoning capability but exhibits significantly increased\ndifficulty. We evaluate various models on BBEH and observe a (harmonic) average\naccuracy of 9.8\\% for the best general-purpose model and 44.8\\% for the best\nreasoning-specialized model, indicating substantial room for improvement and\nhighlighting the ongoing challenge of achieving robust general reasoning in\nLLMs. We release BBEH publicly at: https://github.com/google-deepmind/bbeh.",
            "upvotes": 4,
            "discussionId": "67c01748e8c7d56a8e0cbe0b"
        },
        "publishedAt": "2025-02-27T02:43:05.341Z",
        "title": "BIG-Bench Extra Hard",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19187.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "5f1158120c833276f61f1a84",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
            "fullname": "Niels Rogge",
            "name": "nielsr",
            "type": "user",
            "isPro": false,
            "isHf": true,
            "isMod": false,
            "followerCount": 776
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.19279",
            "authors": [
                {
                    "_id": "67bffaca3f838c1e33e074e7",
                    "user": {
                        "_id": "638ef0b0c67af472d31674a6",
                        "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
                        "isPro": false,
                        "fullname": "Honglin Guo",
                        "user": "KYLN24",
                        "type": "user"
                    },
                    "name": "Honglin Guo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:13:52.094Z",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074e8",
                    "name": "Kai Lv",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074e9",
                    "name": "Qipeng Guo",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074ea",
                    "name": "Tianyi Liang",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074eb",
                    "name": "Zhiheng Xi",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074ec",
                    "name": "Demin Song",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074ed",
                    "name": "Qiuyinzhe Zhang",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074ee",
                    "name": "Yu Sun",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074ef",
                    "name": "Kai Chen",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074f0",
                    "name": "Xipeng Qiu",
                    "hidden": false
                },
                {
                    "_id": "67bffaca3f838c1e33e074f1",
                    "name": "Tao Gui",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T16:33:41.000Z",
            "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
            "summary": "Language model heavily depends on high-quality data for optimal performance.\nExisting approaches rely on manually designed heuristics, the perplexity of\nexisting models, training classifiers, or careful prompt engineering, which\nrequire significant expert experience and human annotation effort while\nintroduce biases. We introduce CritiQ, a novel data selection method that\nautomatically mines criteria from human preferences for data quality with only\nsim30 human-annotated pairs and performs efficient data selection. The main\ncomponent, CritiQ Flow, employs a manager agent to evolve quality criteria and\nworker agents to make pairwise judgments. We build a knowledge base that\nextracts quality criteria from previous work to boost CritiQ Flow. Compared to\nperplexity- and classifier- based methods, verbal criteria are more\ninterpretable and possess reusable value. After deriving the criteria, we train\nthe CritiQ Scorer to give quality scores and perform efficient data selection.\nWe demonstrate the effectiveness of our method in the code, math, and logic\ndomains, achieving high accuracy on human-annotated test sets. To validate the\nquality of the selected data, we continually train Llama 3.1 models and observe\nimproved performance on downstream tasks compared to uniform sampling. Ablation\nstudies validate the benefits of the knowledge base and the reflection process.\nWe analyze how criteria evolve and the effectiveness of majority voting.",
            "upvotes": 4,
            "discussionId": "67bffacc3f838c1e33e075a2"
        },
        "publishedAt": "2025-02-27T00:47:02.948Z",
        "title": "CritiQ: Mining Data Quality Criteria from Human Preferences",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19279.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "638ef0b0c67af472d31674a6",
            "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
            "fullname": "Honglin Guo",
            "name": "KYLN24",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.16776",
            "authors": [
                {
                    "_id": "67bfd8d546083445aacb4605",
                    "name": "Zhexin Zhang",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4606",
                    "name": "Leqi Lei",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4607",
                    "name": "Junxiao Yang",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4608",
                    "name": "Xijie Huang",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4609",
                    "name": "Yida Lu",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb460a",
                    "name": "Shiyao Cui",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb460b",
                    "name": "Renmiao Chen",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb460c",
                    "name": "Qinglin Zhang",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb460d",
                    "name": "Xinyuan Wang",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb460e",
                    "name": "Hao Wang",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb460f",
                    "user": {
                        "_id": "653f1ef4aabbf15fc76a259c",
                        "avatarUrl": "/avatars/94e569999d913e961266394ea2875965.svg",
                        "isPro": false,
                        "fullname": "LLLeo Li",
                        "user": "LLLeo612",
                        "type": "user"
                    },
                    "name": "Hao Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:45.366Z",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4610",
                    "name": "Xianqi Lei",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4611",
                    "name": "Chengwei Pan",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4612",
                    "name": "Lei Sha",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4613",
                    "name": "Hongning Wang",
                    "hidden": false
                },
                {
                    "_id": "67bfd8d546083445aacb4614",
                    "name": "Minlie Huang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-24T02:11:52.000Z",
            "title": "AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and\n  Improvement",
            "summary": "As AI models are increasingly deployed across diverse real-world scenarios,\nensuring their safety remains a critical yet underexplored challenge. While\nsubstantial efforts have been made to evaluate and enhance AI safety, the lack\nof a standardized framework and comprehensive toolkit poses significant\nobstacles to systematic research and practical adoption. To bridge this gap, we\nintroduce AISafetyLab, a unified framework and toolkit that integrates\nrepresentative attack, defense, and evaluation methodologies for AI safety.\nAISafetyLab features an intuitive interface that enables developers to\nseamlessly apply various techniques while maintaining a well-structured and\nextensible codebase for future advancements. Additionally, we conduct empirical\nstudies on Vicuna, analyzing different attack and defense strategies to provide\nvaluable insights into their comparative effectiveness. To facilitate ongoing\nresearch and development in AI safety, AISafetyLab is publicly available at\nhttps://github.com/thu-coai/AISafetyLab, and we are committed to its continuous\nmaintenance and improvement.",
            "upvotes": 4,
            "discussionId": "67bfd8d646083445aacb464f"
        },
        "publishedAt": "2025-02-26T22:16:03.582Z",
        "title": "AISafetyLab: A Comprehensive Framework for AI Safety Evaluation and Improvement",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16776.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "61b58aa0d65058ce70beb98c",
            "avatarUrl": "/avatars/aefd9271b891abc6dd2ded1a30eebca4.svg",
            "fullname": "Zhexin Zhang",
            "name": "nonstopfor",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.19312",
            "authors": [
                {
                    "_id": "67c01972d63ea6742473aa2a",
                    "user": {
                        "_id": "6511ee845b7e52b0251fdee9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6511ee845b7e52b0251fdee9/hTIwiIYBGOVnIrxtpri83.png",
                        "isPro": false,
                        "fullname": "Anikait Singh",
                        "user": "Asap7772",
                        "type": "user"
                    },
                    "name": "Anikait Singh",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-02-27T07:51:17.284Z",
                    "hidden": false
                },
                {
                    "_id": "67c01972d63ea6742473aa2b",
                    "name": "Sheryl Hsu",
                    "hidden": false
                },
                {
                    "_id": "67c01972d63ea6742473aa2c",
                    "name": "Kyle Hsu",
                    "hidden": false
                },
                {
                    "_id": "67c01972d63ea6742473aa2d",
                    "name": "Eric Mitchell",
                    "hidden": false
                },
                {
                    "_id": "67c01972d63ea6742473aa2e",
                    "name": "Stefano Ermon",
                    "hidden": false
                },
                {
                    "_id": "67c01972d63ea6742473aa2f",
                    "name": "Tatsunori Hashimoto",
                    "hidden": false
                },
                {
                    "_id": "67c01972d63ea6742473aa30",
                    "name": "Archit Sharma",
                    "hidden": false
                },
                {
                    "_id": "67c01972d63ea6742473aa31",
                    "name": "Chelsea Finn",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T17:08:46.000Z",
            "title": "FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in\n  LLMs Elicits Effective Personalization to Real Users",
            "summary": "Effective personalization of LLMs is critical for a broad range of\nuser-interfacing applications such as virtual assistants and content curation.\nInspired by the strong in-context learning capabilities of LLMs, we propose\nFew-Shot Preference Optimization (FSPO), which reframes reward modeling as a\nmeta-learning problem. Under this framework, an LLM learns to quickly adapt to\na user via a few labeled preferences from that user, constructing a\npersonalized reward function for them. Additionally, since real-world\npreference data is scarce and challenging to collect at scale, we propose\ncareful design choices to construct synthetic preference datasets for\npersonalization, generating over 1M synthetic personalized preferences using\npublicly available LLMs. In particular, to successfully transfer from synthetic\ndata to real users, we find it crucial for the data to exhibit both high\ndiversity and coherent, self-consistent structure. We evaluate FSPO on\npersonalized open-ended generation for up to 1,500 synthetic users across\nacross three domains: movie reviews, pedagogical adaptation based on\neducational background, and general question answering, along with a controlled\nhuman study. Overall, FSPO achieves an 87% Alpaca Eval winrate on average in\ngenerating responses that are personalized to synthetic users and a 72% winrate\nwith real human users in open-ended question answering.",
            "upvotes": 3,
            "discussionId": "67c01975d63ea6742473aa52"
        },
        "publishedAt": "2025-02-27T11:09:15.703Z",
        "title": "FSPO: Few-Shot Preference Optimization of Synthetic Preference Data in LLMs Elicits Effective Personalization to Real Users",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19312.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6511ee845b7e52b0251fdee9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6511ee845b7e52b0251fdee9/hTIwiIYBGOVnIrxtpri83.png",
            "fullname": "Anikait Singh",
            "name": "Asap7772",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.18779",
            "authors": [
                {
                    "_id": "67c0b4d0cda310c08781e820",
                    "name": "Zhengmian Hu",
                    "hidden": false
                },
                {
                    "_id": "67c0b4d0cda310c08781e821",
                    "user": {
                        "_id": "6623ea65b642e29cdf90a1b4",
                        "avatarUrl": "/avatars/e32e90574c1162b2be87ed78604e3e4d.svg",
                        "isPro": true,
                        "fullname": "TongZheng",
                        "user": "TongZheng1999",
                        "type": "user"
                    },
                    "name": "Tong Zheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T22:08:55.900Z",
                    "hidden": false
                },
                {
                    "_id": "67c0b4d0cda310c08781e822",
                    "name": "Vignesh Viswanathan",
                    "hidden": false
                },
                {
                    "_id": "67c0b4d0cda310c08781e823",
                    "name": "Ziyi Chen",
                    "hidden": false
                },
                {
                    "_id": "67c0b4d0cda310c08781e824",
                    "name": "Ryan A. Rossi",
                    "hidden": false
                },
                {
                    "_id": "67c0b4d0cda310c08781e825",
                    "name": "Yihan Wu",
                    "hidden": false
                },
                {
                    "_id": "67c0b4d0cda310c08781e826",
                    "name": "Dinesh Manocha",
                    "hidden": false
                },
                {
                    "_id": "67c0b4d0cda310c08781e827",
                    "name": "Heng Huang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T03:22:44.000Z",
            "title": "Towards Optimal Multi-draft Speculative Decoding",
            "summary": "Large Language Models (LLMs) have become an indispensable part of natural\nlanguage processing tasks. However, autoregressive sampling has become an\nefficiency bottleneck. Multi-Draft Speculative Decoding (MDSD) is a recent\napproach where, when generating each token, a small draft model generates\nmultiple drafts, and the target LLM verifies them in parallel, ensuring that\nthe final output conforms to the target model distribution. The two main design\nchoices in MDSD are the draft sampling method and the verification algorithm.\nFor a fixed draft sampling method, the optimal acceptance rate is a solution to\nan optimal transport problem, but the complexity of this problem makes it\ndifficult to solve for the optimal acceptance rate and measure the gap between\nexisting verification algorithms and the theoretical upper bound. This paper\ndiscusses the dual of the optimal transport problem, providing a way to\nefficiently compute the optimal acceptance rate. For the first time, we measure\nthe theoretical upper bound of MDSD efficiency for vocabulary sizes in the\nthousands and quantify the gap between existing verification algorithms and\nthis bound. We also compare different draft sampling methods based on their\noptimal acceptance rates. Our results show that the draft sampling method\nstrongly influences the optimal acceptance rate, with sampling without\nreplacement outperforming sampling with replacement. Additionally, existing\nverification algorithms do not reach the theoretical upper bound for both\nwithout replacement and with replacement sampling. Our findings suggest that\ncarefully designed draft sampling methods can potentially improve the optimal\nacceptance rate and enable the development of verification algorithms that\nclosely match the theoretical upper bound.",
            "upvotes": 2,
            "discussionId": "67c0b4d1cda310c08781e864"
        },
        "publishedAt": "2025-02-27T14:03:36.365Z",
        "title": "Towards Optimal Multi-draft Speculative Decoding",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18779.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6623ea65b642e29cdf90a1b4",
            "avatarUrl": "/avatars/e32e90574c1162b2be87ed78604e3e4d.svg",
            "fullname": "TongZheng",
            "name": "TongZheng1999",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.16284",
            "authors": [
                {
                    "_id": "67bfdbd0302c06f220658e9d",
                    "user": {
                        "_id": "64e84ec6d41a68b065bf78a7",
                        "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
                        "isPro": false,
                        "fullname": "Liang Wang",
                        "user": "AzureLeon1",
                        "type": "user"
                    },
                    "name": "Liang Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:14:42.802Z",
                    "hidden": false
                },
                {
                    "_id": "67bfdbd0302c06f220658e9e",
                    "name": "Shaozhen Liu",
                    "hidden": false
                },
                {
                    "_id": "67bfdbd0302c06f220658e9f",
                    "name": "Yu Rong",
                    "hidden": false
                },
                {
                    "_id": "67bfdbd0302c06f220658ea0",
                    "name": "Deli Zhao",
                    "hidden": false
                },
                {
                    "_id": "67bfdbd0302c06f220658ea1",
                    "name": "Qiang Liu",
                    "hidden": false
                },
                {
                    "_id": "67bfdbd0302c06f220658ea2",
                    "name": "Shu Wu",
                    "hidden": false
                },
                {
                    "_id": "67bfdbd0302c06f220658ea3",
                    "name": "Liang Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-22T16:34:32.000Z",
            "title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal\n  Energy Spectra",
            "summary": "Establishing the relationship between 3D structures and the energy states of\nmolecular systems has proven to be a promising approach for learning 3D\nmolecular representations. However, existing methods are limited to modeling\nthe molecular energy states from classical mechanics. This limitation results\nin a significant oversight of quantum mechanical effects, such as quantized\n(discrete) energy level structures, which offer a more accurate estimation of\nmolecular energy and can be experimentally measured through energy spectra. In\nthis paper, we propose to utilize the energy spectra to enhance the\npre-training of 3D molecular representations (MolSpectra), thereby infusing the\nknowledge of quantum mechanics into the molecular representations.\nSpecifically, we propose SpecFormer, a multi-spectrum encoder for encoding\nmolecular spectra via masked patch reconstruction. By further aligning outputs\nfrom the 3D encoder and spectrum encoder using a contrastive objective, we\nenhance the 3D encoder's understanding of molecules. Evaluations on public\nbenchmarks reveal that our pre-trained representations surpass existing methods\nin predicting molecular properties and modeling dynamics.",
            "upvotes": 2,
            "discussionId": "67bfdbd1302c06f220658ece"
        },
        "publishedAt": "2025-02-26T22:29:40.056Z",
        "title": "MolSpectra: Pre-training 3D Molecular Representation with Multi-modal Energy Spectra",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16284.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64e84ec6d41a68b065bf78a7",
            "avatarUrl": "/avatars/bae3c5e3210b40af6e4f113e85f3e206.svg",
            "fullname": "Liang Wang",
            "name": "AzureLeon1",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.19261",
            "authors": [
                {
                    "_id": "67c07170af68756abc571ab8",
                    "user": {
                        "_id": "6308c49c454dc257521bc7f9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6308c49c454dc257521bc7f9/UWUS6OPa6OpVu1T0gd-wJ.jpeg",
                        "isPro": false,
                        "fullname": "Taishi",
                        "user": "Taishi-N324",
                        "type": "user"
                    },
                    "name": "Taishi Nakamura",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T22:09:06.783Z",
                    "hidden": false
                },
                {
                    "_id": "67c07170af68756abc571ab9",
                    "name": "Takuya Akiba",
                    "hidden": false
                },
                {
                    "_id": "67c07170af68756abc571aba",
                    "name": "Kazuki Fujii",
                    "hidden": false
                },
                {
                    "_id": "67c07170af68756abc571abb",
                    "name": "Yusuke Oda",
                    "hidden": false
                },
                {
                    "_id": "67c07170af68756abc571abc",
                    "name": "Rio Yokota",
                    "hidden": false
                },
                {
                    "_id": "67c07170af68756abc571abd",
                    "name": "Jun Suzuki",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T16:06:36.000Z",
            "title": "Drop-Upcycling: Training Sparse Mixture of Experts with Partial\n  Re-initialization",
            "summary": "The Mixture of Experts (MoE) architecture reduces the training and inference\ncost significantly compared to a dense model of equivalent capacity. Upcycling\nis an approach that initializes and trains an MoE model using a pre-trained\ndense model. While upcycling leads to initial performance gains, the training\nprogresses slower than when trained from scratch, leading to suboptimal\nperformance in the long term. We propose Drop-Upcycling - a method that\neffectively addresses this problem. Drop-Upcycling combines two seemingly\ncontradictory approaches: utilizing the knowledge of pre-trained dense models\nwhile statistically re-initializing some parts of the weights. This approach\nstrategically promotes expert specialization, significantly enhancing the MoE\nmodel's efficiency in knowledge acquisition. Extensive large-scale experiments\ndemonstrate that Drop-Upcycling significantly outperforms previous MoE\nconstruction methods in the long term, specifically when training on hundreds\nof billions of tokens or more. As a result, our MoE model with 5.9B active\nparameters achieves comparable performance to a 13B dense model in the same\nmodel family, while requiring approximately 1/4 of the training FLOPs. All\nexperimental resources, including source code, training data, model checkpoints\nand logs, are publicly available to promote reproducibility and future research\non MoE.",
            "upvotes": 1,
            "discussionId": "67c07172af68756abc571b53"
        },
        "publishedAt": "2025-02-27T10:12:03.128Z",
        "title": "Drop-Upcycling: Training Sparse Mixture of Experts with Partial Re-initialization",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19261.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6308c49c454dc257521bc7f9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6308c49c454dc257521bc7f9/UWUS6OPa6OpVu1T0gd-wJ.jpeg",
            "fullname": "Taishi",
            "name": "Taishi-N324",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 19
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.17540",
            "authors": [
                {
                    "_id": "67bff9608d761fc6a75e24ad",
                    "user": {
                        "_id": "657ccbf2869d5bb0e53b482f",
                        "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
                        "isPro": false,
                        "fullname": "Rohit Saxena",
                        "user": "rohitsaxena",
                        "type": "user"
                    },
                    "name": "Rohit Saxena",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T09:13:54.284Z",
                    "hidden": false
                },
                {
                    "_id": "67bff9608d761fc6a75e24ae",
                    "name": "Pasquale Minervini",
                    "hidden": false
                },
                {
                    "_id": "67bff9608d761fc6a75e24af",
                    "name": "Frank Keller",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-24T18:35:39.000Z",
            "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
            "summary": "Generating accurate and concise textual summaries from multimodal documents\nis challenging, especially when dealing with visually complex content like\nscientific posters. We introduce PosterSum, a novel benchmark to advance the\ndevelopment of vision-language models that can understand and summarize\nscientific posters into research paper abstracts. Our dataset contains 16,305\nconference posters paired with their corresponding abstracts as summaries. Each\nposter is provided in image format and presents diverse visual understanding\nchallenges, such as complex layouts, dense text regions, tables, and figures.\nWe benchmark state-of-the-art Multimodal Large Language Models (MLLMs) on\nPosterSum and demonstrate that they struggle to accurately interpret and\nsummarize scientific posters. We propose Segment & Summarize, a hierarchical\nmethod that outperforms current MLLMs on automated metrics, achieving a 3.14%\ngain in ROUGE-L. This will serve as a starting point for future research on\nposter summarization.",
            "upvotes": 1,
            "discussionId": "67bff96d8d761fc6a75e27a0"
        },
        "publishedAt": "2025-02-27T00:37:24.965Z",
        "title": "PosterSum: A Multimodal Benchmark for Scientific Poster Summarization",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.17540.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "657ccbf2869d5bb0e53b482f",
            "avatarUrl": "/avatars/2eae5a10bdc14814a04d9f255f16de6b.svg",
            "fullname": "Rohit Saxena",
            "name": "rohitsaxena",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.15885",
            "authors": [
                {
                    "_id": "67c05aeca2a76d8a27d33c8a",
                    "name": "Hongjie Zhu",
                    "hidden": false
                },
                {
                    "_id": "67c05aeca2a76d8a27d33c8b",
                    "user": {
                        "_id": "64ec877bb93654d4ca5c92e9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ec877bb93654d4ca5c92e9/GvHk_KSdE9Rhnk_o-NaZX.jpeg",
                        "isPro": false,
                        "fullname": "Zeyu Zhang",
                        "user": "SteveZeyuZhang",
                        "type": "user"
                    },
                    "name": "Zeyu Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-02-27T12:53:51.821Z",
                    "hidden": false
                },
                {
                    "_id": "67c05aeca2a76d8a27d33c8c",
                    "name": "Guansong Pang",
                    "hidden": false
                },
                {
                    "_id": "67c05aeca2a76d8a27d33c8d",
                    "name": "Xu Wang",
                    "hidden": false
                },
                {
                    "_id": "67c05aeca2a76d8a27d33c8e",
                    "name": "Shimin Wen",
                    "hidden": false
                },
                {
                    "_id": "67c05aeca2a76d8a27d33c8f",
                    "name": "Yu Bai",
                    "hidden": false
                },
                {
                    "_id": "67c05aeca2a76d8a27d33c90",
                    "name": "Daji Ergu",
                    "hidden": false
                },
                {
                    "_id": "67c05aeca2a76d8a27d33c91",
                    "name": "Ying Cai",
                    "hidden": false
                },
                {
                    "_id": "67c05aeca2a76d8a27d33c92",
                    "name": "Yang Zhao",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-21T19:06:01.000Z",
            "title": "DOEI: Dual Optimization of Embedding Information for Attention-Enhanced\n  Class Activation Maps",
            "summary": "Weakly supervised semantic segmentation (WSSS) typically utilizes limited\nsemantic annotations to obtain initial Class Activation Maps (CAMs). However,\ndue to the inadequate coupling between class activation responses and semantic\ninformation in high-dimensional space, the CAM is prone to object co-occurrence\nor under-activation, resulting in inferior recognition accuracy. To tackle this\nissue, we propose DOEI, Dual Optimization of Embedding Information, a novel\napproach that reconstructs embedding representations through semantic-aware\nattention weight matrices to optimize the expression capability of embedding\ninformation. Specifically, DOEI amplifies tokens with high confidence and\nsuppresses those with low confidence during the class-to-patch interaction.\nThis alignment of activation responses with semantic information strengthens\nthe propagation and decoupling of target features, enabling the generated\nembeddings to more accurately represent target features in high-level semantic\nspace. In addition, we propose a hybrid-feature alignment module in DOEI that\ncombines RGB values, embedding-guided features, and self-attention weights to\nincrease the reliability of candidate tokens. Comprehensive experiments show\nthat DOEI is an effective plug-and-play module that empowers state-of-the-art\nvisual transformer-based WSSS models to significantly improve the quality of\nCAMs and segmentation performance on popular benchmarks, including PASCAL VOC\n(+3.6%, +1.5%, +1.2% mIoU) and MS COCO (+1.2%, +1.6% mIoU). Code will be\navailable at https://github.com/AIGeeksGroup/DOEI.",
            "upvotes": 0,
            "discussionId": "67c05af3a2a76d8a27d33faf"
        },
        "publishedAt": "2025-02-27T07:31:45.499Z",
        "title": "DOEI: Dual Optimization of Embedding Information for Attention-Enhanced Class Activation Maps",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.15885.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64ec877bb93654d4ca5c92e9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ec877bb93654d4ca5c92e9/GvHk_KSdE9Rhnk_o-NaZX.jpeg",
            "fullname": "Zeyu Zhang",
            "name": "SteveZeyuZhang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    }
]