[
    {
        "paper": {
            "id": "2503.01785",
            "authors": [
                {
                    "_id": "67c6816614a1bf9855188b8b",
                    "user": {
                        "_id": "66fe1334ff3ee1f7569fab6d",
                        "avatarUrl": "/avatars/6868b1a545028a9b8bbded52490dc093.svg",
                        "isPro": false,
                        "fullname": "ziyuliu",
                        "user": "ziyuliu",
                        "type": "user"
                    },
                    "name": "Ziyu Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:12:57.481Z",
                    "hidden": false
                },
                {
                    "_id": "67c6816614a1bf9855188b8c",
                    "user": {
                        "_id": "63fda3fced9eead590ff6918",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677566802735-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Zeyi Sun",
                        "user": "Zery",
                        "type": "user"
                    },
                    "name": "Zeyi Sun",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:35:03.275Z",
                    "hidden": false
                },
                {
                    "_id": "67c6816614a1bf9855188b8d",
                    "user": {
                        "_id": "63859cf3b2906edaf83af9f0",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63859cf3b2906edaf83af9f0/iUQm5FAomzqYi6fkqIn9F.jpeg",
                        "isPro": false,
                        "fullname": "Yuhang Zang",
                        "user": "yuhangzang",
                        "type": "user"
                    },
                    "name": "Yuhang Zang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:12:32.723Z",
                    "hidden": false
                },
                {
                    "_id": "67c6816614a1bf9855188b8e",
                    "user": {
                        "_id": "67c0849ee08c178ef8d4e05c",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/mQ6VdnjZnRhb0H_waPclo.png",
                        "isPro": false,
                        "fullname": "Xiaoyi Dong",
                        "user": "sweetFruit",
                        "type": "user"
                    },
                    "name": "Xiaoyi Dong",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:12:25.627Z",
                    "hidden": false
                },
                {
                    "_id": "67c6816614a1bf9855188b8f",
                    "user": {
                        "_id": "65000bef18830fabea469fdd",
                        "avatarUrl": "/avatars/b320c77dfad039d9f9c54127f610d44f.svg",
                        "isPro": false,
                        "fullname": "Cao Yuhang",
                        "user": "yhcao",
                        "type": "user"
                    },
                    "name": "Yuhang Cao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:12:19.177Z",
                    "hidden": false
                },
                {
                    "_id": "67c6816614a1bf9855188b90",
                    "user": {
                        "_id": "63ee1379190ddd6214efd73a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1676546883247-noauth.png",
                        "isPro": false,
                        "fullname": "HAODONG DUAN",
                        "user": "KennyUTC",
                        "type": "user"
                    },
                    "name": "Haodong Duan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:12:05.281Z",
                    "hidden": false
                },
                {
                    "_id": "67c6816614a1bf9855188b91",
                    "user": {
                        "_id": "636317ed80c1a705a6eff396",
                        "avatarUrl": "/avatars/3db090e101b916d9256d0d3e043db71d.svg",
                        "isPro": false,
                        "fullname": "Dahua Lin",
                        "user": "lindahua",
                        "type": "user"
                    },
                    "name": "Dahua Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:11:57.087Z",
                    "hidden": false
                },
                {
                    "_id": "67c6816614a1bf9855188b92",
                    "user": {
                        "_id": "64638c4d51fa6e63060521b5",
                        "avatarUrl": "/avatars/c863ace5b1dc788a341bcf4ddbdfaec1.svg",
                        "isPro": false,
                        "fullname": "JIaqi",
                        "user": "Jiaqiwang",
                        "type": "user"
                    },
                    "name": "Jiaqi Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:11:48.889Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T18:16:32.000Z",
            "title": "Visual-RFT: Visual Reinforcement Fine-Tuning",
            "summary": "Reinforcement Fine-Tuning (RFT) in Large Reasoning Models like OpenAI o1\nlearns from feedback on its answers, which is especially useful in applications\nwhen fine-tuning data is scarce. Recent open-source work like DeepSeek-R1\ndemonstrates that reinforcement learning with verifiable reward is one key\ndirection in reproducing o1. While the R1-style model has demonstrated success\nin language models, its application in multi-modal domains remains\nunder-explored. This work introduces Visual Reinforcement Fine-Tuning\n(Visual-RFT), which further extends the application areas of RFT on visual\ntasks. Specifically, Visual-RFT first uses Large Vision-Language Models (LVLMs)\nto generate multiple responses containing reasoning tokens and final answers\nfor each input, and then uses our proposed visual perception verifiable reward\nfunctions to update the model via the policy optimization algorithm such as\nGroup Relative Policy Optimization (GRPO). We design different verifiable\nreward functions for different perception tasks, such as the Intersection over\nUnion (IoU) reward for object detection. Experimental results on fine-grained\nimage classification, few-shot object detection, reasoning grounding, as well\nas open-vocabulary object detection benchmarks show the competitive performance\nand advanced generalization ability of Visual-RFT compared with Supervised\nFine-tuning (SFT). For example, Visual-RFT improves accuracy by 24.3% over\nthe baseline in one-shot fine-grained image classification with around 100\nsamples. In few-shot object detection, Visual-RFT also exceeds the baseline by\n21.9 on COCO's two-shot setting and 15.4 on LVIS. Our Visual-RFT represents\na paradigm shift in fine-tuning LVLMs, offering a data-efficient, reward-driven\napproach that enhances reasoning and adaptability for domain-specific tasks.",
            "upvotes": 43,
            "discussionId": "67c6816c14a1bf9855188d8c",
            "projectPage": "https://github.com/Liuziyu77/Visual-RFT",
            "githubRepo": "https://github.com/Liuziyu77/Visual-RFT"
        },
        "publishedAt": "2025-03-03T23:29:27.952Z",
        "title": "Visual-RFT: Visual Reinforcement Fine-Tuning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01785.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "63fda3fced9eead590ff6918",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1677566802735-noauth.jpeg",
            "fullname": "Zeyi Sun",
            "name": "Zery",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 16
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01743",
            "authors": [
                {
                    "_id": "67c67d0dfe135a5f482599bb",
                    "name": "Abdelrahman Abouelenin",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599bc",
                    "user": {
                        "_id": "669ed17498ba26df962584f5",
                        "avatarUrl": "/avatars/996c9cf05a4f8e5447552220085157c7.svg",
                        "isPro": false,
                        "fullname": "Atabak Ashfaq",
                        "user": "atabakashfaqMSFT",
                        "type": "user"
                    },
                    "name": "Atabak Ashfaq",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:45:15.511Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599bd",
                    "name": "Adam Atkinson",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599be",
                    "name": "Hany Awadalla",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599bf",
                    "name": "Nguyen Bach",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c0",
                    "user": {
                        "_id": "6481e690f9ed842838a2b106",
                        "avatarUrl": "/avatars/e89a3c8366df504a95dc08a1a412bf3d.svg",
                        "isPro": false,
                        "fullname": "Jianmin Bao",
                        "user": "jianmin-ustc",
                        "type": "user"
                    },
                    "name": "Jianmin Bao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:46:34.578Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c1",
                    "user": {
                        "_id": "65b9b627e7c838136275a681",
                        "avatarUrl": "/avatars/22423f3d9a6c4ee34cad3b0894d27d23.svg",
                        "isPro": false,
                        "fullname": "Alon Benhaim",
                        "user": "alonbenhaim",
                        "type": "user"
                    },
                    "name": "Alon Benhaim",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:46:41.117Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c2",
                    "user": {
                        "_id": "66f81b5b3c7ffa7931b4829a",
                        "avatarUrl": "/avatars/a7f34e8e3fd92fdb96affc367b522fbe.svg",
                        "isPro": false,
                        "fullname": "cai",
                        "user": "martincai",
                        "type": "user"
                    },
                    "name": "Martin Cai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:46:47.556Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c3",
                    "user": {
                        "_id": "659c7ac977ac6f1bf5e63d7e",
                        "avatarUrl": "/avatars/86a6efde0d483564a67ed5f344d479a0.svg",
                        "isPro": false,
                        "fullname": "Vishrav Chaudhary",
                        "user": "vishravmsft",
                        "type": "user"
                    },
                    "name": "Vishrav Chaudhary",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:46:56.428Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c4",
                    "user": {
                        "_id": "66c7a93b92e9f5b19f7533ab",
                        "avatarUrl": "/avatars/e26ebf5cf083a3ec09fce24026ecc76e.svg",
                        "isPro": false,
                        "fullname": "Chen",
                        "user": "congcongchen",
                        "type": "user"
                    },
                    "name": "Congcong Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:47:04.205Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c5",
                    "user": {
                        "_id": "666470a28f5513b0cf11e850",
                        "avatarUrl": "/avatars/7beea758882677ad32a12ce56d4d084a.svg",
                        "isPro": false,
                        "fullname": "Dong Chen",
                        "user": "DongChen06",
                        "type": "user"
                    },
                    "name": "Dong Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:47:11.865Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c6",
                    "user": {
                        "_id": "6567651c6fcc82e5e8c36d4d",
                        "avatarUrl": "/avatars/ba3cc037a7688c4f8d967fc6043e540d.svg",
                        "isPro": false,
                        "fullname": "Dongdong Chen",
                        "user": "dongdongchen",
                        "type": "user"
                    },
                    "name": "Dongdong Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:47:18.197Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c7",
                    "user": {
                        "_id": "669db44d61278f96d8c608a4",
                        "avatarUrl": "/avatars/92a493da10c086af5f2af680f4e2c6c6.svg",
                        "isPro": false,
                        "fullname": "Junkun Chen",
                        "user": "shtpgshus",
                        "type": "user"
                    },
                    "name": "Junkun Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:47:43.236Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c8",
                    "user": {
                        "_id": "64da876370446182be5b608d",
                        "avatarUrl": "/avatars/e412fdc71404ecdf638e416846e3ebfb.svg",
                        "isPro": false,
                        "fullname": "Weizhu Chen",
                        "user": "chenweizhu",
                        "type": "user"
                    },
                    "name": "Weizhu Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:47:51.832Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599c9",
                    "user": {
                        "_id": "662d6b09a47b4da4b23c8b2a",
                        "avatarUrl": "/avatars/6770b1d7e25b2cdce04f9904b543d122.svg",
                        "isPro": false,
                        "fullname": "Yen-Chun Chen",
                        "user": "Yen-ChunChen",
                        "type": "user"
                    },
                    "name": "Yen-Chun Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:47:58.051Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599ca",
                    "name": "Yi-ling Chen",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599cb",
                    "name": "Qi Dai",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599cc",
                    "name": "Xiyang Dai",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599cd",
                    "user": {
                        "_id": "64a8b800b35f48e37dfd20fe",
                        "avatarUrl": "/avatars/1e66be9a5238ce86df8b54150520bcc8.svg",
                        "isPro": false,
                        "fullname": "Ruchao Fan",
                        "user": "fanruchao",
                        "type": "user"
                    },
                    "name": "Ruchao Fan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:40:17.936Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599ce",
                    "name": "Mei Gao",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599cf",
                    "name": "Min Gao",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d0",
                    "name": "Amit Garg",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d1",
                    "user": {
                        "_id": "62cdae333529c21a2283a0a1",
                        "avatarUrl": "/avatars/cafc2821e522bbd06d49830e36a073e3.svg",
                        "isPro": false,
                        "fullname": "Abhishek GOSWAMI",
                        "user": "abgoswam",
                        "type": "user"
                    },
                    "name": "Abhishek Goswami",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:49:02.466Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d2",
                    "user": {
                        "_id": "5f04c4394ec31d33a72116d6",
                        "avatarUrl": "/avatars/75d4b9020070e73604b12e5adc1c8201.svg",
                        "isPro": false,
                        "fullname": "Junheng Hao",
                        "user": "jeffhao",
                        "type": "user"
                    },
                    "name": "Junheng Hao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:53:16.356Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d3",
                    "user": {
                        "_id": "660480db07619487a3718a16",
                        "avatarUrl": "/avatars/9c08d541913e57fd79988ef93d5095d4.svg",
                        "isPro": false,
                        "fullname": "Amr Hendy",
                        "user": "amrhendy",
                        "type": "user"
                    },
                    "name": "Amr Hendy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:53:24.716Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d4",
                    "name": "Yuxuan Hu",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d5",
                    "name": "Xin Jin",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d6",
                    "user": {
                        "_id": "6440905e27dc46cca590994c",
                        "avatarUrl": "/avatars/0346f8ad17038fba87649a0fc59d64ab.svg",
                        "isPro": false,
                        "fullname": "Mahmoud Khademi",
                        "user": "mkhademi",
                        "type": "user"
                    },
                    "name": "Mahmoud Khademi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:53:53.225Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d7",
                    "user": {
                        "_id": "662476aec8920ec351b8d3d8",
                        "avatarUrl": "/avatars/791e40f53073563680ef18f75b3ea95e.svg",
                        "isPro": false,
                        "fullname": "Dongwoo Kim",
                        "user": "dongwookim-ms",
                        "type": "user"
                    },
                    "name": "Dongwoo Kim",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:54:04.257Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d8",
                    "user": {
                        "_id": "63f5173bb51da4d61da6c038",
                        "avatarUrl": "/avatars/0ee530cf80476aa3985c4d591cd384a1.svg",
                        "isPro": false,
                        "fullname": "Young Jin Kim",
                        "user": "ykim362",
                        "type": "user"
                    },
                    "name": "Young Jin Kim",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:40:19.902Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599d9",
                    "name": "Gina Lee",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599da",
                    "user": {
                        "_id": "64004b72330a45b03604303b",
                        "avatarUrl": "/avatars/a1fa3fc700173238d0336258b000d934.svg",
                        "isPro": false,
                        "fullname": "Jinyu Li",
                        "user": "FallTraveler",
                        "type": "user"
                    },
                    "name": "Jinyu Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:54:17.115Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599db",
                    "name": "Yunsheng Li",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599dc",
                    "name": "Chen Liang",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599dd",
                    "user": {
                        "_id": "6464f05e5cdb9ab50f846c98",
                        "avatarUrl": "/avatars/3cb2f60a909b59289209ecc7ba75a338.svg",
                        "isPro": false,
                        "fullname": "Xihui Lin",
                        "user": "linxihui",
                        "type": "user"
                    },
                    "name": "Xihui Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:56:29.024Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599de",
                    "user": {
                        "_id": "62c3a0caf5e2eb44f51de87d",
                        "avatarUrl": "/avatars/3c535c5488476b75443666176fcb4c9b.svg",
                        "isPro": false,
                        "fullname": "Zeqi Lin",
                        "user": "linzeqi",
                        "type": "user"
                    },
                    "name": "Zeqi Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:56:38.534Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599df",
                    "name": "Mengchen Liu",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e0",
                    "name": "Yang Liu",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e1",
                    "user": {
                        "_id": "60c790f1accf7da31ed8240d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60c790f1accf7da31ed8240d/YDohCmgf9OUeWqZIs3Thh.jpeg",
                        "isPro": false,
                        "fullname": "Gilsinia Lopez",
                        "user": "lgg",
                        "type": "user"
                    },
                    "name": "Gilsinia Lopez",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:59:55.169Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e2",
                    "name": "Chong Luo",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e3",
                    "user": {
                        "_id": "66269a329014ef4d10f55d9d",
                        "avatarUrl": "/avatars/d4866c32419a7dd07e9aa0660f4bafa9.svg",
                        "isPro": false,
                        "fullname": "Piyush Madan",
                        "user": "PiyushMadan",
                        "type": "user"
                    },
                    "name": "Piyush Madan",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:02:38.019Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e4",
                    "user": {
                        "_id": "65301591944086d1d5fcf656",
                        "avatarUrl": "/avatars/250a2e898a4fcbe78feaf6e812851bd6.svg",
                        "isPro": false,
                        "fullname": "Vadim Mazalovskii",
                        "user": "JakeRiley",
                        "type": "user"
                    },
                    "name": "Vadim Mazalov",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:02:47.430Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e5",
                    "name": "Ali Mousavi",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e6",
                    "user": {
                        "_id": "649bc84833486cdd77c01c66",
                        "avatarUrl": "/avatars/36f4e4bb15c337c4391bfbd234051f4c.svg",
                        "isPro": false,
                        "fullname": "Nguyen Anh",
                        "user": "Anhnguyen",
                        "type": "user"
                    },
                    "name": "Anh Nguyen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:57:52.311Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e7",
                    "name": "Jing Pan",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e8",
                    "user": {
                        "_id": "673b7f70cdc852f69bebfed1",
                        "avatarUrl": "/avatars/1efad61a42b948c750c96472a6192de5.svg",
                        "isPro": false,
                        "fullname": "Daniel Perez-Becker",
                        "user": "perezbecker",
                        "type": "user"
                    },
                    "name": "Daniel Perez-Becker",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:59:09.929Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599e9",
                    "name": "Jacob Platin",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599ea",
                    "user": {
                        "_id": "65c52dad286bf45e79491697",
                        "avatarUrl": "/avatars/01ebc7979273df6e53971ae9835b503f.svg",
                        "isPro": false,
                        "fullname": "Thomas Portet",
                        "user": "thopo",
                        "type": "user"
                    },
                    "name": "Thomas Portet",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:59:39.865Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599eb",
                    "name": "Kai Qiu",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599ec",
                    "user": {
                        "_id": "668dcf92835bf7e64bbca904",
                        "avatarUrl": "/avatars/416eb3a3c5318a6a45aad87012296470.svg",
                        "isPro": false,
                        "fullname": "Bo Ren",
                        "user": "rosrad",
                        "type": "user"
                    },
                    "name": "Bo Ren",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:40:15.919Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599ed",
                    "user": {
                        "_id": "63815eff4761ddfa00903762",
                        "avatarUrl": "/avatars/3419b239d42e091586f1c51b526d88e5.svg",
                        "isPro": false,
                        "fullname": "Liliang Ren",
                        "user": "renll",
                        "type": "user"
                    },
                    "name": "Liliang Ren",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:57:37.996Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599ee",
                    "name": "Sambuddha Roy",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599ef",
                    "name": "Ning Shang",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f0",
                    "user": {
                        "_id": "6454c337a13edf669cd5d8ea",
                        "avatarUrl": "/avatars/a383a0dda7c2ef6a0d6c3c64651f42ff.svg",
                        "isPro": false,
                        "fullname": "Yelong Shen",
                        "user": "uuu6",
                        "type": "user"
                    },
                    "name": "Yelong Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:00:05.457Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f1",
                    "user": {
                        "_id": "62743aec8cb70eed79073bc0",
                        "avatarUrl": "/avatars/3c8b9a91d898f616265f823ab7d432df.svg",
                        "isPro": false,
                        "fullname": "Saksham Singhal",
                        "user": "sakshamsinghal",
                        "type": "user"
                    },
                    "name": "Saksham Singhal",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:59:03.188Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f2",
                    "user": {
                        "_id": "678bc6b432ee4968eca9bb6a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/wT-Xa3TYem_EzkZZMyDG0.png",
                        "isPro": false,
                        "fullname": "Subhojit Som",
                        "user": "susom",
                        "type": "user"
                    },
                    "name": "Subhojit Som",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:59:47.241Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f3",
                    "name": "Xia Song",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f4",
                    "user": {
                        "_id": "64692ad25d701566394fd8da",
                        "avatarUrl": "/avatars/d6811ccceb14788bfa0aa10fe4ee1054.svg",
                        "isPro": false,
                        "fullname": "Tetyana Sych",
                        "user": "tesych",
                        "type": "user"
                    },
                    "name": "Tetyana Sych",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:58:27.814Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f5",
                    "name": "Praneetha Vaddamanu",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f6",
                    "name": "Shuohang Wang",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f7",
                    "user": {
                        "_id": "6786f93b3ad5585f2c2828b1",
                        "avatarUrl": "/avatars/41411af6f7d547041032a29b34041fe8.svg",
                        "isPro": false,
                        "fullname": "Yiming Wang",
                        "user": "freewym",
                        "type": "user"
                    },
                    "name": "Yiming Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T21:16:18.278Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f8",
                    "name": "Zhenghao Wang",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599f9",
                    "name": "Haibin Wu",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599fa",
                    "user": {
                        "_id": "61384b860317b0a5c10877d3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1631080954171-61384b860317b0a5c10877d3.jpeg",
                        "isPro": false,
                        "fullname": "Haoran Xu",
                        "user": "haoranxu",
                        "type": "user"
                    },
                    "name": "Haoran Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:56:04.939Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599fb",
                    "user": {
                        "_id": "6398f4b32c20654083f36cde",
                        "avatarUrl": "/avatars/4591f514483890997c55e9e6d60bbb0f.svg",
                        "isPro": false,
                        "fullname": "Weijian Xu",
                        "user": "xwjabc",
                        "type": "user"
                    },
                    "name": "Weijian Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:58:36.082Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599fc",
                    "name": "Yifan Yang",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599fd",
                    "name": "Ziyi Yang",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599fe",
                    "user": {
                        "_id": "65b01b8a29ae836e9ed5af24",
                        "avatarUrl": "/avatars/a8b78a4b54d3f10858c5925521357001.svg",
                        "isPro": false,
                        "fullname": "Donghan Yu",
                        "user": "donghanyu",
                        "type": "user"
                    },
                    "name": "Donghan Yu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:55:41.798Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f482599ff",
                    "name": "Ishmam Zabir",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f48259a00",
                    "user": {
                        "_id": "63601ee38fb9c2420ffbe45d",
                        "avatarUrl": "/avatars/56af091aaff1b42dcfbae84a6ee1e7f7.svg",
                        "isPro": false,
                        "fullname": "Zhang",
                        "user": "Jianwen",
                        "type": "user"
                    },
                    "name": "Jianwen Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:55:12.465Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f48259a01",
                    "user": {
                        "_id": "62b0009c72043b05d29492b2",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b0009c72043b05d29492b2/NqRkX2YLhlfOLvYysa7dD.png",
                        "isPro": false,
                        "fullname": "Li Lyna Zhang",
                        "user": "lynazhang",
                        "type": "user"
                    },
                    "name": "Li Lyna Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:55:01.540Z",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f48259a02",
                    "name": "Yunan Zhang",
                    "hidden": false
                },
                {
                    "_id": "67c67d0dfe135a5f48259a03",
                    "user": {
                        "_id": "66ce4c9f864befb39cfc74e9",
                        "avatarUrl": "/avatars/ef66398466c470fc1d384c6817d9e461.svg",
                        "isPro": false,
                        "fullname": "Xiren Zhou",
                        "user": "XirenZhou",
                        "type": "user"
                    },
                    "name": "Xiren Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:54:26.629Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T17:05:52.000Z",
            "title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language\n  Models via Mixture-of-LoRAs",
            "summary": "We introduce Phi-4-Mini and Phi-4-Multimodal, compact yet highly capable\nlanguage and multimodal models. Phi-4-Mini is a 3.8-billion-parameter language\nmodel trained on high-quality web and synthetic data, significantly\noutperforming recent open-source models of similar size and matching the\nperformance of models twice its size on math and coding tasks requiring complex\nreasoning. This achievement is driven by a carefully curated synthetic data\nrecipe emphasizing high-quality math and coding datasets. Compared to its\npredecessor, Phi-3.5-Mini, Phi-4-Mini features an expanded vocabulary size of\n200K tokens to better support multilingual applications, as well as group query\nattention for more efficient long-sequence generation. Phi-4-Multimodal is a\nmultimodal model that integrates text, vision, and speech/audio input\nmodalities into a single model. Its novel modality extension approach leverages\nLoRA adapters and modality-specific routers to allow multiple inference modes\ncombining various modalities without interference. For example, it now ranks\nfirst in the OpenASR leaderboard to date, although the LoRA component of the\nspeech/audio modality has just 460 million parameters. Phi-4-Multimodal\nsupports scenarios involving (vision + language), (vision + speech), and\n(speech/audio) inputs, outperforming larger vision-language and speech-language\nmodels on a wide range of tasks. Additionally, we experiment to further train\nPhi-4-Mini to enhance its reasoning capabilities. Despite its compact\n3.8-billion-parameter size, this experimental version achieves reasoning\nperformance on par with or surpassing significantly larger models, including\nDeepSeek-R1-Distill-Qwen-7B and DeepSeek-R1-Distill-Llama-8B.",
            "upvotes": 42,
            "discussionId": "67c67d0efe135a5f48259a38",
            "projectPage": "https://huggingface.co/microsoft/Phi-4-multimodal-instruct"
        },
        "publishedAt": "2025-03-03T23:15:05.187Z",
        "title": "Phi-4-Mini Technical Report: Compact yet Powerful Multimodal Language Models via Mixture-of-LoRAs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01743.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "63f5173bb51da4d61da6c038",
            "avatarUrl": "/avatars/0ee530cf80476aa3985c4d591cd384a1.svg",
            "fullname": "Young Jin Kim",
            "name": "ykim362",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 6
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01774",
            "authors": [
                {
                    "_id": "67c694febdab31ec59fea175",
                    "user": {
                        "_id": "633aaf695df91da9cea92960",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633aaf695df91da9cea92960/9T4y1ru5wt5iKUUqf9_Tt.png",
                        "isPro": false,
                        "fullname": "Jay Wu",
                        "user": "jayw",
                        "type": "user"
                    },
                    "name": "Jay Zhangjie Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:34:53.874Z",
                    "hidden": false
                },
                {
                    "_id": "67c694febdab31ec59fea176",
                    "name": "Yuxuan Zhang",
                    "hidden": false
                },
                {
                    "_id": "67c694febdab31ec59fea177",
                    "user": {
                        "_id": "656e000253703dd78fd072a9",
                        "avatarUrl": "/avatars/6702ba8fabe3d08884aa757f90cea333.svg",
                        "isPro": false,
                        "fullname": "Haithem Turki",
                        "user": "hturki",
                        "type": "user"
                    },
                    "name": "Haithem Turki",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:13:26.878Z",
                    "hidden": false
                },
                {
                    "_id": "67c694febdab31ec59fea178",
                    "user": {
                        "_id": "658529d61c461dfe88afe8e8",
                        "avatarUrl": "/avatars/a22c1b07d28c2662833c462c6537d835.svg",
                        "isPro": false,
                        "fullname": "Xuanchi Ren",
                        "user": "xrenaa",
                        "type": "user"
                    },
                    "name": "Xuanchi Ren",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:13:33.467Z",
                    "hidden": false
                },
                {
                    "_id": "67c694febdab31ec59fea179",
                    "name": "Jun Gao",
                    "hidden": false
                },
                {
                    "_id": "67c694febdab31ec59fea17a",
                    "user": {
                        "_id": "661ab3da2b14565c7acccf5c",
                        "avatarUrl": "/avatars/fa4fc03664803e02aede4d4c3d50b393.svg",
                        "isPro": false,
                        "fullname": "Mike Zheng Shou",
                        "user": "AnalMom",
                        "type": "user"
                    },
                    "name": "Mike Zheng Shou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:27:21.825Z",
                    "hidden": false
                },
                {
                    "_id": "67c694febdab31ec59fea17b",
                    "name": "Sanja Fidler",
                    "hidden": false
                },
                {
                    "_id": "67c694febdab31ec59fea17c",
                    "user": {
                        "_id": "6366cda3361a96184dc22139",
                        "avatarUrl": "/avatars/d8a88c84cb5f69e69dd038674a29be89.svg",
                        "isPro": false,
                        "fullname": "Zan Gojcic",
                        "user": "zgojcic",
                        "type": "user"
                    },
                    "name": "Zan Gojcic",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T09:27:34.034Z",
                    "hidden": false
                },
                {
                    "_id": "67c694febdab31ec59fea17d",
                    "name": "Huan Ling",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T17:58:33.000Z",
            "title": "Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models",
            "summary": "Neural Radiance Fields and 3D Gaussian Splatting have revolutionized 3D\nreconstruction and novel-view synthesis task. However, achieving photorealistic\nrendering from extreme novel viewpoints remains challenging, as artifacts\npersist across representations. In this work, we introduce Difix3D+, a novel\npipeline designed to enhance 3D reconstruction and novel-view synthesis through\nsingle-step diffusion models. At the core of our approach is Difix, a\nsingle-step image diffusion model trained to enhance and remove artifacts in\nrendered novel views caused by underconstrained regions of the 3D\nrepresentation. Difix serves two critical roles in our pipeline. First, it is\nused during the reconstruction phase to clean up pseudo-training views that are\nrendered from the reconstruction and then distilled back into 3D. This greatly\nenhances underconstrained regions and improves the overall 3D representation\nquality. More importantly, Difix also acts as a neural enhancer during\ninference, effectively removing residual artifacts arising from imperfect 3D\nsupervision and the limited capacity of current reconstruction models. Difix3D+\nis a general solution, a single model compatible with both NeRF and 3DGS\nrepresentations, and it achieves an average 2times improvement in FID score\nover baselines while maintaining 3D consistency.",
            "upvotes": 29,
            "discussionId": "67c69500bdab31ec59fea24d",
            "projectPage": "https://research.nvidia.com/labs/toronto-ai/difix3d"
        },
        "publishedAt": "2025-03-04T00:52:22.204Z",
        "title": "Difix3D+: Improving 3D Reconstructions with Single-Step Diffusion Models",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01774.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "633aaf695df91da9cea92960",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633aaf695df91da9cea92960/9T4y1ru5wt5iKUUqf9_Tt.png",
            "fullname": "Jay Wu",
            "name": "jayw",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 12
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01183",
            "authors": [
                {
                    "_id": "67c6a15e21d722b4248bd9c2",
                    "name": "Ziqian Ning",
                    "hidden": false
                },
                {
                    "_id": "67c6a15e21d722b4248bd9c3",
                    "name": "Huakang Chen",
                    "hidden": false
                },
                {
                    "_id": "67c6a15e21d722b4248bd9c4",
                    "name": "Yuepeng Jiang",
                    "hidden": false
                },
                {
                    "_id": "67c6a15e21d722b4248bd9c5",
                    "name": "Chunbo Hao",
                    "hidden": false
                },
                {
                    "_id": "67c6a15e21d722b4248bd9c6",
                    "name": "Guobin Ma",
                    "hidden": false
                },
                {
                    "_id": "67c6a15e21d722b4248bd9c7",
                    "name": "Shuai Wang",
                    "hidden": false
                },
                {
                    "_id": "67c6a15e21d722b4248bd9c8",
                    "name": "Jixun Yao",
                    "hidden": false
                },
                {
                    "_id": "67c6a15e21d722b4248bd9c9",
                    "name": "Lei Xie",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T05:15:34.000Z",
            "title": "DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End\n  Full-Length Song Generation with Latent Diffusion",
            "summary": "Recent advancements in music generation have garnered significant attention,\nyet existing approaches face critical limitations. Some current generative\nmodels can only synthesize either the vocal track or the accompaniment track.\nWhile some models can generate combined vocal and accompaniment, they typically\nrely on meticulously designed multi-stage cascading architectures and intricate\ndata pipelines, hindering scalability. Additionally, most systems are\nrestricted to generating short musical segments rather than full-length songs.\nFurthermore, widely used language model-based methods suffer from slow\ninference speeds. To address these challenges, we propose DiffRhythm, the first\nlatent diffusion-based song generation model capable of synthesizing complete\nsongs with both vocal and accompaniment for durations of up to 4m45s in only\nten seconds, maintaining high musicality and intelligibility. Despite its\nremarkable capabilities, DiffRhythm is designed to be simple and elegant: it\neliminates the need for complex data preparation, employs a straightforward\nmodel structure, and requires only lyrics and a style prompt during inference.\nAdditionally, its non-autoregressive structure ensures fast inference speeds.\nThis simplicity guarantees the scalability of DiffRhythm. Moreover, we release\nthe complete training code along with the pre-trained model on large-scale data\nto promote reproducibility and further research.",
            "upvotes": 18,
            "discussionId": "67c6a16021d722b4248bda37",
            "projectPage": "https://aslp-lab.github.io/DiffRhythm.github.io/",
            "githubRepo": "https://github.com/ASLP-lab/DiffRhythm"
        },
        "publishedAt": "2025-03-04T04:54:04.054Z",
        "title": "DiffRhythm: Blazingly Fast and Embarrassingly Simple End-to-End Full-Length Song Generation with Latent Diffusion",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01183.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "624bebf604abc7ebb01789af",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649143001781-624bebf604abc7ebb01789af.jpeg",
            "fullname": "Apolinário from multimodal AI art",
            "name": "multimodalart",
            "type": "user",
            "isPro": true,
            "isHf": true,
            "isMod": false,
            "followerCount": 3863
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2502.18965",
            "authors": [
                {
                    "_id": "67c6bfdf96b9f5fa18c517db",
                    "user": {
                        "_id": "625f6ebee1994410eef16a42",
                        "avatarUrl": "/avatars/eaa353afe91e849adcd35656477a6462.svg",
                        "isPro": false,
                        "fullname": "Jiaxin Deng",
                        "user": "OrpheusBetter",
                        "type": "user"
                    },
                    "name": "Jiaxin Deng",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:16:32.410Z",
                    "hidden": false
                },
                {
                    "_id": "67c6bfdf96b9f5fa18c517dc",
                    "user": {
                        "_id": "641f8e596d51620635e49707",
                        "avatarUrl": "/avatars/f30b24da53fea2278f343c318007bb60.svg",
                        "isPro": false,
                        "fullname": "shiyao wang",
                        "user": "oneself",
                        "type": "user"
                    },
                    "name": "Shiyao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:16:39.957Z",
                    "hidden": false
                },
                {
                    "_id": "67c6bfdf96b9f5fa18c517dd",
                    "user": {
                        "_id": "65e6cc77e999cde61fcbc097",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/5NxDLRmS2cQgNeZ6ScSNW.png",
                        "isPro": false,
                        "fullname": "CaiKuo",
                        "user": "caikuo",
                        "type": "user"
                    },
                    "name": "Kuo Cai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T12:01:27.669Z",
                    "hidden": false
                },
                {
                    "_id": "67c6bfdf96b9f5fa18c517de",
                    "name": "Lejian Ren",
                    "hidden": false
                },
                {
                    "_id": "67c6bfdf96b9f5fa18c517df",
                    "name": "Qigen Hu",
                    "hidden": false
                },
                {
                    "_id": "67c6bfdf96b9f5fa18c517e0",
                    "user": {
                        "_id": "64aeb9342cda6a37a4781b7d",
                        "avatarUrl": "/avatars/c1584c10ff0f9871315872245c9934fc.svg",
                        "isPro": false,
                        "fullname": "Weifeng Ding",
                        "user": "DingWF",
                        "type": "user"
                    },
                    "name": "Weifeng Ding",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:17:03.422Z",
                    "hidden": false
                },
                {
                    "_id": "67c6bfdf96b9f5fa18c517e1",
                    "name": "Qiang Luo",
                    "hidden": false
                },
                {
                    "_id": "67c6bfdf96b9f5fa18c517e2",
                    "user": {
                        "_id": "67c6c570cf87e2d2ebfc81aa",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67c6c570cf87e2d2ebfc81aa/7qAstZtIT86Uwrz3u_anv.jpeg",
                        "isPro": false,
                        "fullname": "Guorui Zhou",
                        "user": "GuoruiZhou",
                        "type": "user"
                    },
                    "name": "Guorui Zhou",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:16:52.106Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T09:25:10.000Z",
            "title": "OneRec: Unifying Retrieve and Rank with Generative Recommender and\n  Iterative Preference Alignment",
            "summary": "Recently, generative retrieval-based recommendation systems have emerged as a\npromising paradigm. However, most modern recommender systems adopt a\nretrieve-and-rank strategy, where the generative model functions only as a\nselector during the retrieval stage. In this paper, we propose OneRec, which\nreplaces the cascaded learning framework with a unified generative model. To\nthe best of our knowledge, this is the first end-to-end generative model that\nsignificantly surpasses current complex and well-designed recommender systems\nin real-world scenarios. Specifically, OneRec includes: 1) an encoder-decoder\nstructure, which encodes the user's historical behavior sequences and gradually\ndecodes the videos that the user may be interested in. We adopt sparse\nMixture-of-Experts (MoE) to scale model capacity without proportionally\nincreasing computational FLOPs. 2) a session-wise generation approach. In\ncontrast to traditional next-item prediction, we propose a session-wise\ngeneration, which is more elegant and contextually coherent than point-by-point\ngeneration that relies on hand-crafted rules to properly combine the generated\nresults. 3) an Iterative Preference Alignment module combined with Direct\nPreference Optimization (DPO) to enhance the quality of the generated results.\nUnlike DPO in NLP, a recommendation system typically has only one opportunity\nto display results for each user's browsing request, making it impossible to\nobtain positive and negative samples simultaneously. To address this\nlimitation, We design a reward model to simulate user generation and customize\nthe sampling strategy. Extensive experiments have demonstrated that a limited\nnumber of DPO samples can align user interest preferences and significantly\nimprove the quality of generated results. We deployed OneRec in the main scene\nof Kuaishou, achieving a 1.6\\% increase in watch-time, which is a substantial\nimprovement.",
            "upvotes": 18,
            "discussionId": "67c6bfe396b9f5fa18c518e5"
        },
        "publishedAt": "2025-03-04T03:56:04.503Z",
        "title": "OneRec: Unifying Retrieve and Rank with Generative Recommender and Iterative Preference Alignment",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18965.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "668f5875b5b3081d776e4094",
            "avatarUrl": "/avatars/8c763393f25afbe5fb8b132f775e746a.svg",
            "fullname": "Xiaohuan Zhou",
            "name": "XiaohuanZhou",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2503.01688",
            "authors": [
                {
                    "_id": "67c6e6735aea9d8918635ac2",
                    "user": {
                        "_id": "6728224623d75cbd1cdbe568",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/4sb6TjuzeDc8-PG9hYhjW.jpeg",
                        "isPro": false,
                        "fullname": "Petr Sychev",
                        "user": "sspetya",
                        "type": "user"
                    },
                    "name": "Petr Sychev",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T12:01:33.230Z",
                    "hidden": false
                },
                {
                    "_id": "67c6e6735aea9d8918635ac3",
                    "user": {
                        "_id": "675708985b91dea24c3ef642",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/675708985b91dea24c3ef642/8KmerI1LwJEBHM2vrC54d.jpeg",
                        "isPro": false,
                        "fullname": "Andrey Goncharov",
                        "user": "aigoncharov",
                        "type": "user"
                    },
                    "name": "Andrey Goncharov",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-03-04T11:39:33.550Z",
                    "hidden": false
                },
                {
                    "_id": "67c6e6735aea9d8918635ac4",
                    "user": {
                        "_id": "659e049c01805191e5f67b12",
                        "avatarUrl": "/avatars/4f33e39d85f8fbdfaeb34143e5038b92.svg",
                        "isPro": false,
                        "fullname": "Vyazhev",
                        "user": "DanielVyazhev",
                        "type": "user"
                    },
                    "name": "Daniil Vyazhev",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T12:01:34.869Z",
                    "hidden": false
                },
                {
                    "_id": "67c6e6735aea9d8918635ac5",
                    "name": "Edvard Khalafyan",
                    "hidden": false
                },
                {
                    "_id": "67c6e6735aea9d8918635ac6",
                    "name": "Alexey Zaytsev",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T16:03:46.000Z",
            "title": "When an LLM is apprehensive about its answers -- and when its\n  uncertainty is justified",
            "summary": "Uncertainty estimation is crucial for evaluating Large Language Models\n(LLMs), particularly in high-stakes domains where incorrect answers result in\nsignificant consequences. Numerous approaches consider this problem, while\nfocusing on a specific type of uncertainty, ignoring others. We investigate\nwhat estimates, specifically token-wise entropy and model-as-judge (MASJ),\nwould work for multiple-choice question-answering tasks for different question\ntopics. Our experiments consider three LLMs: Phi-4, Mistral, and Qwen of\ndifferent sizes from 1.5B to 72B and 14 topics. While MASJ performs similarly\nto a random error predictor, the response entropy predicts model error in\nknowledge-dependent domains and serves as an effective indicator of question\ndifficulty: for biology ROC AUC is 0.73. This correlation vanishes for the\nreasoning-dependent domain: for math questions ROC-AUC is 0.55. More\nprincipally, we found out that the entropy measure required a reasoning amount.\nThus, data-uncertainty related entropy should be integrated within uncertainty\nestimates frameworks, while MASJ requires refinement. Moreover, existing\nMMLU-Pro samples are biased, and should balance required amount of reasoning\nfor different subdomains to provide a more fair assessment of LLMs performance.",
            "upvotes": 16,
            "discussionId": "67c6e6755aea9d8918635b20",
            "githubRepo": "https://github.com/LabARSS/question-complextiy-estimation"
        },
        "publishedAt": "2025-03-04T06:41:49.997Z",
        "title": "When an LLM is apprehensive about its answers -- and when its uncertainty is justified",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/675708985b91dea24c3ef642/9wCzAalApYA8hPN94CaEu.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01688.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "675708985b91dea24c3ef642",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/675708985b91dea24c3ef642/8KmerI1LwJEBHM2vrC54d.jpeg",
            "fullname": "Andrey Goncharov",
            "name": "aigoncharov",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.18890",
            "authors": [
                {
                    "_id": "67c6cbd6e52534aa6ada2e26",
                    "user": {
                        "_id": "668f7fee5156d55f72af4f21",
                        "avatarUrl": "/avatars/02edf8d7d5f288d80dc665b18dda4d0a.svg",
                        "isPro": false,
                        "fullname": "TongWu",
                        "user": "TongWu",
                        "type": "user"
                    },
                    "name": "Tong Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:58:45.670Z",
                    "hidden": false
                },
                {
                    "_id": "67c6cbd6e52534aa6ada2e27",
                    "user": {
                        "_id": "6530c9d7d107f378e105d667",
                        "avatarUrl": "/avatars/889dfcb6514c90351802bebb4a34a78f.svg",
                        "isPro": false,
                        "fullname": "Junzhe Shen",
                        "user": "JunzheS",
                        "type": "user"
                    },
                    "name": "Junzhe Shen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:58:27.834Z",
                    "hidden": false
                },
                {
                    "_id": "67c6cbd6e52534aa6ada2e28",
                    "user": {
                        "_id": "64b7ae6cf53ae848e72b997d",
                        "avatarUrl": "/avatars/b55dd3d6fcb3ccac2e3880d01a9bdc63.svg",
                        "isPro": false,
                        "fullname": "Zixia Jia",
                        "user": "vickyandkekey",
                        "type": "user"
                    },
                    "name": "Zixia Jia",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:58:34.128Z",
                    "hidden": false
                },
                {
                    "_id": "67c6cbd6e52534aa6ada2e29",
                    "name": "Yuxuan Wang",
                    "hidden": false
                },
                {
                    "_id": "67c6cbd6e52534aa6ada2e2a",
                    "user": {
                        "_id": "63a95a6a7930fa8c7dd63d4e",
                        "avatarUrl": "/avatars/d9d0420f7ddfe2f3a7e029fb05f1c89f.svg",
                        "isPro": false,
                        "fullname": "Zilong Zheng",
                        "user": "zlzheng",
                        "type": "user"
                    },
                    "name": "Zilong Zheng",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-03-04T09:45:59.571Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T07:10:08.000Z",
            "title": "From Hours to Minutes: Lossless Acceleration of Ultra Long Sequence\n  Generation up to 100K Tokens",
            "summary": "Generating ultra-long sequences with large language models (LLMs) has become\nincreasingly crucial but remains a highly time-intensive task, particularly for\nsequences up to 100K tokens. While traditional speculative decoding methods\nexist, simply extending their generation limits fails to accelerate the process\nand can be detrimental. Through an in-depth analysis, we identify three major\nchallenges hindering efficient generation: frequent model reloading, dynamic\nkey-value (KV) management and repetitive generation. To address these issues,\nwe introduce TOKENSWIFT, a novel framework designed to substantially accelerate\nthe generation process of ultra-long sequences while maintaining the target\nmodel's inherent quality. Experimental results demonstrate that TOKENSWIFT\nachieves over 3 times speedup across models of varying scales (1.5B, 7B, 8B,\n14B) and architectures (MHA, GQA). This acceleration translates to hours of\ntime savings for ultra-long sequence generation, establishing TOKENSWIFT as a\nscalable and effective solution at unprecedented lengths. Code can be found at\nhttps://github.com/bigai-nlco/TokenSwift.",
            "upvotes": 14,
            "discussionId": "67c6cbd7e52534aa6ada2e79",
            "githubRepo": "https://github.com/bigai-nlco/TokenSwift"
        },
        "publishedAt": "2025-03-04T04:56:33.061Z",
        "title": "From Hours to Minutes: Lossless Acceleration of Ultra Long Sequence Generation up to 100K Tokens",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63a95a6a7930fa8c7dd63d4e/3WZ10b-Ku3GcY1fc1MWx8.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.18890.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63a95a6a7930fa8c7dd63d4e",
            "avatarUrl": "/avatars/d9d0420f7ddfe2f3a7e029fb05f1c89f.svg",
            "fullname": "Zilong Zheng",
            "name": "zlzheng",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01307",
            "authors": [
                {
                    "_id": "67c68adc0457c9f809c22df8",
                    "user": {
                        "_id": "63e6a880f2e9a8f22c5a1630",
                        "avatarUrl": "/avatars/53b57690fe052ce6882bbfc87b11567c.svg",
                        "isPro": false,
                        "fullname": "Kanishk Gandhi",
                        "user": "obiwan96",
                        "type": "user"
                    },
                    "name": "Kanishk Gandhi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:35:01.161Z",
                    "hidden": false
                },
                {
                    "_id": "67c68adc0457c9f809c22df9",
                    "user": {
                        "_id": "624f9e3d07bd004fb855f5e9",
                        "avatarUrl": "/avatars/86a349cd4053bc0317e27e75a51c69fa.svg",
                        "isPro": false,
                        "fullname": "Ayush Chakravarthy",
                        "user": "ayushchakravarthy",
                        "type": "user"
                    },
                    "name": "Ayush Chakravarthy",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:04:44.344Z",
                    "hidden": false
                },
                {
                    "_id": "67c68adc0457c9f809c22dfa",
                    "user": {
                        "_id": "6511ee845b7e52b0251fdee9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6511ee845b7e52b0251fdee9/hTIwiIYBGOVnIrxtpri83.png",
                        "isPro": false,
                        "fullname": "Anikait Singh",
                        "user": "Asap7772",
                        "type": "user"
                    },
                    "name": "Anikait Singh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:05:05.759Z",
                    "hidden": false
                },
                {
                    "_id": "67c68adc0457c9f809c22dfb",
                    "user": {
                        "_id": "61aa15fd8a9625ebfe284286",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/61aa15fd8a9625ebfe284286/KaGzIeijcgcN15JErCqft.jpeg",
                        "isPro": false,
                        "fullname": "nathan lile",
                        "user": "nlile",
                        "type": "user"
                    },
                    "name": "Nathan Lile",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:34:58.582Z",
                    "hidden": false
                },
                {
                    "_id": "67c68adc0457c9f809c22dfc",
                    "user": {
                        "_id": "67321274c1f20c742bcf7a8d",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/ltcQhre6eDRVzn6Vbbyhu.png",
                        "isPro": false,
                        "fullname": "Noah D. Goodman",
                        "user": "ngoodman",
                        "type": "user"
                    },
                    "name": "Noah D. Goodman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:05:12.186Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T08:46:22.000Z",
            "title": "Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four\n  Habits of Highly Effective STaRs",
            "summary": "Test-time inference has emerged as a powerful paradigm for enabling language\nmodels to ``think'' longer and more carefully about complex challenges, much\nlike skilled human experts. While reinforcement learning (RL) can drive\nself-improvement in language models on verifiable tasks, some models exhibit\nsubstantial gains while others quickly plateau. For instance, we find that\nQwen-2.5-3B far exceeds Llama-3.2-3B under identical RL training for the game\nof Countdown. This discrepancy raises a critical question: what intrinsic\nproperties enable effective self-improvement? We introduce a framework to\ninvestigate this question by analyzing four key cognitive behaviors --\nverification, backtracking, subgoal setting, and backward chaining -- that both\nexpert human problem solvers and successful language models employ. Our study\nreveals that Qwen naturally exhibits these reasoning behaviors, whereas Llama\ninitially lacks them. In systematic experimentation with controlled behavioral\ndatasets, we find that priming Llama with examples containing these reasoning\nbehaviors enables substantial improvements during RL, matching or exceeding\nQwen's performance. Importantly, the presence of reasoning behaviors, rather\nthan correctness of answers, proves to be the critical factor -- models primed\nwith incorrect solutions containing proper reasoning patterns achieve\ncomparable performance to those trained on correct solutions. Finally,\nleveraging continued pretraining with OpenWebMath data, filtered to amplify\nreasoning behaviors, enables the Llama model to match Qwen's self-improvement\ntrajectory. Our findings establish a fundamental relationship between initial\nreasoning behaviors and the capacity for improvement, explaining why some\nlanguage models effectively utilize additional computation while others\nplateau.",
            "upvotes": 14,
            "discussionId": "67c68add0457c9f809c22e31"
        },
        "publishedAt": "2025-03-04T00:09:04.418Z",
        "title": "Cognitive Behaviors that Enable Self-Improving Reasoners, or, Four Habits of Highly Effective STaRs",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01307.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63e6a880f2e9a8f22c5a1630",
            "avatarUrl": "/avatars/53b57690fe052ce6882bbfc87b11567c.svg",
            "fullname": "Kanishk Gandhi",
            "name": "obiwan96",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01496",
            "authors": [
                {
                    "_id": "67c6b05f35198d0f397adc98",
                    "user": {
                        "_id": "66ea643899af9ac3463639b1",
                        "avatarUrl": "/avatars/252d470e761a57834dee3dbc60dfefed.svg",
                        "isPro": false,
                        "fullname": "Disen Lan",
                        "user": "landisen",
                        "type": "user"
                    },
                    "name": "Disen Lan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:34:46.117Z",
                    "hidden": false
                },
                {
                    "_id": "67c6b05f35198d0f397adc99",
                    "user": {
                        "_id": "6246bb33da617c00b48e4d92",
                        "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
                        "isPro": false,
                        "fullname": "Weigao Sun",
                        "user": "weigao266",
                        "type": "user"
                    },
                    "name": "Weigao Sun",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2025-03-04T08:10:52.130Z",
                    "hidden": false
                },
                {
                    "_id": "67c6b05f35198d0f397adc9a",
                    "user": {
                        "_id": "665dc35752ff9daa9ba5a4ed",
                        "avatarUrl": "/avatars/df8b01879d97e599b610fa51414d3a18.svg",
                        "isPro": false,
                        "fullname": "Hu Jiaxi",
                        "user": "Jiaxihu2",
                        "type": "user"
                    },
                    "name": "Jiaxi Hu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:04:18.982Z",
                    "hidden": false
                },
                {
                    "_id": "67c6b05f35198d0f397adc9b",
                    "user": {
                        "_id": "65003e857804f04a163328d9",
                        "avatarUrl": "/avatars/fe32150aabfde8d283b38ccebcf6982e.svg",
                        "isPro": false,
                        "fullname": "Jusen Du",
                        "user": "JusenK",
                        "type": "user"
                    },
                    "name": "Jusen Du",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:04:26.432Z",
                    "hidden": false
                },
                {
                    "_id": "67c6b05f35198d0f397adc9c",
                    "name": "Yu Cheng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T13:08:00.000Z",
            "title": "Liger: Linearizing Large Language Models to Gated Recurrent Structures",
            "summary": "Transformers with linear recurrent modeling offer linear-time training and\nconstant-memory inference. Despite their demonstrated efficiency and\nperformance, pretraining such non-standard architectures from scratch remains\ncostly and risky. The linearization of large language models (LLMs) transforms\npretrained standard models into linear recurrent structures, enabling more\nefficient deployment. However, current linearization methods typically\nintroduce additional feature map modules that require extensive fine-tuning and\noverlook the gating mechanisms used in state-of-the-art linear recurrent\nmodels. To address these issues, this paper presents Liger, short for\nLinearizing LLMs to gated recurrent structures. Liger is a novel approach for\nconverting pretrained LLMs into gated linear recurrent models without adding\nextra parameters. It repurposes the pretrained key matrix weights to construct\ndiverse gating mechanisms, facilitating the formation of various gated\nrecurrent structures while avoiding the need to train additional components\nfrom scratch. Using lightweight fine-tuning with Low-Rank Adaptation (LoRA),\nLiger restores the performance of the linearized gated recurrent models to\nmatch that of the original LLMs. Additionally, we introduce Liger Attention, an\nintra-layer hybrid attention mechanism, which significantly recovers 93\\% of\nthe Transformer-based LLM at 0.02\\% pre-training tokens during the\nlinearization process, achieving competitive results across multiple\nbenchmarks, as validated on models ranging from 1B to 8B parameters. Code is\navailable at https://github.com/OpenSparseLLMs/Linearization.",
            "upvotes": 13,
            "discussionId": "67c6b06035198d0f397adcc4"
        },
        "publishedAt": "2025-03-04T02:48:58.261Z",
        "title": "Liger: Linearizing Large Language Models to Gated Recurrent Structures",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01496.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6246bb33da617c00b48e4d92",
            "avatarUrl": "/avatars/0304a9f6eb7f5dee4d933d03222f94e9.svg",
            "fullname": "Weigao Sun",
            "name": "weigao266",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.00501",
            "authors": [
                {
                    "_id": "67c6a343ad6b7c2fa29d5e7e",
                    "user": {
                        "_id": "67c03221aed8409476d39da8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67c03221aed8409476d39da8/eQIhOPRLNoiphsR145mfB.png",
                        "isPro": false,
                        "fullname": "Jia Chen",
                        "user": "Regulus309",
                        "type": "user"
                    },
                    "name": "Jia Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T16:08:10.744Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e7f",
                    "user": {
                        "_id": "60c0ed29d8bc072769d78f48",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60c0ed29d8bc072769d78f48/V6q6Tn4kzB46NIbTYw9pQ.jpeg",
                        "isPro": false,
                        "fullname": "Qian Dong",
                        "user": "qian",
                        "type": "user"
                    },
                    "name": "Qian Dong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:34:51.762Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e80",
                    "user": {
                        "_id": "67b5d91558369f6b38c5b596",
                        "avatarUrl": "/avatars/18b08d5d9b05786cad34bc000c7606aa.svg",
                        "isPro": false,
                        "fullname": "Haitao Li",
                        "user": "haitaoli",
                        "type": "user"
                    },
                    "name": "Haitao Li",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:20:57.898Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e81",
                    "name": "Xiaohui He",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e82",
                    "name": "Yan Gao",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e83",
                    "name": "Shaosheng Cao",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e84",
                    "name": "Yi Wu",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e85",
                    "name": "Ping Yang",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e86",
                    "name": "Chen Xu",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e87",
                    "name": "Yao Hu",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e88",
                    "user": {
                        "_id": "6657e7045f6e35c7d541bdd8",
                        "avatarUrl": "/avatars/368e5cef6c93543b2b92fbca79a4e4b9.svg",
                        "isPro": false,
                        "fullname": "Qingyao Ai",
                        "user": "aiqy",
                        "type": "user"
                    },
                    "name": "Qingyao Ai",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:21:22.100Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a343ad6b7c2fa29d5e89",
                    "name": "Yiqun Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-01T14:15:00.000Z",
            "title": "Qilin: A Multimodal Information Retrieval Dataset with APP-level User\n  Sessions",
            "summary": "User-generated content (UGC) communities, especially those featuring\nmultimodal content, improve user experiences by integrating visual and textual\ninformation into results (or items). The challenge of improving user\nexperiences in complex systems with search and recommendation (S\\&R) services\nhas drawn significant attention from both academia and industry these years.\nHowever, the lack of high-quality datasets has limited the research progress on\nmultimodal S\\&R. To address the growing need for developing better S\\&R\nservices, we present a novel multimodal information retrieval dataset in this\npaper, namely Qilin. The dataset is collected from Xiaohongshu, a popular\nsocial platform with over 300 million monthly active users and an average\nsearch penetration rate of over 70\\%. In contrast to existing datasets,\nQilin offers a comprehensive collection of user sessions with\nheterogeneous results like image-text notes, video notes, commercial notes, and\ndirect answers, facilitating the development of advanced multimodal neural\nretrieval models across diverse task settings. To better model user\nsatisfaction and support the analysis of heterogeneous user behaviors, we also\ncollect extensive APP-level contextual signals and genuine user feedback.\nNotably, Qilin contains user-favored answers and their referred results for\nsearch requests triggering the Deep Query Answering (DQA) module. This allows\nnot only the training \\& evaluation of a Retrieval-augmented Generation (RAG)\npipeline, but also the exploration of how such a module would affect users'\nsearch behavior. Through comprehensive analysis and experiments, we provide\ninteresting findings and insights for further improving S\\&R systems. We hope\nthat Qilin will significantly contribute to the advancement of\nmultimodal content platforms with S\\&R services in the future.",
            "upvotes": 11,
            "discussionId": "67c6a346ad6b7c2fa29d5f88",
            "projectPage": "https://huggingface.co/datasets/THUIR/Qilin",
            "githubRepo": "https://github.com/RED-Search/Qilin/"
        },
        "publishedAt": "2025-03-04T01:56:03.632Z",
        "title": "Qilin: A Multimodal Information Retrieval Dataset with APP-level User Sessions",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00501.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60c0ed29d8bc072769d78f48",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60c0ed29d8bc072769d78f48/V6q6Tn4kzB46NIbTYw9pQ.jpeg",
            "fullname": "Qian Dong",
            "name": "qian",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.00714",
            "authors": [
                {
                    "_id": "67c6a803025b72f14ccb0939",
                    "user": {
                        "_id": "6577437552f02732a463d97d",
                        "avatarUrl": "/avatars/8eb271ec249fa9b0d97dfe0eace6da88.svg",
                        "isPro": false,
                        "fullname": "Haoyu Li",
                        "user": "Haoyu0529",
                        "type": "user"
                    },
                    "name": "Haoyu Li",
                    "status": "extracted_pending",
                    "statusLastChangedAt": "2025-03-04T07:13:08.306Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a803025b72f14ccb093a",
                    "name": "Srikanth Kandula",
                    "hidden": false
                },
                {
                    "_id": "67c6a803025b72f14ccb093b",
                    "name": "Maria Angels de Luis Balaguer",
                    "hidden": false
                },
                {
                    "_id": "67c6a803025b72f14ccb093c",
                    "name": "Aditya Akella",
                    "hidden": false
                },
                {
                    "_id": "67c6a803025b72f14ccb093d",
                    "name": "Venkat Arun",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-02T03:44:31.000Z",
            "title": "Speculative Ad-hoc Querying",
            "summary": "Analyzing large datasets requires responsive query execution, but executing\nSQL queries on massive datasets can be slow. This paper explores whether query\nexecution can begin even before the user has finished typing, allowing results\nto appear almost instantly. We propose SpeQL, a system that leverages Large\nLanguage Models (LLMs) to predict likely queries based on the database schema,\nthe user's past queries, and their incomplete query. Since exact query\nprediction is infeasible, SpeQL speculates on partial queries in two ways: 1)\nit predicts the query structure to compile and plan queries in advance, and 2)\nit precomputes smaller temporary tables that are much smaller than the original\ndatabase, but are still predicted to contain all information necessary to\nanswer the user's final query. Additionally, SpeQL continuously displays\nresults for speculated queries and subqueries in real time, aiding exploratory\nanalysis. A utility/user study showed that SpeQL improved task completion time,\nand participants reported that its speculative display of results helped them\ndiscover patterns in the data more quickly. In the study, SpeQL improves user's\nquery latency by up to 289times and kept the overhead reasonable, at 4$\nper hour.",
            "upvotes": 10,
            "discussionId": "67c6a804025b72f14ccb0994",
            "projectPage": "https://github.com/lihy0529/SpeQL",
            "githubRepo": "https://github.com/lihy0529/SpeQL"
        },
        "publishedAt": "2025-03-04T02:21:00.460Z",
        "title": "Speculative Ad-hoc Querying",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6577437552f02732a463d97d/fEkQ4BZ8Yx_CzsjvHBWFq.qt"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00714.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6577437552f02732a463d97d",
            "avatarUrl": "/avatars/8eb271ec249fa9b0d97dfe0eace6da88.svg",
            "fullname": "Haoyu Li",
            "name": "Haoyu0529",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.00031",
            "authors": [
                {
                    "_id": "67c732c14aaf26f75cea0d82",
                    "user": {
                        "_id": "62ea79dd01ed9b0e8f61ccd3",
                        "avatarUrl": "/avatars/70af83e0e267be39fcd5f23b85e2dafa.svg",
                        "isPro": false,
                        "fullname": "Chengsong Huang",
                        "user": "ChengsongHuang",
                        "type": "user"
                    },
                    "name": "Chengsong Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T21:15:36.013Z",
                    "hidden": false
                },
                {
                    "_id": "67c732c14aaf26f75cea0d83",
                    "name": "Langlin Huang",
                    "hidden": false
                },
                {
                    "_id": "67c732c14aaf26f75cea0d84",
                    "name": "Jixuan Leng",
                    "hidden": false
                },
                {
                    "_id": "67c732c14aaf26f75cea0d85",
                    "name": "Jiacheng Liu",
                    "hidden": false
                },
                {
                    "_id": "67c732c14aaf26f75cea0d86",
                    "name": "Jiaxin Huang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-25T00:21:14.000Z",
            "title": "Efficient Test-Time Scaling via Self-Calibration",
            "summary": "Increasing test-time computation is a straightforward approach to enhancing\nthe quality of responses in Large Language Models (LLMs). While Best-of-N\nsampling and Self-Consistency with majority voting are simple and effective,\nthey require a fixed number of sampling responses for each query, regardless of\nits complexity. This could result in wasted computation for simpler questions\nand insufficient exploration for more challenging ones. In this work, we argue\nthat model confidence of responses can be used for improving the efficiency of\ntest-time scaling. Unfortunately, LLMs are known to be overconfident and\nprovide unreliable confidence estimation. To address this limitation, we\nintroduce Self-Calibration by distilling Self-Consistency-derived confidence\ninto the model itself. This enables reliable confidence estimation at test time\nwith one forward pass. We then design confidence-based efficient test-time\nscaling methods to handle queries of various difficulty, such as Early-Stopping\nfor Best-of-N and Self-Consistency with calibrated confidence. Experiments on\nthree LLMs across six datasets demonstrate the effectiveness of our approach.\nSpecifically, applying confidence-based Early Stopping to Best-of-N improves\nMathQA accuracy from 81.0 to 83.6 with a sample budget of 16 responses,\nindicating the efficacy of confidence-based sampling strategy at inference\ntime.",
            "upvotes": 9,
            "discussionId": "67c732c34aaf26f75cea0df7"
        },
        "publishedAt": "2025-03-04T12:05:25.041Z",
        "title": "Efficient Test-Time Scaling via Self-Calibration",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00031.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "62ea79dd01ed9b0e8f61ccd3",
            "avatarUrl": "/avatars/70af83e0e267be39fcd5f23b85e2dafa.svg",
            "fullname": "Chengsong Huang",
            "name": "ChengsongHuang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.00784",
            "authors": [
                {
                    "_id": "67c673bcf47209364f0cec96",
                    "user": {
                        "_id": "6485d5b300c9cfe5c2470c81",
                        "avatarUrl": "/avatars/c29aa81d2add795e8448b99274a04b83.svg",
                        "isPro": false,
                        "fullname": "Kai",
                        "user": "KaiLv",
                        "type": "user"
                    },
                    "name": "Kai Lv",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:14:11.523Z",
                    "hidden": false
                },
                {
                    "_id": "67c673bcf47209364f0cec97",
                    "user": {
                        "_id": "638ef0b0c67af472d31674a6",
                        "avatarUrl": "/avatars/02df97d15a0f46b47f9162221733b121.svg",
                        "isPro": false,
                        "fullname": "Honglin Guo",
                        "user": "KYLN24",
                        "type": "user"
                    },
                    "name": "Honglin Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:14:04.672Z",
                    "hidden": false
                },
                {
                    "_id": "67c673bcf47209364f0cec98",
                    "user": {
                        "_id": "6491cd52b1e5d3444528edb1",
                        "avatarUrl": "/avatars/a85635d886c7f157b6723dec5c01c030.svg",
                        "isPro": false,
                        "fullname": "Qipeng Guo",
                        "user": "QipengGuo",
                        "type": "user"
                    },
                    "name": "Qipeng Guo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:13:46.322Z",
                    "hidden": false
                },
                {
                    "_id": "67c673bcf47209364f0cec99",
                    "user": {
                        "_id": "61457b8deff2c9fdb4de4988",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1632381702899-61457b8deff2c9fdb4de4988.jpeg",
                        "isPro": false,
                        "fullname": "Xipeng Qiu",
                        "user": "xpqiu",
                        "type": "user"
                    },
                    "name": "Xipeng Qiu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:13:40.885Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-02T08:27:48.000Z",
            "title": "DuoDecoding: Hardware-aware Heterogeneous Speculative Decoding with\n  Dynamic Multi-Sequence Drafting",
            "summary": "Large language models (LLMs) exhibit exceptional performance across a wide\nrange of tasks; however, their token-by-token autoregressive generation process\nsignificantly hinders inference speed. Speculative decoding presents a\npromising draft-then-verify framework that reduces generation latency while\nmaintaining output distribution fidelity. Nevertheless, the draft model\nintroduces additional computational overhead, becoming a performance bottleneck\nand increasing the time to first token (TTFT). Previous approaches to mitigate\ndraft model overhead have primarily relied on heuristics and generally failed\nto match the quality of the draft language models. To address these challenges,\nwe propose DuoDecoding, a novel approach that strategically deploys the draft\nand target models on the CPU and GPU respectively, enabling parallel decoding\nwhile preserving draft quality. Our method incorporates a hardware-aware\noptimal draft budget to minimize idle times and employs dynamic multi-sequence\ndrafting to enhance draft quality. Extensive experiments across seven tasks\nshow that DuoDecoding achieves up to 2.61x speedup in generation latency, while\nreducing TTFT to 83% of that in conventional speculative decoding. The Code is\navailable at https://github.com/KaiLv69/DuoDecoding.",
            "upvotes": 8,
            "discussionId": "67c673bdf47209364f0cecb7",
            "githubRepo": "https://github.com/KaiLv69/DuoDecoding"
        },
        "publishedAt": "2025-03-03T22:35:45.299Z",
        "title": "DuoDecoding: Hardware-aware Heterogeneous Speculative Decoding with Dynamic Multi-Sequence Drafting",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00784.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6485d5b300c9cfe5c2470c81",
            "avatarUrl": "/avatars/c29aa81d2add795e8448b99274a04b83.svg",
            "fullname": "Kai",
            "name": "KaiLv",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01506",
            "authors": [
                {
                    "_id": "67c67cf5c8d296910ca74711",
                    "user": {
                        "_id": "63edb098679c2cc40abc6c2e",
                        "avatarUrl": "/avatars/288c7229937c2c3f29fda6d17c7df2eb.svg",
                        "isPro": false,
                        "fullname": "Xiangyu",
                        "user": "xixy",
                        "type": "user"
                    },
                    "name": "Xiangyu Xi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T12:01:25.632Z",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca74712",
                    "user": {
                        "_id": "65a0aade5fafc248c2156e95",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a0aade5fafc248c2156e95/S9YjJMTuKc-U1cFizqUMA.jpeg",
                        "isPro": false,
                        "fullname": "DeyangKong",
                        "user": "DeyangKong",
                        "type": "user"
                    },
                    "name": "Deyang Kong",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:40:21.910Z",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca74713",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca74714",
                    "name": "Jiawei Yang",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca74715",
                    "user": {
                        "_id": "67b7ebf3d00e69f10cfcf551",
                        "avatarUrl": "/avatars/8adea7ae44c459079113a690ec7da73a.svg",
                        "isPro": false,
                        "fullname": "Chen Zhengyu",
                        "user": "WQYC",
                        "type": "user"
                    },
                    "name": "Zhengyu Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:16:14.018Z",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca74716",
                    "user": {
                        "_id": "62fa0ffe0697d224219a0cb7",
                        "avatarUrl": "/avatars/f0ef59e1c0cf4ab4fe5cee08d488bd03.svg",
                        "isPro": false,
                        "fullname": "Wei Wang",
                        "user": "WeiWang",
                        "type": "user"
                    },
                    "name": "Wei Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:16:23.635Z",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca74717",
                    "user": {
                        "_id": "647097cbcfd57849518e656b",
                        "avatarUrl": "/avatars/c66fe0add29c1bde9e3a98bf4a8793b9.svg",
                        "isPro": false,
                        "fullname": "Jingang Wang",
                        "user": "bitwjg",
                        "type": "user"
                    },
                    "name": "Jingang Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:16:00.303Z",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca74718",
                    "name": "Xunliang Cai",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca74719",
                    "name": "Shikun Zhang",
                    "hidden": false
                },
                {
                    "_id": "67c67cf5c8d296910ca7471a",
                    "name": "Wei Ye",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T13:22:11.000Z",
            "title": "SampleMix: A Sample-wise Pre-training Data Mixing Strategey by\n  Coordinating Data Quality and Diversity",
            "summary": "Existing pretraining data mixing methods for large language models (LLMs)\ntypically follow a domain-wise methodology, a top-down process that first\ndetermines domain weights and then performs uniform data sampling across each\ndomain. However, these approaches neglect significant inter-domain overlaps and\ncommonalities, failing to control the global diversity of the constructed\ntraining dataset. Further, uniform sampling within domains ignores fine-grained\nsample-specific features, potentially leading to suboptimal data distribution.\nTo address these shortcomings, we propose a novel sample-wise data mixture\napproach based on a bottom-up paradigm. This method performs global\ncross-domain sampling by systematically evaluating the quality and diversity of\neach sample, thereby dynamically determining the optimal domain distribution.\nComprehensive experiments across multiple downstream tasks and perplexity\nassessments demonstrate that SampleMix surpasses existing domain-based methods.\nMeanwhile, SampleMix requires 1.4x to 2.1x training steps to achieves the\nbaselines' performance, highlighting the substantial potential of SampleMix to\noptimize pre-training data.",
            "upvotes": 7,
            "discussionId": "67c67d03c8d296910ca7494f"
        },
        "publishedAt": "2025-03-04T05:28:10.012Z",
        "title": "SampleMix: A Sample-wise Pre-training Data Mixing Strategey by Coordinating Data Quality and Diversity",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01506.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "65a0aade5fafc248c2156e95",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65a0aade5fafc248c2156e95/S9YjJMTuKc-U1cFizqUMA.jpeg",
            "fullname": "DeyangKong",
            "name": "DeyangKong",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01370",
            "authors": [
                {
                    "_id": "67c691673ff65c55829685a0",
                    "user": {
                        "_id": "6332e2689bf698ce68a22e8c",
                        "avatarUrl": "/avatars/c1922acfda2e6d2fe7b03194a404eb10.svg",
                        "isPro": true,
                        "fullname": "JIANTAO LIN",
                        "user": "LTT",
                        "type": "user"
                    },
                    "name": "Jiantao Lin",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:52:36.682Z",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a1",
                    "name": "Xin Yang",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a2",
                    "user": {
                        "_id": "63641f09a53b71b7a1b02955",
                        "avatarUrl": "/avatars/2f43703cbbc56f3e3f98090f44bccfe6.svg",
                        "isPro": false,
                        "fullname": "Meixi Chen",
                        "user": "MeixiChen",
                        "type": "user"
                    },
                    "name": "Meixi Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:52:44.047Z",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a3",
                    "name": "Yingjie Xu",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a4",
                    "user": {
                        "_id": "64049ae20ab5e22719f35103",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1678023295407-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Dongyu Yan",
                        "user": "StarYDY",
                        "type": "user"
                    },
                    "name": "Dongyu Yan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:34:56.252Z",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a5",
                    "name": "Leyi Wu",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a6",
                    "user": {
                        "_id": "64b4ab62eec33e27dcd733b5",
                        "avatarUrl": "/avatars/0a9bf220c9a5efe7279f9b287b087d36.svg",
                        "isPro": false,
                        "fullname": "Xinli XU",
                        "user": "Xxlbigbrother",
                        "type": "user"
                    },
                    "name": "Xinli Xu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:53:15.555Z",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a7",
                    "name": "Lie XU",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a8",
                    "name": "Shunsi Zhang",
                    "hidden": false
                },
                {
                    "_id": "67c691673ff65c55829685a9",
                    "user": {
                        "_id": "655cba1d87b67834000590e8",
                        "avatarUrl": "/avatars/3bd43b7c9351f65b8f38f4c8237a0146.svg",
                        "isPro": false,
                        "fullname": "Yingcong Chen",
                        "user": "yingcongchen",
                        "type": "user"
                    },
                    "name": "Ying-Cong Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:53:33.509Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T10:07:19.000Z",
            "title": "Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation",
            "summary": "Diffusion models have achieved great success in generating 2D images.\nHowever, the quality and generalizability of 3D content generation remain\nlimited. State-of-the-art methods often require large-scale 3D assets for\ntraining, which are challenging to collect. In this work, we introduce\nKiss3DGen (Keep It Simple and Straightforward in 3D Generation), an efficient\nframework for generating, editing, and enhancing 3D objects by repurposing a\nwell-trained 2D image diffusion model for 3D generation. Specifically, we\nfine-tune a diffusion model to generate ''3D Bundle Image'', a tiled\nrepresentation composed of multi-view images and their corresponding normal\nmaps. The normal maps are then used to reconstruct a 3D mesh, and the\nmulti-view images provide texture mapping, resulting in a complete 3D model.\nThis simple method effectively transforms the 3D generation problem into a 2D\nimage generation task, maximizing the utilization of knowledge in pretrained\ndiffusion models. Furthermore, we demonstrate that our Kiss3DGen model is\ncompatible with various diffusion model techniques, enabling advanced features\nsuch as 3D editing, mesh and texture enhancement, etc. Through extensive\nexperiments, we demonstrate the effectiveness of our approach, showcasing its\nability to produce high-quality 3D models efficiently.",
            "upvotes": 7,
            "discussionId": "67c6916b3ff65c5582968702",
            "projectPage": "https://ltt-o.github.io/Kiss3dgen.github.io/",
            "githubRepo": "https://github.com/EnVision-Research/Kiss3DGen"
        },
        "publishedAt": "2025-03-04T01:19:45.715Z",
        "title": "Kiss3DGen: Repurposing Image Diffusion Models for 3D Asset Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01370.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "6332e2689bf698ce68a22e8c",
            "avatarUrl": "/avatars/c1922acfda2e6d2fe7b03194a404eb10.svg",
            "fullname": "JIANTAO LIN",
            "name": "LTT",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.00455",
            "authors": [
                {
                    "_id": "67c6facdd8af5b36fd4b59cf",
                    "user": {
                        "_id": "674836767b7151c3ff30f865",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/jcwK5NW-efhCt8s2TE6vK.png",
                        "isPro": false,
                        "fullname": "Yujia Xiao",
                        "user": "Yogurt928",
                        "type": "user"
                    },
                    "name": "Yujia Xiao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T16:08:12.490Z",
                    "hidden": false
                },
                {
                    "_id": "67c6facdd8af5b36fd4b59d0",
                    "name": "Lei He",
                    "hidden": false
                },
                {
                    "_id": "67c6facdd8af5b36fd4b59d1",
                    "name": "Haohan Guo",
                    "hidden": false
                },
                {
                    "_id": "67c6facdd8af5b36fd4b59d2",
                    "name": "Fenglong Xie",
                    "hidden": false
                },
                {
                    "_id": "67c6facdd8af5b36fd4b59d3",
                    "name": "Tan Lee",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-01T11:35:17.000Z",
            "title": "PodAgent: A Comprehensive Framework for Podcast Generation",
            "summary": "Existing Existing automatic audio generation methods struggle to generate\npodcast-like audio programs effectively. The key challenges lie in in-depth\ncontent generation, appropriate and expressive voice production. This paper\nproposed PodAgent, a comprehensive framework for creating audio programs.\nPodAgent 1) generates informative topic-discussion content by designing a\nHost-Guest-Writer multi-agent collaboration system, 2) builds a voice pool for\nsuitable voice-role matching and 3) utilizes LLM-enhanced speech synthesis\nmethod to generate expressive conversational speech. Given the absence of\nstandardized evaluation criteria for podcast-like audio generation, we\ndeveloped comprehensive assessment guidelines to effectively evaluate the\nmodel's performance. Experimental results demonstrate PodAgent's effectiveness,\nsignificantly surpassing direct GPT-4 generation in topic-discussion dialogue\ncontent, achieving an 87.4% voice-matching accuracy, and producing more\nexpressive speech through LLM-guided synthesis. Demo page:\nhttps://podcast-agent.github.io/demo/. Source code:\nhttps://github.com/yujxx/PodAgent.",
            "upvotes": 5,
            "discussionId": "67c6facfd8af5b36fd4b5a45",
            "projectPage": "https://podcast-agent.github.io/demo/",
            "githubRepo": "https://github.com/yujxx/PodAgent"
        },
        "publishedAt": "2025-03-04T08:11:33.371Z",
        "title": "PodAgent: A Comprehensive Framework for Podcast Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00455.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "674836767b7151c3ff30f865",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/jcwK5NW-efhCt8s2TE6vK.png",
            "fullname": "Yujia Xiao",
            "name": "Yogurt928",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01714",
            "authors": [
                {
                    "_id": "67c6d22d983375492193aab0",
                    "user": {
                        "_id": "679bc0ec7f3c28bf968321c8",
                        "avatarUrl": "/avatars/9d5ab9c6af32878e28987518c0210c1a.svg",
                        "isPro": false,
                        "fullname": "Chenxi Wang",
                        "user": "Aurora-cx",
                        "type": "user"
                    },
                    "name": "Chenxi Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T11:16:44.551Z",
                    "hidden": false
                },
                {
                    "_id": "67c6d22d983375492193aab1",
                    "user": {
                        "_id": "6346361c5efccdc07f179cae",
                        "avatarUrl": "/avatars/217818114a4c19ea4f3e5cdafefb625e.svg",
                        "isPro": false,
                        "fullname": "Gu Tianle",
                        "user": "Carol0110",
                        "type": "user"
                    },
                    "name": "Tianle Gu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T10:54:29.015Z",
                    "hidden": false
                },
                {
                    "_id": "67c6d22d983375492193aab2",
                    "name": "Zhongyu Wei",
                    "hidden": false
                },
                {
                    "_id": "67c6d22d983375492193aab3",
                    "name": "Lang Gao",
                    "hidden": false
                },
                {
                    "_id": "67c6d22d983375492193aab4",
                    "user": {
                        "_id": "65407ba7a38390065750233f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65407ba7a38390065750233f/1_IPMZbk-S9u2t18PQgMp.jpeg",
                        "isPro": false,
                        "fullname": "Zirui Song",
                        "user": "Ziruibest",
                        "type": "user"
                    },
                    "name": "Zirui Song",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T10:17:25.935Z",
                    "hidden": false
                },
                {
                    "_id": "67c6d22d983375492193aab5",
                    "name": "Xiuying Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T16:31:45.000Z",
            "title": "Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia",
            "summary": "Human readers can efficiently comprehend scrambled words, a phenomenon known\nas Typoglycemia, primarily by relying on word form; if word form alone is\ninsufficient, they further utilize contextual cues for interpretation. While\nadvanced large language models (LLMs) exhibit similar abilities, the underlying\nmechanisms remain unclear. To investigate this, we conduct controlled\nexperiments to analyze the roles of word form and contextual information in\nsemantic reconstruction and examine LLM attention patterns. Specifically, we\nfirst propose SemRecScore, a reliable metric to quantify the degree of semantic\nreconstruction, and validate its effectiveness. Using this metric, we study how\nword form and contextual information influence LLMs' semantic reconstruction\nability, identifying word form as the core factor in this process. Furthermore,\nwe analyze how LLMs utilize word form and find that they rely on specialized\nattention heads to extract and process word form information, with this\nmechanism remaining stable across varying levels of word scrambling. This\ndistinction between LLMs' fixed attention patterns primarily focused on word\nform and human readers' adaptive strategy in balancing word form and contextual\ninformation provides insights into enhancing LLM performance by incorporating\nhuman-like, context-aware mechanisms.",
            "upvotes": 5,
            "discussionId": "67c6d22e983375492193ab13"
        },
        "publishedAt": "2025-03-04T05:13:44.578Z",
        "title": "Word Form Matters: LLMs' Semantic Reconstruction under Typoglycemia",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01714.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "65407ba7a38390065750233f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65407ba7a38390065750233f/1_IPMZbk-S9u2t18PQgMp.jpeg",
            "fullname": "Zirui Song",
            "name": "Ziruibest",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01295",
            "authors": [
                {
                    "_id": "67c6a8b534aeb86063e94010",
                    "user": {
                        "_id": "61711f02e0b1ddb56eb9b526",
                        "avatarUrl": "/avatars/3e2fdf774f5bc1f73b450486d6da42d4.svg",
                        "isPro": false,
                        "fullname": "Mingzhe Du",
                        "user": "Elfsong",
                        "type": "user"
                    },
                    "name": "Mingzhe Du",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:34:49.954Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a8b534aeb86063e94011",
                    "user": {
                        "_id": "655722e80438e0854fae7554",
                        "avatarUrl": "/avatars/b93a74f7c7880f9fe0f3ffb47e2aef5e.svg",
                        "isPro": false,
                        "fullname": "Luu Anh Tuan",
                        "user": "anhtuanluu36",
                        "type": "user"
                    },
                    "name": "Anh Tuan Luu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:02:20.575Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a8b534aeb86063e94012",
                    "name": "Bin Ji",
                    "hidden": false
                },
                {
                    "_id": "67c6a8b534aeb86063e94013",
                    "user": {
                        "_id": "64cb02869e30a46f7b80b355",
                        "avatarUrl": "/avatars/81ce4ba78826b54f0e1b53eeaff87ee6.svg",
                        "isPro": false,
                        "fullname": "Xiaobao Wu",
                        "user": "bobxwu",
                        "type": "user"
                    },
                    "name": "Xiaobao Wu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:02:48.996Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a8b534aeb86063e94014",
                    "user": {
                        "_id": "67c56a7f083bb2c50254bbe5",
                        "avatarUrl": "/avatars/bdf6fd8934c2199ff169b178f6482773.svg",
                        "isPro": false,
                        "fullname": "Huang, Dong",
                        "user": "DongHuang-ebay",
                        "type": "user"
                    },
                    "name": "Dong Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:02:43.013Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a8b534aeb86063e94015",
                    "user": {
                        "_id": "62b7fb545233925f253531c8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b7fb545233925f253531c8/W50u2G1HK3EtUKHRU189V.jpeg",
                        "isPro": false,
                        "fullname": "Terry Yue Zhuo",
                        "user": "terryyz",
                        "type": "user"
                    },
                    "name": "Terry Yue Zhuo",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:02:33.977Z",
                    "hidden": false
                },
                {
                    "_id": "67c6a8b534aeb86063e94016",
                    "name": "Qian Liu",
                    "hidden": false
                },
                {
                    "_id": "67c6a8b534aeb86063e94017",
                    "name": "See-Kiong Ng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T08:31:16.000Z",
            "title": "CodeArena: A Collective Evaluation Platform for LLM Code Generation",
            "summary": "Large Language Models (LLMs) have reshaped code generation by synergizing\ntheir exceptional comprehension of natural language and programming syntax,\nthereby substantially boosting developer productivity. These advancements have\nprompted numerous efforts to quantitatively evaluate their coding capabilities.\nHowever, persistent challenges, such as benchmark leakage, data dissipation,\nand limited system accessibility, continue to impede a timely and accurate\nassessment. To address these limitations, we introduce CodeArena, an online\nevaluation framework tailored for LLM code generation. The key innovation is a\ncollective evaluation mechanism, which dynamically recalibrates individual\nmodel scores based on the holistic performance of all participating models,\nmitigating score biases caused by widespread benchmark leakage. In addition,\nCodeArena ensures open access to all submitted solutions and test cases and\nprovides automation-friendly APIs to streamline the code evaluation workflow.\nOur main contributions are: (1) a collective evaluation system for unbiased\nassessment, (2) a public repository of solutions and test cases, and (3)\nautomation-ready APIs for seamless integration.",
            "upvotes": 5,
            "discussionId": "67c6a8b634aeb86063e9406a"
        },
        "publishedAt": "2025-03-04T02:16:25.633Z",
        "title": "CodeArena: A Collective Evaluation Platform for LLM Code Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01295.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "61711f02e0b1ddb56eb9b526",
            "avatarUrl": "/avatars/3e2fdf774f5bc1f73b450486d6da42d4.svg",
            "fullname": "Mingzhe Du",
            "name": "Elfsong",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01807",
            "authors": [
                {
                    "_id": "67c67ff6dec55d10cb10fc9e",
                    "user": {
                        "_id": "62608fc2ffe8827cb1d89f9f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654027835241-62608fc2ffe8827cb1d89f9f.png",
                        "isPro": false,
                        "fullname": "Hamish Ivison",
                        "user": "hamishivi",
                        "type": "user"
                    },
                    "name": "Hamish Ivison",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:40:13.649Z",
                    "hidden": false
                },
                {
                    "_id": "67c67ff6dec55d10cb10fc9f",
                    "user": {
                        "_id": "61cc2cf4dcb47bd5ed3cd3b8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1640770780085-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Muru Zhang",
                        "user": "nanami",
                        "type": "user"
                    },
                    "name": "Muru Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:14:59.402Z",
                    "hidden": false
                },
                {
                    "_id": "67c67ff6dec55d10cb10fca0",
                    "user": {
                        "_id": "65282b8d578679aac7888aec",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65282b8d578679aac7888aec/dibBkhH-z1c70mJZZxJ7u.jpeg",
                        "isPro": false,
                        "fullname": "Faeze Brahman",
                        "user": "faezeb",
                        "type": "user"
                    },
                    "name": "Faeze Brahman",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:15:05.562Z",
                    "hidden": false
                },
                {
                    "_id": "67c67ff6dec55d10cb10fca1",
                    "user": {
                        "_id": "641b4263abfce26bcf7b27de",
                        "avatarUrl": "/avatars/e91b4205e4f74b0dd8c333c23203a924.svg",
                        "isPro": false,
                        "fullname": "Pang Wei Koh",
                        "user": "pangwei",
                        "type": "user"
                    },
                    "name": "Pang Wei Koh",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:15:14.558Z",
                    "hidden": false
                },
                {
                    "_id": "67c67ff6dec55d10cb10fca2",
                    "user": {
                        "_id": "6408fcc93461c51cf735a61e",
                        "avatarUrl": "/avatars/619f3653911d111f046a5a6c30fc8319.svg",
                        "isPro": false,
                        "fullname": "Pradeep Dasigi",
                        "user": "pradeepd",
                        "type": "user"
                    },
                    "name": "Pradeep Dasigi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:15:20.400Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T18:37:26.000Z",
            "title": "Large-Scale Data Selection for Instruction Tuning",
            "summary": "Selecting high-quality training data from a larger pool is a crucial step\nwhen instruction-tuning language models, as carefully curated datasets often\nproduce models that outperform those trained on much larger, noisier datasets.\nAutomated data selection approaches for instruction-tuning are typically tested\nby selecting small datasets (roughly 10k samples) from small pools (100-200k\nsamples). However, popular deployed instruction-tuned models often train on\nhundreds of thousands to millions of samples, subsampled from even larger data\npools. We present a systematic study of how well data selection methods scale\nto these settings, selecting up to 2.5M samples from pools of up to 5.8M\nsamples and evaluating across 7 diverse tasks. We show that many recently\nproposed methods fall short of random selection in this setting (while using\nmore compute), and even decline in performance when given access to larger\npools of data to select over. However, we find that a variant of\nrepresentation-based data selection (RDS+), which uses weighted mean pooling of\npretrained LM hidden states, consistently outperforms more complex methods\nacross all settings tested -- all whilst being more compute-efficient. Our\nfindings highlight that the scaling properties of proposed automated selection\nmethods should be more closely examined. We release our code, data, and models\nat https://github.com/hamishivi/automated-instruction-selection.",
            "upvotes": 5,
            "discussionId": "67c67ff9dec55d10cb10fcef"
        },
        "publishedAt": "2025-03-03T23:44:06.105Z",
        "title": "Large-Scale Data Selection for Instruction Tuning",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01807.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "62608fc2ffe8827cb1d89f9f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1654027835241-62608fc2ffe8827cb1d89f9f.png",
            "fullname": "Hamish Ivison",
            "name": "hamishivi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 11
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.19402",
            "authors": [
                {
                    "_id": "67c66a6321d722b4247e5959",
                    "user": {
                        "_id": "6520d6db2a16045c092b3b36",
                        "avatarUrl": "/avatars/dab34f141a1aef39d00c789ff85e729f.svg",
                        "isPro": false,
                        "fullname": "Seungwook Han",
                        "user": "hanseungwook",
                        "type": "user"
                    },
                    "name": "Seungwook Han",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T16:08:58.266Z",
                    "hidden": false
                },
                {
                    "_id": "67c66a6321d722b4247e595a",
                    "name": "Jyothish Pari",
                    "hidden": false
                },
                {
                    "_id": "67c66a6321d722b4247e595b",
                    "user": {
                        "_id": "6520d6db2a16045c092b3b36",
                        "avatarUrl": "/avatars/dab34f141a1aef39d00c789ff85e729f.svg",
                        "isPro": false,
                        "fullname": "Seungwook Han",
                        "user": "hanseungwook",
                        "type": "user"
                    },
                    "name": "Samuel J. Gershman",
                    "status": "extracted_confirmed",
                    "statusLastChangedAt": "2025-03-04T13:57:29.748Z",
                    "hidden": false
                },
                {
                    "_id": "67c66a6321d722b4247e595c",
                    "name": "Pulkit Agrawal",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-26T18:51:12.000Z",
            "title": "General Reasoning Requires Learning to Reason from the Get-go",
            "summary": "Large Language Models (LLMs) have demonstrated impressive real-world utility,\nexemplifying artificial useful intelligence (AUI). However, their ability to\nreason adaptively and robustly -- the hallmarks of artificial general\nintelligence (AGI) -- remains fragile. While LLMs seemingly succeed in\ncommonsense reasoning, programming, and mathematics, they struggle to\ngeneralize algorithmic understanding across novel contexts. Our experiments\nwith algorithmic tasks in esoteric programming languages reveal that LLM's\nreasoning overfits to the training data and is limited in its transferability.\nWe hypothesize that the core issue underlying such limited transferability is\nthe coupling of reasoning and knowledge in LLMs.\n  To transition from AUI to AGI, we propose disentangling knowledge and\nreasoning through three key directions: (1) pretaining to reason using RL from\nscratch as an alternative to the widely used next-token prediction pretraining,\n(2) using a curriculum of synthetic tasks to ease the learning of a\nreasoning prior for RL that can then be transferred to natural\nlanguage tasks, and (3) learning more generalizable reasoning functions using a\nsmall context window to reduce exploiting spurious correlations between tokens.\nSuch a reasoning system coupled with a trained retrieval system and a large\nexternal memory bank as a knowledge store can overcome several limitations of\nexisting architectures at learning to reason in novel scenarios.",
            "upvotes": 4,
            "discussionId": "67c66a6521d722b4247e59c8"
        },
        "publishedAt": "2025-03-04T08:19:57.557Z",
        "title": "General Reasoning Requires Learning to Reason from the Get-go",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.19402.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6520d6db2a16045c092b3b36",
            "avatarUrl": "/avatars/dab34f141a1aef39d00c789ff85e729f.svg",
            "fullname": "Seungwook Han",
            "name": "hanseungwook",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01739",
            "authors": [
                {
                    "_id": "67c68f7828a037872c5ce5bb",
                    "user": {
                        "_id": "62b32a4429a410b7f6b06710",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b32a4429a410b7f6b06710/VzgvmnlYZWuifZTkIkCxy.jpeg",
                        "isPro": false,
                        "fullname": "Wenhao Wang",
                        "user": "WenhaoWang",
                        "type": "user"
                    },
                    "name": "Wenhao Wang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:14:37.907Z",
                    "hidden": false
                },
                {
                    "_id": "67c68f7828a037872c5ce5bc",
                    "name": "Yi Yang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T17:00:36.000Z",
            "title": "VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video\n  Generation",
            "summary": "Text-to-video generative models convert textual prompts into dynamic visual\ncontent, offering wide-ranging applications in film production, gaming, and\neducation. However, their real-world performance often falls short of user\nexpectations. One key reason is that these models have not been trained on\nvideos related to some topics users want to create. In this paper, we propose\nVideoUFO, the first Video dataset specifically curated to align with Users'\nFOcus in real-world scenarios. Beyond this, our VideoUFO also features: (1)\nminimal (0.29%) overlap with existing video datasets, and (2) videos\nsearched exclusively via YouTube's official API under the Creative Commons\nlicense. These two attributes provide future researchers with greater freedom\nto broaden their training sources. The VideoUFO comprises over 1.09 million\nvideo clips, each paired with both a brief and a detailed caption\n(description). Specifically, through clustering, we first identify 1,291\nuser-focused topics from the million-scale real text-to-video prompt dataset,\nVidProM. Then, we use these topics to retrieve videos from YouTube, split the\nretrieved videos into clips, and generate both brief and detailed captions for\neach clip. After verifying the clips with specified topics, we are left with\nabout 1.09 million video clips. Our experiments reveal that (1) current 16\ntext-to-video models do not achieve consistent performance across all\nuser-focused topics; and (2) a simple model trained on VideoUFO outperforms\nothers on worst-performing topics. The dataset is publicly available at\nhttps://huggingface.co/datasets/WenhaoWang/VideoUFO under the CC BY 4.0\nLicense.",
            "upvotes": 3,
            "discussionId": "67c68f7a28a037872c5ce60d"
        },
        "publishedAt": "2025-03-04T00:29:56.570Z",
        "title": "VideoUFO: A Million-Scale User-Focused Dataset for Text-to-Video Generation",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01739.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "62b32a4429a410b7f6b06710",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62b32a4429a410b7f6b06710/VzgvmnlYZWuifZTkIkCxy.jpeg",
            "fullname": "Wenhao Wang",
            "name": "WenhaoWang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 14
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01103",
            "authors": [
                {
                    "_id": "67c6d1c35e896ed915374027",
                    "user": {
                        "_id": "652bf7edc3cba555d5673c6e",
                        "avatarUrl": "/avatars/78f6416c30203b30671f8423f061c657.svg",
                        "isPro": false,
                        "fullname": "Kaiwen Zheng",
                        "user": "worstcoder",
                        "type": "user"
                    },
                    "name": "Kaiwen Zheng",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T10:17:24.142Z",
                    "hidden": false
                },
                {
                    "_id": "67c6d1c35e896ed915374028",
                    "user": {
                        "_id": "66f4cf1a03b5ba8a7f1f6522",
                        "avatarUrl": "/avatars/2768d6e37d3f280194cfb8ed274f6015.svg",
                        "isPro": false,
                        "fullname": "Yongxin Chen",
                        "user": "Ema11",
                        "type": "user"
                    },
                    "name": "Yongxin Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:16:59.170Z",
                    "hidden": false
                },
                {
                    "_id": "67c6d1c35e896ed915374029",
                    "user": {
                        "_id": "6630f87ee53fcb71c3887df0",
                        "avatarUrl": "/avatars/50191a3d45bebf90cf08df09477e95db.svg",
                        "isPro": false,
                        "fullname": "HuayuChen",
                        "user": "HuayuChen",
                        "type": "user"
                    },
                    "name": "Huayu Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:17:06.080Z",
                    "hidden": false
                },
                {
                    "_id": "67c6d1c35e896ed91537402a",
                    "user": {
                        "_id": "67492ee82ad3cfc108a41bbb",
                        "avatarUrl": "/avatars/7ad03e55a8791c62f1271a5c9bf8cc60.svg",
                        "isPro": false,
                        "fullname": "Guande He",
                        "user": "gdhe17",
                        "type": "user"
                    },
                    "name": "Guande He",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:17:20.266Z",
                    "hidden": false
                },
                {
                    "_id": "67c6d1c35e896ed91537402b",
                    "user": {
                        "_id": "62f049afdf4b93aad5c7f2d6",
                        "avatarUrl": "/avatars/e272e58ad996733d7098e50248e5b57e.svg",
                        "isPro": false,
                        "fullname": "Ming-Yu Liu",
                        "user": "mingyuliutw",
                        "type": "user"
                    },
                    "name": "Ming-Yu Liu",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:17:27.270Z",
                    "hidden": false
                },
                {
                    "_id": "67c6d1c35e896ed91537402c",
                    "name": "Jun Zhu",
                    "hidden": false
                },
                {
                    "_id": "67c6d1c35e896ed91537402d",
                    "user": {
                        "_id": "6732d5dea24987c43bfbafd8",
                        "avatarUrl": "/avatars/1581373b9de5069975716932fceb976b.svg",
                        "isPro": false,
                        "fullname": "Qinsheng Zhang",
                        "user": "qsh-zh",
                        "type": "user"
                    },
                    "name": "Qinsheng Zhang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:17:33.763Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-03T02:06:22.000Z",
            "title": "Direct Discriminative Optimization: Your Likelihood-Based Visual\n  Generative Model is Secretly a GAN Discriminator",
            "summary": "While likelihood-based generative models, particularly diffusion and\nautoregressive models, have achieved remarkable fidelity in visual generation,\nthe maximum likelihood estimation (MLE) objective inherently suffers from a\nmode-covering tendency that limits the generation quality under limited model\ncapacity. In this work, we propose Direct Discriminative Optimization (DDO) as\na unified framework that bridges likelihood-based generative training and the\nGAN objective to bypass this fundamental constraint. Our key insight is to\nparameterize a discriminator implicitly using the likelihood ratio between a\nlearnable target model and a fixed reference model, drawing parallels with the\nphilosophy of Direct Preference Optimization (DPO). Unlike GANs, this\nparameterization eliminates the need for joint training of generator and\ndiscriminator networks, allowing for direct, efficient, and effective\nfinetuning of a well-trained model to its full potential beyond the limits of\nMLE. DDO can be performed iteratively in a self-play manner for progressive\nmodel refinement, with each round requiring less than 1% of pretraining epochs.\nOur experiments demonstrate the effectiveness of DDO by significantly advancing\nthe previous SOTA diffusion model EDM, reducing FID scores from 1.79/1.58 to\nnew records of 1.30/0.97 on CIFAR-10/ImageNet-64 datasets, and by consistently\nimproving both guidance-free and CFG-enhanced FIDs of visual autoregressive\nmodels on ImageNet 256times256.",
            "upvotes": 2,
            "discussionId": "67c6d1c65e896ed9153740e4",
            "projectPage": "https://research.nvidia.com/labs/dir/ddo/"
        },
        "publishedAt": "2025-03-04T05:12:10.849Z",
        "title": "Direct Discriminative Optimization: Your Likelihood-Based Visual Generative Model is Secretly a GAN Discriminator",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01103.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "652bf7edc3cba555d5673c6e",
            "avatarUrl": "/avatars/78f6416c30203b30671f8423f061c657.svg",
            "fullname": "Kaiwen Zheng",
            "name": "worstcoder",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.16779",
            "authors": [
                {
                    "_id": "67c65c06e116e361574405e9",
                    "user": {
                        "_id": "642bdfc65edcc5760cb1ea12",
                        "avatarUrl": "/avatars/599b0bbb379b43cd39097c204c946075.svg",
                        "isPro": false,
                        "fullname": "huang",
                        "user": "yxuan",
                        "type": "user"
                    },
                    "name": "Yaxuan Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:51:27.582Z",
                    "hidden": false
                },
                {
                    "_id": "67c65c06e116e361574405ea",
                    "name": "Xili Dai",
                    "hidden": false
                },
                {
                    "_id": "67c65c06e116e361574405eb",
                    "name": "Jianan Wang",
                    "hidden": false
                },
                {
                    "_id": "67c65c06e116e361574405ec",
                    "user": {
                        "_id": "6494483aa13255720397287a",
                        "avatarUrl": "/avatars/61ff2e0371df513194246cf6fbb2b78a.svg",
                        "isPro": false,
                        "fullname": "Xianbiao Qi",
                        "user": "qixianbiao",
                        "type": "user"
                    },
                    "name": "Xianbiao Qi",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:01:12.106Z",
                    "hidden": false
                },
                {
                    "_id": "67c65c06e116e361574405ed",
                    "name": "Yixing Yuan",
                    "hidden": false
                },
                {
                    "_id": "67c65c06e116e361574405ee",
                    "user": {
                        "_id": "666a8f24e2990b0cb16b7bf9",
                        "avatarUrl": "/avatars/fcbaf8f1e3e53a2a4a819b7cb2c53aa4.svg",
                        "isPro": false,
                        "fullname": "Xiangyu Yue",
                        "user": "xyyue",
                        "type": "user"
                    },
                    "name": "Xiangyu Yue",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:00:56.439Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-24T02:14:19.000Z",
            "title": "Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain\n  Model",
            "summary": "Room layout estimation from multiple-perspective images is poorly\ninvestigated due to the complexities that emerge from multi-view geometry,\nwhich requires muti-step solutions such as camera intrinsic and extrinsic\nestimation, image matching, and triangulation. However, in 3D reconstruction,\nthe advancement of recent 3D foundation models such as DUSt3R has shifted the\nparadigm from the traditional multi-step structure-from-motion process to an\nend-to-end single-step approach. To this end, we introduce Plane-DUSt3R, a\nnovel method for multi-view room layout estimation leveraging the 3D foundation\nmodel DUSt3R. Plane-DUSt3R incorporates the DUSt3R framework and fine-tunes on\na room layout dataset (Structure3D) with a modified objective to estimate\nstructural planes. By generating uniform and parsimonious results, Plane-DUSt3R\nenables room layout estimation with only a single post-processing step and 2D\ndetection results. Unlike previous methods that rely on single-perspective or\npanorama image, Plane-DUSt3R extends the setting to handle multiple-perspective\nimages. Moreover, it offers a streamlined, end-to-end solution that simplifies\nthe process and reduces error accumulation. Experimental results demonstrate\nthat Plane-DUSt3R not only outperforms state-of-the-art methods on the\nsynthetic dataset but also proves robust and effective on in the wild data with\ndifferent image styles such as cartoon.Our code is available at:\nhttps://github.com/justacar/Plane-DUSt3R",
            "upvotes": 2,
            "discussionId": "67c65c0be116e36157440751",
            "githubRepo": "https://github.com/justacar/Plane-DUSt3R"
        },
        "publishedAt": "2025-03-04T04:17:23.806Z",
        "title": "Unposed Sparse Views Room Layout Reconstruction in the Age of Pretrain Model",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.16779.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "642bdfc65edcc5760cb1ea12",
            "avatarUrl": "/avatars/599b0bbb379b43cd39097c204c946075.svg",
            "fullname": "huang",
            "name": "yxuan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.00729",
            "authors": [
                {
                    "_id": "67c6ab3ec0b62d612c54ddf5",
                    "user": {
                        "_id": "6628c6107751d297d7025a71",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6628c6107751d297d7025a71/S1rm5VIwV2Uxfv8GetKMU.jpeg",
                        "isPro": false,
                        "fullname": "Lei Mingcong",
                        "user": "SP4595",
                        "type": "user"
                    },
                    "name": "Mingcong Lei",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:34:48.061Z",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddf6",
                    "name": "Ge Wang",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddf7",
                    "name": "Yiming Zhao",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddf8",
                    "name": "Zhixin Mai",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddf9",
                    "name": "Qing Zhao",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddfa",
                    "name": "Yao Guo",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddfb",
                    "name": "Zhen Li",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddfc",
                    "name": "Shuguang Cui",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddfd",
                    "name": "Yatong Han",
                    "hidden": false
                },
                {
                    "_id": "67c6ab3ec0b62d612c54ddfe",
                    "name": "Jinke Ren",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-02T04:50:59.000Z",
            "title": "CLEA: Closed-Loop Embodied Agent for Enhancing Task Execution in Dynamic\n  Environments",
            "summary": "Large Language Models (LLMs) exhibit remarkable capabilities in the\nhierarchical decomposition of complex tasks through semantic reasoning.\nHowever, their application in embodied systems faces challenges in ensuring\nreliable execution of subtask sequences and achieving one-shot success in\nlong-term task completion. To address these limitations in dynamic\nenvironments, we propose Closed-Loop Embodied Agent (CLEA) -- a novel\narchitecture incorporating four specialized open-source LLMs with functional\ndecoupling for closed-loop task management. The framework features two core\ninnovations: (1) Interactive task planner that dynamically generates executable\nsubtasks based on the environmental memory, and (2) Multimodal execution critic\nemploying an evaluation framework to conduct a probabilistic assessment of\naction feasibility, triggering hierarchical re-planning mechanisms when\nenvironmental perturbations exceed preset thresholds. To validate CLEA's\neffectiveness, we conduct experiments in a real environment with manipulable\nobjects, using two heterogeneous robots for object search, manipulation, and\nsearch-manipulation integration tasks. Across 12 task trials, CLEA outperforms\nthe baseline model, achieving a 67.3% improvement in success rate and a 52.8%\nincrease in task completion rate. These results demonstrate that CLEA\nsignificantly enhances the robustness of task planning and execution in dynamic\nenvironments.",
            "upvotes": 2,
            "discussionId": "67c6ab42c0b62d612c54df71",
            "projectPage": "https://sp4595.github.io/CLEA/",
            "githubRepo": "https://github.com/SP4595/CLEA-Closed-Loop-Embodied-Agent"
        },
        "publishedAt": "2025-03-04T02:27:17.351Z",
        "title": "CLEA: Closed-Loop Embodied Agent for Enhancing Task Execution in Dynamic Environments",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.00729.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6628c6107751d297d7025a71",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6628c6107751d297d7025a71/S1rm5VIwV2Uxfv8GetKMU.jpeg",
            "fullname": "Lei Mingcong",
            "name": "SP4595",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2502.20383",
            "authors": [
                {
                    "_id": "67c284e76e9f0735ea1c436d",
                    "user": {
                        "_id": "63e0b1925ba41def87930c47",
                        "avatarUrl": "/avatars/4d55fdbe979ddf72a21430d66518d24f.svg",
                        "isPro": false,
                        "fullname": "Jeffrey Yang Fan Chiang",
                        "user": "RandomHakkaDude",
                        "type": "user"
                    },
                    "name": "Jeffrey Yang Fan Chiang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-03-04T08:51:34.456Z",
                    "hidden": false
                },
                {
                    "_id": "67c284e76e9f0735ea1c436e",
                    "user": {
                        "_id": "64081a908dca6cec91caf136",
                        "avatarUrl": "/avatars/c45d7fcdf879f4d6020863fd3be39771.svg",
                        "isPro": false,
                        "fullname": "SeungJae Lee",
                        "user": "SeungJaeLee",
                        "type": "user"
                    },
                    "name": "Seungjae Lee",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T16:07:28.645Z",
                    "hidden": false
                },
                {
                    "_id": "67c284e76e9f0735ea1c436f",
                    "user": {
                        "_id": "641c139b73296f7ee256970c",
                        "avatarUrl": "/avatars/5a2550d95e686640242840ad3bd0e680.svg",
                        "isPro": false,
                        "fullname": "Jiabin Huang",
                        "user": "YellowAddice",
                        "type": "user"
                    },
                    "name": "Jia-Bin Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T16:07:55.181Z",
                    "hidden": false
                },
                {
                    "_id": "67c284e76e9f0735ea1c4370",
                    "user": {
                        "_id": "64cbc3e2a257a3212c00a115",
                        "avatarUrl": "/avatars/836e61be4aeda2080ddf2db9f2626cc6.svg",
                        "isPro": false,
                        "fullname": "Furong Huang Lab at UMD",
                        "user": "furongh-lab",
                        "type": "user"
                    },
                    "name": "Furong Huang",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T16:07:44.428Z",
                    "hidden": false
                },
                {
                    "_id": "67c284e76e9f0735ea1c4371",
                    "user": {
                        "_id": "660daf1d62d63ad000a53b9b",
                        "avatarUrl": "/avatars/2f79d4b7db395e94b614358c7f322efe.svg",
                        "isPro": false,
                        "fullname": "Yizheng Chen",
                        "user": "surrealyz",
                        "type": "user"
                    },
                    "name": "Yizheng Chen",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T16:07:37.149Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-02-27T18:56:26.000Z",
            "title": "Why Are Web AI Agents More Vulnerable Than Standalone LLMs? A Security\n  Analysis",
            "summary": "Recent advancements in Web AI agents have demonstrated remarkable\ncapabilities in addressing complex web navigation tasks. However, emerging\nresearch shows that these agents exhibit greater vulnerability compared to\nstandalone Large Language Models (LLMs), despite both being built upon the same\nsafety-aligned models. This discrepancy is particularly concerning given the\ngreater flexibility of Web AI Agent compared to standalone LLMs, which may\nexpose them to a wider range of adversarial user inputs. To build a scaffold\nthat addresses these concerns, this study investigates the underlying factors\nthat contribute to the increased vulnerability of Web AI agents. Notably, this\ndisparity stems from the multifaceted differences between Web AI agents and\nstandalone LLMs, as well as the complex signals - nuances that simple\nevaluation metrics, such as success rate, often fail to capture. To tackle\nthese challenges, we propose a component-level analysis and a more granular,\nsystematic evaluation framework. Through this fine-grained investigation, we\nidentify three critical factors that amplify the vulnerability of Web AI\nagents; (1) embedding user goals into the system prompt, (2) multi-step action\ngeneration, and (3) observational capabilities. Our findings highlights the\npressing need to enhance security and robustness in AI agent design and provide\nactionable insights for targeted defense strategies.",
            "upvotes": 1,
            "discussionId": "67c284e96e9f0735ea1c43dd",
            "projectPage": "https://vulnerable-ai-agents.github.io/"
        },
        "publishedAt": "2025-03-04T10:47:26.717Z",
        "title": "Why Are Web AI Agents More Vulnerable Than Standalone LLMs? A Security Analysis",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63e0b1925ba41def87930c47/OQIn8hn8i8nP9HMjOk5cR.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2502.20383.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63e0b1925ba41def87930c47",
            "avatarUrl": "/avatars/4d55fdbe979ddf72a21430d66518d24f.svg",
            "fullname": "Jeffrey Yang Fan Chiang",
            "name": "RandomHakkaDude",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2503.01063",
            "authors": [
                {
                    "_id": "67c6b72b7aad9a016ae60797",
                    "user": {
                        "_id": "63136a82e29fb2e86d5e5bdd",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63136a82e29fb2e86d5e5bdd/pFZDuQtzfUStovbwwZGvn.png",
                        "isPro": false,
                        "fullname": "David Noever",
                        "user": "dnoever",
                        "type": "user"
                    },
                    "name": "David Noever",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2025-03-04T11:17:50.200Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-03-02T23:59:52.000Z",
            "title": "AI-Invented Tonal Languages: Preventing a Machine Lingua Franca Beyond\n  Human Understanding",
            "summary": "This paper investigates the potential for large language models (LLMs) to\ndevelop private tonal languages for machine-to-machine (M2M) communication.\nInspired by cryptophasia in human twins (affecting up to 50% of twin births)\nand natural tonal languages like Mandarin and Vietnamese, we implement a\nprecise character-to-frequency mapping system that encodes the full ASCII\ncharacter set (32-126) using musical semitones. Each character is assigned a\nunique frequency, creating a logarithmic progression beginning with space (220\nHz) and ending with tilde (50,175.42 Hz). This spans approximately 7.9 octaves,\nwith higher characters deliberately mapped to ultrasonic frequencies beyond\nhuman perception (>20 kHz). Our implemented software prototype demonstrates\nthis encoding through visualization, auditory playback, and ABC musical\nnotation, allowing for analysis of information density and transmission speed.\nTesting reveals that tonal encoding can achieve information rates exceeding\nhuman speech while operating partially outside human perceptual boundaries.\nThis work responds directly to concerns about AI systems catastrophically\ndeveloping private languages within the next five years, providing a concrete\nprototype software example of how such communication might function and the\ntechnical foundation required for its emergence, detection, and governance.",
            "upvotes": 1,
            "discussionId": "67c6b72c7aad9a016ae607bb"
        },
        "publishedAt": "2025-03-04T03:20:03.380Z",
        "title": "AI-Invented Tonal Languages: Preventing a Machine Lingua Franca Beyond Human Understanding",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63136a82e29fb2e86d5e5bdd/mgIPjnhtUaGLR2Iv4ViL6.jpeg"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2503.01063.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63136a82e29fb2e86d5e5bdd",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/63136a82e29fb2e86d5e5bdd/pFZDuQtzfUStovbwwZGvn.png",
            "fullname": "David Noever",
            "name": "dnoever",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    }
]