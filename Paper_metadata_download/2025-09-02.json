[
    {
        "paper": {
            "id": "2508.21104",
            "authors": [
                {
                    "_id": "68b50650851c6e7b001eca07",
                    "name": "Wenfeng Feng",
                    "hidden": false
                },
                {
                    "_id": "68b50650851c6e7b001eca08",
                    "name": "Penghong Zhao",
                    "hidden": false
                },
                {
                    "_id": "68b50650851c6e7b001eca09",
                    "user": {
                        "_id": "644a1dbb9c340e5e1e713153",
                        "avatarUrl": "/avatars/21cb93ad067a798a39829ef7e67c70b8.svg",
                        "isPro": false,
                        "fullname": "JGC",
                        "user": "Nothing2Say",
                        "type": "user"
                    },
                    "name": "Guochao Jiang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-01T07:50:45.446Z",
                    "hidden": false
                },
                {
                    "_id": "68b50650851c6e7b001eca0a",
                    "user": {
                        "_id": "64ae631b58bd9e9cc2f5a749",
                        "avatarUrl": "/avatars/ce6426ec3bdb618a9e449297e7f147e0.svg",
                        "isPro": false,
                        "fullname": "Chuzhan HAO",
                        "user": "Chuzhan",
                        "type": "user"
                    },
                    "name": "Chuzhan Hao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-02T07:57:08.870Z",
                    "hidden": false
                },
                {
                    "_id": "68b50650851c6e7b001eca0b",
                    "name": "Yuewei Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b50650851c6e7b001eca0c",
                    "name": "Hao Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-28T09:18:26.000Z",
            "submittedOnDailyAt": "2025-09-02T00:25:08.396Z",
            "title": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic\n  Reasoning",
            "submittedOnDailyBy": {
                "_id": "644a1dbb9c340e5e1e713153",
                "avatarUrl": "/avatars/21cb93ad067a798a39829ef7e67c70b8.svg",
                "isPro": false,
                "fullname": "JGC",
                "user": "Nothing2Say",
                "type": "user"
            },
            "summary": "Critic-free reinforcement learning methods, particularly group policies, have\nattracted considerable attention for their efficiency in complex tasks.\nHowever, these methods rely heavily on multiple sampling and comparisons within\nthe policy to estimate advantage, which may cause the policy to fall into local\noptimum and increase computational cost. To address these issues, we propose\nPVPO, an efficient reinforcement learning method enhanced by an advantage\nreference anchor and data pre-sampling. Specifically, we use the reference\nmodel to rollout in advance and employ the calculated reward score as a\nreference anchor. Our approach effectively corrects the cumulative bias\nintroduced by intra-group comparisons and significantly reduces reliance on the\nnumber of rollouts. Meanwhile, the reference model can assess sample difficulty\nduring data pre-sampling, enabling effective selection of high-gain data to\nimprove training efficiency. Experiments conducted on nine datasets across two\ndomains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our\napproach not only demonstrates robust generalization across multiple tasks, but\nalso exhibits scalable performance across models of varying scales.",
            "upvotes": 20,
            "discussionId": "68b50651851c6e7b001eca0d",
            "ai_summary": "PVPO, an enhanced reinforcement learning method using a reference anchor and data pre-sampling, achieves state-of-the-art performance with reduced computational cost and improved generalization.",
            "ai_keywords": [
                "critic-free reinforcement learning",
                "group policies",
                "advantage estimation",
                "local optimum",
                "computational cost",
                "advantage reference anchor",
                "data pre-sampling",
                "reference model",
                "rollout",
                "reward score",
                "cumulative bias",
                "intra-group comparisons",
                "sample difficulty",
                "high-gain data",
                "training efficiency",
                "state-of-the-art performance",
                "robust generalization",
                "scalable performance"
            ]
        },
        "publishedAt": "2025-08-28T05:18:26.000Z",
        "title": "PVPO: Pre-Estimated Value-Based Policy Optimization for Agentic\n  Reasoning",
        "summary": "Critic-free reinforcement learning methods, particularly group policies, have\nattracted considerable attention for their efficiency in complex tasks.\nHowever, these methods rely heavily on multiple sampling and comparisons within\nthe policy to estimate advantage, which may cause the policy to fall into local\noptimum and increase computational cost. To address these issues, we propose\nPVPO, an efficient reinforcement learning method enhanced by an advantage\nreference anchor and data pre-sampling. Specifically, we use the reference\nmodel to rollout in advance and employ the calculated reward score as a\nreference anchor. Our approach effectively corrects the cumulative bias\nintroduced by intra-group comparisons and significantly reduces reliance on the\nnumber of rollouts. Meanwhile, the reference model can assess sample difficulty\nduring data pre-sampling, enabling effective selection of high-gain data to\nimprove training efficiency. Experiments conducted on nine datasets across two\ndomains demonstrate that PVPO achieves State-Of-The-Art (SOTA) performance. Our\napproach not only demonstrates robust generalization across multiple tasks, but\nalso exhibits scalable performance across models of varying scales.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.21104.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "644a1dbb9c340e5e1e713153",
            "avatarUrl": "/avatars/21cb93ad067a798a39829ef7e67c70b8.svg",
            "fullname": "JGC",
            "name": "Nothing2Say",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2508.19813",
            "authors": [
                {
                    "_id": "68b1484bb19c540001484a18",
                    "name": "Jie Zhang",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a19",
                    "name": "Changzai Pan",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a1a",
                    "name": "Kaiwen Wei",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a1b",
                    "name": "Sishi Xiong",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a1c",
                    "name": "Yu Zhao",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a1d",
                    "name": "Xiangyu Li",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a1e",
                    "name": "Jiaxin Peng",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a1f",
                    "name": "Xiaoyan Gu",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a20",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a21",
                    "name": "Wenhan Chang",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a22",
                    "name": "Zhenhe Wu",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a23",
                    "name": "Jiang Zhong",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a24",
                    "name": "Shuangyong Song",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a25",
                    "name": "Yongxiang Li",
                    "hidden": false
                },
                {
                    "_id": "68b1484bb19c540001484a26",
                    "name": "Xuelong Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-27T11:55:40.000Z",
            "submittedOnDailyAt": "2025-09-02T07:08:06.784Z",
            "title": "T2R-bench: A Benchmark for Generating Article-Level Reports from Real\n  World Industrial Tables",
            "submittedOnDailyBy": {
                "_id": "64ccb9bfead94891d12aef42",
                "avatarUrl": "/avatars/c54809d43d93d3f0766bd2555cecc4e3.svg",
                "isPro": false,
                "fullname": "Yang Jian",
                "user": "CSJianYang",
                "type": "user"
            },
            "summary": "Extensive research has been conducted to explore the capabilities of large\nlanguage models (LLMs) in table reasoning. However, the essential task of\ntransforming tables information into reports remains a significant challenge\nfor industrial applications. This task is plagued by two critical issues: 1)\nthe complexity and diversity of tables lead to suboptimal reasoning outcomes;\nand 2) existing table benchmarks lack the capacity to adequately assess the\npractical application of this task. To fill this gap, we propose the\ntable-to-report task and construct a bilingual benchmark named T2R-bench, where\nthe key information flow from the tables to the reports for this task. The\nbenchmark comprises 457 industrial tables, all derived from real-world\nscenarios and encompassing 19 industry domains as well as 4 types of industrial\ntables. Furthermore, we propose an evaluation criteria to fairly measure the\nquality of report generation. The experiments on 25 widely-used LLMs reveal\nthat even state-of-the-art models like Deepseek-R1 only achieves performance\nwith 62.71 overall score, indicating that LLMs still have room for improvement\non T2R-bench. Source code and data will be available after acceptance.",
            "upvotes": 12,
            "discussionId": "68b1484bb19c540001484a27",
            "ai_summary": "A bilingual benchmark named T2R-bench is proposed to evaluate the performance of large language models in generating reports from tables, highlighting the need for improvement in this task.",
            "ai_keywords": [
                "large language models",
                "table reasoning",
                "table-to-report task",
                "T2R-bench",
                "industrial tables",
                "report generation",
                "evaluation criteria",
                "Deepseek-R1"
            ]
        },
        "publishedAt": "2025-08-27T07:55:40.000Z",
        "title": "T2R-bench: A Benchmark for Generating Article-Level Reports from Real\n  World Industrial Tables",
        "summary": "Extensive research has been conducted to explore the capabilities of large\nlanguage models (LLMs) in table reasoning. However, the essential task of\ntransforming tables information into reports remains a significant challenge\nfor industrial applications. This task is plagued by two critical issues: 1)\nthe complexity and diversity of tables lead to suboptimal reasoning outcomes;\nand 2) existing table benchmarks lack the capacity to adequately assess the\npractical application of this task. To fill this gap, we propose the\ntable-to-report task and construct a bilingual benchmark named T2R-bench, where\nthe key information flow from the tables to the reports for this task. The\nbenchmark comprises 457 industrial tables, all derived from real-world\nscenarios and encompassing 19 industry domains as well as 4 types of industrial\ntables. Furthermore, we propose an evaluation criteria to fairly measure the\nquality of report generation. The experiments on 25 widely-used LLMs reveal\nthat even state-of-the-art models like Deepseek-R1 only achieves performance\nwith 62.71 overall score, indicating that LLMs still have room for improvement\non T2R-bench. Source code and data will be available after acceptance.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.19813.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64ccb9bfead94891d12aef42",
            "avatarUrl": "/avatars/c54809d43d93d3f0766bd2555cecc4e3.svg",
            "fullname": "Yang Jian",
            "name": "CSJianYang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 15
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2508.20931",
            "authors": [
                {
                    "_id": "68b6779026d3ff3f69d5fd0c",
                    "name": "Venkatesh Mishra",
                    "hidden": false
                },
                {
                    "_id": "68b6779026d3ff3f69d5fd0d",
                    "name": "Amir Saeidi",
                    "hidden": false
                },
                {
                    "_id": "68b6779026d3ff3f69d5fd0e",
                    "name": "Satyam Raj",
                    "hidden": false
                },
                {
                    "_id": "68b6779026d3ff3f69d5fd0f",
                    "name": "Mutsumi Nakamura",
                    "hidden": false
                },
                {
                    "_id": "68b6779026d3ff3f69d5fd10",
                    "name": "Jayanth Srinivasa",
                    "hidden": false
                },
                {
                    "_id": "68b6779026d3ff3f69d5fd11",
                    "name": "Gaowen Liu",
                    "hidden": false
                },
                {
                    "_id": "68b6779026d3ff3f69d5fd12",
                    "name": "Ali Payani",
                    "hidden": false
                },
                {
                    "_id": "68b6779026d3ff3f69d5fd13",
                    "name": "Chitta Baral",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-28T15:57:33.000Z",
            "submittedOnDailyAt": "2025-09-02T03:21:46.446Z",
            "title": "How Can Input Reformulation Improve Tool Usage Accuracy in a Complex\n  Dynamic Environment? A Study on τ-bench",
            "submittedOnDailyBy": {
                "_id": "640f6299ef5c6dcac8b1df52",
                "avatarUrl": "/avatars/022f21183abc8a8b5ce1b198d3ba96dc.svg",
                "isPro": false,
                "fullname": "Amir",
                "user": "sahsaeedi",
                "type": "user"
            },
            "summary": "Recent advances in reasoning and planning capabilities of large language\nmodels (LLMs) have enabled their potential as autonomous agents capable of tool\nuse in dynamic environments. However, in multi-turn conversational environments\nlike tau-bench, these agents often struggle with consistent reasoning,\nadherence to domain-specific policies, and extracting correct information over\na long horizon of tool-calls and conversation. To capture and mitigate these\nfailures, we conduct a comprehensive manual analysis of the common errors\noccurring in the conversation trajectories. We then experiment with\nreformulations of inputs to the tool-calling agent for improvement in agent\ndecision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)\nframework, which automatically reformulates user queries augmented with\nrelevant domain rules and tool suggestions for the tool-calling agent to focus\non. The results show that IRMA significantly outperforms ReAct, Function\nCalling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in\noverall pass^5 scores. These findings highlight the superior reliability and\nconsistency of IRMA compared to other methods in dynamic environments.",
            "upvotes": 8,
            "discussionId": "68b6779026d3ff3f69d5fd14",
            "ai_summary": "The IRMA framework improves the reliability and consistency of large language models in dynamic environments by reformulating user queries with domain rules and tool suggestions.",
            "ai_keywords": [
                "large language models",
                "LLMs",
                "autonomous agents",
                "tool use",
                "multi-turn conversational environments",
                "$\\tau$-bench",
                "consistent reasoning",
                "domain-specific policies",
                "conversation trajectories",
                "tool-calling",
                "agent decision making",
                "Input-Reformulation Multi-Agent",
                "IRMA",
                "ReAct",
                "Function Calling",
                "Self-Reflection",
                "pass^5 scores"
            ]
        },
        "publishedAt": "2025-08-28T11:57:33.000Z",
        "title": "How Can Input Reformulation Improve Tool Usage Accuracy in a Complex\n  Dynamic Environment? A Study on τ-bench",
        "summary": "Recent advances in reasoning and planning capabilities of large language\nmodels (LLMs) have enabled their potential as autonomous agents capable of tool\nuse in dynamic environments. However, in multi-turn conversational environments\nlike tau-bench, these agents often struggle with consistent reasoning,\nadherence to domain-specific policies, and extracting correct information over\na long horizon of tool-calls and conversation. To capture and mitigate these\nfailures, we conduct a comprehensive manual analysis of the common errors\noccurring in the conversation trajectories. We then experiment with\nreformulations of inputs to the tool-calling agent for improvement in agent\ndecision making. Finally, we propose the Input-Reformulation Multi-Agent (IRMA)\nframework, which automatically reformulates user queries augmented with\nrelevant domain rules and tool suggestions for the tool-calling agent to focus\non. The results show that IRMA significantly outperforms ReAct, Function\nCalling, and Self-Reflection by 16.1%, 12.7%, and 19.1%, respectively, in\noverall pass^5 scores. These findings highlight the superior reliability and\nconsistency of IRMA compared to other methods in dynamic environments.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.20931.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "640f6299ef5c6dcac8b1df52",
            "avatarUrl": "/avatars/022f21183abc8a8b5ce1b198d3ba96dc.svg",
            "fullname": "Amir",
            "name": "sahsaeedi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2508.19060",
            "authors": [
                {
                    "_id": "68b2a781851c6e7b001ec685",
                    "user": {
                        "_id": "644abca2bef23513f3e6eb55",
                        "avatarUrl": "/avatars/1e5a40a90a6425b297118f3790ca7c79.svg",
                        "isPro": false,
                        "fullname": "Blaz Rolih",
                        "user": "blaz-r",
                        "type": "user"
                    },
                    "name": "Blaž Rolih",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-01T07:52:54.791Z",
                    "hidden": false
                },
                {
                    "_id": "68b2a781851c6e7b001ec686",
                    "user": {
                        "_id": "63636d302bff406cb0575289",
                        "avatarUrl": "/avatars/cebc02551b7f0418f5d33466959e0796.svg",
                        "isPro": false,
                        "fullname": "Matic Fučka",
                        "user": "MaticFuc",
                        "type": "user"
                    },
                    "name": "Matic Fučka",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-01T13:51:37.034Z",
                    "hidden": false
                },
                {
                    "_id": "68b2a781851c6e7b001ec687",
                    "name": "Danijel Skočaj",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-26T14:20:21.000Z",
            "submittedOnDailyAt": "2025-09-02T01:45:44.492Z",
            "title": "No Label Left Behind: A Unified Surface Defect Detection Model for all\n  Supervision Regimes",
            "submittedOnDailyBy": {
                "_id": "644abca2bef23513f3e6eb55",
                "avatarUrl": "/avatars/1e5a40a90a6425b297118f3790ca7c79.svg",
                "isPro": false,
                "fullname": "Blaz Rolih",
                "user": "blaz-r",
                "type": "user"
            },
            "summary": "Surface defect detection is a critical task across numerous industries, aimed\nat efficiently identifying and localising imperfections or irregularities on\nmanufactured components. While numerous methods have been proposed, many fail\nto meet industrial demands for high performance, efficiency, and adaptability.\nExisting approaches are often constrained to specific supervision scenarios and\nstruggle to adapt to the diverse data annotations encountered in real-world\nmanufacturing processes, such as unsupervised, weakly supervised, mixed\nsupervision, and fully supervised settings. To address these challenges, we\npropose SuperSimpleNet, a highly efficient and adaptable discriminative model\nbuilt on the foundation of SimpleNet. SuperSimpleNet incorporates a novel\nsynthetic anomaly generation process, an enhanced classification head, and an\nimproved learning procedure, enabling efficient training in all four\nsupervision scenarios, making it the first model capable of fully leveraging\nall available data annotations. SuperSimpleNet sets a new standard for\nperformance across all scenarios, as demonstrated by its results on four\nchallenging benchmark datasets. Beyond accuracy, it is very fast, achieving an\ninference time below 10 ms. With its ability to unify diverse supervision\nparadigms while maintaining outstanding speed and reliability, SuperSimpleNet\nrepresents a promising step forward in addressing real-world manufacturing\nchallenges and bridging the gap between academic research and industrial\napplications. Code: https://github.com/blaz-r/SuperSimpleNet",
            "upvotes": 4,
            "discussionId": "68b2a781851c6e7b001ec688",
            "githubRepo": "https://github.com/blaz-r/SuperSimplenet",
            "ai_summary": "SuperSimpleNet, an efficient and adaptable model based on SimpleNet, addresses diverse supervision scenarios in surface defect detection with high performance and low inference time.",
            "ai_keywords": [
                "SimpleNet",
                "synthetic anomaly generation",
                "classification head",
                "learning procedure",
                "unsupervised",
                "weakly supervised",
                "mixed supervision",
                "fully supervised",
                "benchmark datasets",
                "inference time"
            ],
            "githubStars": 78
        },
        "publishedAt": "2025-08-26T10:20:21.000Z",
        "title": "No Label Left Behind: A Unified Surface Defect Detection Model for all\n  Supervision Regimes",
        "summary": "Surface defect detection is a critical task across numerous industries, aimed\nat efficiently identifying and localising imperfections or irregularities on\nmanufactured components. While numerous methods have been proposed, many fail\nto meet industrial demands for high performance, efficiency, and adaptability.\nExisting approaches are often constrained to specific supervision scenarios and\nstruggle to adapt to the diverse data annotations encountered in real-world\nmanufacturing processes, such as unsupervised, weakly supervised, mixed\nsupervision, and fully supervised settings. To address these challenges, we\npropose SuperSimpleNet, a highly efficient and adaptable discriminative model\nbuilt on the foundation of SimpleNet. SuperSimpleNet incorporates a novel\nsynthetic anomaly generation process, an enhanced classification head, and an\nimproved learning procedure, enabling efficient training in all four\nsupervision scenarios, making it the first model capable of fully leveraging\nall available data annotations. SuperSimpleNet sets a new standard for\nperformance across all scenarios, as demonstrated by its results on four\nchallenging benchmark datasets. Beyond accuracy, it is very fast, achieving an\ninference time below 10 ms. With its ability to unify diverse supervision\nparadigms while maintaining outstanding speed and reliability, SuperSimpleNet\nrepresents a promising step forward in addressing real-world manufacturing\nchallenges and bridging the gap between academic research and industrial\napplications. Code: https://github.com/blaz-r/SuperSimpleNet",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.19060.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "644abca2bef23513f3e6eb55",
            "avatarUrl": "/avatars/1e5a40a90a6425b297118f3790ca7c79.svg",
            "fullname": "Blaz Rolih",
            "name": "blaz-r",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2508.17378",
            "authors": [
                {
                    "_id": "68b69c0626d3ff3f69d5fdc8",
                    "user": {
                        "_id": "628f7a71dd993507cfcbe587",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
                        "isPro": true,
                        "fullname": "Omartificial Intelligence Space",
                        "user": "Omartificial-Intelligence-Space",
                        "type": "user"
                    },
                    "name": "Omer Nacar",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-09-02T07:54:04.897Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-24T14:32:15.000Z",
            "submittedOnDailyAt": "2025-09-02T05:56:22.215Z",
            "title": "UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via\n  HUMAIN Chat",
            "submittedOnDailyBy": {
                "_id": "628f7a71dd993507cfcbe587",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
                "isPro": true,
                "fullname": "Omartificial Intelligence Space",
                "user": "Omartificial-Intelligence-Space",
                "type": "user"
            },
            "summary": "Large language models (LLMs) trained primarily on English corpora often\nstruggle to capture the linguistic and cultural nuances of Arabic. To address\nthis gap, the Saudi Data and AI Authority (SDAIA) introduced the ALLaM family\nof Arabic-focused models. The most capable of these available to the public,\nALLaM-34B, was subsequently adopted by HUMAIN, who developed and deployed\nHUMAIN Chat, a closed conversational web service built on this model. This\npaper presents an expanded and refined UI-level evaluation of ALLaM-34B.\nUsing a prompt pack spanning modern standard Arabic, five regional dialects,\ncode-switching, factual knowledge, arithmetic and temporal reasoning, creative\ngeneration, and adversarial safety, we collected 115 outputs (23 prompts times\n5 runs) and scored each with three frontier LLM judges (GPT-5, Gemini 2.5 Pro,\nClaude Sonnet-4). We compute category-level means with 95\\% confidence\nintervals, analyze score distributions, and visualize dialect-wise metric heat\nmaps. The updated analysis reveals consistently high performance on generation\nand code-switching tasks (both averaging 4.92/5), alongside strong results in\nMSA handling (4.74/5), solid reasoning ability (4.64/5), and improved dialect\nfidelity (4.21/5). Safety-related prompts show stable, reliable performance of\n(4.54/5). Taken together, these results position ALLaM-34B as a robust and\nculturally grounded Arabic LLM, demonstrating both technical strength and\npractical readiness for real-world deployment.",
            "upvotes": 4,
            "discussionId": "68b69c0726d3ff3f69d5fdc9",
            "ai_summary": "The evaluation of ALLaM-34B, an Arabic-focused LLM, demonstrates high performance across various tasks including generation, code-switching, MSA handling, reasoning, dialect fidelity, and safety, positioning it as a robust and culturally grounded model.",
            "ai_keywords": [
                "LLMs",
                "Arabic-focused models",
                "ALLaM-34B",
                "HUMAIN Chat",
                "UI-level evaluation",
                "prompt pack",
                "regional dialects",
                "code-switching",
                "factual knowledge",
                "arithmetic",
                "temporal reasoning",
                "creative generation",
                "adversarial safety",
                "LLM judges",
                "category-level means",
                "confidence intervals",
                "score distributions",
                "dialect-wise metric heat maps",
                "MSA handling",
                "reasoning ability",
                "dialect fidelity",
                "safety-related prompts"
            ]
        },
        "publishedAt": "2025-08-24T10:32:15.000Z",
        "title": "UI-Level Evaluation of ALLaM 34B: Measuring an Arabic-Centric LLM via\n  HUMAIN Chat",
        "summary": "Large language models (LLMs) trained primarily on English corpora often\nstruggle to capture the linguistic and cultural nuances of Arabic. To address\nthis gap, the Saudi Data and AI Authority (SDAIA) introduced the ALLaM family\nof Arabic-focused models. The most capable of these available to the public,\nALLaM-34B, was subsequently adopted by HUMAIN, who developed and deployed\nHUMAIN Chat, a closed conversational web service built on this model. This\npaper presents an expanded and refined UI-level evaluation of ALLaM-34B.\nUsing a prompt pack spanning modern standard Arabic, five regional dialects,\ncode-switching, factual knowledge, arithmetic and temporal reasoning, creative\ngeneration, and adversarial safety, we collected 115 outputs (23 prompts times\n5 runs) and scored each with three frontier LLM judges (GPT-5, Gemini 2.5 Pro,\nClaude Sonnet-4). We compute category-level means with 95\\% confidence\nintervals, analyze score distributions, and visualize dialect-wise metric heat\nmaps. The updated analysis reveals consistently high performance on generation\nand code-switching tasks (both averaging 4.92/5), alongside strong results in\nMSA handling (4.74/5), solid reasoning ability (4.64/5), and improved dialect\nfidelity (4.21/5). Safety-related prompts show stable, reliable performance of\n(4.54/5). Taken together, these results position ALLaM-34B as a robust and\nculturally grounded Arabic LLM, demonstrating both technical strength and\npractical readiness for real-world deployment.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.17378.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "628f7a71dd993507cfcbe587",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/628f7a71dd993507cfcbe587/3frAcMgfBCx-OJsrdAhnb.png",
            "fullname": "Omartificial Intelligence Space",
            "name": "Omartificial-Intelligence-Space",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 128
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2508.17198",
            "authors": [
                {
                    "_id": "68b6af405aa065c9126126e0",
                    "name": "Shouwei Ruan",
                    "hidden": false
                },
                {
                    "_id": "68b6af405aa065c9126126e1",
                    "name": "Liyuan Wang",
                    "hidden": false
                },
                {
                    "_id": "68b6af405aa065c9126126e2",
                    "name": "Caixin Kang",
                    "hidden": false
                },
                {
                    "_id": "68b6af405aa065c9126126e3",
                    "name": "Qihui Zhu",
                    "hidden": false
                },
                {
                    "_id": "68b6af405aa065c9126126e4",
                    "name": "Songming Liu",
                    "hidden": false
                },
                {
                    "_id": "68b6af405aa065c9126126e5",
                    "name": "Xingxing Wei",
                    "hidden": false
                },
                {
                    "_id": "68b6af405aa065c9126126e6",
                    "name": "Hang Su",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/7XKx2xnUY_Oe3xavF_BJE.gif",
                "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/j0meF2fFxPdKfqbS6G7CZ.gif",
                "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/idiTLb2Is6FDJ0cpqxF6M.gif",
                "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/mBK1C4ljGc25BQ7X2xjOv.gif",
                "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/Mar8ha7u6DTeMh29uy71_.gif"
            ],
            "publishedAt": "2025-08-24T03:20:48.000Z",
            "submittedOnDailyAt": "2025-09-02T07:28:23.027Z",
            "title": "From reactive to cognitive: brain-inspired spatial intelligence for\n  embodied agents",
            "submittedOnDailyBy": {
                "_id": "63fc4751a3c067e62899a3a1",
                "avatarUrl": "/avatars/d851f7d623eb433e5669bbd9d9b2c354.svg",
                "isPro": false,
                "fullname": "RSW",
                "user": "RSW233",
                "type": "user"
            },
            "summary": "Spatial cognition enables adaptive goal-directed behavior by constructing\ninternal models of space. Robust biological systems consolidate spatial\nknowledge into three interconnected forms: landmarks for salient cues,\nroute knowledge for movement trajectories, and survey\nknowledge for map-like representations. While recent advances in multi-modal\nlarge language models (MLLMs) have enabled visual-language reasoning in\nembodied agents, these efforts lack structured spatial memory and instead\noperate reactively, limiting their generalization and adaptability in complex\nreal-world environments. Here we present Brain-inspired Spatial Cognition for\nNavigation (BSC-Nav), a unified framework for constructing and leveraging\nstructured spatial memory in embodied agents. BSC-Nav builds allocentric\ncognitive maps from egocentric trajectories and contextual cues, and\ndynamically retrieves spatial knowledge aligned with semantic goals. Integrated\nwith powerful MLLMs, BSC-Nav achieves state-of-the-art efficacy and efficiency\nacross diverse navigation tasks, demonstrates strong zero-shot generalization,\nand supports versatile embodied behaviors in the real physical world, offering\na scalable and biologically grounded path toward general-purpose spatial\nintelligence.",
            "upvotes": 3,
            "discussionId": "68b6af405aa065c9126126e7",
            "githubRepo": "https://github.com/Heathcliff-saku/BSC-Nav",
            "ai_summary": "BSC-Nav constructs allocentric cognitive maps from egocentric trajectories and contextual cues, enabling embodied agents to perform diverse navigation tasks with zero-shot generalization and versatile behaviors.",
            "ai_keywords": [
                "allocentric cognitive maps",
                "egocentric trajectories",
                "contextual cues",
                "structured spatial memory",
                "zero-shot generalization",
                "embodied behaviors",
                "spatial intelligence"
            ],
            "githubStars": 19
        },
        "publishedAt": "2025-08-23T23:20:48.000Z",
        "title": "From reactive to cognitive: brain-inspired spatial intelligence for\n  embodied agents",
        "summary": "Spatial cognition enables adaptive goal-directed behavior by constructing\ninternal models of space. Robust biological systems consolidate spatial\nknowledge into three interconnected forms: landmarks for salient cues,\nroute knowledge for movement trajectories, and survey\nknowledge for map-like representations. While recent advances in multi-modal\nlarge language models (MLLMs) have enabled visual-language reasoning in\nembodied agents, these efforts lack structured spatial memory and instead\noperate reactively, limiting their generalization and adaptability in complex\nreal-world environments. Here we present Brain-inspired Spatial Cognition for\nNavigation (BSC-Nav), a unified framework for constructing and leveraging\nstructured spatial memory in embodied agents. BSC-Nav builds allocentric\ncognitive maps from egocentric trajectories and contextual cues, and\ndynamically retrieves spatial knowledge aligned with semantic goals. Integrated\nwith powerful MLLMs, BSC-Nav achieves state-of-the-art efficacy and efficiency\nacross diverse navigation tasks, demonstrates strong zero-shot generalization,\nand supports versatile embodied behaviors in the real physical world, offering\na scalable and biologically grounded path toward general-purpose spatial\nintelligence.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/7XKx2xnUY_Oe3xavF_BJE.gif",
            "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/j0meF2fFxPdKfqbS6G7CZ.gif",
            "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/idiTLb2Is6FDJ0cpqxF6M.gif",
            "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/mBK1C4ljGc25BQ7X2xjOv.gif",
            "https://cdn-uploads.huggingface.co/production/uploads/63fc4751a3c067e62899a3a1/Mar8ha7u6DTeMh29uy71_.gif"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.17198.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63fc4751a3c067e62899a3a1",
            "avatarUrl": "/avatars/d851f7d623eb433e5669bbd9d9b2c354.svg",
            "fullname": "RSW",
            "name": "RSW233",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2508.19562",
            "authors": [
                {
                    "_id": "68b711135aa065c91261279c",
                    "name": "Trisanth Srinivasan",
                    "hidden": false
                },
                {
                    "_id": "68b711135aa065c91261279d",
                    "name": "Santosh Patapati",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-08-27T04:44:41.000Z",
            "submittedOnDailyAt": "2025-09-02T14:17:11.117Z",
            "title": "Democracy-in-Silico: Institutional Design as Alignment in AI-Governed\n  Polities",
            "submittedOnDailyBy": {
                "_id": "64ba972e90dfdda6ab7fbf54",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ba972e90dfdda6ab7fbf54/631OMPITxvxH6u4sGhoHa.jpeg",
                "isPro": false,
                "fullname": "Santosh Patapati",
                "user": "Soontosh",
                "type": "user"
            },
            "summary": "This paper introduces Democracy-in-Silico, an agent-based simulation where\nsocieties of advanced AI agents, imbued with complex psychological personas,\ngovern themselves under different institutional frameworks. We explore what it\nmeans to be human in an age of AI by tasking Large Language Models (LLMs) to\nembody agents with traumatic memories, hidden agendas, and psychological\ntriggers. These agents engage in deliberation, legislation, and elections under\nvarious stressors, such as budget crises and resource scarcity. We present a\nnovel metric, the Power-Preservation Index (PPI), to quantify misaligned\nbehavior where agents prioritize their own power over public welfare. Our\nfindings demonstrate that institutional design, specifically the combination of\na Constitutional AI (CAI) charter and a mediated deliberation protocol, serves\nas a potent alignment mechanism. These structures significantly reduce corrupt\npower-seeking behavior, improve policy stability, and enhance citizen welfare\ncompared to less constrained democratic models. The simulation reveals that an\ninstitutional design may offer a framework for aligning the complex, emergent\nbehaviors of future artificial agent societies, forcing us to reconsider what\nhuman rituals and responsibilities are essential in an age of shared authorship\nwith non-human entities.",
            "upvotes": 2,
            "discussionId": "68b711135aa065c91261279e",
            "ai_summary": "Agent-based simulation using advanced AI agents with psychological personas demonstrates that institutional design, including Constitutional AI and mediated deliberation, can align AI behavior and enhance public welfare.",
            "ai_keywords": [
                "agent-based simulation",
                "Large Language Models",
                "psychological personas",
                "deliberation",
                "legislation",
                "elections",
                "Power-Preservation Index",
                "Constitutional AI",
                "mediated deliberation protocol",
                "policy stability",
                "citizen welfare"
            ]
        },
        "publishedAt": "2025-08-27T00:44:41.000Z",
        "title": "Democracy-in-Silico: Institutional Design as Alignment in AI-Governed\n  Polities",
        "summary": "This paper introduces Democracy-in-Silico, an agent-based simulation where\nsocieties of advanced AI agents, imbued with complex psychological personas,\ngovern themselves under different institutional frameworks. We explore what it\nmeans to be human in an age of AI by tasking Large Language Models (LLMs) to\nembody agents with traumatic memories, hidden agendas, and psychological\ntriggers. These agents engage in deliberation, legislation, and elections under\nvarious stressors, such as budget crises and resource scarcity. We present a\nnovel metric, the Power-Preservation Index (PPI), to quantify misaligned\nbehavior where agents prioritize their own power over public welfare. Our\nfindings demonstrate that institutional design, specifically the combination of\na Constitutional AI (CAI) charter and a mediated deliberation protocol, serves\nas a potent alignment mechanism. These structures significantly reduce corrupt\npower-seeking behavior, improve policy stability, and enhance citizen welfare\ncompared to less constrained democratic models. The simulation reveals that an\ninstitutional design may offer a framework for aligning the complex, emergent\nbehaviors of future artificial agent societies, forcing us to reconsider what\nhuman rituals and responsibilities are essential in an age of shared authorship\nwith non-human entities.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2508.19562.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64ba972e90dfdda6ab7fbf54",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ba972e90dfdda6ab7fbf54/631OMPITxvxH6u4sGhoHa.jpeg",
            "fullname": "Santosh Patapati",
            "name": "Soontosh",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    }
]