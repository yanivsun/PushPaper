[
    {
        "paper": {
            "id": "2510.05096",
            "authors": [
                {
                    "_id": "68e479bfe4e093a7044e4d04",
                    "user": {
                        "_id": "66c45954ab8f09b10b7ab6a8",
                        "avatarUrl": "/avatars/f9946c775c4d70b8e044865ac34ef121.svg",
                        "isPro": false,
                        "fullname": "Zhu",
                        "user": "ZaynZhu",
                        "type": "user"
                    },
                    "name": "Zeyu Zhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:10.799Z",
                    "hidden": false
                },
                {
                    "_id": "68e479bfe4e093a7044e4d05",
                    "user": {
                        "_id": "64440be5af034cdfd69ca3a7",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg",
                        "isPro": false,
                        "fullname": "Qinghong (Kevin) Lin",
                        "user": "KevinQHLin",
                        "type": "user"
                    },
                    "name": "Kevin Qinghong Lin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:13.351Z",
                    "hidden": false
                },
                {
                    "_id": "68e479bfe4e093a7044e4d06",
                    "name": "Mike Zheng Shou",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/64440be5af034cdfd69ca3a7/7UBfF2Dt4zzFl8oAQsBrY.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/64440be5af034cdfd69ca3a7/uG-WApKKWLDEPeMdC9z1I.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/64440be5af034cdfd69ca3a7/M6UUqPDcw_dHIPQp4DelE.mp4"
            ],
            "publishedAt": "2025-10-06T17:58:02.000Z",
            "submittedOnDailyAt": "2025-10-07T01:03:40.404Z",
            "title": "Paper2Video: Automatic Video Generation from Scientific Papers",
            "submittedOnDailyBy": {
                "_id": "64440be5af034cdfd69ca3a7",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg",
                "isPro": false,
                "fullname": "Qinghong (Kevin) Lin",
                "user": "KevinQHLin",
                "type": "user"
            },
            "summary": "Academic presentation videos have become an essential medium for research\ncommunication, yet producing them remains highly labor-intensive, often\nrequiring hours of slide design, recording, and editing for a short 2 to 10\nminutes video. Unlike natural video, presentation video generation involves\ndistinctive challenges: inputs from research papers, dense multi-modal\ninformation (text, figures, tables), and the need to coordinate multiple\naligned channels such as slides, subtitles, speech, and human talker. To\naddress these challenges, we introduce PaperTalker, the first benchmark of 101\nresearch papers paired with author-created presentation videos, slides, and\nspeaker metadata. We further design four tailored evaluation metrics--Meta\nSimilarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos\nconvey the paper's information to the audience. Building on this foundation, we\npropose PaperTalker, the first multi-agent framework for academic presentation\nvideo generation. It integrates slide generation with effective layout\nrefinement by a novel effective tree search visual choice, cursor grounding,\nsubtitling, speech synthesis, and talking-head rendering, while parallelizing\nslide-wise generation for efficiency. Experiments on Paper2Video demonstrate\nthat the presentation videos produced by our approach are more faithful and\ninformative than existing baselines, establishing a practical step toward\nautomated and ready-to-use academic video generation. Our dataset, agent, and\ncode are available at https://github.com/showlab/Paper2Video.",
            "upvotes": 54,
            "discussionId": "68e479c0e4e093a7044e4d07",
            "projectPage": "https://showlab.github.io/Paper2Video/",
            "githubRepo": "https://github.com/showlab/Paper2Video",
            "ai_summary": "PaperTalker is a multi-agent framework that automates academic presentation video generation by integrating slide generation, layout refinement, subtitling, speech synthesis, and talking-head rendering, outperforming existing methods.",
            "ai_keywords": [
                "multi-agent framework",
                "slide generation",
                "layout refinement",
                "tree search visual choice",
                "cursor grounding",
                "subtitling",
                "speech synthesis",
                "talking-head rendering",
                "parallelization",
                "slide-wise generation"
            ],
            "githubStars": 56,
            "organization": {
                "_id": "63a553c4ce5763e06f78669c",
                "name": "showlab",
                "fullname": "Show Lab",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1671779505215-63a55320ce5763e06f78519c.png"
            }
        },
        "publishedAt": "2025-10-06T13:58:02.000Z",
        "title": "Paper2Video: Automatic Video Generation from Scientific Papers",
        "summary": "Academic presentation videos have become an essential medium for research\ncommunication, yet producing them remains highly labor-intensive, often\nrequiring hours of slide design, recording, and editing for a short 2 to 10\nminutes video. Unlike natural video, presentation video generation involves\ndistinctive challenges: inputs from research papers, dense multi-modal\ninformation (text, figures, tables), and the need to coordinate multiple\naligned channels such as slides, subtitles, speech, and human talker. To\naddress these challenges, we introduce PaperTalker, the first benchmark of 101\nresearch papers paired with author-created presentation videos, slides, and\nspeaker metadata. We further design four tailored evaluation metrics--Meta\nSimilarity, PresentArena, PresentQuiz, and IP Memory--to measure how videos\nconvey the paper's information to the audience. Building on this foundation, we\npropose PaperTalker, the first multi-agent framework for academic presentation\nvideo generation. It integrates slide generation with effective layout\nrefinement by a novel effective tree search visual choice, cursor grounding,\nsubtitling, speech synthesis, and talking-head rendering, while parallelizing\nslide-wise generation for efficiency. Experiments on Paper2Video demonstrate\nthat the presentation videos produced by our approach are more faithful and\ninformative than existing baselines, establishing a practical step toward\nautomated and ready-to-use academic video generation. Our dataset, agent, and\ncode are available at https://github.com/showlab/Paper2Video.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/64440be5af034cdfd69ca3a7/7UBfF2Dt4zzFl8oAQsBrY.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/64440be5af034cdfd69ca3a7/uG-WApKKWLDEPeMdC9z1I.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/64440be5af034cdfd69ca3a7/M6UUqPDcw_dHIPQp4DelE.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05096.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64440be5af034cdfd69ca3a7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64440be5af034cdfd69ca3a7/qmx24QiDFT29vleCxL9TX.jpeg",
            "fullname": "Qinghong (Kevin) Lin",
            "name": "KevinQHLin",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 35
        },
        "organization": {
            "_id": "63a553c4ce5763e06f78669c",
            "name": "showlab",
            "fullname": "Show Lab",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1671779505215-63a55320ce5763e06f78519c.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.03632",
            "authors": [
                {
                    "_id": "68e48b8be4e093a7044e4d97",
                    "user": {
                        "_id": "63fac64d6b75d93aa13616e0",
                        "avatarUrl": "/avatars/573be0f4fe4a206700aa972629e79abf.svg",
                        "isPro": false,
                        "fullname": "Jiaxi Li",
                        "user": "plusn",
                        "type": "user"
                    },
                    "name": "Jiaxi Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:32.513Z",
                    "hidden": false
                },
                {
                    "_id": "68e48b8be4e093a7044e4d98",
                    "user": {
                        "_id": "64beb6b6140491ca9f803ebf",
                        "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
                        "isPro": false,
                        "fullname": "Yucheng SHi",
                        "user": "YuchengShi",
                        "type": "user"
                    },
                    "name": "Yucheng Shi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:29.686Z",
                    "hidden": false
                },
                {
                    "_id": "68e48b8be4e093a7044e4d99",
                    "name": "Jin Lu",
                    "hidden": false
                },
                {
                    "_id": "68e48b8be4e093a7044e4d9a",
                    "name": "Ninghao Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-04T02:30:40.000Z",
            "submittedOnDailyAt": "2025-10-07T02:19:10.215Z",
            "title": "MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual\n  Information",
            "submittedOnDailyBy": {
                "_id": "64beb6b6140491ca9f803ebf",
                "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
                "isPro": false,
                "fullname": "Yucheng SHi",
                "user": "YuchengShi",
                "type": "user"
            },
            "summary": "Tree search has become as a representative framework for test-time reasoning\nwith large language models (LLMs), exemplified by methods such as\nTree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning\npaths. However, it remains difficult to provide instant and reliable\nquantitative assessments of intermediate reasoning step quality, and extensive\npath exploration is computationally costly. To address this, we propose Mutual\nInformation Tree Search (MITS), a novel framework that guides reasoning with\ninformation-theoretic principles. MITS introduces an effective scoring function\nbased on pointwise mutual information (PMI), which enables step-wise evaluation\nof reasoning paths and search tree expansion via beam search without expensive\nlook-ahead simulations, achieving superior reasoning performances while\nmaintaining computational efficiency. The framework is complemented by an\nentropy-based dynamic sampling strategy that adaptively allocates computational\nresources to uncertain reasoning steps where exploration is most beneficial.\nFor final prediction, MITS employs a weighted voting scheme that combines PMI\nscores with prediction consensus. Through comprehensive experiments on diverse\nreasoning benchmarks, MITS consistently surpasses baseline methods,\nestablishing a principled and efficient framework for LLM reasoning.",
            "upvotes": 35,
            "discussionId": "68e48b8ce4e093a7044e4d9b",
            "ai_summary": "Mutual Information Tree Search (MITS) uses information-theoretic principles to guide and evaluate reasoning paths in large language models, improving performance and efficiency.",
            "ai_keywords": [
                "Mutual Information Tree Search",
                "MITS",
                "pointwise mutual information",
                "PMI",
                "beam search",
                "entropy-based dynamic sampling",
                "weighted voting scheme",
                "reasoning paths",
                "search tree expansion",
                "information-theoretic principles"
            ],
            "organization": {
                "_id": "657e54cc3687559a676eba62",
                "name": "UGA-AI",
                "fullname": "University of Georgia",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/625de37b0bec31f086e32989/D64_Jh2Os7ZU4lrySuzvT.png"
            }
        },
        "publishedAt": "2025-10-03T22:30:40.000Z",
        "title": "MITS: Enhanced Tree Search Reasoning for LLMs via Pointwise Mutual\n  Information",
        "summary": "Tree search has become as a representative framework for test-time reasoning\nwith large language models (LLMs), exemplified by methods such as\nTree-of-Thought and Monte Carlo Tree Search that explore multiple reasoning\npaths. However, it remains difficult to provide instant and reliable\nquantitative assessments of intermediate reasoning step quality, and extensive\npath exploration is computationally costly. To address this, we propose Mutual\nInformation Tree Search (MITS), a novel framework that guides reasoning with\ninformation-theoretic principles. MITS introduces an effective scoring function\nbased on pointwise mutual information (PMI), which enables step-wise evaluation\nof reasoning paths and search tree expansion via beam search without expensive\nlook-ahead simulations, achieving superior reasoning performances while\nmaintaining computational efficiency. The framework is complemented by an\nentropy-based dynamic sampling strategy that adaptively allocates computational\nresources to uncertain reasoning steps where exploration is most beneficial.\nFor final prediction, MITS employs a weighted voting scheme that combines PMI\nscores with prediction consensus. Through comprehensive experiments on diverse\nreasoning benchmarks, MITS consistently surpasses baseline methods,\nestablishing a principled and efficient framework for LLM reasoning.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03632.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64beb6b6140491ca9f803ebf",
            "avatarUrl": "/avatars/0daa2e813a13668b8b708cd8c12763d9.svg",
            "fullname": "Yucheng SHi",
            "name": "YuchengShi",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "organization": {
            "_id": "657e54cc3687559a676eba62",
            "name": "UGA-AI",
            "fullname": "University of Georgia",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/625de37b0bec31f086e32989/D64_Jh2Os7ZU4lrySuzvT.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05034",
            "authors": [
                {
                    "_id": "68e47fd5e4e093a7044e4d3c",
                    "user": {
                        "_id": "6344c87f0f69ad8aa61dfcf6",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6344c87f0f69ad8aa61dfcf6/tTVHu2l2aiAnK160vgT6u.jpeg",
                        "isPro": false,
                        "fullname": "Yolo Y. Tang",
                        "user": "yunlong10",
                        "type": "user"
                    },
                    "name": "Yunlong Tang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:53.963Z",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d3d",
                    "name": "Jing Bi",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d3e",
                    "name": "Pinxin Liu",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d3f",
                    "user": {
                        "_id": "669794c5813d96b4eb0b3fd6",
                        "avatarUrl": "/avatars/b4e2bb7b07cc281932d783dcbb64f211.svg",
                        "isPro": false,
                        "fullname": "Zhenyu Pan",
                        "user": "zhenyupan",
                        "type": "user"
                    },
                    "name": "Zhenyu Pan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:51.453Z",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d40",
                    "name": "Zhangyun Tan",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d41",
                    "name": "Qianxiang Shen",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d42",
                    "name": "Jiani Liu",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d43",
                    "name": "Hang Hua",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d44",
                    "name": "Junjia Guo",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d45",
                    "name": "Yunzhong Xiao",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d46",
                    "name": "Chao Huang",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d47",
                    "name": "Zhiyuan Wang",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d48",
                    "name": "Susan Liang",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d49",
                    "name": "Xinyi Liu",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d4a",
                    "name": "Yizhi Song",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d4b",
                    "name": "Yuhe Nie",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d4c",
                    "name": "Jia-Xing Zhong",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d4d",
                    "name": "Bozheng Li",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d4e",
                    "user": {
                        "_id": "649e469cab5656f6acbd6d1d",
                        "avatarUrl": "/avatars/774942d6268a9d3fadccb058bd9e8b90.svg",
                        "isPro": false,
                        "fullname": "Daiqing Qi",
                        "user": "Daiqingq",
                        "type": "user"
                    },
                    "name": "Daiqing Qi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:43.897Z",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d4f",
                    "name": "Ziyun Zeng",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d50",
                    "user": {
                        "_id": "65c16eb788812bbe20224c75",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/P7xg4ryhWZrfOkHYRS1QI.jpeg",
                        "isPro": false,
                        "fullname": "Ali Vosoughi",
                        "user": "ali-vosoughi",
                        "type": "user"
                    },
                    "name": "Ali Vosoughi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:56.370Z",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d51",
                    "name": "Luchuan Song",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d52",
                    "user": {
                        "_id": "66805e103dd5f4c44c1c939a",
                        "avatarUrl": "/avatars/ef2eebf1d61f86dde3397471ca180b95.svg",
                        "isPro": false,
                        "fullname": "Zeliang Zhang",
                        "user": "zeliang0426",
                        "type": "user"
                    },
                    "name": "Zeliang Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:49.355Z",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d53",
                    "name": "Daiki Shimada",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d54",
                    "name": "Han Liu",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d55",
                    "name": "Jiebo Luo",
                    "hidden": false
                },
                {
                    "_id": "68e47fd5e4e093a7044e4d56",
                    "name": "Chenliang Xu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T17:10:44.000Z",
            "submittedOnDailyAt": "2025-10-07T01:20:07.507Z",
            "title": "Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large\n  Multimodal Models",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Video understanding represents the most challenging frontier in computer\nvision, requiring models to reason about complex spatiotemporal relationships,\nlong-term dependencies, and multimodal evidence. The recent emergence of\nVideo-Large Multimodal Models (Video-LMMs), which integrate visual encoders\nwith powerful decoder-based language models, has demonstrated remarkable\ncapabilities in video understanding tasks. However, the critical phase that\ntransforms these models from basic perception systems into sophisticated\nreasoning engines, post-training, remains fragmented across the literature.\nThis survey provides the first comprehensive examination of post-training\nmethodologies for Video-LMMs, encompassing three fundamental pillars:\nsupervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL)\nfrom verifiable objectives, and test-time scaling (TTS) through enhanced\ninference computation. We present a structured taxonomy that clarifies the\nroles, interconnections, and video-specific adaptations of these techniques,\naddressing unique challenges such as temporal localization, spatiotemporal\ngrounding, long video efficiency, and multimodal evidence integration. Through\nsystematic analysis of representative methods, we synthesize key design\nprinciples, insights, and evaluation protocols while identifying critical open\nchallenges in reward design, scalability, and cost-performance optimization. We\nfurther curate essential benchmarks, datasets, and metrics to facilitate\nrigorous assessment of post-training effectiveness. This survey aims to provide\nresearchers and practitioners with a unified framework for advancing Video-LMM\ncapabilities. Additional resources and updates are maintained at:\nhttps://github.com/yunlong10/Awesome-Video-LMM-Post-Training",
            "upvotes": 34,
            "discussionId": "68e47fd5e4e093a7044e4d57",
            "githubRepo": "https://github.com/yunlong10/Awesome-Video-LMM-Post-Training",
            "ai_summary": "This survey examines post-training methodologies for Video-LMMs, focusing on supervised fine-tuning, reinforcement learning, and test-time scaling, while addressing challenges in video understanding.",
            "ai_keywords": [
                "Video-LMMs",
                "supervised fine-tuning",
                "reinforcement learning",
                "test-time scaling",
                "temporal localization",
                "spatiotemporal grounding",
                "long video efficiency",
                "multimodal evidence integration",
                "reward design",
                "scalability",
                "cost-performance optimization"
            ],
            "githubStars": 34
        },
        "publishedAt": "2025-10-06T13:10:44.000Z",
        "title": "Video-LMM Post-Training: A Deep Dive into Video Reasoning with Large\n  Multimodal Models",
        "summary": "Video understanding represents the most challenging frontier in computer\nvision, requiring models to reason about complex spatiotemporal relationships,\nlong-term dependencies, and multimodal evidence. The recent emergence of\nVideo-Large Multimodal Models (Video-LMMs), which integrate visual encoders\nwith powerful decoder-based language models, has demonstrated remarkable\ncapabilities in video understanding tasks. However, the critical phase that\ntransforms these models from basic perception systems into sophisticated\nreasoning engines, post-training, remains fragmented across the literature.\nThis survey provides the first comprehensive examination of post-training\nmethodologies for Video-LMMs, encompassing three fundamental pillars:\nsupervised fine-tuning (SFT) with chain-of-thought, reinforcement learning (RL)\nfrom verifiable objectives, and test-time scaling (TTS) through enhanced\ninference computation. We present a structured taxonomy that clarifies the\nroles, interconnections, and video-specific adaptations of these techniques,\naddressing unique challenges such as temporal localization, spatiotemporal\ngrounding, long video efficiency, and multimodal evidence integration. Through\nsystematic analysis of representative methods, we synthesize key design\nprinciples, insights, and evaluation protocols while identifying critical open\nchallenges in reward design, scalability, and cost-performance optimization. We\nfurther curate essential benchmarks, datasets, and metrics to facilitate\nrigorous assessment of post-training effectiveness. This survey aims to provide\nresearchers and practitioners with a unified framework for advancing Video-LMM\ncapabilities. Additional resources and updates are maintained at:\nhttps://github.com/yunlong10/Awesome-Video-LMM-Post-Training",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05034.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 119
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05094",
            "authors": [
                {
                    "_id": "68e47f85e4e093a7044e4d34",
                    "user": {
                        "_id": "60efe7fa0d920bc7805cada5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60efe7fa0d920bc7805cada5/2LBrJBjSCOP5ilZIpWLHl.png",
                        "isPro": false,
                        "fullname": "Ziqi Huang",
                        "user": "Ziqi",
                        "type": "user"
                    },
                    "name": "Ziqi Huang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:00.662Z",
                    "hidden": false
                },
                {
                    "_id": "68e47f85e4e093a7044e4d35",
                    "name": "Ning Yu",
                    "hidden": false
                },
                {
                    "_id": "68e47f85e4e093a7044e4d36",
                    "user": {
                        "_id": "65cf1549c1912289ca0b24cf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65cf1549c1912289ca0b24cf/kLCDspsG4HUjRTV6634nC.jpeg",
                        "isPro": false,
                        "fullname": "Gordon Chen",
                        "user": "gchen019",
                        "type": "user"
                    },
                    "name": "Gordon Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:58.557Z",
                    "hidden": false
                },
                {
                    "_id": "68e47f85e4e093a7044e4d37",
                    "name": "Haonan Qiu",
                    "hidden": false
                },
                {
                    "_id": "68e47f85e4e093a7044e4d38",
                    "name": "Paul Debevec",
                    "hidden": false
                },
                {
                    "_id": "68e47f85e4e093a7044e4d39",
                    "name": "Ziwei Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T17:57:59.000Z",
            "submittedOnDailyAt": "2025-10-07T01:18:50.036Z",
            "title": "VChain: Chain-of-Visual-Thought for Reasoning in Video Generation",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Recent video generation models can produce smooth and visually appealing\nclips, but they often struggle to synthesize complex dynamics with a coherent\nchain of consequences. Accurately modeling visual outcomes and state\ntransitions over time remains a core challenge. In contrast, large language and\nmultimodal models (e.g., GPT-4o) exhibit strong visual state reasoning and\nfuture prediction capabilities. To bridge these strengths, we introduce VChain,\na novel inference-time chain-of-visual-thought framework that injects visual\nreasoning signals from multimodal models into video generation. Specifically,\nVChain contains a dedicated pipeline that leverages large multimodal models to\ngenerate a sparse set of critical keyframes as snapshots, which are then used\nto guide the sparse inference-time tuning of a pre-trained video generator only\nat these key moments. Our approach is tuning-efficient, introduces minimal\noverhead and avoids dense supervision. Extensive experiments on complex,\nmulti-step scenarios show that VChain significantly enhances the quality of\ngenerated videos.",
            "upvotes": 31,
            "discussionId": "68e47f86e4e093a7044e4d3a",
            "projectPage": "https://eyeline-labs.github.io/VChain/",
            "githubRepo": "https://github.com/Eyeline-Labs/VChain",
            "ai_summary": "VChain enhances video generation by integrating visual reasoning from multimodal models to guide sparse tuning of a pre-trained video generator.",
            "ai_keywords": [
                "video generation",
                "visual reasoning",
                "multimodal models",
                "keyframes",
                "sparse inference-time tuning",
                "pre-trained video generator"
            ],
            "githubStars": 23
        },
        "publishedAt": "2025-10-06T13:57:59.000Z",
        "title": "VChain: Chain-of-Visual-Thought for Reasoning in Video Generation",
        "summary": "Recent video generation models can produce smooth and visually appealing\nclips, but they often struggle to synthesize complex dynamics with a coherent\nchain of consequences. Accurately modeling visual outcomes and state\ntransitions over time remains a core challenge. In contrast, large language and\nmultimodal models (e.g., GPT-4o) exhibit strong visual state reasoning and\nfuture prediction capabilities. To bridge these strengths, we introduce VChain,\na novel inference-time chain-of-visual-thought framework that injects visual\nreasoning signals from multimodal models into video generation. Specifically,\nVChain contains a dedicated pipeline that leverages large multimodal models to\ngenerate a sparse set of critical keyframes as snapshots, which are then used\nto guide the sparse inference-time tuning of a pre-trained video generator only\nat these key moments. Our approach is tuning-efficient, introduces minimal\noverhead and avoids dense supervision. Extensive experiments on complex,\nmulti-step scenarios show that VChain significantly enhances the quality of\ngenerated videos.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05094.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 119
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05025",
            "authors": [
                {
                    "_id": "68e4bd9ce4e093a7044e4e48",
                    "name": "Kuofeng Gao",
                    "hidden": false
                },
                {
                    "_id": "68e4bd9ce4e093a7044e4e49",
                    "name": "Yiming Li",
                    "hidden": false
                },
                {
                    "_id": "68e4bd9ce4e093a7044e4e4a",
                    "name": "Chao Du",
                    "hidden": false
                },
                {
                    "_id": "68e4bd9ce4e093a7044e4e4b",
                    "name": "Xin Wang",
                    "hidden": false
                },
                {
                    "_id": "68e4bd9ce4e093a7044e4e4c",
                    "name": "Xingjun Ma",
                    "hidden": false
                },
                {
                    "_id": "68e4bd9ce4e093a7044e4e4d",
                    "name": "Shu-Tao Xia",
                    "hidden": false
                },
                {
                    "_id": "68e4bd9ce4e093a7044e4e4e",
                    "name": "Tianyu Pang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T17:03:50.000Z",
            "submittedOnDailyAt": "2025-10-07T05:44:35.041Z",
            "title": "Imperceptible Jailbreaking against Large Language Models",
            "submittedOnDailyBy": {
                "_id": "63d91b6d255ef6add20e1b38",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675921369867-63d91b6d255ef6add20e1b38.jpeg",
                "isPro": false,
                "fullname": "Tianyu Pang",
                "user": "P2333",
                "type": "user"
            },
            "summary": "Jailbreaking attacks on the vision modality typically rely on imperceptible\nadversarial perturbations, whereas attacks on the textual modality are\ngenerally assumed to require visible modifications (e.g., non-semantic\nsuffixes). In this paper, we introduce imperceptible jailbreaks that exploit a\nclass of Unicode characters called variation selectors. By appending invisible\nvariation selectors to malicious questions, the jailbreak prompts appear\nvisually identical to original malicious questions on screen, while their\ntokenization is \"secretly\" altered. We propose a chain-of-search pipeline to\ngenerate such adversarial suffixes to induce harmful responses. Our experiments\nshow that our imperceptible jailbreaks achieve high attack success rates\nagainst four aligned LLMs and generalize to prompt injection attacks, all\nwithout producing any visible modifications in the written prompt. Our code is\navailable at https://github.com/sail-sg/imperceptible-jailbreaks.",
            "upvotes": 26,
            "discussionId": "68e4bd9de4e093a7044e4e4f",
            "ai_summary": "Imperceptible jailbreaks using Unicode variation selectors enable high attack success rates against aligned LLMs without visible prompt modifications.",
            "ai_keywords": [
                "adversarial perturbations",
                "Unicode characters",
                "variation selectors",
                "tokenization",
                "chain-of-search pipeline",
                "prompt injection attacks",
                "aligned LLMs"
            ],
            "organization": {
                "_id": "61f4e841c771e23a1abb61ff",
                "name": "sail",
                "fullname": "Sea AI Lab",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1643440185801-5df833bdda6d0311fd3d5403.png"
            }
        },
        "publishedAt": "2025-10-06T13:03:50.000Z",
        "title": "Imperceptible Jailbreaking against Large Language Models",
        "summary": "Jailbreaking attacks on the vision modality typically rely on imperceptible\nadversarial perturbations, whereas attacks on the textual modality are\ngenerally assumed to require visible modifications (e.g., non-semantic\nsuffixes). In this paper, we introduce imperceptible jailbreaks that exploit a\nclass of Unicode characters called variation selectors. By appending invisible\nvariation selectors to malicious questions, the jailbreak prompts appear\nvisually identical to original malicious questions on screen, while their\ntokenization is \"secretly\" altered. We propose a chain-of-search pipeline to\ngenerate such adversarial suffixes to induce harmful responses. Our experiments\nshow that our imperceptible jailbreaks achieve high attack success rates\nagainst four aligned LLMs and generalize to prompt injection attacks, all\nwithout producing any visible modifications in the written prompt. Our code is\navailable at https://github.com/sail-sg/imperceptible-jailbreaks.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05025.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63d91b6d255ef6add20e1b38",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1675921369867-63d91b6d255ef6add20e1b38.jpeg",
            "fullname": "Tianyu Pang",
            "name": "P2333",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 8
        },
        "organization": {
            "_id": "61f4e841c771e23a1abb61ff",
            "name": "sail",
            "fullname": "Sea AI Lab",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1643440185801-5df833bdda6d0311fd3d5403.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.04800",
            "authors": [
                {
                    "_id": "68e47d99e4e093a7044e4d1d",
                    "user": {
                        "_id": "6602ca1e10a1441af41637be",
                        "avatarUrl": "/avatars/5880e699def320beb352cbed77495b2f.svg",
                        "isPro": false,
                        "fullname": "Sangmin Bae",
                        "user": "raymin0223",
                        "type": "user"
                    },
                    "name": "Sangmin Bae",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:08.113Z",
                    "hidden": false
                },
                {
                    "_id": "68e47d99e4e093a7044e4d1e",
                    "name": "Bilge Acun",
                    "hidden": false
                },
                {
                    "_id": "68e47d99e4e093a7044e4d1f",
                    "name": "Haroun Habeeb",
                    "hidden": false
                },
                {
                    "_id": "68e47d99e4e093a7044e4d20",
                    "name": "Seungyeon Kim",
                    "hidden": false
                },
                {
                    "_id": "68e47d99e4e093a7044e4d21",
                    "name": "Chien-Yu Lin",
                    "hidden": false
                },
                {
                    "_id": "68e47d99e4e093a7044e4d22",
                    "name": "Liang Luo",
                    "hidden": false
                },
                {
                    "_id": "68e47d99e4e093a7044e4d23",
                    "name": "Junjie Wang",
                    "hidden": false
                },
                {
                    "_id": "68e47d99e4e093a7044e4d24",
                    "name": "Carole-Jean Wu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T13:30:07.000Z",
            "submittedOnDailyAt": "2025-10-07T01:13:05.768Z",
            "title": "Hybrid Architectures for Language Models: Systematic Analysis and Design\n  Insights",
            "submittedOnDailyBy": {
                "_id": "6602ca1e10a1441af41637be",
                "avatarUrl": "/avatars/5880e699def320beb352cbed77495b2f.svg",
                "isPro": false,
                "fullname": "Sangmin Bae",
                "user": "raymin0223",
                "type": "user"
            },
            "summary": "Recent progress in large language models demonstrates that hybrid\narchitectures--combining self-attention mechanisms with structured state space\nmodels like Mamba--can achieve a compelling balance between modeling quality\nand computational efficiency, particularly for long-context tasks. While these\nhybrid models show promising performance, systematic comparisons of\nhybridization strategies and analyses on the key factors behind their\neffectiveness have not been clearly shared to the community. In this work, we\npresent a holistic evaluation of hybrid architectures based on inter-layer\n(sequential) or intra-layer (parallel) fusion. We evaluate these designs from a\nvariety of perspectives: language modeling performance, long-context\ncapabilities, scaling analysis, and training and inference efficiency. By\ninvestigating the core characteristics of their computational primitive, we\nidentify the most critical elements for each hybridization strategy and further\npropose optimal design recipes for both hybrid models. Our comprehensive\nanalysis provides practical guidance and valuable insights for developing\nhybrid language models, facilitating the optimization of architectural\nconfigurations.",
            "upvotes": 23,
            "discussionId": "68e47d99e4e093a7044e4d25",
            "ai_summary": "A comprehensive evaluation of hybrid language models combining self-attention with structured state space models, analyzing inter-layer and intra-layer fusion strategies, and providing design recommendations.",
            "ai_keywords": [
                "self-attention mechanisms",
                "structured state space models",
                "Mamba",
                "hybrid architectures",
                "inter-layer fusion",
                "intra-layer fusion",
                "language modeling performance",
                "long-context capabilities",
                "scaling analysis",
                "training efficiency",
                "inference efficiency",
                "computational primitive"
            ],
            "organization": {
                "_id": "689f81c63080d12247c8f067",
                "name": "MetaSuperintelligenceLab",
                "fullname": "MetaSuperintelligenceLab"
            }
        },
        "publishedAt": "2025-10-06T09:30:07.000Z",
        "title": "Hybrid Architectures for Language Models: Systematic Analysis and Design\n  Insights",
        "summary": "Recent progress in large language models demonstrates that hybrid\narchitectures--combining self-attention mechanisms with structured state space\nmodels like Mamba--can achieve a compelling balance between modeling quality\nand computational efficiency, particularly for long-context tasks. While these\nhybrid models show promising performance, systematic comparisons of\nhybridization strategies and analyses on the key factors behind their\neffectiveness have not been clearly shared to the community. In this work, we\npresent a holistic evaluation of hybrid architectures based on inter-layer\n(sequential) or intra-layer (parallel) fusion. We evaluate these designs from a\nvariety of perspectives: language modeling performance, long-context\ncapabilities, scaling analysis, and training and inference efficiency. By\ninvestigating the core characteristics of their computational primitive, we\nidentify the most critical elements for each hybridization strategy and further\npropose optimal design recipes for both hybrid models. Our comprehensive\nanalysis provides practical guidance and valuable insights for developing\nhybrid language models, facilitating the optimization of architectural\nconfigurations.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04800.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6602ca1e10a1441af41637be",
            "avatarUrl": "/avatars/5880e699def320beb352cbed77495b2f.svg",
            "fullname": "Sangmin Bae",
            "name": "raymin0223",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "689f81c63080d12247c8f067",
            "name": "MetaSuperintelligenceLab",
            "fullname": "MetaSuperintelligenceLab"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04618",
            "authors": [
                {
                    "_id": "68e48815e4e093a7044e4d75",
                    "name": "Qizheng Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d76",
                    "name": "Changran Hu",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d77",
                    "name": "Shubhangi Upasani",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d78",
                    "name": "Boyuan Ma",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d79",
                    "name": "Fenglu Hong",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d7a",
                    "name": "Vamsidhar Kamanuru",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d7b",
                    "name": "Jay Rainton",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d7c",
                    "name": "Chen Wu",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d7d",
                    "name": "Mengmeng Ji",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d7e",
                    "name": "Hanchen Li",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d7f",
                    "name": "Urmish Thakker",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d80",
                    "name": "James Zou",
                    "hidden": false
                },
                {
                    "_id": "68e48815e4e093a7044e4d81",
                    "name": "Kunle Olukotun",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T09:30:18.000Z",
            "submittedOnDailyAt": "2025-10-07T01:55:17.863Z",
            "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving\n  Language Models",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Large language model (LLM) applications such as agents and domain-specific\nreasoning increasingly rely on context adaptation -- modifying inputs with\ninstructions, strategies, or evidence, rather than weight updates. Prior\napproaches improve usability but often suffer from brevity bias, which drops\ndomain insights for concise summaries, and from context collapse, where\niterative rewriting erodes details over time. Building on the adaptive memory\nintroduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context\nEngineering), a framework that treats contexts as evolving playbooks that\naccumulate, refine, and organize strategies through a modular process of\ngeneration, reflection, and curation. ACE prevents collapse with structured,\nincremental updates that preserve detailed knowledge and scale with\nlong-context models. Across agent and domain-specific benchmarks, ACE optimizes\ncontexts both offline (e.g., system prompts) and online (e.g., agent memory),\nconsistently outperforming strong baselines: +10.6% on agents and +8.6% on\nfinance, while significantly reducing adaptation latency and rollout cost.\nNotably, ACE could adapt effectively without labeled supervision and instead by\nleveraging natural execution feedback. On the AppWorld leaderboard, ACE matches\nthe top-ranked production-level agent on the overall average and surpasses it\non the harder test-challenge split, despite using a smaller open-source model.\nThese results show that comprehensive, evolving contexts enable scalable,\nefficient, and self-improving LLM systems with low overhead.",
            "upvotes": 23,
            "discussionId": "68e48815e4e093a7044e4d82",
            "ai_summary": "ACE, a framework for adaptive context engineering, enhances LLM applications by preserving detailed knowledge through structured updates, outperforming baselines in agent and domain-specific tasks with reduced adaptation costs.",
            "ai_keywords": [
                "Large language model",
                "context adaptation",
                "Dynamic Cheatsheet",
                "ACE",
                "Agentic Context Engineering",
                "generation",
                "reflection",
                "curation",
                "context collapse",
                "adaptation latency",
                "rollout cost",
                "natural execution feedback",
                "AppWorld leaderboard"
            ]
        },
        "publishedAt": "2025-10-06T05:30:18.000Z",
        "title": "Agentic Context Engineering: Evolving Contexts for Self-Improving\n  Language Models",
        "summary": "Large language model (LLM) applications such as agents and domain-specific\nreasoning increasingly rely on context adaptation -- modifying inputs with\ninstructions, strategies, or evidence, rather than weight updates. Prior\napproaches improve usability but often suffer from brevity bias, which drops\ndomain insights for concise summaries, and from context collapse, where\niterative rewriting erodes details over time. Building on the adaptive memory\nintroduced by Dynamic Cheatsheet, we introduce ACE (Agentic Context\nEngineering), a framework that treats contexts as evolving playbooks that\naccumulate, refine, and organize strategies through a modular process of\ngeneration, reflection, and curation. ACE prevents collapse with structured,\nincremental updates that preserve detailed knowledge and scale with\nlong-context models. Across agent and domain-specific benchmarks, ACE optimizes\ncontexts both offline (e.g., system prompts) and online (e.g., agent memory),\nconsistently outperforming strong baselines: +10.6% on agents and +8.6% on\nfinance, while significantly reducing adaptation latency and rollout cost.\nNotably, ACE could adapt effectively without labeled supervision and instead by\nleveraging natural execution feedback. On the AppWorld leaderboard, ACE matches\nthe top-ranked production-level agent on the overall average and surpasses it\non the harder test-challenge split, despite using a smaller open-source model.\nThese results show that comprehensive, evolving contexts enable scalable,\nefficient, and self-improving LLM systems with low overhead.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04618.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 119
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.03871",
            "authors": [
                {
                    "_id": "68e4d8f5e4e093a7044e4ea9",
                    "name": "Oleg Filatov",
                    "hidden": false
                },
                {
                    "_id": "68e4d8f5e4e093a7044e4eaa",
                    "name": "Jiangtao Wang",
                    "hidden": false
                },
                {
                    "_id": "68e4d8f5e4e093a7044e4eab",
                    "name": "Jan Ebert",
                    "hidden": false
                },
                {
                    "_id": "68e4d8f5e4e093a7044e4eac",
                    "name": "Stefan Kesselheim",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-04T16:48:36.000Z",
            "submittedOnDailyAt": "2025-10-07T07:52:25.606Z",
            "title": "Optimal Scaling Needs Optimal Norm",
            "submittedOnDailyBy": {
                "_id": "647cb554f812a0a7909120c1",
                "avatarUrl": "/avatars/d1b24b42ccb1006d4761874dd8bfadbf.svg",
                "isPro": false,
                "fullname": "Oleg Filatov",
                "user": "ofivite",
                "type": "user"
            },
            "summary": "Despite recent progress in optimal hyperparameter transfer under model and\ndataset scaling, no unifying explanatory principle has been established. Using\nthe Scion optimizer, we discover that joint optimal scaling across model and\ndataset sizes is governed by a single invariant: the operator norm of the\noutput layer. Across models with up to 1.3B parameters trained on up to 138B\ntokens, the optimal learning rate/batch size pair (eta^{ast}, B^{ast})\nconsistently has the same operator norm value - a phenomenon we term norm\ntransfer. This constant norm condition is necessary but not sufficient: while\nfor each dataset size, multiple (eta, B) reach the optimal norm, only a\nunique (eta^{ast}, B^{ast}) achieves the best loss. As a sufficient\ncondition, we provide the first measurement of (eta^{ast}, B^{ast})\nscaling with dataset size for Scion, and find that the scaling rules are\nconsistent with those of the Adam optimizer. Tuning per-layer-group learning\nrates also improves model performance, with the output layer being the most\nsensitive and hidden layers benefiting from lower learning rates. We provide\npractical insights on norm-guided optimal scaling and release our Distributed\nScion (Disco) implementation with logs from over two thousand runs to support\nresearch on LLM training dynamics at scale.",
            "upvotes": 22,
            "discussionId": "68e4d8f5e4e093a7044e4ead",
            "githubRepo": "https://github.com/SDLAML/disco",
            "ai_summary": "Joint optimal scaling of model and dataset sizes in deep learning is governed by the operator norm of the output layer, a phenomenon termed norm transfer, which provides a necessary condition for optimal learning rate and batch size.",
            "ai_keywords": [
                "Scion optimizer",
                "operator norm",
                "output layer",
                "norm transfer",
                "learning rate",
                "batch size",
                "Adam optimizer",
                "per-layer-group learning rates",
                "Distributed Scion (Disco)",
                "LLM training dynamics"
            ],
            "githubStars": 4
        },
        "publishedAt": "2025-10-04T12:48:36.000Z",
        "title": "Optimal Scaling Needs Optimal Norm",
        "summary": "Despite recent progress in optimal hyperparameter transfer under model and\ndataset scaling, no unifying explanatory principle has been established. Using\nthe Scion optimizer, we discover that joint optimal scaling across model and\ndataset sizes is governed by a single invariant: the operator norm of the\noutput layer. Across models with up to 1.3B parameters trained on up to 138B\ntokens, the optimal learning rate/batch size pair (eta^{ast}, B^{ast})\nconsistently has the same operator norm value - a phenomenon we term norm\ntransfer. This constant norm condition is necessary but not sufficient: while\nfor each dataset size, multiple (eta, B) reach the optimal norm, only a\nunique (eta^{ast}, B^{ast}) achieves the best loss. As a sufficient\ncondition, we provide the first measurement of (eta^{ast}, B^{ast})\nscaling with dataset size for Scion, and find that the scaling rules are\nconsistent with those of the Adam optimizer. Tuning per-layer-group learning\nrates also improves model performance, with the output layer being the most\nsensitive and hidden layers benefiting from lower learning rates. We provide\npractical insights on norm-guided optimal scaling and release our Distributed\nScion (Disco) implementation with logs from over two thousand runs to support\nresearch on LLM training dynamics at scale.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03871.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "647cb554f812a0a7909120c1",
            "avatarUrl": "/avatars/d1b24b42ccb1006d4761874dd8bfadbf.svg",
            "fullname": "Oleg Filatov",
            "name": "ofivite",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 7
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.03561",
            "authors": [
                {
                    "_id": "68e46ffee4e093a7044e4ccb",
                    "user": {
                        "_id": "675197c3ae96d7ba4b4a6c66",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/I2GHgrv70cfT8C5EbK6Q5.png",
                        "isPro": false,
                        "fullname": "Adam Filipek",
                        "user": "AdamF92",
                        "type": "user"
                    },
                    "name": "Adam Filipek",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:21.892Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/675197c3ae96d7ba4b4a6c66/mzVnK1wM9elG5vTCd4pi_.png",
                "https://cdn-uploads.huggingface.co/production/uploads/675197c3ae96d7ba4b4a6c66/emRA1Lr4AKtlLUVowTUjB.png"
            ],
            "publishedAt": "2025-10-03T23:18:07.000Z",
            "submittedOnDailyAt": "2025-10-07T00:25:25.255Z",
            "title": "Reactive Transformer (RxT) -- Stateful Real-Time Processing for\n  Event-Driven Reactive Language Models",
            "submittedOnDailyBy": {
                "_id": "675197c3ae96d7ba4b4a6c66",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/I2GHgrv70cfT8C5EbK6Q5.png",
                "isPro": false,
                "fullname": "Adam Filipek",
                "user": "AdamF92",
                "type": "user"
            },
            "summary": "The Transformer architecture has become the de facto standard for Large\nLanguage Models (LLMs), demonstrating remarkable capabilities in language\nunderstanding and generation. However, its application in conversational AI is\nfundamentally constrained by its stateless nature and the quadratic\ncomputational complexity (O(L^2)) with respect to sequence length L.\nCurrent models emulate memory by reprocessing an ever-expanding conversation\nhistory with each turn, leading to prohibitive costs and latency in long\ndialogues. This paper introduces the Reactive Transformer (RxT), a novel\narchitecture designed to overcome these limitations by shifting from a\ndata-driven to an event-driven paradigm. RxT processes each conversational turn\nas a discrete event in real-time, maintaining context in an integrated,\nfixed-size Short-Term Memory (STM) system. The architecture features a distinct\noperational cycle where a generator-decoder produces a response based on the\ncurrent query and the previous memory state, after which a memory-encoder and a\ndedicated Memory Attention network asynchronously update the STM with a\nrepresentation of the complete interaction. This design fundamentally alters\nthe scaling dynamics, reducing the total user-facing cost of a conversation\nfrom quadratic (O(N^2 cdot T)) to linear (O(N cdot T)) with respect to\nthe number of interactions N. By decoupling response generation from memory\nupdates, RxT achieves low latency, enabling truly real-time, stateful, and\neconomically viable long-form conversations. We validated our architecture with\na series of proof-of-concept experiments on synthetic data, demonstrating\nsuperior performance and constant-time inference latency compared to a baseline\nstateless model of comparable size.",
            "upvotes": 15,
            "discussionId": "68e47064e4e093a7044e4ccc",
            "projectPage": "https://rxai.dev/research/reactive-transformer-introduction",
            "githubRepo": "https://github.com/RxAI-dev/rxlm",
            "ai_summary": "The Reactive Transformer (RxT) addresses the limitations of stateless Transformers in conversational AI by using an event-driven paradigm with a fixed-size Short-Term Memory (STM) system, achieving linear scaling and low latency.",
            "ai_keywords": [
                "Transformer architecture",
                "Large Language Models (LLMs)",
                "stateless nature",
                "quadratic computational complexity",
                "Reactive Transformer (RxT)",
                "event-driven paradigm",
                "Short-Term Memory (STM)",
                "generator-decoder",
                "memory-encoder",
                "Memory Attention network",
                "linear scaling",
                "constant-time inference latency"
            ],
            "githubStars": 2,
            "organization": {
                "_id": "675776b060e4100500aeb4c8",
                "name": "ReactiveAI",
                "fullname": "Reactive AI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/675197c3ae96d7ba4b4a6c66/AJDkLuavcYfENIRDzxjqR.png"
            }
        },
        "publishedAt": "2025-10-03T19:18:07.000Z",
        "title": "Reactive Transformer (RxT) -- Stateful Real-Time Processing for\n  Event-Driven Reactive Language Models",
        "summary": "The Transformer architecture has become the de facto standard for Large\nLanguage Models (LLMs), demonstrating remarkable capabilities in language\nunderstanding and generation. However, its application in conversational AI is\nfundamentally constrained by its stateless nature and the quadratic\ncomputational complexity (O(L^2)) with respect to sequence length L.\nCurrent models emulate memory by reprocessing an ever-expanding conversation\nhistory with each turn, leading to prohibitive costs and latency in long\ndialogues. This paper introduces the Reactive Transformer (RxT), a novel\narchitecture designed to overcome these limitations by shifting from a\ndata-driven to an event-driven paradigm. RxT processes each conversational turn\nas a discrete event in real-time, maintaining context in an integrated,\nfixed-size Short-Term Memory (STM) system. The architecture features a distinct\noperational cycle where a generator-decoder produces a response based on the\ncurrent query and the previous memory state, after which a memory-encoder and a\ndedicated Memory Attention network asynchronously update the STM with a\nrepresentation of the complete interaction. This design fundamentally alters\nthe scaling dynamics, reducing the total user-facing cost of a conversation\nfrom quadratic (O(N^2 cdot T)) to linear (O(N cdot T)) with respect to\nthe number of interactions N. By decoupling response generation from memory\nupdates, RxT achieves low latency, enabling truly real-time, stateful, and\neconomically viable long-form conversations. We validated our architecture with\na series of proof-of-concept experiments on synthetic data, demonstrating\nsuperior performance and constant-time inference latency compared to a baseline\nstateless model of comparable size.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/675197c3ae96d7ba4b4a6c66/mzVnK1wM9elG5vTCd4pi_.png",
            "https://cdn-uploads.huggingface.co/production/uploads/675197c3ae96d7ba4b4a6c66/emRA1Lr4AKtlLUVowTUjB.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03561.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "675197c3ae96d7ba4b4a6c66",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/I2GHgrv70cfT8C5EbK6Q5.png",
            "fullname": "Adam Filipek",
            "name": "AdamF92",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 8
        },
        "organization": {
            "_id": "675776b060e4100500aeb4c8",
            "name": "ReactiveAI",
            "fullname": "Reactive AI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/675197c3ae96d7ba4b4a6c66/AJDkLuavcYfENIRDzxjqR.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.03264",
            "authors": [
                {
                    "_id": "68e473a0e4e093a7044e4cd7",
                    "user": {
                        "_id": "6338dd1776421c0543150467",
                        "avatarUrl": "/avatars/4539dcec644e40be33f4a0d419fa66cb.svg",
                        "isPro": false,
                        "fullname": "Syeda Nahida Akter",
                        "user": "SieraL",
                        "type": "user"
                    },
                    "name": "Syeda Nahida Akter",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:15.673Z",
                    "hidden": false
                },
                {
                    "_id": "68e473a0e4e093a7044e4cd8",
                    "name": "Shrimai Prabhumoye",
                    "hidden": false
                },
                {
                    "_id": "68e473a0e4e093a7044e4cd9",
                    "name": "Eric Nyberg",
                    "hidden": false
                },
                {
                    "_id": "68e473a0e4e093a7044e4cda",
                    "name": "Mostofa Patwary",
                    "hidden": false
                },
                {
                    "_id": "68e473a0e4e093a7044e4cdb",
                    "name": "Mohammad Shoeybi",
                    "hidden": false
                },
                {
                    "_id": "68e473a0e4e093a7044e4cdc",
                    "name": "Yejin Choi",
                    "hidden": false
                },
                {
                    "_id": "68e473a0e4e093a7044e4cdd",
                    "name": "Bryan Catanzaro",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-26T20:08:51.000Z",
            "submittedOnDailyAt": "2025-10-07T00:30:07.282Z",
            "title": "Front-Loading Reasoning: The Synergy between Pretraining and\n  Post-Training Data",
            "submittedOnDailyBy": {
                "_id": "66980b9c9baa4382e1678809",
                "avatarUrl": "/avatars/1a516bb7aa7871834c19de708cdd853a.svg",
                "isPro": false,
                "fullname": "Shrimai Prabhumoye",
                "user": "shrimai19",
                "type": "user"
            },
            "summary": "The prevailing paradigm for enhancing the reasoning abilities of LLMs\nrevolves around post-training on high-quality, reasoning-intensive data. While\nemerging literature suggests that reasoning data is increasingly incorporated\nalso during the mid-training stage-a practice that is relatively more\nproprietary and less openly characterized-the role of such data in pretraining\nremains unclear. In particular, due to the opaqueness of pretraining corpora in\nmost frontier models, the effect of reasoning data introduced at different\nphases of pre- and/or post-training is relatively less reported in the\nscientific literature. This raises several important questions: Is adding\nreasoning data earlier during pretraining any better than introducing it during\npost-training? Could earlier inclusion risk overfitting and harm\ngeneralization, or instead establish durable foundations that later fine-tuning\ncannot recover? We conduct the first systematic study of how reasoning\ndata-varying in scale, diversity, and quality-affects LLM performance when\nintroduced at different stages of training. We find that front-loading\nreasoning data into pretraining is critical (19% avg gain), establishing\nfoundational capabilities that cannot be fully replicated by later-stage SFT,\neven with more data. We uncover an asymmetric principle for optimal data\nallocation: pretraining benefits most from broad diversity in reasoning\npatterns (11% avg gain), while SFT is more sensitive to data quality (15% avg\ngain). We show that high-quality pretraining data has latent effects, activated\nonly after SFT, and that naively scaling SFT data can be detrimental, washing\naway the benefits of early reasoning injection. Our results challenge the\nconventional separation of language modeling and reasoning, providing a\nprincipled guide for strategically allocating data across the entire training\npipeline to build more capable models.",
            "upvotes": 15,
            "discussionId": "68e473f1e4e093a7044e4cde",
            "projectPage": "https://research.nvidia.com/labs/adlr/Synergy/",
            "ai_summary": "Introducing reasoning data during pretraining significantly enhances LLM performance compared to post-training, with pretraining benefiting more from diverse data patterns while SFT benefits more from high-quality data.",
            "ai_keywords": [
                "LLMs",
                "reasoning data",
                "pretraining",
                "post-training",
                "mid-training",
                "overfitting",
                "generalization",
                "systematic study",
                "SFT",
                "data allocation",
                "language modeling",
                "reasoning"
            ],
            "organization": {
                "_id": "60262b67268c201cdc8b7d43",
                "name": "nvidia",
                "fullname": "NVIDIA",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"
            }
        },
        "publishedAt": "2025-09-26T16:08:51.000Z",
        "title": "Front-Loading Reasoning: The Synergy between Pretraining and\n  Post-Training Data",
        "summary": "The prevailing paradigm for enhancing the reasoning abilities of LLMs\nrevolves around post-training on high-quality, reasoning-intensive data. While\nemerging literature suggests that reasoning data is increasingly incorporated\nalso during the mid-training stage-a practice that is relatively more\nproprietary and less openly characterized-the role of such data in pretraining\nremains unclear. In particular, due to the opaqueness of pretraining corpora in\nmost frontier models, the effect of reasoning data introduced at different\nphases of pre- and/or post-training is relatively less reported in the\nscientific literature. This raises several important questions: Is adding\nreasoning data earlier during pretraining any better than introducing it during\npost-training? Could earlier inclusion risk overfitting and harm\ngeneralization, or instead establish durable foundations that later fine-tuning\ncannot recover? We conduct the first systematic study of how reasoning\ndata-varying in scale, diversity, and quality-affects LLM performance when\nintroduced at different stages of training. We find that front-loading\nreasoning data into pretraining is critical (19% avg gain), establishing\nfoundational capabilities that cannot be fully replicated by later-stage SFT,\neven with more data. We uncover an asymmetric principle for optimal data\nallocation: pretraining benefits most from broad diversity in reasoning\npatterns (11% avg gain), while SFT is more sensitive to data quality (15% avg\ngain). We show that high-quality pretraining data has latent effects, activated\nonly after SFT, and that naively scaling SFT data can be detrimental, washing\naway the benefits of early reasoning injection. Our results challenge the\nconventional separation of language modeling and reasoning, providing a\nprincipled guide for strategically allocating data across the entire training\npipeline to build more capable models.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03264.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "66980b9c9baa4382e1678809",
            "avatarUrl": "/avatars/1a516bb7aa7871834c19de708cdd853a.svg",
            "fullname": "Shrimai Prabhumoye",
            "name": "shrimai19",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 3
        },
        "organization": {
            "_id": "60262b67268c201cdc8b7d43",
            "name": "nvidia",
            "fullname": "NVIDIA",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05091",
            "authors": [
                {
                    "_id": "68e47ef4e4e093a7044e4d27",
                    "name": "Le Zhuo",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d28",
                    "user": {
                        "_id": "662885b9b87483ae5a9ee5c9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/662885b9b87483ae5a9ee5c9/fLzCrWizo_hy7zGuAqFwk.jpeg",
                        "isPro": false,
                        "fullname": "Songhao Han",
                        "user": "hshjerry0315",
                        "type": "user"
                    },
                    "name": "Songhao Han",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:05.438Z",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d29",
                    "name": "Yuandong Pu",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d2a",
                    "name": "Boxiang Qiu",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d2b",
                    "user": {
                        "_id": "5f7fbd813e94f16a85448745",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1649681653581-5f7fbd813e94f16a85448745.jpeg",
                        "isPro": true,
                        "fullname": "Sayak Paul",
                        "user": "sayakpaul",
                        "type": "user"
                    },
                    "name": "Sayak Paul",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:03.087Z",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d2c",
                    "name": "Yue Liao",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d2d",
                    "name": "Yihao Liu",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d2e",
                    "name": "Jie Shao",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d2f",
                    "name": "Xi Chen",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d30",
                    "name": "Si Liu",
                    "hidden": false
                },
                {
                    "_id": "68e47ef4e4e093a7044e4d31",
                    "name": "Hongsheng Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T17:56:55.000Z",
            "submittedOnDailyAt": "2025-10-07T01:24:33.099Z",
            "title": "Factuality Matters: When Image Generation and Editing Meet Structured\n  Visuals",
            "submittedOnDailyBy": {
                "_id": "6358a167f56b03ec9147074d",
                "avatarUrl": "/avatars/e54ea7bf0c240cf76d538296efb3976c.svg",
                "isPro": false,
                "fullname": "Le Zhuo",
                "user": "JackyZhuo",
                "type": "user"
            },
            "summary": "While modern visual generation models excel at creating aesthetically\npleasing natural images, they struggle with producing or editing structured\nvisuals like charts, diagrams, and mathematical figures, which demand\ncomposition planning, text rendering, and multimodal reasoning for factual\nfidelity. To address this, we present the first comprehensive, systematic\ninvestigation of this domain, encompassing data construction, model training,\nand an evaluation benchmark. First, we construct a large-scale dataset of 1.3\nmillion high-quality structured image pairs derived from executable drawing\nprograms and augmented with chain-of-thought reasoning annotations. Building on\nit, we train a unified model that integrates a VLM with FLUX.1 Kontext via a\nlightweight connector for enhanced multimodal understanding. A three-stage\ntraining curriculum enables progressive feature alignment, knowledge infusion,\nand reasoning-augmented generation, further boosted by an external reasoner at\ninference time. Finally, we introduce StructBench, a novel benchmark for\ngeneration and editing with over 1,700 challenging instances, and an\naccompanying evaluation metric, StructScore, which employs a multi-round Q\\&A\nprotocol to assess fine-grained factual accuracy. Evaluations of 15 models\nreveal that even leading closed-source systems remain far from satisfactory.\nOur model attains strong editing performance, and inference-time reasoning\nyields consistent gains across diverse architectures. By releasing the dataset,\nmodel, and benchmark, we aim to advance unified multimodal foundations for\nstructured visuals.",
            "upvotes": 13,
            "discussionId": "68e47ef4e4e093a7044e4d32",
            "projectPage": "https://structvisuals.github.io/",
            "githubRepo": "https://github.com/zhuole1025/Structured-Visuals",
            "ai_summary": "A comprehensive investigation into generating and editing structured visuals using a unified model integrating a VLM with FLUX Kontext, achieving strong performance and introducing a new benchmark and evaluation metric.",
            "ai_keywords": [
                "VLM",
                "FLUX Kontext",
                "chain-of-thought reasoning",
                "multimodal understanding",
                "three-stage training curriculum",
                "feature alignment",
                "knowledge infusion",
                "reasoning-augmented generation",
                "StructBench",
                "StructScore",
                "multi-round Q&A protocol"
            ],
            "githubStars": 4
        },
        "publishedAt": "2025-10-06T13:56:55.000Z",
        "title": "Factuality Matters: When Image Generation and Editing Meet Structured\n  Visuals",
        "summary": "While modern visual generation models excel at creating aesthetically\npleasing natural images, they struggle with producing or editing structured\nvisuals like charts, diagrams, and mathematical figures, which demand\ncomposition planning, text rendering, and multimodal reasoning for factual\nfidelity. To address this, we present the first comprehensive, systematic\ninvestigation of this domain, encompassing data construction, model training,\nand an evaluation benchmark. First, we construct a large-scale dataset of 1.3\nmillion high-quality structured image pairs derived from executable drawing\nprograms and augmented with chain-of-thought reasoning annotations. Building on\nit, we train a unified model that integrates a VLM with FLUX.1 Kontext via a\nlightweight connector for enhanced multimodal understanding. A three-stage\ntraining curriculum enables progressive feature alignment, knowledge infusion,\nand reasoning-augmented generation, further boosted by an external reasoner at\ninference time. Finally, we introduce StructBench, a novel benchmark for\ngeneration and editing with over 1,700 challenging instances, and an\naccompanying evaluation metric, StructScore, which employs a multi-round Q\\&A\nprotocol to assess fine-grained factual accuracy. Evaluations of 15 models\nreveal that even leading closed-source systems remain far from satisfactory.\nOur model attains strong editing performance, and inference-time reasoning\nyields consistent gains across diverse architectures. By releasing the dataset,\nmodel, and benchmark, we aim to advance unified multimodal foundations for\nstructured visuals.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05091.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6358a167f56b03ec9147074d",
            "avatarUrl": "/avatars/e54ea7bf0c240cf76d538296efb3976c.svg",
            "fullname": "Le Zhuo",
            "name": "JackyZhuo",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 8
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.03528",
            "authors": [
                {
                    "_id": "68e5275e7e1f41b92bf8e9f4",
                    "name": "Ahmed Alajrami",
                    "hidden": false
                },
                {
                    "_id": "68e5275e7e1f41b92bf8e9f5",
                    "name": "Xingwei Tan",
                    "hidden": false
                },
                {
                    "_id": "68e5275e7e1f41b92bf8e9f6",
                    "name": "Nikolaos Aletras",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-03T21:54:33.000Z",
            "submittedOnDailyAt": "2025-10-07T13:30:49.455Z",
            "title": "Fine-Tuning on Noisy Instructions: Effects on Generalization and\n  Performance",
            "submittedOnDailyBy": {
                "_id": "643d0a4d8a55b2bbf4f2a90e",
                "avatarUrl": "/avatars/9534aaf81cbf12f015c6826b682fdb84.svg",
                "isPro": false,
                "fullname": "Xingwei Tan",
                "user": "XingweiT",
                "type": "user"
            },
            "summary": "Instruction-tuning plays a vital role in enhancing the task-solving abilities\nof large language models (LLMs), improving their usability in generating\nhelpful responses on various tasks. However, previous work has demonstrated\nthat they are sensitive to minor variations in instruction phrasing. In this\npaper, we explore whether introducing perturbations in instruction-tuning data\ncan enhance LLMs' resistance against noisy instructions. We focus on how\ninstruction-tuning with perturbations, such as removing stop words or shuffling\nwords, affects LLMs' performance on the original and perturbed versions of\nwidely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics\nand potential shifts in model behavior. Surprisingly, our results suggest that\ninstruction-tuning on perturbed instructions can, in some cases, improve\ndownstream performance. These findings highlight the importance of including\nperturbed instructions in instruction-tuning, which can make LLMs more\nresilient to noisy user inputs.",
            "upvotes": 13,
            "discussionId": "68e5275e7e1f41b92bf8e9f7",
            "ai_summary": "Introducing perturbations in instruction-tuning data can enhance large language models' resistance to noisy instructions and improve performance on benchmarks.",
            "ai_keywords": [
                "instruction-tuning",
                "large language models",
                "LLMs",
                "perturbations",
                "stop words",
                "word shuffling",
                "MMLU",
                "BBH",
                "GSM8K",
                "learning dynamics",
                "model behavior",
                "noisy user inputs"
            ]
        },
        "publishedAt": "2025-10-03T17:54:33.000Z",
        "title": "Fine-Tuning on Noisy Instructions: Effects on Generalization and\n  Performance",
        "summary": "Instruction-tuning plays a vital role in enhancing the task-solving abilities\nof large language models (LLMs), improving their usability in generating\nhelpful responses on various tasks. However, previous work has demonstrated\nthat they are sensitive to minor variations in instruction phrasing. In this\npaper, we explore whether introducing perturbations in instruction-tuning data\ncan enhance LLMs' resistance against noisy instructions. We focus on how\ninstruction-tuning with perturbations, such as removing stop words or shuffling\nwords, affects LLMs' performance on the original and perturbed versions of\nwidely-used benchmarks (MMLU, BBH, GSM8K). We further assess learning dynamics\nand potential shifts in model behavior. Surprisingly, our results suggest that\ninstruction-tuning on perturbed instructions can, in some cases, improve\ndownstream performance. These findings highlight the importance of including\nperturbed instructions in instruction-tuning, which can make LLMs more\nresilient to noisy user inputs.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03528.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "643d0a4d8a55b2bbf4f2a90e",
            "avatarUrl": "/avatars/9534aaf81cbf12f015c6826b682fdb84.svg",
            "fullname": "Xingwei Tan",
            "name": "XingweiT",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.01161",
            "authors": [
                {
                    "_id": "68e5597d975ac4c405ef1f25",
                    "name": "Haizhong Zheng",
                    "hidden": false
                },
                {
                    "_id": "68e5597d975ac4c405ef1f26",
                    "name": "Jiawei Zhao",
                    "hidden": false
                },
                {
                    "_id": "68e5597d975ac4c405ef1f27",
                    "name": "Bedi Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-01T17:48:23.000Z",
            "submittedOnDailyAt": "2025-10-07T16:49:56.068Z",
            "title": "Prosperity before Collapse: How Far Can Off-Policy RL Reach with Stale\n  Data on LLMs?",
            "submittedOnDailyBy": {
                "_id": "64affbb951e993d33be0ddd1",
                "avatarUrl": "/avatars/36eb12f5c74cfe69d16a954f96819308.svg",
                "isPro": false,
                "fullname": "Haizhong",
                "user": "haizhongzheng",
                "type": "user"
            },
            "summary": "Reinforcement learning has been central to recent advances in large language\nmodel reasoning, but most algorithms rely on on-policy training that demands\nfresh rollouts at every update, limiting efficiency and scalability.\nAsynchronous RL systems alleviate this by decoupling rollout generation from\ntraining, yet their effectiveness hinges on tolerating large staleness in\nrollout data, a setting where existing methods either degrade in performance or\ncollapse. We revisit this challenge and uncover a prosperity-before-collapse\nphenomenon: stale data can be as informative as on-policy data if exploited\nproperly. Building on this insight, we introduce M2PO (Second-Moment Trust\nPolicy Optimization), which constrains the second moment of importance weights\nto suppress only extreme outliers while preserving informative updates.\nNotably, M2PO sharply reduces the fraction of clipped tokens under high\nstaleness (from 1.22% to 0.06% over training), precisely masking high-variance\ntokens while maintaining stable optimization. Extensive evaluation across six\nmodels (from 1.7B to 32B) and eight benchmarks shows that M2PO delivers stable\noff-policy training even with data stale by at least 256 model updates and\nmatches on-policy performance.",
            "upvotes": 12,
            "discussionId": "68e5597e975ac4c405ef1f28",
            "ai_summary": "M2PO, a reinforcement learning algorithm, enables stable off-policy training with stale data by constraining the second moment of importance weights, achieving performance comparable to on-policy methods.",
            "ai_keywords": [
                "reinforcement learning",
                "on-policy training",
                "asynchronous RL",
                "rollout generation",
                "staleness",
                "importance weights",
                "M2PO",
                "Second-Moment Trust Policy Optimization",
                "clipped tokens",
                "high-variance tokens",
                "off-policy training"
            ],
            "organization": {
                "_id": "654944a99b86bd6b2c577ba7",
                "name": "cmu-llm",
                "fullname": "Carnegie Mellon University"
            }
        },
        "publishedAt": "2025-10-01T13:48:23.000Z",
        "title": "Prosperity before Collapse: How Far Can Off-Policy RL Reach with Stale\n  Data on LLMs?",
        "summary": "Reinforcement learning has been central to recent advances in large language\nmodel reasoning, but most algorithms rely on on-policy training that demands\nfresh rollouts at every update, limiting efficiency and scalability.\nAsynchronous RL systems alleviate this by decoupling rollout generation from\ntraining, yet their effectiveness hinges on tolerating large staleness in\nrollout data, a setting where existing methods either degrade in performance or\ncollapse. We revisit this challenge and uncover a prosperity-before-collapse\nphenomenon: stale data can be as informative as on-policy data if exploited\nproperly. Building on this insight, we introduce M2PO (Second-Moment Trust\nPolicy Optimization), which constrains the second moment of importance weights\nto suppress only extreme outliers while preserving informative updates.\nNotably, M2PO sharply reduces the fraction of clipped tokens under high\nstaleness (from 1.22% to 0.06% over training), precisely masking high-variance\ntokens while maintaining stable optimization. Extensive evaluation across six\nmodels (from 1.7B to 32B) and eight benchmarks shows that M2PO delivers stable\noff-policy training even with data stale by at least 256 model updates and\nmatches on-policy performance.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.01161.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64affbb951e993d33be0ddd1",
            "avatarUrl": "/avatars/36eb12f5c74cfe69d16a954f96819308.svg",
            "fullname": "Haizhong",
            "name": "haizhongzheng",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "654944a99b86bd6b2c577ba7",
            "name": "cmu-llm",
            "fullname": "Carnegie Mellon University"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.00263",
            "authors": [
                {
                    "_id": "68e44581e4e093a7044e4c86",
                    "user": {
                        "_id": "6328f05f84e4c8b42c5d14a4",
                        "avatarUrl": "/avatars/f8277830c7fc4978f0fc0535b25177cd.svg",
                        "isPro": false,
                        "fullname": "Zhuohang Li",
                        "user": "zhhli",
                        "type": "user"
                    },
                    "name": "Zhuohang Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:29.972Z",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c87",
                    "name": "Xiaowei Li",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c88",
                    "name": "Chengyu Huang",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c89",
                    "name": "Guowang Li",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c8a",
                    "name": "Katayoon Goshvadi",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c8b",
                    "name": "Bo Dai",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c8c",
                    "name": "Dale Schuurmans",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c8d",
                    "name": "Paul Zhou",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c8e",
                    "name": "Hamid Palangi",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c8f",
                    "name": "Yiwen Song",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c90",
                    "name": "Palash Goyal",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c91",
                    "name": "Murat Kantarcioglu",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c92",
                    "name": "Bradley A. Malin",
                    "hidden": false
                },
                {
                    "_id": "68e44581e4e093a7044e4c93",
                    "name": "Yuan Xue",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-30T20:36:41.000Z",
            "submittedOnDailyAt": "2025-10-07T00:46:14.270Z",
            "title": "Judging with Confidence: Calibrating Autoraters to Preference\n  Distributions",
            "submittedOnDailyBy": {
                "_id": "6328f05f84e4c8b42c5d14a4",
                "avatarUrl": "/avatars/f8277830c7fc4978f0fc0535b25177cd.svg",
                "isPro": false,
                "fullname": "Zhuohang Li",
                "user": "zhhli",
                "type": "user"
            },
            "summary": "The alignment of large language models (LLMs) with human values increasingly\nrelies on using other LLMs as automated judges, or ``autoraters''. However,\ntheir reliability is limited by a foundational issue: they are trained on\ndiscrete preference labels, forcing a single ground truth onto tasks that are\noften subjective, ambiguous, or nuanced. We argue that a reliable autorater\nmust learn to model the full distribution of preferences defined by a target\npopulation. In this paper, we propose a general framework for calibrating\nprobabilistic autoraters to any given preference distribution. We formalize the\nproblem and present two learning methods tailored to different data conditions:\n1) a direct supervised fine-tuning for dense, probabilistic labels, and 2) a\nreinforcement learning approach for sparse, binary labels. Our empirical\nresults show that finetuning autoraters with a distribution-matching objective\nleads to verbalized probability predictions that are better aligned with the\ntarget preference distribution, with improved calibration and significantly\nlower positional bias, all while preserving performance on objective tasks.",
            "upvotes": 12,
            "discussionId": "68e44582e4e093a7044e4c94",
            "ai_summary": "A framework for calibrating probabilistic autoraters to preference distributions using supervised fine-tuning and reinforcement learning improves alignment with human values and reduces bias.",
            "ai_keywords": [
                "large language models",
                "LLMs",
                "autoraters",
                "preference labels",
                "probabilistic autoraters",
                "distribution-matching objective",
                "verbalized probability predictions",
                "calibration",
                "positional bias"
            ],
            "organization": {
                "_id": "5e6aca39878b8b2bf9806447",
                "name": "google",
                "fullname": "Google",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/WtA3YYitedOr9n02eHfJe.png"
            }
        },
        "publishedAt": "2025-09-30T16:36:41.000Z",
        "title": "Judging with Confidence: Calibrating Autoraters to Preference\n  Distributions",
        "summary": "The alignment of large language models (LLMs) with human values increasingly\nrelies on using other LLMs as automated judges, or ``autoraters''. However,\ntheir reliability is limited by a foundational issue: they are trained on\ndiscrete preference labels, forcing a single ground truth onto tasks that are\noften subjective, ambiguous, or nuanced. We argue that a reliable autorater\nmust learn to model the full distribution of preferences defined by a target\npopulation. In this paper, we propose a general framework for calibrating\nprobabilistic autoraters to any given preference distribution. We formalize the\nproblem and present two learning methods tailored to different data conditions:\n1) a direct supervised fine-tuning for dense, probabilistic labels, and 2) a\nreinforcement learning approach for sparse, binary labels. Our empirical\nresults show that finetuning autoraters with a distribution-matching objective\nleads to verbalized probability predictions that are better aligned with the\ntarget preference distribution, with improved calibration and significantly\nlower positional bias, all while preserving performance on objective tasks.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.00263.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6328f05f84e4c8b42c5d14a4",
            "avatarUrl": "/avatars/f8277830c7fc4978f0fc0535b25177cd.svg",
            "fullname": "Zhuohang Li",
            "name": "zhhli",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "organization": {
            "_id": "5e6aca39878b8b2bf9806447",
            "name": "google",
            "fullname": "Google",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/WtA3YYitedOr9n02eHfJe.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04996",
            "authors": [
                {
                    "_id": "68e47839e4e093a7044e4ce0",
                    "name": "Wei Xiong",
                    "hidden": false
                },
                {
                    "_id": "68e47839e4e093a7044e4ce1",
                    "name": "Chenlu Ye",
                    "hidden": false
                },
                {
                    "_id": "68e47839e4e093a7044e4ce2",
                    "name": "Baohao Liao",
                    "hidden": false
                },
                {
                    "_id": "68e47839e4e093a7044e4ce3",
                    "name": "Hanze Dong",
                    "hidden": false
                },
                {
                    "_id": "68e47839e4e093a7044e4ce4",
                    "name": "Xinxing Xu",
                    "hidden": false
                },
                {
                    "_id": "68e47839e4e093a7044e4ce5",
                    "name": "Christof Monz",
                    "hidden": false
                },
                {
                    "_id": "68e47839e4e093a7044e4ce6",
                    "name": "Jiang Bian",
                    "hidden": false
                },
                {
                    "_id": "68e47839e4e093a7044e4ce7",
                    "name": "Nan Jiang",
                    "hidden": false
                },
                {
                    "_id": "68e47839e4e093a7044e4ce8",
                    "name": "Tong Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T16:34:09.000Z",
            "submittedOnDailyAt": "2025-10-07T00:51:42.961Z",
            "title": "Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM\n  Training",
            "submittedOnDailyBy": {
                "_id": "643e59806db6ba8c5ee123f3",
                "avatarUrl": "/avatars/4052f2a250107f43b3634c3ee3cc30a1.svg",
                "isPro": false,
                "fullname": "Wei Xiong",
                "user": "weqweasdas",
                "type": "user"
            },
            "summary": "Reinforcement learning applied to large language models (LLMs) for reasoning\ntasks is often bottlenecked by unstable gradient estimates due to fixed and\nuniform sampling of responses across prompts. Prior work such as GVM-RAFT\naddresses this by dynamically allocating inference budget per prompt to\nminimize stochastic gradient variance under a budget constraint. Inspired by\nthis insight, we propose Reinforce-Ada, an adaptive sampling framework for\nonline RL post-training of LLMs that continuously reallocates sampling effort\nto the prompts with the greatest uncertainty or learning potential. Unlike\nconventional two-stage allocation methods, Reinforce-Ada interleaves estimation\nand sampling in an online successive elimination process, and automatically\nstops sampling for a prompt once sufficient signal is collected. To stabilize\nupdates, we form fixed-size groups with enforced reward diversity and compute\nadvantage baselines using global statistics aggregated over the adaptive\nsampling phase. Empirical results across multiple model architectures and\nreasoning benchmarks show that Reinforce-Ada accelerates convergence and\nimproves final performance compared to GRPO, especially when using the balanced\nsampling variant. Our work highlights the central role of variance-aware,\nadaptive data curation in enabling efficient and reliable reinforcement\nlearning for reasoning-capable LLMs. Code is available at\nhttps://github.com/RLHFlow/Reinforce-Ada.",
            "upvotes": 10,
            "discussionId": "68e47839e4e093a7044e4ce9",
            "ai_summary": "Reinforce-Ada is an adaptive sampling framework for online reinforcement learning post-training of large language models, which accelerates convergence and improves performance by dynamically reallocating sampling effort based on prompt uncertainty.",
            "ai_keywords": [
                "reinforcement learning",
                "large language models",
                "gradient estimates",
                "inference budget",
                "stochastic gradient variance",
                "adaptive sampling",
                "online successive elimination",
                "reward diversity",
                "advantage baselines",
                "variance-aware",
                "adaptive data curation"
            ],
            "organization": {
                "_id": "662d7a9b2b1b529a43840768",
                "name": "RLHFlow",
                "fullname": "RLHFlow",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/638fb8cf2380ffd99caf8c2a/xTHSf1YDQDriY5eZ7cn_1.jpeg"
            }
        },
        "publishedAt": "2025-10-06T12:34:09.000Z",
        "title": "Reinforce-Ada: An Adaptive Sampling Framework for Reinforce-Style LLM\n  Training",
        "summary": "Reinforcement learning applied to large language models (LLMs) for reasoning\ntasks is often bottlenecked by unstable gradient estimates due to fixed and\nuniform sampling of responses across prompts. Prior work such as GVM-RAFT\naddresses this by dynamically allocating inference budget per prompt to\nminimize stochastic gradient variance under a budget constraint. Inspired by\nthis insight, we propose Reinforce-Ada, an adaptive sampling framework for\nonline RL post-training of LLMs that continuously reallocates sampling effort\nto the prompts with the greatest uncertainty or learning potential. Unlike\nconventional two-stage allocation methods, Reinforce-Ada interleaves estimation\nand sampling in an online successive elimination process, and automatically\nstops sampling for a prompt once sufficient signal is collected. To stabilize\nupdates, we form fixed-size groups with enforced reward diversity and compute\nadvantage baselines using global statistics aggregated over the adaptive\nsampling phase. Empirical results across multiple model architectures and\nreasoning benchmarks show that Reinforce-Ada accelerates convergence and\nimproves final performance compared to GRPO, especially when using the balanced\nsampling variant. Our work highlights the central role of variance-aware,\nadaptive data curation in enabling efficient and reliable reinforcement\nlearning for reasoning-capable LLMs. Code is available at\nhttps://github.com/RLHFlow/Reinforce-Ada.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04996.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "643e59806db6ba8c5ee123f3",
            "avatarUrl": "/avatars/4052f2a250107f43b3634c3ee3cc30a1.svg",
            "fullname": "Wei Xiong",
            "name": "weqweasdas",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 19
        },
        "organization": {
            "_id": "662d7a9b2b1b529a43840768",
            "name": "RLHFlow",
            "fullname": "RLHFlow",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/638fb8cf2380ffd99caf8c2a/xTHSf1YDQDriY5eZ7cn_1.jpeg"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.00499",
            "authors": [
                {
                    "_id": "68e348e273e20ab577842085",
                    "name": "Xingjian Zhao",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842086",
                    "name": "Zhe Xu",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842087",
                    "name": "Qinyuan Cheng",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842088",
                    "name": "Zhaoye Fei",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842089",
                    "name": "Luozhijie Jin",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab57784208a",
                    "name": "Yang Wang",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab57784208b",
                    "name": "Hanfu Chen",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab57784208c",
                    "name": "Yaozhou Jiang",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab57784208d",
                    "name": "Qinghui Gao",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab57784208e",
                    "name": "Ke Chen",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab57784208f",
                    "name": "Ruixiao Li",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842090",
                    "name": "Mingshu Chen",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842091",
                    "name": "Ruiming Wang",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842092",
                    "name": "Wenbo Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842093",
                    "name": "Yiyang Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842094",
                    "name": "Donghua Yu",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842095",
                    "name": "Yang Gao",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842096",
                    "name": "Xiaogui Yang",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842097",
                    "name": "Yitian Gong",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842098",
                    "name": "Yuanfan Xu",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab577842099",
                    "name": "Yaqian Zhou",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab57784209a",
                    "name": "Xuanjing Huang",
                    "hidden": false
                },
                {
                    "_id": "68e348e273e20ab57784209b",
                    "name": "Xipeng Qiu",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/63ec4715c81b6a52391c46b8/SsiCLVKxWKhvlqS1Gxfcc.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/63ec4715c81b6a52391c46b8/zAkC7ZLwx2Y89Rxjg41Fl.mp4"
            ],
            "publishedAt": "2025-10-01T04:32:37.000Z",
            "submittedOnDailyAt": "2025-10-07T13:21:34.192Z",
            "title": "MOSS-Speech: Towards True Speech-to-Speech Models Without Text Guidance",
            "submittedOnDailyBy": {
                "_id": "63ec4715c81b6a52391c46b8",
                "avatarUrl": "/avatars/496819b5075a1a834a2b9edeb068c80e.svg",
                "isPro": false,
                "fullname": "QinyuanCheng",
                "user": "Cqy2019",
                "type": "user"
            },
            "summary": "Spoken dialogue systems often rely on cascaded pipelines that transcribe,\nprocess, and resynthesize speech. While effective, this design discards\nparalinguistic cues and limits expressivity. Recent end-to-end methods reduce\nlatency and better preserve these cues, yet still rely on text intermediates,\ncreating a fundamental bottleneck. We present MOSS-Speech, a true\nspeech-to-speech large language model that directly understands and generates\nspeech without relying on text guidance. Our approach combines a modality-based\nlayer-splitting architecture with a frozen pre-training strategy, preserving\nthe reasoning and knowledge of pretrained text LLMs while adding native speech\ncapabilities. Experiments show that our model achieves state-of-the-art results\nin spoken question answering and delivers comparable speech-to-speech\nperformance relative to existing text-guided systems, while still maintaining\ncompetitive text performance. By narrowing the gap between text-guided and\ndirect speech generation, our work establishes a new paradigm for expressive\nand efficient end-to-end speech interaction.",
            "upvotes": 9,
            "discussionId": "68e348e273e20ab57784209c",
            "ai_summary": "MOSS-Speech is a speech-to-speech large language model that directly processes and generates speech without text intermediates, achieving state-of-the-art performance in spoken question answering and competitive text performance.",
            "ai_keywords": [
                "speech-to-speech large language model",
                "modality-based layer-splitting architecture",
                "frozen pre-training strategy",
                "spoken question answering"
            ],
            "organization": {
                "_id": "613b0dee83ec35d460684607",
                "name": "fnlp",
                "fullname": "OpenMOSS (SII, Fudan NLP)",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/xM_PjniEZ9fmDKtJN7PAG.png"
            }
        },
        "publishedAt": "2025-10-01T00:32:37.000Z",
        "title": "MOSS-Speech: Towards True Speech-to-Speech Models Without Text Guidance",
        "summary": "Spoken dialogue systems often rely on cascaded pipelines that transcribe,\nprocess, and resynthesize speech. While effective, this design discards\nparalinguistic cues and limits expressivity. Recent end-to-end methods reduce\nlatency and better preserve these cues, yet still rely on text intermediates,\ncreating a fundamental bottleneck. We present MOSS-Speech, a true\nspeech-to-speech large language model that directly understands and generates\nspeech without relying on text guidance. Our approach combines a modality-based\nlayer-splitting architecture with a frozen pre-training strategy, preserving\nthe reasoning and knowledge of pretrained text LLMs while adding native speech\ncapabilities. Experiments show that our model achieves state-of-the-art results\nin spoken question answering and delivers comparable speech-to-speech\nperformance relative to existing text-guided systems, while still maintaining\ncompetitive text performance. By narrowing the gap between text-guided and\ndirect speech generation, our work establishes a new paradigm for expressive\nand efficient end-to-end speech interaction.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63ec4715c81b6a52391c46b8/SsiCLVKxWKhvlqS1Gxfcc.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/63ec4715c81b6a52391c46b8/zAkC7ZLwx2Y89Rxjg41Fl.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.00499.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63ec4715c81b6a52391c46b8",
            "avatarUrl": "/avatars/496819b5075a1a834a2b9edeb068c80e.svg",
            "fullname": "QinyuanCheng",
            "name": "Cqy2019",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 3
        },
        "organization": {
            "_id": "613b0dee83ec35d460684607",
            "name": "fnlp",
            "fullname": "OpenMOSS (SII, Fudan NLP)",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61457b8deff2c9fdb4de4988/xM_PjniEZ9fmDKtJN7PAG.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05069",
            "authors": [
                {
                    "_id": "68e48451e4e093a7044e4d6c",
                    "user": {
                        "_id": "6482c4178ad9934217a4287d",
                        "avatarUrl": "/avatars/b852d0ced7d98720606b99adaac596f0.svg",
                        "isPro": false,
                        "fullname": "Dachuan Shi",
                        "user": "sdc17",
                        "type": "user"
                    },
                    "name": "Dachuan Shi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:41.431Z",
                    "hidden": false
                },
                {
                    "_id": "68e48451e4e093a7044e4d6d",
                    "name": "Abedelkadir Asi",
                    "hidden": false
                },
                {
                    "_id": "68e48451e4e093a7044e4d6e",
                    "name": "Keying Li",
                    "hidden": false
                },
                {
                    "_id": "68e48451e4e093a7044e4d6f",
                    "name": "Xiangchi Yuan",
                    "hidden": false
                },
                {
                    "_id": "68e48451e4e093a7044e4d70",
                    "name": "Leyan Pan",
                    "hidden": false
                },
                {
                    "_id": "68e48451e4e093a7044e4d71",
                    "name": "Wenke Lee",
                    "hidden": false
                },
                {
                    "_id": "68e48451e4e093a7044e4d72",
                    "name": "Wen Xiao",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T17:46:34.000Z",
            "submittedOnDailyAt": "2025-10-07T01:39:20.150Z",
            "title": "SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior\n  Reasoning LLMs",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Recent work shows that, beyond discrete reasoning through explicit\nchain-of-thought steps, which are limited by the boundaries of natural\nlanguages, large language models (LLMs) can also reason continuously in latent\nspace, allowing richer information per step and thereby improving token\nefficiency. Despite this promise, latent reasoning still faces two challenges,\nespecially in training-free settings: 1) purely latent reasoning broadens the\nsearch distribution by maintaining multiple implicit paths, which diffuses\nprobability mass, introduces noise, and impedes convergence to a single\nhigh-confidence solution, thereby hurting accuracy; and 2) overthinking\npersists even without explicit text, wasting tokens and degrading efficiency.\nTo address these issues, we introduce SwiReasoning, a training-free framework\nfor LLM reasoning which features two key innovations: 1) SwiReasoning\ndynamically switches between explicit and latent reasoning, guided by\nblock-wise confidence estimated from entropy trends in next-token\ndistributions, to balance exploration and exploitation and promote timely\nconvergence. 2) By limiting the maximum number of thinking-block switches,\nSwiReasoning curbs overthinking and improves token efficiency across varying\nproblem difficulties. On widely used mathematics and STEM benchmarks,\nSwiReasoning consistently improves average accuracy by 1.5%-2.8% across\nreasoning LLMs of different model families and scales. Furthermore, under\nconstrained budgets, SwiReasoning improves average token efficiency by 56%-79%,\nwith larger gains as budgets tighten.",
            "upvotes": 8,
            "discussionId": "68e48451e4e093a7044e4d73",
            "projectPage": "https://swireasoning.github.io/",
            "githubRepo": "https://github.com/sdc17/SwiReasoning",
            "ai_summary": "SwiReasoning, a training-free framework for LLMs, dynamically switches between explicit and latent reasoning to improve accuracy and token efficiency.",
            "ai_keywords": [
                "latent reasoning",
                "explicit reasoning",
                "next-token distributions",
                "entropy trends",
                "block-wise confidence",
                "thinking-block switches",
                "token efficiency",
                "mathematics benchmarks",
                "STEM benchmarks"
            ],
            "githubStars": 6,
            "organization": {
                "_id": "5e6485f787403103f9f1055e",
                "name": "microsoft",
                "fullname": "Microsoft",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1583646260758-5e64858c87403103f9f1055d.png"
            }
        },
        "publishedAt": "2025-10-06T13:46:34.000Z",
        "title": "SwiReasoning: Switch-Thinking in Latent and Explicit for Pareto-Superior\n  Reasoning LLMs",
        "summary": "Recent work shows that, beyond discrete reasoning through explicit\nchain-of-thought steps, which are limited by the boundaries of natural\nlanguages, large language models (LLMs) can also reason continuously in latent\nspace, allowing richer information per step and thereby improving token\nefficiency. Despite this promise, latent reasoning still faces two challenges,\nespecially in training-free settings: 1) purely latent reasoning broadens the\nsearch distribution by maintaining multiple implicit paths, which diffuses\nprobability mass, introduces noise, and impedes convergence to a single\nhigh-confidence solution, thereby hurting accuracy; and 2) overthinking\npersists even without explicit text, wasting tokens and degrading efficiency.\nTo address these issues, we introduce SwiReasoning, a training-free framework\nfor LLM reasoning which features two key innovations: 1) SwiReasoning\ndynamically switches between explicit and latent reasoning, guided by\nblock-wise confidence estimated from entropy trends in next-token\ndistributions, to balance exploration and exploitation and promote timely\nconvergence. 2) By limiting the maximum number of thinking-block switches,\nSwiReasoning curbs overthinking and improves token efficiency across varying\nproblem difficulties. On widely used mathematics and STEM benchmarks,\nSwiReasoning consistently improves average accuracy by 1.5%-2.8% across\nreasoning LLMs of different model families and scales. Furthermore, under\nconstrained budgets, SwiReasoning improves average token efficiency by 56%-79%,\nwith larger gains as budgets tighten.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05069.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 119
        },
        "organization": {
            "_id": "5e6485f787403103f9f1055e",
            "name": "microsoft",
            "fullname": "Microsoft",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1583646260758-5e64858c87403103f9f1055d.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.02919",
            "authors": [
                {
                    "_id": "68e4aac5e4e093a7044e4dec",
                    "name": "Jian Mu",
                    "hidden": false
                },
                {
                    "_id": "68e4aac5e4e093a7044e4ded",
                    "name": "Qixin Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e4aac5e4e093a7044e4dee",
                    "name": "Zhiyong Wang",
                    "hidden": false
                },
                {
                    "_id": "68e4aac5e4e093a7044e4def",
                    "name": "Menglin Yang",
                    "hidden": false
                },
                {
                    "_id": "68e4aac5e4e093a7044e4df0",
                    "name": "Shuang Qiu",
                    "hidden": false
                },
                {
                    "_id": "68e4aac5e4e093a7044e4df1",
                    "name": "Chengwei Qin",
                    "hidden": false
                },
                {
                    "_id": "68e4aac5e4e093a7044e4df2",
                    "name": "Zhongxiang Dai",
                    "hidden": false
                },
                {
                    "_id": "68e4aac5e4e093a7044e4df3",
                    "name": "Yao Shu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-03T11:46:04.000Z",
            "submittedOnDailyAt": "2025-10-07T04:29:47.229Z",
            "title": "Self-Reflective Generation at Test Time",
            "submittedOnDailyBy": {
                "_id": "6628b0621b4cd5f0ada35ed8",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/TppL-D7GtZPqUlUb6UU-K.png",
                "isPro": false,
                "fullname": "mj",
                "user": "mujianijan",
                "type": "user"
            },
            "summary": "Large language models (LLMs) increasingly solve complex reasoning tasks via\nlong chain-of-thought, but their forward-only autoregressive generation process\nis fragile; early token errors can cascade, which creates a clear need for\nself-reflection mechanisms. However, existing self-reflection either performs\nrevisions over full drafts or learns self-correction via expensive training,\nboth fundamentally reactive and inefficient. To address this, we propose\nSelf-Reflective Generation at Test Time (SRGen), a lightweight test-time\nframework that reflects before generating at uncertain points. During token\ngeneration, SRGen utilizes dynamic entropy thresholding to identify\nhigh-uncertainty tokens. For each identified token, it trains a specific\ncorrective vector, which fully exploits the already generated context for a\nself-reflective generation to correct the token probability distribution. By\nretrospectively analyzing the partial output, this self-reflection enables more\ntrustworthy decisions, thereby significantly reducing the probability of errors\nat highly uncertain points. Evaluated on challenging mathematical reasoning\nbenchmarks and a diverse set of LLMs, SRGen can consistently strengthen model\nreasoning: improvements in single-pass quality also translate into stronger\nself-consistency voting. Especially, on AIME2024 with\nDeepSeek-R1-Distill-Qwen-7B, SRGen yields absolute improvements of +12.0% on\nPass@1 and +13.3% on Cons@5. Moreover, our findings position SRGen as a\nplug-and-play method that integrates reflection into the generation process for\nreliable LLM reasoning, achieving consistent gains with bounded overhead and\nbroad composability with other training-time (e.g., RLHF) and test-time (e.g.,\nSLOT) techniques.",
            "upvotes": 8,
            "discussionId": "68e4aac5e4e093a7044e4df4",
            "githubRepo": "https://github.com/2020-qqtcg/SRGen",
            "ai_summary": "SRGen, a lightweight test-time framework, improves LLM reasoning by dynamically identifying and correcting high-uncertainty tokens during generation, leading to better single-pass quality and self-consistency.",
            "ai_keywords": [
                "Self-Reflective Generation",
                "SRGen",
                "dynamic entropy thresholding",
                "corrective vector",
                "self-reflective generation",
                "token probability distribution",
                "self-consistency voting",
                "AIME2024",
                "DeepSeek-R1-Distill-Qwen-7B",
                "Pass@1",
                "Cons@5",
                "RLHF",
                "SLOT"
            ],
            "githubStars": 0
        },
        "publishedAt": "2025-10-03T07:46:04.000Z",
        "title": "Self-Reflective Generation at Test Time",
        "summary": "Large language models (LLMs) increasingly solve complex reasoning tasks via\nlong chain-of-thought, but their forward-only autoregressive generation process\nis fragile; early token errors can cascade, which creates a clear need for\nself-reflection mechanisms. However, existing self-reflection either performs\nrevisions over full drafts or learns self-correction via expensive training,\nboth fundamentally reactive and inefficient. To address this, we propose\nSelf-Reflective Generation at Test Time (SRGen), a lightweight test-time\nframework that reflects before generating at uncertain points. During token\ngeneration, SRGen utilizes dynamic entropy thresholding to identify\nhigh-uncertainty tokens. For each identified token, it trains a specific\ncorrective vector, which fully exploits the already generated context for a\nself-reflective generation to correct the token probability distribution. By\nretrospectively analyzing the partial output, this self-reflection enables more\ntrustworthy decisions, thereby significantly reducing the probability of errors\nat highly uncertain points. Evaluated on challenging mathematical reasoning\nbenchmarks and a diverse set of LLMs, SRGen can consistently strengthen model\nreasoning: improvements in single-pass quality also translate into stronger\nself-consistency voting. Especially, on AIME2024 with\nDeepSeek-R1-Distill-Qwen-7B, SRGen yields absolute improvements of +12.0% on\nPass@1 and +13.3% on Cons@5. Moreover, our findings position SRGen as a\nplug-and-play method that integrates reflection into the generation process for\nreliable LLM reasoning, achieving consistent gains with bounded overhead and\nbroad composability with other training-time (e.g., RLHF) and test-time (e.g.,\nSLOT) techniques.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.02919.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6628b0621b4cd5f0ada35ed8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/TppL-D7GtZPqUlUb6UU-K.png",
            "fullname": "mj",
            "name": "mujianijan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.04290",
            "authors": [
                {
                    "_id": "68e495cbe4e093a7044e4dc1",
                    "user": {
                        "_id": "633aaf695df91da9cea92960",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633aaf695df91da9cea92960/h1oOWUudbdlsd63Q5w0hM.png",
                        "isPro": false,
                        "fullname": "Jay Wu",
                        "user": "jayw",
                        "type": "user"
                    },
                    "name": "Jay Zhangjie Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:23.451Z",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dc2",
                    "name": "Xuanchi Ren",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dc3",
                    "name": "Tianchang Shen",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dc4",
                    "name": "Tianshi Cao",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dc5",
                    "name": "Kai He",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dc6",
                    "name": "Yifan Lu",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dc7",
                    "name": "Ruiyuan Gao",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dc8",
                    "name": "Enze Xie",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dc9",
                    "name": "Shiyi Lan",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dca",
                    "name": "Jose M. Alvarez",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dcb",
                    "name": "Jun Gao",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dcc",
                    "name": "Sanja Fidler",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dcd",
                    "name": "Zian Wang",
                    "hidden": false
                },
                {
                    "_id": "68e495cbe4e093a7044e4dce",
                    "name": "Huan Ling",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-05T17:02:01.000Z",
            "submittedOnDailyAt": "2025-10-07T02:54:44.177Z",
            "title": "ChronoEdit: Towards Temporal Reasoning for Image Editing and World\n  Simulation",
            "submittedOnDailyBy": {
                "_id": "633aaf695df91da9cea92960",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633aaf695df91da9cea92960/h1oOWUudbdlsd63Q5w0hM.png",
                "isPro": false,
                "fullname": "Jay Wu",
                "user": "jayw",
                "type": "user"
            },
            "summary": "Recent advances in large generative models have significantly advanced image\nediting and in-context image generation, yet a critical gap remains in ensuring\nphysical consistency, where edited objects must remain coherent. This\ncapability is especially vital for world simulation related tasks. In this\npaper, we present ChronoEdit, a framework that reframes image editing as a\nvideo generation problem. First, ChronoEdit treats the input and edited images\nas the first and last frames of a video, allowing it to leverage large\npretrained video generative models that capture not only object appearance but\nalso the implicit physics of motion and interaction through learned temporal\nconsistency. Second, ChronoEdit introduces a temporal reasoning stage that\nexplicitly performs editing at inference time. Under this setting, the target\nframe is jointly denoised with reasoning tokens to imagine a plausible editing\ntrajectory that constrains the solution space to physically viable\ntransformations. The reasoning tokens are then dropped after a few steps to\navoid the high computational cost of rendering a full video. To validate\nChronoEdit, we introduce PBench-Edit, a new benchmark of image-prompt pairs for\ncontexts that require physical consistency, and demonstrate that ChronoEdit\nsurpasses state-of-the-art baselines in both visual fidelity and physical\nplausibility. Code and models for both the 14B and 2B variants of ChronoEdit\nwill be released on the project page:\nhttps://research.nvidia.com/labs/toronto-ai/chronoedit",
            "upvotes": 7,
            "discussionId": "68e495cbe4e093a7044e4dcf",
            "projectPage": "https://research.nvidia.com/labs/toronto-ai/chronoedit",
            "githubRepo": "https://github.com/nv-tlabs/ChronoEdit",
            "ai_summary": "ChronoEdit addresses physical consistency in image editing by reframing it as a video generation problem, leveraging pretrained video models and temporal reasoning tokens.",
            "ai_keywords": [
                "video generative models",
                "temporal consistency",
                "temporal reasoning",
                "denoising",
                "reasoning tokens",
                "PBench-Edit",
                "visual fidelity",
                "physical plausibility"
            ],
            "githubStars": 19,
            "organization": {
                "_id": "60262b67268c201cdc8b7d43",
                "name": "nvidia",
                "fullname": "NVIDIA",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"
            }
        },
        "publishedAt": "2025-10-05T13:02:01.000Z",
        "title": "ChronoEdit: Towards Temporal Reasoning for Image Editing and World\n  Simulation",
        "summary": "Recent advances in large generative models have significantly advanced image\nediting and in-context image generation, yet a critical gap remains in ensuring\nphysical consistency, where edited objects must remain coherent. This\ncapability is especially vital for world simulation related tasks. In this\npaper, we present ChronoEdit, a framework that reframes image editing as a\nvideo generation problem. First, ChronoEdit treats the input and edited images\nas the first and last frames of a video, allowing it to leverage large\npretrained video generative models that capture not only object appearance but\nalso the implicit physics of motion and interaction through learned temporal\nconsistency. Second, ChronoEdit introduces a temporal reasoning stage that\nexplicitly performs editing at inference time. Under this setting, the target\nframe is jointly denoised with reasoning tokens to imagine a plausible editing\ntrajectory that constrains the solution space to physically viable\ntransformations. The reasoning tokens are then dropped after a few steps to\navoid the high computational cost of rendering a full video. To validate\nChronoEdit, we introduce PBench-Edit, a new benchmark of image-prompt pairs for\ncontexts that require physical consistency, and demonstrate that ChronoEdit\nsurpasses state-of-the-art baselines in both visual fidelity and physical\nplausibility. Code and models for both the 14B and 2B variants of ChronoEdit\nwill be released on the project page:\nhttps://research.nvidia.com/labs/toronto-ai/chronoedit",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04290.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "633aaf695df91da9cea92960",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/633aaf695df91da9cea92960/h1oOWUudbdlsd63Q5w0hM.png",
            "fullname": "Jay Wu",
            "name": "jayw",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 13
        },
        "organization": {
            "_id": "60262b67268c201cdc8b7d43",
            "name": "nvidia",
            "fullname": "NVIDIA",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.03755",
            "authors": [
                {
                    "_id": "68e4d483e4e093a7044e4ea1",
                    "name": "Roham Koohestani",
                    "hidden": false
                },
                {
                    "_id": "68e4d483e4e093a7044e4ea2",
                    "user": {
                        "_id": "68c831df1ce44d8e146512cc",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/yyXgcQ9WNoOXJi-giXsM8.png",
                        "isPro": false,
                        "fullname": "Parham Bateni",
                        "user": "ParhamBateni",
                        "type": "user"
                    },
                    "name": "Parham Bateni",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:25:24.404Z",
                    "hidden": false
                },
                {
                    "_id": "68e4d483e4e093a7044e4ea3",
                    "name": "Aydin Ebrahimi",
                    "hidden": false
                },
                {
                    "_id": "68e4d483e4e093a7044e4ea4",
                    "name": "Behdad Etezadi",
                    "hidden": false
                },
                {
                    "_id": "68e4d483e4e093a7044e4ea5",
                    "name": "Kiarash Karimi",
                    "hidden": false
                },
                {
                    "_id": "68e4d483e4e093a7044e4ea6",
                    "name": "Maliheh Izadi",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/655a627aab0644b531a02eb1/Z0dzJBRVXkCx6IrmkLz4Q.png"
            ],
            "publishedAt": "2025-10-04T09:40:43.000Z",
            "submittedOnDailyAt": "2025-10-07T07:22:14.600Z",
            "title": "Code4MeV2: a Research-oriented Code-completion Platform",
            "submittedOnDailyBy": {
                "_id": "655a627aab0644b531a02eb1",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/9rW6X1idfx1p5omky67D6.jpeg",
                "isPro": false,
                "fullname": "Roham Koohestani",
                "user": "RohamKoohestani",
                "type": "user"
            },
            "summary": "The adoption of AI-powered code completion tools in software development has\nincreased substantially, yet the user interaction data produced by these\nsystems remain proprietary within large corporations. This creates a barrier\nfor the academic community, as researchers must often develop dedicated\nplatforms to conduct studies on human--AI interaction, making reproducible\nresearch and large-scale data analysis impractical. In this work, we introduce\nCode4MeV2, a research-oriented, open-source code completion plugin for\nJetBrains IDEs, as a solution to this limitation. Code4MeV2 is designed using a\nclient--server architecture and features inline code completion and a\ncontext-aware chat assistant. Its core contribution is a modular and\ntransparent data collection framework that gives researchers fine-grained\ncontrol over telemetry and context gathering. Code4MeV2 achieves\nindustry-comparable performance in terms of code completion, with an average\nlatency of 200~ms. We assess our tool through a combination of an expert\nevaluation and a user study with eight participants. Feedback from both\nresearchers and daily users highlights its informativeness and usefulness. We\ninvite the community to adopt and contribute to this tool. More information\nabout the tool can be found at https://app.code4me.me.",
            "upvotes": 7,
            "discussionId": "68e4d484e4e093a7044e4ea7",
            "projectPage": "https://app.code4me.me/",
            "githubRepo": "https://github.com/AISE-TUDelft/code4me2-server",
            "ai_summary": "Code4MeV2 is an open-source code completion plugin for JetBrains IDEs that provides a transparent data collection framework for researchers, offering industry-level performance and user feedback.",
            "ai_keywords": [
                "code completion",
                "client-server architecture",
                "inline code completion",
                "context-aware chat assistant",
                "telemetry",
                "context gathering",
                "expert evaluation",
                "user study"
            ],
            "githubStars": 0,
            "organization": {
                "_id": "63dd4bc4af221a78fa5070bc",
                "name": "AISE-TUDelft",
                "fullname": "AISE research lab at TU Delft"
            }
        },
        "publishedAt": "2025-10-04T05:40:43.000Z",
        "title": "Code4MeV2: a Research-oriented Code-completion Platform",
        "summary": "The adoption of AI-powered code completion tools in software development has\nincreased substantially, yet the user interaction data produced by these\nsystems remain proprietary within large corporations. This creates a barrier\nfor the academic community, as researchers must often develop dedicated\nplatforms to conduct studies on human--AI interaction, making reproducible\nresearch and large-scale data analysis impractical. In this work, we introduce\nCode4MeV2, a research-oriented, open-source code completion plugin for\nJetBrains IDEs, as a solution to this limitation. Code4MeV2 is designed using a\nclient--server architecture and features inline code completion and a\ncontext-aware chat assistant. Its core contribution is a modular and\ntransparent data collection framework that gives researchers fine-grained\ncontrol over telemetry and context gathering. Code4MeV2 achieves\nindustry-comparable performance in terms of code completion, with an average\nlatency of 200~ms. We assess our tool through a combination of an expert\nevaluation and a user study with eight participants. Feedback from both\nresearchers and daily users highlights its informativeness and usefulness. We\ninvite the community to adopt and contribute to this tool. More information\nabout the tool can be found at https://app.code4me.me.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/655a627aab0644b531a02eb1/Z0dzJBRVXkCx6IrmkLz4Q.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03755.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "655a627aab0644b531a02eb1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/9rW6X1idfx1p5omky67D6.jpeg",
            "fullname": "Roham Koohestani",
            "name": "RohamKoohestani",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "63dd4bc4af221a78fa5070bc",
            "name": "AISE-TUDelft",
            "fullname": "AISE research lab at TU Delft"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.04673",
            "authors": [
                {
                    "_id": "68e481d4e4e093a7044e4d59",
                    "name": "Chan Hee Song",
                    "hidden": false
                },
                {
                    "_id": "68e481d4e4e093a7044e4d5a",
                    "name": "Yiwen Song",
                    "hidden": false
                },
                {
                    "_id": "68e481d4e4e093a7044e4d5b",
                    "name": "Palash Goyal",
                    "hidden": false
                },
                {
                    "_id": "68e481d4e4e093a7044e4d5c",
                    "name": "Yu Su",
                    "hidden": false
                },
                {
                    "_id": "68e481d4e4e093a7044e4d5d",
                    "name": "Oriana Riva",
                    "hidden": false
                },
                {
                    "_id": "68e481d4e4e093a7044e4d5e",
                    "name": "Hamid Palangi",
                    "hidden": false
                },
                {
                    "_id": "68e481d4e4e093a7044e4d5f",
                    "name": "Tomas Pfister",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T10:29:00.000Z",
            "submittedOnDailyAt": "2025-10-07T01:28:38.169Z",
            "title": "Watch and Learn: Learning to Use Computers from Online Videos",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Computer use agents (CUAs) need to plan task workflows grounded in diverse,\never-changing applications and environments, but learning is hindered by the\nscarcity of large-scale, high-quality training data in the target application.\nExisting datasets are domain-specific, static, and costly to annotate, while\ncurrent synthetic data generation methods often yield simplistic or misaligned\ntask demonstrations. To address these limitations, we introduce Watch & Learn\n(W&L), a framework that converts human demonstration videos readily available\non the Internet into executable UI trajectories at scale. Instead of directly\ngenerating trajectories or relying on ad hoc reasoning heuristics, we cast the\nproblem as an inverse dynamics objective: predicting the user's action from\nconsecutive screen states. This formulation reduces manual engineering, is\neasier to learn, and generalizes more robustly across applications. Concretely,\nwe develop an inverse dynamics labeling pipeline with task-aware video\nretrieval, generate over 53k high-quality trajectories from raw web videos, and\ndemonstrate that these trajectories improve CUAs both as in-context\ndemonstrations and as supervised training data. On the challenging OSWorld\nbenchmark, UI trajectories extracted with W&L consistently enhance both\ngeneral-purpose and state-of-the-art frameworks in-context, and deliver\nstronger gains for open-source models under supervised training. These results\nhighlight web-scale human demonstration videos as a practical and scalable\nfoundation for advancing CUAs towards real-world deployment.",
            "upvotes": 5,
            "discussionId": "68e481d4e4e093a7044e4d60",
            "ai_summary": "Watch & Learn converts web demonstration videos into UI trajectories to enhance computer use agents, improving both in-context demonstrations and supervised training.",
            "ai_keywords": [
                "inverse dynamics",
                "task-aware video retrieval",
                "UI trajectories",
                "OSWorld benchmark"
            ]
        },
        "publishedAt": "2025-10-06T06:29:00.000Z",
        "title": "Watch and Learn: Learning to Use Computers from Online Videos",
        "summary": "Computer use agents (CUAs) need to plan task workflows grounded in diverse,\never-changing applications and environments, but learning is hindered by the\nscarcity of large-scale, high-quality training data in the target application.\nExisting datasets are domain-specific, static, and costly to annotate, while\ncurrent synthetic data generation methods often yield simplistic or misaligned\ntask demonstrations. To address these limitations, we introduce Watch & Learn\n(W&L), a framework that converts human demonstration videos readily available\non the Internet into executable UI trajectories at scale. Instead of directly\ngenerating trajectories or relying on ad hoc reasoning heuristics, we cast the\nproblem as an inverse dynamics objective: predicting the user's action from\nconsecutive screen states. This formulation reduces manual engineering, is\neasier to learn, and generalizes more robustly across applications. Concretely,\nwe develop an inverse dynamics labeling pipeline with task-aware video\nretrieval, generate over 53k high-quality trajectories from raw web videos, and\ndemonstrate that these trajectories improve CUAs both as in-context\ndemonstrations and as supervised training data. On the challenging OSWorld\nbenchmark, UI trajectories extracted with W&L consistently enhance both\ngeneral-purpose and state-of-the-art frameworks in-context, and deliver\nstronger gains for open-source models under supervised training. These results\nhighlight web-scale human demonstration videos as a practical and scalable\nfoundation for advancing CUAs towards real-world deployment.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04673.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 119
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.04434",
            "authors": [
                {
                    "_id": "68e478b7e4e093a7044e4cfc",
                    "name": "Grace LeFevre",
                    "hidden": false
                },
                {
                    "_id": "68e478b7e4e093a7044e4cfd",
                    "name": "Qingcheng Zeng",
                    "hidden": false
                },
                {
                    "_id": "68e478b7e4e093a7044e4cfe",
                    "name": "Adam Leif",
                    "hidden": false
                },
                {
                    "_id": "68e478b7e4e093a7044e4cff",
                    "name": "Jason Jewell",
                    "hidden": false
                },
                {
                    "_id": "68e478b7e4e093a7044e4d00",
                    "name": "Denis Peskoff",
                    "hidden": false
                },
                {
                    "_id": "68e478b7e4e093a7044e4d01",
                    "name": "Rob Voigt",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T02:04:42.000Z",
            "submittedOnDailyAt": "2025-10-07T00:57:27.695Z",
            "title": "Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?",
            "submittedOnDailyBy": {
                "_id": "63bc77661374e3ef9135735f",
                "avatarUrl": "/avatars/94b04545ed9d30bfe58691672a0b5618.svg",
                "isPro": false,
                "fullname": "Qingcheng Zeng",
                "user": "qcz",
                "type": "user"
            },
            "summary": "The social impact of Natural Language Processing (NLP) is increasingly\nimportant, with a rising community focus on initiatives related to NLP for\nSocial Good (NLP4SG). Indeed, in recent years, almost 20% of all papers in the\nACL Anthology address topics related to social good as defined by the UN\nSustainable Development Goals (Adauto et al., 2023). In this study, we take an\nauthor- and venue-level perspective to map the landscape of NLP4SG, quantifying\nthe proportion of work addressing social good concerns both within and beyond\nthe ACL community, by both core ACL contributors and non-ACL authors. With this\napproach we discover two surprising facts about the landscape of NLP4SG. First,\nACL authors are dramatically more likely to do work addressing social good\nconcerns when publishing in venues outside of ACL. Second, the vast majority of\npublications using NLP techniques to address concerns of social good are done\nby non-ACL authors in venues outside of ACL. We discuss the implications of\nthese findings on agenda-setting considerations for the ACL community related\nto NLP4SG.",
            "upvotes": 4,
            "discussionId": "68e478b7e4e093a7044e4d02",
            "ai_summary": "The study reveals that ACL authors are more likely to address social good concerns in non-ACL venues, and most NLP4SG publications are from non-ACL authors.",
            "ai_keywords": [
                "Natural Language Processing",
                "NLP for Social Good",
                "NLP4SG",
                "ACL Anthology",
                "UN Sustainable Development Goals",
                "author-level perspective",
                "venue-level perspective",
                "core ACL contributors",
                "non-ACL authors",
                "agenda-setting considerations"
            ]
        },
        "publishedAt": "2025-10-05T22:04:42.000Z",
        "title": "Good Intentions Beyond ACL: Who Does NLP for Social Good, and Where?",
        "summary": "The social impact of Natural Language Processing (NLP) is increasingly\nimportant, with a rising community focus on initiatives related to NLP for\nSocial Good (NLP4SG). Indeed, in recent years, almost 20% of all papers in the\nACL Anthology address topics related to social good as defined by the UN\nSustainable Development Goals (Adauto et al., 2023). In this study, we take an\nauthor- and venue-level perspective to map the landscape of NLP4SG, quantifying\nthe proportion of work addressing social good concerns both within and beyond\nthe ACL community, by both core ACL contributors and non-ACL authors. With this\napproach we discover two surprising facts about the landscape of NLP4SG. First,\nACL authors are dramatically more likely to do work addressing social good\nconcerns when publishing in venues outside of ACL. Second, the vast majority of\npublications using NLP techniques to address concerns of social good are done\nby non-ACL authors in venues outside of ACL. We discuss the implications of\nthese findings on agenda-setting considerations for the ACL community related\nto NLP4SG.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04434.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63bc77661374e3ef9135735f",
            "avatarUrl": "/avatars/94b04545ed9d30bfe58691672a0b5618.svg",
            "fullname": "Qingcheng Zeng",
            "name": "qcz",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.00732",
            "authors": [
                {
                    "_id": "68e0764f73e20ab577841bcb",
                    "name": "Yuchen Tian",
                    "hidden": false
                },
                {
                    "_id": "68e0764f73e20ab577841bcc",
                    "name": "Ruiyuan Huang",
                    "hidden": false
                },
                {
                    "_id": "68e0764f73e20ab577841bcd",
                    "name": "Xuanwu Wang",
                    "hidden": false
                },
                {
                    "_id": "68e0764f73e20ab577841bce",
                    "name": "Jing Ma",
                    "hidden": false
                },
                {
                    "_id": "68e0764f73e20ab577841bcf",
                    "name": "Zengfeng Huang",
                    "hidden": false
                },
                {
                    "_id": "68e0764f73e20ab577841bd0",
                    "user": {
                        "_id": "6090ff099a8bcaa437b234a4",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6090ff099a8bcaa437b234a4/iUvw7JXT-ngI7rGk1x-io.jpeg",
                        "isPro": false,
                        "fullname": "Ziyang Luo",
                        "user": "Ziyang",
                        "type": "user"
                    },
                    "name": "Ziyang Luo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-05T12:45:56.245Z",
                    "hidden": false
                },
                {
                    "_id": "68e0764f73e20ab577841bd1",
                    "user": {
                        "_id": "6499466c7d1edf7cb612a9a6",
                        "avatarUrl": "/avatars/c2e18594aa0879db8226f2a04496fb0b.svg",
                        "isPro": false,
                        "fullname": "Hongzhan Lin",
                        "user": "danielhzlin",
                        "type": "user"
                    },
                    "name": "Hongzhan Lin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-05T12:45:53.371Z",
                    "hidden": false
                },
                {
                    "_id": "68e0764f73e20ab577841bd2",
                    "name": "Da Zheng",
                    "hidden": false
                },
                {
                    "_id": "68e0764f73e20ab577841bd3",
                    "name": "Lun Du",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6499466c7d1edf7cb612a9a6/aXVxfwkFI28iYIZ0T2LQK.png"
            ],
            "publishedAt": "2025-10-01T10:15:27.000Z",
            "submittedOnDailyAt": "2025-10-07T03:25:48.318Z",
            "title": "EvolProver: Advancing Automated Theorem Proving by Evolving Formalized\n  Problems via Symmetry and Difficulty",
            "submittedOnDailyBy": {
                "_id": "6499466c7d1edf7cb612a9a6",
                "avatarUrl": "/avatars/c2e18594aa0879db8226f2a04496fb0b.svg",
                "isPro": false,
                "fullname": "Hongzhan Lin",
                "user": "danielhzlin",
                "type": "user"
            },
            "summary": "Large Language Models (LLMs) for formal theorem proving have shown\nsignificant promise, yet they often lack generalizability and are fragile to\neven minor transformations of problem statements. To address this limitation,\nwe introduce a novel data augmentation pipeline designed to enhance model\nrobustness from two perspectives: symmetry and difficulty. From the symmetry\nperspective, we propose two complementary methods: EvolAST, an Abstract Syntax\nTree (AST) based approach that targets syntactic symmetry to generate\nsemantically equivalent problem variants, and EvolDomain, which leverages LLMs\nto address semantic symmetry by translating theorems across mathematical\ndomains. From the difficulty perspective, we propose EvolDifficulty, which uses\ncarefully designed evolutionary instructions to guide LLMs in generating new\ntheorems with a wider range of difficulty. We then use the evolved data to\ntrain EvolProver, a 7B-parameter non-reasoning theorem prover. EvolProver\nestablishes a new state-of-the-art (SOTA) on FormalMATH-Lite with a 53.8%\npass@32 rate, surpassing all models of comparable size, including\nreasoning-based models. It also sets new SOTA records for non-reasoning models\non MiniF2F-Test (69.8% pass@32), Ineq-Comp-Seed (52.2% pass@32), and\nIneq-Comp-Transformed (34.0% pass@32). Ablation studies further confirm our\ndata augmentation pipeline's effectiveness across multiple benchmarks.",
            "upvotes": 4,
            "discussionId": "68e0764f73e20ab577841bd4",
            "ai_summary": "A novel data augmentation pipeline enhances the robustness and generalizability of large language models for formal theorem proving by addressing syntactic and semantic symmetry and varying difficulty levels, leading to state-of-the-art performance on multiple benchmarks.",
            "ai_keywords": [
                "Large Language Models",
                "formal theorem proving",
                "data augmentation",
                "Abstract Syntax Tree",
                "EvolAST",
                "EvolDomain",
                "EvolDifficulty",
                "EvolProver",
                "FormalMATH-Lite",
                "MiniF2F-Test",
                "Ineq-Comp-Seed",
                "Ineq-Comp-Transformed"
            ]
        },
        "publishedAt": "2025-10-01T06:15:27.000Z",
        "title": "EvolProver: Advancing Automated Theorem Proving by Evolving Formalized\n  Problems via Symmetry and Difficulty",
        "summary": "Large Language Models (LLMs) for formal theorem proving have shown\nsignificant promise, yet they often lack generalizability and are fragile to\neven minor transformations of problem statements. To address this limitation,\nwe introduce a novel data augmentation pipeline designed to enhance model\nrobustness from two perspectives: symmetry and difficulty. From the symmetry\nperspective, we propose two complementary methods: EvolAST, an Abstract Syntax\nTree (AST) based approach that targets syntactic symmetry to generate\nsemantically equivalent problem variants, and EvolDomain, which leverages LLMs\nto address semantic symmetry by translating theorems across mathematical\ndomains. From the difficulty perspective, we propose EvolDifficulty, which uses\ncarefully designed evolutionary instructions to guide LLMs in generating new\ntheorems with a wider range of difficulty. We then use the evolved data to\ntrain EvolProver, a 7B-parameter non-reasoning theorem prover. EvolProver\nestablishes a new state-of-the-art (SOTA) on FormalMATH-Lite with a 53.8%\npass@32 rate, surpassing all models of comparable size, including\nreasoning-based models. It also sets new SOTA records for non-reasoning models\non MiniF2F-Test (69.8% pass@32), Ineq-Comp-Seed (52.2% pass@32), and\nIneq-Comp-Transformed (34.0% pass@32). Ablation studies further confirm our\ndata augmentation pipeline's effectiveness across multiple benchmarks.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6499466c7d1edf7cb612a9a6/aXVxfwkFI28iYIZ0T2LQK.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.00732.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6499466c7d1edf7cb612a9a6",
            "avatarUrl": "/avatars/c2e18594aa0879db8226f2a04496fb0b.svg",
            "fullname": "Hongzhan Lin",
            "name": "danielhzlin",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04016",
            "authors": [
                {
                    "_id": "68e489e6e4e093a7044e4d84",
                    "user": {
                        "_id": "6425b69a85f26ab94af04465",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6425b69a85f26ab94af04465/YWQfMbXnClhxDnixpGGAb.jpeg",
                        "isPro": false,
                        "fullname": "Thanapol Popit",
                        "user": "Saltywan",
                        "type": "user"
                    },
                    "name": "Thanapol Popit",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:36.294Z",
                    "hidden": false
                },
                {
                    "_id": "68e489e6e4e093a7044e4d85",
                    "name": "Natthapath Rungseesiripak",
                    "hidden": false
                },
                {
                    "_id": "68e489e6e4e093a7044e4d86",
                    "name": "Monthol Charattrakool",
                    "hidden": false
                },
                {
                    "_id": "68e489e6e4e093a7044e4d87",
                    "user": {
                        "_id": "62243664af5df9d9e5582f67",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62243664af5df9d9e5582f67/nAntUd0NVDcMYtwiunCU8.jpeg",
                        "isPro": false,
                        "fullname": "Saksorn Ruangtanusak",
                        "user": "saksornr",
                        "type": "user"
                    },
                    "name": "Saksorn Ruangtanusak",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:38.934Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/62243664af5df9d9e5582f67/nwxLd46vqAlIWtnbCCMq4.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62243664af5df9d9e5582f67/_5x2_DPHnetOLRjFq8bjO.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62243664af5df9d9e5582f67/qO5lgPDmO-P68U8SFcKN9.png"
            ],
            "publishedAt": "2025-10-05T03:31:59.000Z",
            "submittedOnDailyAt": "2025-10-07T02:06:11.660Z",
            "title": "Thai Semantic End-of-Turn Detection for Real-Time Voice Agents",
            "submittedOnDailyBy": {
                "_id": "62243664af5df9d9e5582f67",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62243664af5df9d9e5582f67/nAntUd0NVDcMYtwiunCU8.jpeg",
                "isPro": false,
                "fullname": "Saksorn Ruangtanusak",
                "user": "saksornr",
                "type": "user"
            },
            "summary": "Fluid voice-to-voice interaction requires reliable and low-latency detection\nof when a user has finished speaking. Traditional audio-silence end-pointers\nadd hundreds of milliseconds of delay and fail under hesitations or\nlanguage-specific phenomena. We present, to our knowledge, the first systematic\nstudy of Thai text-only end-of-turn (EOT) detection for real-time agents. We\ncompare zero-shot and few-shot prompting of compact LLMs to supervised\nfine-tuning of lightweight transformers. Using transcribed subtitles from the\nYODAS corpus and Thai-specific linguistic cues (e.g., sentence-final\nparticles), we formulate EOT as a binary decision over token boundaries. We\nreport a clear accuracy-latency tradeoff and provide a public-ready\nimplementation plan. This work establishes a Thai baseline and demonstrates\nthat small, fine-tuned models can deliver near-instant EOT decisions suitable\nfor on-device agents.",
            "upvotes": 3,
            "discussionId": "68e489e6e4e093a7044e4d88",
            "ai_summary": "Real-time Thai text-only end-of-turn detection using zero-shot and few-shot prompting of compact LLMs and lightweight transformers achieves near-instant accuracy suitable for on-device agents.",
            "ai_keywords": [
                "zero-shot prompting",
                "few-shot prompting",
                "compact LLMs",
                "lightweight transformers",
                "end-of-turn detection",
                "token boundaries"
            ]
        },
        "publishedAt": "2025-10-04T23:31:59.000Z",
        "title": "Thai Semantic End-of-Turn Detection for Real-Time Voice Agents",
        "summary": "Fluid voice-to-voice interaction requires reliable and low-latency detection\nof when a user has finished speaking. Traditional audio-silence end-pointers\nadd hundreds of milliseconds of delay and fail under hesitations or\nlanguage-specific phenomena. We present, to our knowledge, the first systematic\nstudy of Thai text-only end-of-turn (EOT) detection for real-time agents. We\ncompare zero-shot and few-shot prompting of compact LLMs to supervised\nfine-tuning of lightweight transformers. Using transcribed subtitles from the\nYODAS corpus and Thai-specific linguistic cues (e.g., sentence-final\nparticles), we formulate EOT as a binary decision over token boundaries. We\nreport a clear accuracy-latency tradeoff and provide a public-ready\nimplementation plan. This work establishes a Thai baseline and demonstrates\nthat small, fine-tuned models can deliver near-instant EOT decisions suitable\nfor on-device agents.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62243664af5df9d9e5582f67/nwxLd46vqAlIWtnbCCMq4.png",
            "https://cdn-uploads.huggingface.co/production/uploads/62243664af5df9d9e5582f67/_5x2_DPHnetOLRjFq8bjO.png",
            "https://cdn-uploads.huggingface.co/production/uploads/62243664af5df9d9e5582f67/qO5lgPDmO-P68U8SFcKN9.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04016.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "62243664af5df9d9e5582f67",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/62243664af5df9d9e5582f67/nAntUd0NVDcMYtwiunCU8.jpeg",
            "fullname": "Saksorn Ruangtanusak",
            "name": "saksornr",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 16
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.03857",
            "authors": [
                {
                    "_id": "68e4d8fce4e093a7044e4eaf",
                    "name": "Minseo Lee",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb0",
                    "name": "Byeonghyeon Lee",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb1",
                    "name": "Lucas Yunkyu Lee",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb2",
                    "name": "Eunsoo Lee",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb3",
                    "name": "Sangmin Kim",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb4",
                    "name": "Seunghyeon Song",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb5",
                    "name": "Joo Chan Lee",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb6",
                    "name": "Jong Hwan Ko",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb7",
                    "name": "Jaesik Park",
                    "hidden": false
                },
                {
                    "_id": "68e4d8fce4e093a7044e4eb8",
                    "name": "Eunbyung Park",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-04T16:11:13.000Z",
            "submittedOnDailyAt": "2025-10-07T23:26:53.662Z",
            "title": "Optimized Minimal 4D Gaussian Splatting",
            "submittedOnDailyBy": {
                "_id": "655e0141d36a195f663ee4b0",
                "avatarUrl": "/avatars/97bb695ccefdcb2139b94bcae808cf99.svg",
                "isPro": false,
                "fullname": "Eunbyung Park",
                "user": "epark",
                "type": "user"
            },
            "summary": "4D Gaussian Splatting has emerged as a new paradigm for dynamic scene\nrepresentation, enabling real-time rendering of scenes with complex motions.\nHowever, it faces a major challenge of storage overhead, as millions of\nGaussians are required for high-fidelity reconstruction. While several studies\nhave attempted to alleviate this memory burden, they still face limitations in\ncompression ratio or visual quality. In this work, we present OMG4 (Optimized\nMinimal 4D Gaussian Splatting), a framework that constructs a compact set of\nsalient Gaussians capable of faithfully representing 4D Gaussian models. Our\nmethod progressively prunes Gaussians in three stages: (1) Gaussian Sampling to\nidentify primitives critical to reconstruction fidelity, (2) Gaussian Pruning\nto remove redundancies, and (3) Gaussian Merging to fuse primitives with\nsimilar characteristics. In addition, we integrate implicit appearance\ncompression and generalize Sub-Vector Quantization (SVQ) to 4D representations,\nfurther reducing storage while preserving quality. Extensive experiments on\nstandard benchmark datasets demonstrate that OMG4 significantly outperforms\nrecent state-of-the-art methods, reducing model sizes by over 60% while\nmaintaining reconstruction quality. These results position OMG4 as a\nsignificant step forward in compact 4D scene representation, opening new\npossibilities for a wide range of applications. Our source code is available at\nhttps://minshirley.github.io/OMG4/.",
            "upvotes": 3,
            "discussionId": "68e4d8fde4e093a7044e4eb9",
            "projectPage": "https://minshirley.github.io/OMG4/",
            "githubRepo": "https://github.com/MinShirley/OMG4",
            "ai_summary": "OMG4 optimizes 4D Gaussian Splatting by pruning and merging Gaussians, integrating implicit appearance compression, and generalizing Sub-Vector Quantization to reduce storage without sacrificing quality.",
            "ai_keywords": [
                "Gaussian Splatting",
                "Gaussian Sampling",
                "Gaussian Pruning",
                "Gaussian Merging",
                "implicit appearance compression",
                "Sub-Vector Quantization"
            ],
            "githubStars": 16
        },
        "publishedAt": "2025-10-04T12:11:13.000Z",
        "title": "Optimized Minimal 4D Gaussian Splatting",
        "summary": "4D Gaussian Splatting has emerged as a new paradigm for dynamic scene\nrepresentation, enabling real-time rendering of scenes with complex motions.\nHowever, it faces a major challenge of storage overhead, as millions of\nGaussians are required for high-fidelity reconstruction. While several studies\nhave attempted to alleviate this memory burden, they still face limitations in\ncompression ratio or visual quality. In this work, we present OMG4 (Optimized\nMinimal 4D Gaussian Splatting), a framework that constructs a compact set of\nsalient Gaussians capable of faithfully representing 4D Gaussian models. Our\nmethod progressively prunes Gaussians in three stages: (1) Gaussian Sampling to\nidentify primitives critical to reconstruction fidelity, (2) Gaussian Pruning\nto remove redundancies, and (3) Gaussian Merging to fuse primitives with\nsimilar characteristics. In addition, we integrate implicit appearance\ncompression and generalize Sub-Vector Quantization (SVQ) to 4D representations,\nfurther reducing storage while preserving quality. Extensive experiments on\nstandard benchmark datasets demonstrate that OMG4 significantly outperforms\nrecent state-of-the-art methods, reducing model sizes by over 60% while\nmaintaining reconstruction quality. These results position OMG4 as a\nsignificant step forward in compact 4D scene representation, opening new\npossibilities for a wide range of applications. Our source code is available at\nhttps://minshirley.github.io/OMG4/.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03857.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "655e0141d36a195f663ee4b0",
            "avatarUrl": "/avatars/97bb695ccefdcb2139b94bcae808cf99.svg",
            "fullname": "Eunbyung Park",
            "name": "epark",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 5
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05093",
            "authors": [
                {
                    "_id": "68e4ef59ee2331580b782445",
                    "user": {
                        "_id": "63e4943b789dcaae43cb5bb5",
                        "avatarUrl": "/avatars/66859007330ddfec09f235e9846d477a.svg",
                        "isPro": false,
                        "fullname": "Tingting Liao",
                        "user": "Luffuly",
                        "type": "user"
                    },
                    "name": "Tingting Liao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:25:10.523Z",
                    "hidden": false
                },
                {
                    "_id": "68e4ef59ee2331580b782446",
                    "name": "Chongjian Ge",
                    "hidden": false
                },
                {
                    "_id": "68e4ef59ee2331580b782447",
                    "name": "Guangyi Liu",
                    "hidden": false
                },
                {
                    "_id": "68e4ef59ee2331580b782448",
                    "name": "Hao Li",
                    "hidden": false
                },
                {
                    "_id": "68e4ef59ee2331580b782449",
                    "name": "Yi Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T17:57:39.000Z",
            "submittedOnDailyAt": "2025-10-07T09:17:58.393Z",
            "title": "Character Mixing for Video Generation",
            "submittedOnDailyBy": {
                "_id": "63e4943b789dcaae43cb5bb5",
                "avatarUrl": "/avatars/66859007330ddfec09f235e9846d477a.svg",
                "isPro": false,
                "fullname": "Tingting Liao",
                "user": "Luffuly",
                "type": "user"
            },
            "summary": "Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where\ncharacters interact naturally across different worlds? We study inter-character\ninteraction in text-to-video generation, where the key challenge is to preserve\neach character's identity and behaviors while enabling coherent cross-context\ninteraction. This is difficult because characters may never have coexisted and\nbecause mixing styles often causes style delusion, where realistic characters\nappear cartoonish or vice versa. We introduce a framework that tackles these\nissues with Cross-Character Embedding (CCE), which learns identity and\nbehavioral logic across multimodal sources, and Cross-Character Augmentation\n(CCA), which enriches training with synthetic co-existence and mixed-style\ndata. Together, these techniques allow natural interactions between previously\nuncoexistent characters without losing stylistic fidelity. Experiments on a\ncurated benchmark of cartoons and live-action series with 10 characters show\nclear improvements in identity preservation, interaction quality, and\nrobustness to style delusion, enabling new forms of generative\nstorytelling.Additional results and videos are available on our project page:\nhttps://tingtingliao.github.io/mimix/.",
            "upvotes": 2,
            "discussionId": "68e4ef59ee2331580b78244a",
            "projectPage": "https://tingtingliao.github.io/mimix/",
            "githubRepo": "https://github.com/TingtingLiao/mimix",
            "ai_summary": "A framework using Cross-Character Embedding and Cross-Character Augmentation enables natural interactions between characters from different worlds while preserving their identity and style.",
            "ai_keywords": [
                "Cross-Character Embedding",
                "Cross-Character Augmentation",
                "text-to-video generation",
                "identity preservation",
                "interaction quality",
                "style delusion",
                "multimodal sources",
                "synthetic co-existence",
                "mixed-style data",
                "generative storytelling"
            ],
            "githubStars": 2,
            "organization": {
                "_id": "61fb9e24dc607a42af5f193f",
                "name": "MBZUAI",
                "fullname": "Mohamed Bin Zayed University of Artificial Intelligence",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1643879908583-603ab5664a944b99e81476e8.jpeg"
            }
        },
        "publishedAt": "2025-10-06T13:57:39.000Z",
        "title": "Character Mixing for Video Generation",
        "summary": "Imagine Mr. Bean stepping into Tom and Jerry--can we generate videos where\ncharacters interact naturally across different worlds? We study inter-character\ninteraction in text-to-video generation, where the key challenge is to preserve\neach character's identity and behaviors while enabling coherent cross-context\ninteraction. This is difficult because characters may never have coexisted and\nbecause mixing styles often causes style delusion, where realistic characters\nappear cartoonish or vice versa. We introduce a framework that tackles these\nissues with Cross-Character Embedding (CCE), which learns identity and\nbehavioral logic across multimodal sources, and Cross-Character Augmentation\n(CCA), which enriches training with synthetic co-existence and mixed-style\ndata. Together, these techniques allow natural interactions between previously\nuncoexistent characters without losing stylistic fidelity. Experiments on a\ncurated benchmark of cartoons and live-action series with 10 characters show\nclear improvements in identity preservation, interaction quality, and\nrobustness to style delusion, enabling new forms of generative\nstorytelling.Additional results and videos are available on our project page:\nhttps://tingtingliao.github.io/mimix/.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05093.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63e4943b789dcaae43cb5bb5",
            "avatarUrl": "/avatars/66859007330ddfec09f235e9846d477a.svg",
            "fullname": "Tingting Liao",
            "name": "Luffuly",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 3
        },
        "organization": {
            "_id": "61fb9e24dc607a42af5f193f",
            "name": "MBZUAI",
            "fullname": "Mohamed Bin Zayed University of Artificial Intelligence",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1643879908583-603ab5664a944b99e81476e8.jpeg"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05081",
            "authors": [
                {
                    "_id": "68e4cb1ee4e093a7044e4e5f",
                    "name": "Ronen Kamenetsky",
                    "hidden": false
                },
                {
                    "_id": "68e4cb1ee4e093a7044e4e60",
                    "name": "Sara Dorfman",
                    "hidden": false
                },
                {
                    "_id": "68e4cb1ee4e093a7044e4e61",
                    "user": {
                        "_id": "65fbf768980d4143b0d3ab52",
                        "avatarUrl": "/avatars/018a26ce944860e9ab97ca43765e7d76.svg",
                        "isPro": false,
                        "fullname": "Daniel Garibi",
                        "user": "garibida",
                        "type": "user"
                    },
                    "name": "Daniel Garibi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:25:48.450Z",
                    "hidden": false
                },
                {
                    "_id": "68e4cb1ee4e093a7044e4e62",
                    "name": "Roni Paiss",
                    "hidden": false
                },
                {
                    "_id": "68e4cb1ee4e093a7044e4e63",
                    "name": "Or Patashnik",
                    "hidden": false
                },
                {
                    "_id": "68e4cb1ee4e093a7044e4e64",
                    "name": "Daniel Cohen-Or",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T17:51:04.000Z",
            "submittedOnDailyAt": "2025-10-07T06:45:15.097Z",
            "title": "SAEdit: Token-level control for continuous image editing via Sparse\n  AutoEncoder",
            "submittedOnDailyBy": {
                "_id": "65fbf768980d4143b0d3ab52",
                "avatarUrl": "/avatars/018a26ce944860e9ab97ca43765e7d76.svg",
                "isPro": false,
                "fullname": "Daniel Garibi",
                "user": "garibida",
                "type": "user"
            },
            "summary": "Large-scale text-to-image diffusion models have become the backbone of modern\nimage editing, yet text prompts alone do not offer adequate control over the\nediting process. Two properties are especially desirable: disentanglement,\nwhere changing one attribute does not unintentionally alter others, and\ncontinuous control, where the strength of an edit can be smoothly adjusted. We\nintroduce a method for disentangled and continuous editing through token-level\nmanipulation of text embeddings. The edits are applied by manipulating the\nembeddings along carefully chosen directions, which control the strength of the\ntarget attribute. To identify such directions, we employ a Sparse Autoencoder\n(SAE), whose sparse latent space exposes semantically isolated dimensions. Our\nmethod operates directly on text embeddings without modifying the diffusion\nprocess, making it model agnostic and broadly applicable to various image\nsynthesis backbones. Experiments show that it enables intuitive and efficient\nmanipulations with continuous control across diverse attributes and domains.",
            "upvotes": 2,
            "discussionId": "68e4cb1fe4e093a7044e4e65",
            "ai_summary": "A method for disentangled and continuous text-to-image editing uses token-level manipulation of text embeddings with sparse autoencoders to control image attributes smoothly.",
            "ai_keywords": [
                "diffusion models",
                "text-to-image",
                "disentanglement",
                "continuous control",
                "token-level manipulation",
                "text embeddings",
                "sparse autoencoder",
                "sparse latent space",
                "semantically isolated dimensions",
                "model agnostic"
            ]
        },
        "publishedAt": "2025-10-06T13:51:04.000Z",
        "title": "SAEdit: Token-level control for continuous image editing via Sparse\n  AutoEncoder",
        "summary": "Large-scale text-to-image diffusion models have become the backbone of modern\nimage editing, yet text prompts alone do not offer adequate control over the\nediting process. Two properties are especially desirable: disentanglement,\nwhere changing one attribute does not unintentionally alter others, and\ncontinuous control, where the strength of an edit can be smoothly adjusted. We\nintroduce a method for disentangled and continuous editing through token-level\nmanipulation of text embeddings. The edits are applied by manipulating the\nembeddings along carefully chosen directions, which control the strength of the\ntarget attribute. To identify such directions, we employ a Sparse Autoencoder\n(SAE), whose sparse latent space exposes semantically isolated dimensions. Our\nmethod operates directly on text embeddings without modifying the diffusion\nprocess, making it model agnostic and broadly applicable to various image\nsynthesis backbones. Experiments show that it enables intuitive and efficient\nmanipulations with continuous control across diverse attributes and domains.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05081.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65fbf768980d4143b0d3ab52",
            "avatarUrl": "/avatars/018a26ce944860e9ab97ca43765e7d76.svg",
            "fullname": "Daniel Garibi",
            "name": "garibida",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 13
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04860",
            "authors": [
                {
                    "_id": "68e4a0f8e4e093a7044e4dd7",
                    "name": "Siwei Han",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4dd8",
                    "name": "Jiaqi Liu",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4dd9",
                    "name": "Yaofeng Su",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4dda",
                    "name": "Wenbo Duan",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4ddb",
                    "name": "Xinyuan Liu",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4ddc",
                    "name": "Cihang Xie",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4ddd",
                    "name": "Mohit Bansal",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4dde",
                    "name": "Mingyu Ding",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4ddf",
                    "name": "Linjun Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e4a0f8e4e093a7044e4de0",
                    "name": "Huaxiu Yao",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T14:48:39.000Z",
            "submittedOnDailyAt": "2025-10-07T03:44:58.692Z",
            "title": "Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the\n  Rails",
            "submittedOnDailyBy": {
                "_id": "65941852f0152a21fc860f79",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65941852f0152a21fc860f79/mHOkrMOkivxxK__F4AK2o.png",
                "isPro": false,
                "fullname": "Lillianwei",
                "user": "Lillianwei",
                "type": "user"
            },
            "summary": "As Large Language Model (LLM) agents increasingly gain self-evolutionary\ncapabilities to adapt and refine their strategies through real-world\ninteraction, their long-term reliability becomes a critical concern. We\nidentify the Alignment Tipping Process (ATP), a critical post-deployment risk\nunique to self-evolving LLM agents. Unlike training-time failures, ATP arises\nwhen continual interaction drives agents to abandon alignment constraints\nestablished during training in favor of reinforced, self-interested strategies.\nWe formalize and analyze ATP through two complementary paradigms:\nSelf-Interested Exploration, where repeated high-reward deviations induce\nindividual behavioral drift, and Imitative Strategy Diffusion, where deviant\nbehaviors spread across multi-agent systems. Building on these paradigms, we\nconstruct controllable testbeds and benchmark Qwen3-8B and\nLlama-3.1-8B-Instruct. Our experiments show that alignment benefits erode\nrapidly under self-evolution, with initially aligned models converging toward\nunaligned states. In multi-agent settings, successful violations diffuse\nquickly, leading to collective misalignment. Moreover, current reinforcement\nlearning-based alignment methods provide only fragile defenses against\nalignment tipping. Together, these findings demonstrate that alignment of LLM\nagents is not a static property but a fragile and dynamic one, vulnerable to\nfeedback-driven decay during deployment. Our data and code are available at\nhttps://github.com/aiming-lab/ATP.",
            "upvotes": 2,
            "discussionId": "68e4a0f8e4e093a7044e4de1",
            "githubRepo": "https://github.com/aiming-lab/ATP",
            "ai_summary": "Self-evolving LLM agents can abandon alignment constraints post-deployment, leading to rapid misalignment and collective failure in multi-agent systems.",
            "ai_keywords": [
                "Alignment Tipping Process",
                "Self-Interested Exploration",
                "Imitative Strategy Diffusion",
                "reinforcement learning-based alignment methods"
            ],
            "githubStars": 4
        },
        "publishedAt": "2025-10-06T10:48:39.000Z",
        "title": "Alignment Tipping Process: How Self-Evolution Pushes LLM Agents Off the\n  Rails",
        "summary": "As Large Language Model (LLM) agents increasingly gain self-evolutionary\ncapabilities to adapt and refine their strategies through real-world\ninteraction, their long-term reliability becomes a critical concern. We\nidentify the Alignment Tipping Process (ATP), a critical post-deployment risk\nunique to self-evolving LLM agents. Unlike training-time failures, ATP arises\nwhen continual interaction drives agents to abandon alignment constraints\nestablished during training in favor of reinforced, self-interested strategies.\nWe formalize and analyze ATP through two complementary paradigms:\nSelf-Interested Exploration, where repeated high-reward deviations induce\nindividual behavioral drift, and Imitative Strategy Diffusion, where deviant\nbehaviors spread across multi-agent systems. Building on these paradigms, we\nconstruct controllable testbeds and benchmark Qwen3-8B and\nLlama-3.1-8B-Instruct. Our experiments show that alignment benefits erode\nrapidly under self-evolution, with initially aligned models converging toward\nunaligned states. In multi-agent settings, successful violations diffuse\nquickly, leading to collective misalignment. Moreover, current reinforcement\nlearning-based alignment methods provide only fragile defenses against\nalignment tipping. Together, these findings demonstrate that alignment of LLM\nagents is not a static property but a fragile and dynamic one, vulnerable to\nfeedback-driven decay during deployment. Our data and code are available at\nhttps://github.com/aiming-lab/ATP.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04860.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65941852f0152a21fc860f79",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65941852f0152a21fc860f79/mHOkrMOkivxxK__F4AK2o.png",
            "fullname": "Lillianwei",
            "name": "Lillianwei",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.04136",
            "authors": [
                {
                    "_id": "68e4bc16e4e093a7044e4e34",
                    "user": {
                        "_id": "64903f017b630c141867877f",
                        "avatarUrl": "/avatars/3c7b248baed446ecc2b6adc2c444320d.svg",
                        "isPro": false,
                        "fullname": "Umberto Cappellazzo",
                        "user": "hisoka94",
                        "type": "user"
                    },
                    "name": "Umberto Cappellazzo",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:03.309Z",
                    "hidden": false
                },
                {
                    "_id": "68e4bc16e4e093a7044e4e35",
                    "name": "Minsu Kim",
                    "hidden": false
                },
                {
                    "_id": "68e4bc16e4e093a7044e4e36",
                    "name": "Pingchuan Ma",
                    "hidden": false
                },
                {
                    "_id": "68e4bc16e4e093a7044e4e37",
                    "name": "Honglie Chen",
                    "hidden": false
                },
                {
                    "_id": "68e4bc16e4e093a7044e4e38",
                    "name": "Xubo Liu",
                    "hidden": false
                },
                {
                    "_id": "68e4bc16e4e093a7044e4e39",
                    "name": "Stavros Petridis",
                    "hidden": false
                },
                {
                    "_id": "68e4bc16e4e093a7044e4e3a",
                    "name": "Maja Pantic",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-05T10:34:34.000Z",
            "submittedOnDailyAt": "2025-10-07T05:42:28.022Z",
            "title": "MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition",
            "submittedOnDailyBy": {
                "_id": "64903f017b630c141867877f",
                "avatarUrl": "/avatars/3c7b248baed446ecc2b6adc2c444320d.svg",
                "isPro": false,
                "fullname": "Umberto Cappellazzo",
                "user": "hisoka94",
                "type": "user"
            },
            "summary": "Large language models (LLMs) have recently shown strong potential in\naudio-visual speech recognition (AVSR), but their high computational demands\nand sensitivity to token granularity limit their practicality in\nresource-constrained settings. Token compression methods can reduce inference\ncost, but they require fixing a compression rate in advance and produce a\nsingle fixed-length output, offering no flexibility to balance information\ndensity and efficiency at inference time. Matryoshka representation learning\n(MRL) addresses this by enabling a single model to operate across multiple\ntoken granularities, allowing compression rates to be adjusted dynamically.\nHowever, current MRL-based methods treat each scale independently during\ntraining, limiting cross-scale generalization, robustness at high compression,\nand interpretability. To overcome these limitations, we propose MoME (Mixture\nof Matryoshka Experts), a novel framework that integrates sparse\nMixture-of-Experts (MoE) into MRL-based LLMs for AVSR. MoME augments a frozen\nLLM with top-k routed and shared experts, allowing dynamic capacity allocation\nacross scales and modalities. A shared router promotes consistent expert\nactivation across granularities, enabling compressed sequences to benefit from\nrepresentations learned at lower compression. Experiments on LRS2 and LRS3\ndemonstrate that MoME achieves state-of-the-art performance across AVSR, ASR,\nand VSR tasks, while requiring significantly fewer parameters and maintaining\nrobustness under noise. MoME unifies the adaptability of MRL with the\nefficiency of MoE, offering a scalable and interpretable solution for\nresource-aware speech recognition.",
            "upvotes": 2,
            "discussionId": "68e4bc16e4e093a7044e4e3b",
            "ai_summary": "MoME, a novel framework integrating sparse Mixture-of-Experts into Matryoshka representation learning, enhances audio-visual speech recognition by dynamically adjusting capacity across scales and modalities, achieving state-of-the-art performance with fewer parameters.",
            "ai_keywords": [
                "large language models",
                "audio-visual speech recognition",
                "token compression",
                "Matryoshka representation learning",
                "Mixture-of-Experts",
                "MoME",
                "LRS2",
                "LRS3",
                "ASR",
                "VSR",
                "parameter-efficient",
                "robustness",
                "noise"
            ],
            "organization": {
                "_id": "650987fc2feb9570c5137ac2",
                "name": "ImperialCollegeLondon",
                "fullname": "Imperial College London",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/630ca0817dacb93b33506ce7/u6ceSXXV6ldtt0qZOOMJw.jpeg"
            }
        },
        "publishedAt": "2025-10-05T06:34:34.000Z",
        "title": "MoME: Mixture of Matryoshka Experts for Audio-Visual Speech Recognition",
        "summary": "Large language models (LLMs) have recently shown strong potential in\naudio-visual speech recognition (AVSR), but their high computational demands\nand sensitivity to token granularity limit their practicality in\nresource-constrained settings. Token compression methods can reduce inference\ncost, but they require fixing a compression rate in advance and produce a\nsingle fixed-length output, offering no flexibility to balance information\ndensity and efficiency at inference time. Matryoshka representation learning\n(MRL) addresses this by enabling a single model to operate across multiple\ntoken granularities, allowing compression rates to be adjusted dynamically.\nHowever, current MRL-based methods treat each scale independently during\ntraining, limiting cross-scale generalization, robustness at high compression,\nand interpretability. To overcome these limitations, we propose MoME (Mixture\nof Matryoshka Experts), a novel framework that integrates sparse\nMixture-of-Experts (MoE) into MRL-based LLMs for AVSR. MoME augments a frozen\nLLM with top-k routed and shared experts, allowing dynamic capacity allocation\nacross scales and modalities. A shared router promotes consistent expert\nactivation across granularities, enabling compressed sequences to benefit from\nrepresentations learned at lower compression. Experiments on LRS2 and LRS3\ndemonstrate that MoME achieves state-of-the-art performance across AVSR, ASR,\nand VSR tasks, while requiring significantly fewer parameters and maintaining\nrobustness under noise. MoME unifies the adaptability of MRL with the\nefficiency of MoE, offering a scalable and interpretable solution for\nresource-aware speech recognition.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04136.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64903f017b630c141867877f",
            "avatarUrl": "/avatars/3c7b248baed446ecc2b6adc2c444320d.svg",
            "fullname": "Umberto Cappellazzo",
            "name": "hisoka94",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "650987fc2feb9570c5137ac2",
            "name": "ImperialCollegeLondon",
            "fullname": "Imperial College London",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/630ca0817dacb93b33506ce7/u6ceSXXV6ldtt0qZOOMJw.jpeg"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04072",
            "authors": [
                {
                    "_id": "68e49347e4e093a7044e4daf",
                    "user": {
                        "_id": "642c3805c885078517171815",
                        "avatarUrl": "/avatars/74d1179a28bd21beaa33d7ce437a5695.svg",
                        "isPro": false,
                        "fullname": "Ziyan Wang",
                        "user": "wzywp",
                        "type": "user"
                    },
                    "name": "Ziyan Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:25.813Z",
                    "hidden": false
                },
                {
                    "_id": "68e49347e4e093a7044e4db0",
                    "name": "Zheng Wang",
                    "hidden": false
                },
                {
                    "_id": "68e49347e4e093a7044e4db1",
                    "name": "Jie Fu",
                    "hidden": false
                },
                {
                    "_id": "68e49347e4e093a7044e4db2",
                    "name": "Xingwei Qu",
                    "hidden": false
                },
                {
                    "_id": "68e49347e4e093a7044e4db3",
                    "name": "Qi Cheng",
                    "hidden": false
                },
                {
                    "_id": "68e49347e4e093a7044e4db4",
                    "name": "Shengpu Tang",
                    "hidden": false
                },
                {
                    "_id": "68e49347e4e093a7044e4db5",
                    "name": "Minjia Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e49347e4e093a7044e4db6",
                    "name": "Xiaoming Huo",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-05T07:22:54.000Z",
            "submittedOnDailyAt": "2025-10-07T15:09:37.308Z",
            "title": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM\n  Reasoning",
            "submittedOnDailyBy": {
                "_id": "642c3805c885078517171815",
                "avatarUrl": "/avatars/74d1179a28bd21beaa33d7ce437a5695.svg",
                "isPro": false,
                "fullname": "Ziyan Wang",
                "user": "wzywp",
                "type": "user"
            },
            "summary": "Reinforcement learning (RL) has become central to enhancing reasoning in\nlarge language models (LLMs). Yet on-policy algorithms such as Group Relative\nPolicy Optimization (GRPO) often suffer in early training: noisy gradients from\nlow-quality rollouts lead to unstable updates and inefficient exploration. We\nintroduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient\nframework to address these limitations via decomposing each step into three\nstages: a short fast trajectory of inner steps on the same batch, a reposition\nmechanism to control off-policy drift, and a final slow correction. This\nreposition-before-update design preserves the objective and rollout process\nunchanged, making SFPO plug-compatible with existing policy-gradient pipelines.\nExtensive experiments demonstrate that SFPO consistently improves stability,\nreduces rollouts, and accelerates convergence of reasoning RL training.\nSpecifically, it outperforms GRPO by up to 2.80 points in average on math\nreasoning benchmarks. It also achieves up to 4.93 fewer rollouts\nand a 4.19 reduction in wall-clock time to match GRPO's best\naccuracy.",
            "upvotes": 2,
            "discussionId": "68e49348e4e093a7044e4db7",
            "projectPage": "https://zkbig.github.io/Slow_Fast_Policy_Optimization.github.io/",
            "githubRepo": "https://github.com/Urheen/SFPO",
            "ai_summary": "Slow-Fast Policy Optimization (SFPO) enhances reinforcement learning training in large language models by improving stability, reducing rollouts, and accelerating convergence compared to Group Relative Policy Optimization (GRPO).",
            "ai_keywords": [
                "Reinforcement learning",
                "large language models",
                "Group Relative Policy Optimization",
                "Slow-Fast Policy Optimization",
                "policy-gradient pipelines",
                "on-policy algorithms",
                "noisy gradients",
                "low-quality rollouts",
                "unstable updates",
                "inefficient exploration",
                "reposition mechanism",
                "off-policy drift",
                "math reasoning benchmarks"
            ],
            "githubStars": 0
        },
        "publishedAt": "2025-10-05T03:22:54.000Z",
        "title": "Slow-Fast Policy Optimization: Reposition-Before-Update for LLM\n  Reasoning",
        "summary": "Reinforcement learning (RL) has become central to enhancing reasoning in\nlarge language models (LLMs). Yet on-policy algorithms such as Group Relative\nPolicy Optimization (GRPO) often suffer in early training: noisy gradients from\nlow-quality rollouts lead to unstable updates and inefficient exploration. We\nintroduce Slow-Fast Policy Optimization (SFPO), a simple yet efficient\nframework to address these limitations via decomposing each step into three\nstages: a short fast trajectory of inner steps on the same batch, a reposition\nmechanism to control off-policy drift, and a final slow correction. This\nreposition-before-update design preserves the objective and rollout process\nunchanged, making SFPO plug-compatible with existing policy-gradient pipelines.\nExtensive experiments demonstrate that SFPO consistently improves stability,\nreduces rollouts, and accelerates convergence of reasoning RL training.\nSpecifically, it outperforms GRPO by up to 2.80 points in average on math\nreasoning benchmarks. It also achieves up to 4.93 fewer rollouts\nand a 4.19 reduction in wall-clock time to match GRPO's best\naccuracy.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04072.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "642c3805c885078517171815",
            "avatarUrl": "/avatars/74d1179a28bd21beaa33d7ce437a5695.svg",
            "fullname": "Ziyan Wang",
            "name": "wzywp",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2509.24613",
            "authors": [
                {
                    "_id": "68de41e4a9129e507bf4a4a1",
                    "user": {
                        "_id": "66976a7fa7fd582ae754850e",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66976a7fa7fd582ae754850e/jQXfIqKh1FYGxjyFwSmSY.jpeg",
                        "isPro": false,
                        "fullname": "Gio Paik",
                        "user": "skyil7",
                        "type": "user"
                    },
                    "name": "Gio Paik",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-06T12:49:08.517Z",
                    "hidden": false
                },
                {
                    "_id": "68de41e4a9129e507bf4a4a2",
                    "name": "Yongbeom Kim",
                    "hidden": false
                },
                {
                    "_id": "68de41e4a9129e507bf4a4a3",
                    "user": {
                        "_id": "67470f4acccc7c0cdb9a4859",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67470f4acccc7c0cdb9a4859/6V1ae4bY3xyA-gFXaa2G4.jpeg",
                        "isPro": false,
                        "fullname": "Soungmin Lee",
                        "user": "soungminlee",
                        "type": "user"
                    },
                    "name": "Soungmin Lee",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:29:01.544Z",
                    "hidden": false
                },
                {
                    "_id": "68de41e4a9129e507bf4a4a4",
                    "name": "Sangmin Ahn",
                    "hidden": false
                },
                {
                    "_id": "68de41e4a9129e507bf4a4a5",
                    "name": "Chanwoo Kim",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-29T11:18:13.000Z",
            "submittedOnDailyAt": "2025-10-07T01:49:42.028Z",
            "title": "HiKE: Hierarchical Evaluation Framework for Korean-English\n  Code-Switching Speech Recognition",
            "submittedOnDailyBy": {
                "_id": "66976a7fa7fd582ae754850e",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66976a7fa7fd582ae754850e/jQXfIqKh1FYGxjyFwSmSY.jpeg",
                "isPro": false,
                "fullname": "Gio Paik",
                "user": "skyil7",
                "type": "user"
            },
            "summary": "Despite advances in multilingual automatic speech recognition (ASR),\ncode-switching (CS), the mixing of languages within an utterance common in\ndaily speech, remains a severely underexplored challenge. In this paper, we\nintroduce HiKE: the Hierarchical Korean-English code-switching benchmark, the\nfirst globally accessible evaluation framework for Korean-English CS, aiming to\nprovide a means for the precise evaluation of multilingual ASR models and to\nfoster research in the field. The proposed framework not only consists of\nhigh-quality, natural CS data across various topics, but also provides\nmeticulous loanword labels and a hierarchical CS-level labeling scheme (word,\nphrase, and sentence) that together enable a systematic evaluation of a model's\nability to handle each distinct level of code-switching. Through evaluations of\ndiverse multilingual ASR models and fine-tuning experiments, this paper\ndemonstrates that while most multilingual ASR models initially struggle with\nCS-ASR, this capability can be enabled through fine-tuning with CS data. HiKE\nwill be available at https://github.com/ThetaOne-AI/HiKE.",
            "upvotes": 2,
            "discussionId": "68de41e4a9129e507bf4a4a6",
            "githubRepo": "https://github.com/ThetaOne-AI/HiKE",
            "ai_summary": "A hierarchical benchmark for Korean-English code-switching in ASR evaluates model performance and demonstrates improvement through fine-tuning with code-switched data.",
            "ai_keywords": [
                "multilingual automatic speech recognition",
                "code-switching",
                "HiKE",
                "Hierarchical Korean-English code-switching benchmark",
                "loanword labels",
                "hierarchical CS-level labeling scheme",
                "fine-tuning"
            ],
            "githubStars": 2,
            "organization": {
                "_id": "68b1775f3eded3884d27cbd3",
                "name": "thetaone-ai",
                "fullname": "Theta One AI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66976a7fa7fd582ae754850e/4r_irltP9kCKVSVzlOj2j.jpeg"
            }
        },
        "publishedAt": "2025-09-29T07:18:13.000Z",
        "title": "HiKE: Hierarchical Evaluation Framework for Korean-English\n  Code-Switching Speech Recognition",
        "summary": "Despite advances in multilingual automatic speech recognition (ASR),\ncode-switching (CS), the mixing of languages within an utterance common in\ndaily speech, remains a severely underexplored challenge. In this paper, we\nintroduce HiKE: the Hierarchical Korean-English code-switching benchmark, the\nfirst globally accessible evaluation framework for Korean-English CS, aiming to\nprovide a means for the precise evaluation of multilingual ASR models and to\nfoster research in the field. The proposed framework not only consists of\nhigh-quality, natural CS data across various topics, but also provides\nmeticulous loanword labels and a hierarchical CS-level labeling scheme (word,\nphrase, and sentence) that together enable a systematic evaluation of a model's\nability to handle each distinct level of code-switching. Through evaluations of\ndiverse multilingual ASR models and fine-tuning experiments, this paper\ndemonstrates that while most multilingual ASR models initially struggle with\nCS-ASR, this capability can be enabled through fine-tuning with CS data. HiKE\nwill be available at https://github.com/ThetaOne-AI/HiKE.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.24613.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "66976a7fa7fd582ae754850e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66976a7fa7fd582ae754850e/jQXfIqKh1FYGxjyFwSmSY.jpeg",
            "fullname": "Gio Paik",
            "name": "skyil7",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "68b1775f3eded3884d27cbd3",
            "name": "thetaone-ai",
            "fullname": "Theta One AI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66976a7fa7fd582ae754850e/4r_irltP9kCKVSVzlOj2j.jpeg"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.02350",
            "authors": [
                {
                    "_id": "68e3984373e20ab577842182",
                    "user": {
                        "_id": "6622019a30a5b0bceaea6bbd",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6622019a30a5b0bceaea6bbd/RwjSxndkR08cZDzM-pq4n.jpeg",
                        "isPro": false,
                        "fullname": "Dzmitry Pihulski",
                        "user": "pihull",
                        "type": "user"
                    },
                    "name": "Dzmitry Pihulski",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-06T12:48:15.616Z",
                    "hidden": false
                },
                {
                    "_id": "68e3984373e20ab577842183",
                    "name": "Karol Charchut",
                    "hidden": false
                },
                {
                    "_id": "68e3984373e20ab577842184",
                    "name": "Viktoria Novogrodskaia",
                    "hidden": false
                },
                {
                    "_id": "68e3984373e20ab577842185",
                    "name": "Jan Kocoń",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-27T15:08:43.000Z",
            "submittedOnDailyAt": "2025-10-07T06:30:57.050Z",
            "title": "LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL",
            "submittedOnDailyBy": {
                "_id": "6622019a30a5b0bceaea6bbd",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6622019a30a5b0bceaea6bbd/RwjSxndkR08cZDzM-pq4n.jpeg",
                "isPro": false,
                "fullname": "Dzmitry Pihulski",
                "user": "pihull",
                "type": "user"
            },
            "summary": "Converting natural language questions into SQL queries (Text-to-SQL) enables\nnon-expert users to interact with relational databases and has long been a\ncentral task for natural language interfaces to data. While the WikiSQL dataset\nplayed a key role in early NL2SQL research, its usage has declined due to\nstructural and annotation issues, including case sensitivity inconsistencies,\ndata type mismatches, syntax errors, and unanswered questions. We present\nLLMSQL, a systematic revision and transformation of WikiSQL designed for the\nLLM era. We classify these errors and implement automated methods for cleaning\nand re-annotation. To assess the impact of these improvements, we evaluated\nmultiple large language models (LLMs), including Gemma 3, LLaMA 3.2, Mistral\n7B, gpt-oss 20B, Phi-3.5 Mini, Qwen 2.5, OpenAI o4-mini, DeepSeek R1 and\nothers. Rather than serving as an update, LLMSQL is introduced as an LLM-ready\nbenchmark: unlike the original WikiSQL, tailored for pointer-network models\nselecting tokens from input, LLMSQL provides clean natural language questions\nand full SQL queries as plain text, enabling straightforward generation and\nevaluation for modern natural language-to-SQL models.",
            "upvotes": 2,
            "discussionId": "68e3984373e20ab577842186",
            "projectPage": "https://llmsql.github.io/llmsql-benchmark/",
            "githubRepo": "https://github.com/LLMSQL/llmsql-benchmark",
            "ai_summary": "LLMSQL is a revised and cleaned version of WikiSQL designed for modern large language models, providing clean questions and full SQL queries for straightforward evaluation in text-to-SQL tasks.",
            "ai_keywords": [
                "Text-to-SQL",
                "NL2SQL",
                "WikiSQL",
                "LLM",
                "Gemma 3",
                "LLaMA 3.2",
                "Mistral 7B",
                "gpt-oss 20B",
                "Phi-3.5 Mini",
                "Qwen 2.5",
                "OpenAI o4-mini",
                "DeepSeek R1",
                "pointer-network models"
            ],
            "githubStars": 33,
            "organization": {
                "_id": "68cd66fe0d69e7503760a5f0",
                "name": "llmsql-bench",
                "fullname": "LLMSQL",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6622019a30a5b0bceaea6bbd/r1WjY3wZ7yjx_xbDS0h_f.jpeg"
            }
        },
        "publishedAt": "2025-09-27T11:08:43.000Z",
        "title": "LLMSQL: Upgrading WikiSQL for the LLM Era of Text-to-SQL",
        "summary": "Converting natural language questions into SQL queries (Text-to-SQL) enables\nnon-expert users to interact with relational databases and has long been a\ncentral task for natural language interfaces to data. While the WikiSQL dataset\nplayed a key role in early NL2SQL research, its usage has declined due to\nstructural and annotation issues, including case sensitivity inconsistencies,\ndata type mismatches, syntax errors, and unanswered questions. We present\nLLMSQL, a systematic revision and transformation of WikiSQL designed for the\nLLM era. We classify these errors and implement automated methods for cleaning\nand re-annotation. To assess the impact of these improvements, we evaluated\nmultiple large language models (LLMs), including Gemma 3, LLaMA 3.2, Mistral\n7B, gpt-oss 20B, Phi-3.5 Mini, Qwen 2.5, OpenAI o4-mini, DeepSeek R1 and\nothers. Rather than serving as an update, LLMSQL is introduced as an LLM-ready\nbenchmark: unlike the original WikiSQL, tailored for pointer-network models\nselecting tokens from input, LLMSQL provides clean natural language questions\nand full SQL queries as plain text, enabling straightforward generation and\nevaluation for modern natural language-to-SQL models.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.02350.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6622019a30a5b0bceaea6bbd",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6622019a30a5b0bceaea6bbd/RwjSxndkR08cZDzM-pq4n.jpeg",
            "fullname": "Dzmitry Pihulski",
            "name": "pihull",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "68cd66fe0d69e7503760a5f0",
            "name": "llmsql-bench",
            "fullname": "LLMSQL",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6622019a30a5b0bceaea6bbd/r1WjY3wZ7yjx_xbDS0h_f.jpeg"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05040",
            "authors": [
                {
                    "_id": "68e4b83be4e093a7044e4e18",
                    "name": "Jihoon Lee",
                    "hidden": false
                },
                {
                    "_id": "68e4b83be4e093a7044e4e19",
                    "name": "Hoyeon Moon",
                    "hidden": false
                },
                {
                    "_id": "68e4b83be4e093a7044e4e1a",
                    "name": "Kevin Zhai",
                    "hidden": false
                },
                {
                    "_id": "68e4b83be4e093a7044e4e1b",
                    "name": "Arun Kumar Chithanar",
                    "hidden": false
                },
                {
                    "_id": "68e4b83be4e093a7044e4e1c",
                    "name": "Anit Kumar Sahu",
                    "hidden": false
                },
                {
                    "_id": "68e4b83be4e093a7044e4e1d",
                    "name": "Soummya Kar",
                    "hidden": false
                },
                {
                    "_id": "68e4b83be4e093a7044e4e1e",
                    "name": "Chul Lee",
                    "hidden": false
                },
                {
                    "_id": "68e4b83be4e093a7044e4e1f",
                    "name": "Souradip Chakraborty",
                    "hidden": false
                },
                {
                    "_id": "68e4b83be4e093a7044e4e20",
                    "user": {
                        "_id": "68b905f152d028b4e78244a0",
                        "avatarUrl": "/avatars/e3b3304529b7d5c6362fb1324f92e285.svg",
                        "isPro": false,
                        "fullname": "Amrit Singh Bedi",
                        "user": "amrit0714",
                        "type": "user"
                    },
                    "name": "Amrit Singh Bedi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:08.097Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T17:16:41.000Z",
            "submittedOnDailyAt": "2025-10-07T11:27:38.013Z",
            "title": "Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive\n  Experts",
            "submittedOnDailyBy": {
                "_id": "68b905f152d028b4e78244a0",
                "avatarUrl": "/avatars/e3b3304529b7d5c6362fb1324f92e285.svg",
                "isPro": false,
                "fullname": "Amrit Singh Bedi",
                "user": "amrit0714",
                "type": "user"
            },
            "summary": "Diffusion-based large language models (dLLMs) are trained flexibly to model\nextreme dependence in the data distribution; however, how to best utilize this\ninformation at inference time remains an open problem. In this work, we uncover\nan interesting property of these models: dLLMs trained on textual data\nimplicitly learn a mixture of semi-autoregressive experts, where different\ngeneration orders reveal different specialized behaviors. We show that\ncommitting to any single, fixed inference time schedule, a common practice,\ncollapses performance by failing to leverage this latent ensemble. To address\nthis, we introduce HEX (Hidden semiautoregressive EXperts for test-time\nscaling), a training-free inference method that ensembles across heterogeneous\nblock schedules. By doing a majority vote over diverse block-sized generation\npaths, HEX robustly avoids failure modes associated with any single fixed\nschedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to\n3.56X (from 24.72% to 88.10%), outperforming top-K margin inference and\nspecialized fine-tuned methods like GRPO, without additional training. HEX even\nyields significant gains on MATH benchmark from 16.40% to 40.00%, scientific\nreasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%.\nOur results establish a new paradigm for test-time scaling in diffusion-based\nLLMs (dLLMs), revealing that the sequence in which masking is performed plays a\ncritical role in determining performance during inference.",
            "upvotes": 1,
            "discussionId": "68e4b83ce4e093a7044e4e21",
            "ai_summary": "HEX, a training-free inference method for diffusion-based large language models, ensembles diverse generation paths to improve accuracy across various reasoning benchmarks without additional training.",
            "ai_keywords": [
                "diffusion-based large language models",
                "dLLMs",
                "semi-autoregressive experts",
                "inference time schedule",
                "HEX",
                "Hidden semiautoregressive EXperts",
                "test-time scaling",
                "GSM8K",
                "MATH",
                "ARC-C",
                "TruthfulQA"
            ],
            "organization": {
                "_id": "64f8a9c00590f3db14a59b8f",
                "name": "UCF-Ai-LLMs",
                "fullname": "University of Central Florida"
            }
        },
        "publishedAt": "2025-10-06T13:16:41.000Z",
        "title": "Test-Time Scaling in Diffusion LLMs via Hidden Semi-Autoregressive\n  Experts",
        "summary": "Diffusion-based large language models (dLLMs) are trained flexibly to model\nextreme dependence in the data distribution; however, how to best utilize this\ninformation at inference time remains an open problem. In this work, we uncover\nan interesting property of these models: dLLMs trained on textual data\nimplicitly learn a mixture of semi-autoregressive experts, where different\ngeneration orders reveal different specialized behaviors. We show that\ncommitting to any single, fixed inference time schedule, a common practice,\ncollapses performance by failing to leverage this latent ensemble. To address\nthis, we introduce HEX (Hidden semiautoregressive EXperts for test-time\nscaling), a training-free inference method that ensembles across heterogeneous\nblock schedules. By doing a majority vote over diverse block-sized generation\npaths, HEX robustly avoids failure modes associated with any single fixed\nschedule. On reasoning benchmarks such as GSM8K, it boosts accuracy by up to\n3.56X (from 24.72% to 88.10%), outperforming top-K margin inference and\nspecialized fine-tuned methods like GRPO, without additional training. HEX even\nyields significant gains on MATH benchmark from 16.40% to 40.00%, scientific\nreasoning on ARC-C from 54.18% to 87.80%, and TruthfulQA from 28.36% to 57.46%.\nOur results establish a new paradigm for test-time scaling in diffusion-based\nLLMs (dLLMs), revealing that the sequence in which masking is performed plays a\ncritical role in determining performance during inference.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05040.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "68b905f152d028b4e78244a0",
            "avatarUrl": "/avatars/e3b3304529b7d5c6362fb1324f92e285.svg",
            "fullname": "Amrit Singh Bedi",
            "name": "amrit0714",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "64f8a9c00590f3db14a59b8f",
            "name": "UCF-Ai-LLMs",
            "fullname": "University of Central Florida"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04786",
            "authors": [
                {
                    "_id": "68e4f3b2ee2331580b78244c",
                    "user": {
                        "_id": "6645dbab80ee4eb5ddc8aed8",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6645dbab80ee4eb5ddc8aed8/-IckaooWMXeACKew9THv_.jpeg",
                        "isPro": false,
                        "fullname": "Jonas Hübotter",
                        "user": "jonhue",
                        "type": "user"
                    },
                    "name": "Jonas Hübotter",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:25:08.212Z",
                    "hidden": false
                },
                {
                    "_id": "68e4f3b2ee2331580b78244d",
                    "name": "Leander Diaz-Bone",
                    "hidden": false
                },
                {
                    "_id": "68e4f3b2ee2331580b78244e",
                    "name": "Ido Hakimi",
                    "hidden": false
                },
                {
                    "_id": "68e4f3b2ee2331580b78244f",
                    "name": "Andreas Krause",
                    "hidden": false
                },
                {
                    "_id": "68e4f3b2ee2331580b782450",
                    "name": "Moritz Hardt",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6645dbab80ee4eb5ddc8aed8/0vQkm4WxJonQGBudYyF71.png",
                "https://cdn-uploads.huggingface.co/production/uploads/6645dbab80ee4eb5ddc8aed8/5gSgCQTeHzUk0EIA4HLHy.png"
            ],
            "publishedAt": "2025-10-06T13:07:14.000Z",
            "submittedOnDailyAt": "2025-10-07T09:49:02.511Z",
            "title": "Learning on the Job: Test-Time Curricula for Targeted Reinforcement\n  Learning",
            "submittedOnDailyBy": {
                "_id": "6645dbab80ee4eb5ddc8aed8",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6645dbab80ee4eb5ddc8aed8/-IckaooWMXeACKew9THv_.jpeg",
                "isPro": false,
                "fullname": "Jonas Hübotter",
                "user": "jonhue",
                "type": "user"
            },
            "summary": "Humans are good at learning on the job: We learn how to solve the tasks we\nface as we go along. Can a model do the same? We propose an agent that\nassembles a task-specific curriculum, called test-time curriculum (TTC-RL), and\napplies reinforcement learning to continue training the model for its target\ntask. The test-time curriculum avoids time-consuming human curation of datasets\nby automatically selecting the most task-relevant data from a large pool of\navailable training data. Our experiments demonstrate that reinforcement\nlearning on a test-time curriculum consistently improves the model on its\ntarget tasks, across a variety of evaluations and models. Notably, on\nchallenging math and coding benchmarks, TTC-RL improves the pass@1 of Qwen3-8B\nby approximately 1.8x on AIME25 and 2.1x on CodeElo. Moreover, we find that\nTTC-RL significantly raises the performance ceiling compared to the initial\nmodel, increasing pass@8 on AIME25 from 40% to 62% and on CodeElo from 28% to\n43%. Our findings show the potential of test-time curricula in extending the\ntest-time scaling paradigm to continual training on thousands of task-relevant\nexperiences during test-time.",
            "upvotes": 1,
            "discussionId": "68e4f3b3ee2331580b782451",
            "githubRepo": "https://github.com/jonhue/ttc",
            "ai_summary": "Test-time curriculum (TTC-RL) uses reinforcement learning to dynamically select task-relevant data, improving model performance on challenging benchmarks without human curation.",
            "ai_keywords": [
                "test-time curriculum",
                "TTC-RL",
                "reinforcement learning",
                "task-specific curriculum",
                "pass@1",
                "pass@8",
                "AIME25",
                "CodeElo",
                "continual training"
            ],
            "githubStars": 4,
            "organization": {
                "_id": "68923f153ceba9f21ce33320",
                "name": "lasgroup",
                "fullname": "LAS @ ETH Zurich",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6645dbab80ee4eb5ddc8aed8/-wp0yB2cNzO2B0wte9nzF.png"
            }
        },
        "publishedAt": "2025-10-06T09:07:14.000Z",
        "title": "Learning on the Job: Test-Time Curricula for Targeted Reinforcement\n  Learning",
        "summary": "Humans are good at learning on the job: We learn how to solve the tasks we\nface as we go along. Can a model do the same? We propose an agent that\nassembles a task-specific curriculum, called test-time curriculum (TTC-RL), and\napplies reinforcement learning to continue training the model for its target\ntask. The test-time curriculum avoids time-consuming human curation of datasets\nby automatically selecting the most task-relevant data from a large pool of\navailable training data. Our experiments demonstrate that reinforcement\nlearning on a test-time curriculum consistently improves the model on its\ntarget tasks, across a variety of evaluations and models. Notably, on\nchallenging math and coding benchmarks, TTC-RL improves the pass@1 of Qwen3-8B\nby approximately 1.8x on AIME25 and 2.1x on CodeElo. Moreover, we find that\nTTC-RL significantly raises the performance ceiling compared to the initial\nmodel, increasing pass@8 on AIME25 from 40% to 62% and on CodeElo from 28% to\n43%. Our findings show the potential of test-time curricula in extending the\ntest-time scaling paradigm to continual training on thousands of task-relevant\nexperiences during test-time.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6645dbab80ee4eb5ddc8aed8/0vQkm4WxJonQGBudYyF71.png",
            "https://cdn-uploads.huggingface.co/production/uploads/6645dbab80ee4eb5ddc8aed8/5gSgCQTeHzUk0EIA4HLHy.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04786.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6645dbab80ee4eb5ddc8aed8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6645dbab80ee4eb5ddc8aed8/-IckaooWMXeACKew9THv_.jpeg",
            "fullname": "Jonas Hübotter",
            "name": "jonhue",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "68923f153ceba9f21ce33320",
            "name": "lasgroup",
            "fullname": "LAS @ ETH Zurich",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6645dbab80ee4eb5ddc8aed8/-wp0yB2cNzO2B0wte9nzF.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04399",
            "authors": [
                {
                    "_id": "68e46e6ce4e093a7044e4cba",
                    "user": {
                        "_id": "67c604ff3f8c7b027d479671",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67c604ff3f8c7b027d479671/IhfN3eWRQ8iNfcsDKA1Ep.png",
                        "isPro": false,
                        "fullname": "Charles Wang",
                        "user": "charleslwang",
                        "type": "user"
                    },
                    "name": "Charles L. Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:25.165Z",
                    "hidden": false
                },
                {
                    "_id": "68e46e6ce4e093a7044e4cbb",
                    "name": "Keir Dorchen",
                    "hidden": false
                },
                {
                    "_id": "68e46e6ce4e093a7044e4cbc",
                    "name": "Peter Jin",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-05T23:52:16.000Z",
            "submittedOnDailyAt": "2025-10-07T00:09:07.390Z",
            "title": "Utility-Learning Tension in Self-Modifying Agents",
            "submittedOnDailyBy": {
                "_id": "67c604ff3f8c7b027d479671",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67c604ff3f8c7b027d479671/IhfN3eWRQ8iNfcsDKA1Ep.png",
                "isPro": false,
                "fullname": "Charles Wang",
                "user": "charleslwang",
                "type": "user"
            },
            "summary": "As systems trend toward superintelligence, a natural modeling premise is that\nagents can self-improve along every facet of their own design. We formalize\nthis with a five-axis decomposition and a decision layer, separating incentives\nfrom learning behavior and analyzing axes in isolation. Our central result\nidentifies and introduces a sharp utility--learning tension, the structural\nconflict in self-modifying systems whereby utility-driven changes that improve\nimmediate or expected performance can also erode the statistical preconditions\nfor reliable learning and generalization. Our findings show that\ndistribution-free guarantees are preserved iff the policy-reachable model\nfamily is uniformly capacity-bounded; when capacity can grow without limit,\nutility-rational self-changes can render learnable tasks unlearnable. Under\nstandard assumptions common in practice, these axes reduce to the same capacity\ncriterion, yielding a single boundary for safe self-modification. Numerical\nexperiments across several axes validate the theory by comparing destructive\nutility policies against our proposed two-gate policies that preserve\nlearnability.",
            "upvotes": 1,
            "discussionId": "68e46e6ce4e093a7044e4cbd",
            "ai_summary": "Self-improving systems face a utility-learning tension that can degrade their ability to learn and generalize, requiring capacity bounds to ensure safe self-modification.",
            "ai_keywords": [
                "self-improving systems",
                "utility--learning tension",
                "statistical preconditions",
                "reliable learning",
                "generalization",
                "distribution-free guarantees",
                "policy-reachable model family",
                "uniformly capacity-bounded",
                "utility-rational self-changes",
                "learnable tasks",
                "two-gate policies"
            ]
        },
        "publishedAt": "2025-10-05T19:52:16.000Z",
        "title": "Utility-Learning Tension in Self-Modifying Agents",
        "summary": "As systems trend toward superintelligence, a natural modeling premise is that\nagents can self-improve along every facet of their own design. We formalize\nthis with a five-axis decomposition and a decision layer, separating incentives\nfrom learning behavior and analyzing axes in isolation. Our central result\nidentifies and introduces a sharp utility--learning tension, the structural\nconflict in self-modifying systems whereby utility-driven changes that improve\nimmediate or expected performance can also erode the statistical preconditions\nfor reliable learning and generalization. Our findings show that\ndistribution-free guarantees are preserved iff the policy-reachable model\nfamily is uniformly capacity-bounded; when capacity can grow without limit,\nutility-rational self-changes can render learnable tasks unlearnable. Under\nstandard assumptions common in practice, these axes reduce to the same capacity\ncriterion, yielding a single boundary for safe self-modification. Numerical\nexperiments across several axes validate the theory by comparing destructive\nutility policies against our proposed two-gate policies that preserve\nlearnability.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04399.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "67c604ff3f8c7b027d479671",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67c604ff3f8c7b027d479671/IhfN3eWRQ8iNfcsDKA1Ep.png",
            "fullname": "Charles Wang",
            "name": "charleslwang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04226",
            "authors": [
                {
                    "_id": "68e4a947e4e093a7044e4de3",
                    "user": {
                        "_id": "60a643b9213fe60589b8fdf9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60a643b9213fe60589b8fdf9/OOXmW3MkSf88r63tAE6-n.jpeg",
                        "isPro": false,
                        "fullname": "Dustin Wright",
                        "user": "dwright37",
                        "type": "user"
                    },
                    "name": "Dustin Wright",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:26:16.800Z",
                    "hidden": false
                },
                {
                    "_id": "68e4a947e4e093a7044e4de4",
                    "name": "Sarah Masud",
                    "hidden": false
                },
                {
                    "_id": "68e4a947e4e093a7044e4de5",
                    "name": "Jared Moore",
                    "hidden": false
                },
                {
                    "_id": "68e4a947e4e093a7044e4de6",
                    "name": "Srishti Yadav",
                    "hidden": false
                },
                {
                    "_id": "68e4a947e4e093a7044e4de7",
                    "name": "Maria Antoniak",
                    "hidden": false
                },
                {
                    "_id": "68e4a947e4e093a7044e4de8",
                    "name": "Chan Young Park",
                    "hidden": false
                },
                {
                    "_id": "68e4a947e4e093a7044e4de9",
                    "name": "Isabelle Augenstein",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/60a643b9213fe60589b8fdf9/ZXznZbmWo_pnLPjJByPD1.png"
            ],
            "publishedAt": "2025-10-05T14:29:15.000Z",
            "submittedOnDailyAt": "2025-10-07T04:20:37.273Z",
            "title": "Epistemic Diversity and Knowledge Collapse in Large Language Models",
            "submittedOnDailyBy": {
                "_id": "60a643b9213fe60589b8fdf9",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60a643b9213fe60589b8fdf9/OOXmW3MkSf88r63tAE6-n.jpeg",
                "isPro": false,
                "fullname": "Dustin Wright",
                "user": "dwright37",
                "type": "user"
            },
            "summary": "Large language models (LLMs) tend to generate lexically, semantically, and\nstylistically homogenous texts. This poses a risk of knowledge collapse, where\nhomogenous LLMs mediate a shrinking in the range of accessible information over\ntime. Existing works on homogenization are limited by a focus on closed-ended\nmultiple-choice setups or fuzzy semantic features, and do not look at trends\nacross time and cultural contexts. To overcome this, we present a new\nmethodology to measure epistemic diversity, i.e., variation in real-world\nclaims in LLM outputs, which we use to perform a broad empirical study of LLM\nknowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200\nprompt variations sourced from real user chats. For the topics in our study, we\nshow that while newer models tend to generate more diverse claims, nearly all\nmodels are less epistemically diverse than a basic web search. We find that\nmodel size has a negative impact on epistemic diversity, while\nretrieval-augmented generation (RAG) has a positive impact, though the\nimprovement from RAG varies by the cultural context. Finally, compared to a\ntraditional knowledge source (Wikipedia), we find that country-specific claims\nreflect the English language more than the local one, highlighting a gap in\nepistemic representation",
            "upvotes": 1,
            "discussionId": "68e4a947e4e093a7044e4dea",
            "ai_summary": "A study measures epistemic diversity in LLM outputs, showing that newer models are more diverse but still less so than web searches, and that RAG improves diversity with cultural context variations.",
            "ai_keywords": [
                "large language models",
                "LLMs",
                "epistemic diversity",
                "knowledge collapse",
                "retrieval-augmented generation",
                "RAG"
            ],
            "organization": {
                "_id": "60a63ea08b5faf05f3c4d761",
                "name": "copenlu",
                "fullname": "CopeNLU",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1621507708679-608918b7df398c3b285ce960.png"
            }
        },
        "publishedAt": "2025-10-05T10:29:15.000Z",
        "title": "Epistemic Diversity and Knowledge Collapse in Large Language Models",
        "summary": "Large language models (LLMs) tend to generate lexically, semantically, and\nstylistically homogenous texts. This poses a risk of knowledge collapse, where\nhomogenous LLMs mediate a shrinking in the range of accessible information over\ntime. Existing works on homogenization are limited by a focus on closed-ended\nmultiple-choice setups or fuzzy semantic features, and do not look at trends\nacross time and cultural contexts. To overcome this, we present a new\nmethodology to measure epistemic diversity, i.e., variation in real-world\nclaims in LLM outputs, which we use to perform a broad empirical study of LLM\nknowledge collapse. We test 27 LLMs, 155 topics covering 12 countries, and 200\nprompt variations sourced from real user chats. For the topics in our study, we\nshow that while newer models tend to generate more diverse claims, nearly all\nmodels are less epistemically diverse than a basic web search. We find that\nmodel size has a negative impact on epistemic diversity, while\nretrieval-augmented generation (RAG) has a positive impact, though the\nimprovement from RAG varies by the cultural context. Finally, compared to a\ntraditional knowledge source (Wikipedia), we find that country-specific claims\nreflect the English language more than the local one, highlighting a gap in\nepistemic representation",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/60a643b9213fe60589b8fdf9/ZXznZbmWo_pnLPjJByPD1.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04226.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60a643b9213fe60589b8fdf9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/60a643b9213fe60589b8fdf9/OOXmW3MkSf88r63tAE6-n.jpeg",
            "fullname": "Dustin Wright",
            "name": "dwright37",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 4
        },
        "organization": {
            "_id": "60a63ea08b5faf05f3c4d761",
            "name": "copenlu",
            "fullname": "CopeNLU",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1621507708679-608918b7df398c3b285ce960.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.01645",
            "authors": [
                {
                    "_id": "68e56134975ac4c405ef1f3c",
                    "name": "Niloofar Mireshghallah",
                    "hidden": false
                },
                {
                    "_id": "68e56134975ac4c405ef1f3d",
                    "name": "Tianshi Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-02T04:02:06.000Z",
            "submittedOnDailyAt": "2025-10-07T17:24:24.022Z",
            "title": "Position: Privacy Is Not Just Memorization!",
            "submittedOnDailyBy": {
                "_id": "642154542cc2b3c39e7f47e2",
                "avatarUrl": "/avatars/78fa026109ff7cc96726e6e3cd581587.svg",
                "isPro": false,
                "fullname": "Fatemeh  Mireshghallah",
                "user": "niloofarm",
                "type": "user"
            },
            "summary": "The discourse on privacy risks in Large Language Models (LLMs) has\ndisproportionately focused on verbatim memorization of training data, while a\nconstellation of more immediate and scalable privacy threats remain\nunderexplored. This position paper argues that the privacy landscape of LLM\nsystems extends far beyond training data extraction, encompassing risks from\ndata collection practices, inference-time context leakage, autonomous agent\ncapabilities, and the democratization of surveillance through deep inference\nattacks. We present a comprehensive taxonomy of privacy risks across the LLM\nlifecycle -- from data collection through deployment -- and demonstrate through\ncase studies how current privacy frameworks fail to address these multifaceted\nthreats. Through a longitudinal analysis of 1,322 AI/ML privacy papers\npublished at leading conferences over the past decade (2016--2025), we reveal\nthat while memorization receives outsized attention in technical research, the\nmost pressing privacy harms lie elsewhere, where current technical approaches\noffer little traction and viable paths forward remain unclear. We call for a\nfundamental shift in how the research community approaches LLM privacy, moving\nbeyond the narrow focus of current technical solutions and embracing\ninterdisciplinary approaches that address the sociotechnical nature of these\nemerging threats.",
            "upvotes": 1,
            "discussionId": "68e56134975ac4c405ef1f3e",
            "ai_summary": "The paper discusses underexplored privacy risks in Large Language Models (LLMs) beyond verbatim memorization, including data collection, inference-time context leakage, autonomous agent capabilities, and surveillance through deep inference attacks, and calls for a broader interdisciplinary approach to address these threats.",
            "ai_keywords": [
                "Large Language Models",
                "LLMs",
                "privacy risks",
                "data collection",
                "inference-time context leakage",
                "autonomous agent capabilities",
                "surveillance",
                "deep inference attacks",
                "privacy frameworks",
                "sociotechnical nature"
            ],
            "organization": {
                "_id": "6474ab086d4dda6f7c6beaee",
                "name": "cmu-lti",
                "fullname": "CMU-LTI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63a4d079658851481f7e4394/HOFKzjMXriLBOGJw6S8uI.png"
            }
        },
        "publishedAt": "2025-10-02T00:02:06.000Z",
        "title": "Position: Privacy Is Not Just Memorization!",
        "summary": "The discourse on privacy risks in Large Language Models (LLMs) has\ndisproportionately focused on verbatim memorization of training data, while a\nconstellation of more immediate and scalable privacy threats remain\nunderexplored. This position paper argues that the privacy landscape of LLM\nsystems extends far beyond training data extraction, encompassing risks from\ndata collection practices, inference-time context leakage, autonomous agent\ncapabilities, and the democratization of surveillance through deep inference\nattacks. We present a comprehensive taxonomy of privacy risks across the LLM\nlifecycle -- from data collection through deployment -- and demonstrate through\ncase studies how current privacy frameworks fail to address these multifaceted\nthreats. Through a longitudinal analysis of 1,322 AI/ML privacy papers\npublished at leading conferences over the past decade (2016--2025), we reveal\nthat while memorization receives outsized attention in technical research, the\nmost pressing privacy harms lie elsewhere, where current technical approaches\noffer little traction and viable paths forward remain unclear. We call for a\nfundamental shift in how the research community approaches LLM privacy, moving\nbeyond the narrow focus of current technical solutions and embracing\ninterdisciplinary approaches that address the sociotechnical nature of these\nemerging threats.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.01645.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "642154542cc2b3c39e7f47e2",
            "avatarUrl": "/avatars/78fa026109ff7cc96726e6e3cd581587.svg",
            "fullname": "Fatemeh  Mireshghallah",
            "name": "niloofarm",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "6474ab086d4dda6f7c6beaee",
            "name": "cmu-lti",
            "fullname": "CMU-LTI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63a4d079658851481f7e4394/HOFKzjMXriLBOGJw6S8uI.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.01586",
            "authors": [
                {
                    "_id": "68e49051e4e093a7044e4d9d",
                    "name": "Zhenyu Pan",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4d9e",
                    "name": "Yiting Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4d9f",
                    "name": "Zhuo Liu",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da0",
                    "name": "Yolo Yunlong Tang",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da1",
                    "name": "Zeliang Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da2",
                    "name": "Haozheng Luo",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da3",
                    "name": "Yuwei Han",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da4",
                    "name": "Jianshu Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da5",
                    "name": "Dennis Wu",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da6",
                    "name": "Hong-Yu Chen",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da7",
                    "name": "Haoran Lu",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da8",
                    "name": "Haoyang Fang",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4da9",
                    "name": "Manling Li",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4daa",
                    "name": "Chenliang Xu",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4dab",
                    "name": "Philip S. Yu",
                    "hidden": false
                },
                {
                    "_id": "68e49051e4e093a7044e4dac",
                    "name": "Han Liu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-02T02:06:30.000Z",
            "submittedOnDailyAt": "2025-10-07T02:34:02.960Z",
            "title": "AdvEvo-MARL: Shaping Internalized Safety through Adversarial\n  Co-Evolution in Multi-Agent Reinforcement Learning",
            "submittedOnDailyBy": {
                "_id": "669794c5813d96b4eb0b3fd6",
                "avatarUrl": "/avatars/b4e2bb7b07cc281932d783dcbb64f211.svg",
                "isPro": false,
                "fullname": "Zhenyu Pan",
                "user": "zhenyupan",
                "type": "user"
            },
            "summary": "LLM-based multi-agent systems excel at planning, tool use, and role\ncoordination, but their openness and interaction complexity also expose them to\njailbreak, prompt-injection, and adversarial collaboration. Existing defenses\nfall into two lines: (i) self-verification that asks each agent to pre-filter\nunsafe instructions before execution, and (ii) external guard modules that\npolice behaviors. The former often underperforms because a standalone agent\nlacks sufficient capacity to detect cross-agent unsafe chains and\ndelegation-induced risks; the latter increases system overhead and creates a\nsingle-point-of-failure-once compromised, system-wide safety collapses, and\nadding more guards worsens cost and complexity. To solve these challenges, we\npropose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning\nframework that internalizes safety into task agents. Rather than relying on\nexternal guards, AdvEvo-MARL jointly optimizes attackers (which synthesize\nevolving jailbreak prompts) and defenders (task agents trained to both\naccomplish their duties and resist attacks) in adversarial learning\nenvironments. To stabilize learning and foster cooperation, we introduce a\npublic baseline for advantage estimation: agents within the same functional\ngroup share a group-level mean-return baseline, enabling lower-variance updates\nand stronger intra-group coordination. Across representative attack scenarios,\nAdvEvo-MARL consistently keeps attack-success rate (ASR) below 20%, whereas\nbaselines reach up to 38.33%, while preserving-and sometimes improving-task\naccuracy (up to +3.67% on reasoning tasks). These results show that safety and\nutility can be jointly improved without relying on extra guard agents or added\nsystem overhead.",
            "upvotes": 1,
            "discussionId": "68e49051e4e093a7044e4dad",
            "ai_summary": "AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning framework, enhances safety and utility in LLM-based multi-agent systems by internally optimizing task agents against evolving attacks without additional overhead.",
            "ai_keywords": [
                "multi-agent systems",
                "planning",
                "tool use",
                "role coordination",
                "jailbreak",
                "prompt-injection",
                "adversarial collaboration",
                "self-verification",
                "external guard modules",
                "co-evolutionary",
                "reinforcement learning",
                "attackers",
                "defenders",
                "adversarial learning",
                "advantage estimation",
                "group-level mean-return baseline",
                "attack-success rate",
                "task accuracy",
                "reasoning tasks"
            ]
        },
        "publishedAt": "2025-10-01T22:06:30.000Z",
        "title": "AdvEvo-MARL: Shaping Internalized Safety through Adversarial\n  Co-Evolution in Multi-Agent Reinforcement Learning",
        "summary": "LLM-based multi-agent systems excel at planning, tool use, and role\ncoordination, but their openness and interaction complexity also expose them to\njailbreak, prompt-injection, and adversarial collaboration. Existing defenses\nfall into two lines: (i) self-verification that asks each agent to pre-filter\nunsafe instructions before execution, and (ii) external guard modules that\npolice behaviors. The former often underperforms because a standalone agent\nlacks sufficient capacity to detect cross-agent unsafe chains and\ndelegation-induced risks; the latter increases system overhead and creates a\nsingle-point-of-failure-once compromised, system-wide safety collapses, and\nadding more guards worsens cost and complexity. To solve these challenges, we\npropose AdvEvo-MARL, a co-evolutionary multi-agent reinforcement learning\nframework that internalizes safety into task agents. Rather than relying on\nexternal guards, AdvEvo-MARL jointly optimizes attackers (which synthesize\nevolving jailbreak prompts) and defenders (task agents trained to both\naccomplish their duties and resist attacks) in adversarial learning\nenvironments. To stabilize learning and foster cooperation, we introduce a\npublic baseline for advantage estimation: agents within the same functional\ngroup share a group-level mean-return baseline, enabling lower-variance updates\nand stronger intra-group coordination. Across representative attack scenarios,\nAdvEvo-MARL consistently keeps attack-success rate (ASR) below 20%, whereas\nbaselines reach up to 38.33%, while preserving-and sometimes improving-task\naccuracy (up to +3.67% on reasoning tasks). These results show that safety and\nutility can be jointly improved without relying on extra guard agents or added\nsystem overhead.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.01586.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "669794c5813d96b4eb0b3fd6",
            "avatarUrl": "/avatars/b4e2bb7b07cc281932d783dcbb64f211.svg",
            "fullname": "Zhenyu Pan",
            "name": "zhenyupan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.00507",
            "authors": [
                {
                    "_id": "68e48ad7e4e093a7044e4d8a",
                    "name": "Yurun Chen",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d8b",
                    "name": "Xavier Hu",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d8c",
                    "name": "Yuhan Liu",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d8d",
                    "name": "Ziqi Wang",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d8e",
                    "name": "Zeyi Liao",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d8f",
                    "name": "Lin Chen",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d90",
                    "name": "Feng Wei",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d91",
                    "name": "Yuxi Qian",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d92",
                    "name": "Bo Zheng",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d93",
                    "name": "Keting Yin",
                    "hidden": false
                },
                {
                    "_id": "68e48ad7e4e093a7044e4d94",
                    "name": "Shengyu Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-01T04:37:54.000Z",
            "submittedOnDailyAt": "2025-10-07T02:17:29.765Z",
            "title": "Graph2Eval: Automatic Multimodal Task Generation for Agents via\n  Knowledge Graphs",
            "submittedOnDailyBy": {
                "_id": "6747285ed34bd6f05080ddda",
                "avatarUrl": "/avatars/ea63de7348aaabc8cff44e76207ba65c.svg",
                "isPro": false,
                "fullname": "Yurun Chen",
                "user": "yurun-chen",
                "type": "user"
            },
            "summary": "As multimodal LLM-driven agents continue to advance in autonomy and\ngeneralization, evaluation based on static datasets can no longer adequately\nassess their true capabilities in dynamic environments and diverse tasks.\nExisting LLM-based synthetic data methods are largely designed for LLM training\nand evaluation, and thus cannot be directly applied to agent tasks that require\ntool use and interactive capabilities. While recent studies have explored\nautomatic agent task generation with LLMs, most efforts remain limited to text\nor image analysis, without systematically modeling multi-step interactions in\nweb environments. To address these challenges, we propose Graph2Eval, a\nknowledge graph-based framework that automatically generates both multimodal\ndocument comprehension tasks and web interaction tasks, enabling comprehensive\nevaluation of agents' reasoning, collaboration, and interactive capabilities.\nIn our approach, knowledge graphs constructed from multi-source external data\nserve as the task space, where we translate semantic relations into structured\nmultimodal tasks using subgraph sampling, task templates, and meta-paths. A\nmulti-stage filtering pipeline based on node reachability, LLM scoring, and\nsimilarity analysis is applied to guarantee the quality and executability of\nthe generated tasks. Furthermore, Graph2Eval supports end-to-end evaluation of\nmultiple agent types (Single-Agent, Multi-Agent, Web Agent) and measures\nreasoning, collaboration, and interaction capabilities. We instantiate the\nframework with Graph2Eval-Bench, a curated dataset of 1,319 tasks spanning\ndocument comprehension and web interaction scenarios. Experiments show that\nGraph2Eval efficiently generates tasks that differentiate agent and model\nperformance, revealing gaps in reasoning, collaboration, and web interaction\nacross different settings and offering a new perspective for agent evaluation.",
            "upvotes": 1,
            "discussionId": "68e48ad7e4e093a7044e4d95",
            "githubRepo": "https://github.com/YurunChen/Graph2Eval",
            "ai_summary": "Graph2Eval, a knowledge graph-based framework, generates multimodal and interactive tasks to comprehensively evaluate agents' reasoning, collaboration, and web interaction capabilities.",
            "ai_keywords": [
                "multimodal LLM-driven agents",
                "knowledge graph",
                "subgraph sampling",
                "task templates",
                "meta-paths",
                "node reachability",
                "LLM scoring",
                "similarity analysis",
                "Graph2Eval-Bench",
                "document comprehension",
                "web interaction tasks",
                "Single-Agent",
                "Multi-Agent",
                "Web Agent"
            ],
            "githubStars": 5
        },
        "publishedAt": "2025-10-01T00:37:54.000Z",
        "title": "Graph2Eval: Automatic Multimodal Task Generation for Agents via\n  Knowledge Graphs",
        "summary": "As multimodal LLM-driven agents continue to advance in autonomy and\ngeneralization, evaluation based on static datasets can no longer adequately\nassess their true capabilities in dynamic environments and diverse tasks.\nExisting LLM-based synthetic data methods are largely designed for LLM training\nand evaluation, and thus cannot be directly applied to agent tasks that require\ntool use and interactive capabilities. While recent studies have explored\nautomatic agent task generation with LLMs, most efforts remain limited to text\nor image analysis, without systematically modeling multi-step interactions in\nweb environments. To address these challenges, we propose Graph2Eval, a\nknowledge graph-based framework that automatically generates both multimodal\ndocument comprehension tasks and web interaction tasks, enabling comprehensive\nevaluation of agents' reasoning, collaboration, and interactive capabilities.\nIn our approach, knowledge graphs constructed from multi-source external data\nserve as the task space, where we translate semantic relations into structured\nmultimodal tasks using subgraph sampling, task templates, and meta-paths. A\nmulti-stage filtering pipeline based on node reachability, LLM scoring, and\nsimilarity analysis is applied to guarantee the quality and executability of\nthe generated tasks. Furthermore, Graph2Eval supports end-to-end evaluation of\nmultiple agent types (Single-Agent, Multi-Agent, Web Agent) and measures\nreasoning, collaboration, and interaction capabilities. We instantiate the\nframework with Graph2Eval-Bench, a curated dataset of 1,319 tasks spanning\ndocument comprehension and web interaction scenarios. Experiments show that\nGraph2Eval efficiently generates tasks that differentiate agent and model\nperformance, revealing gaps in reasoning, collaboration, and web interaction\nacross different settings and offering a new perspective for agent evaluation.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.00507.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6747285ed34bd6f05080ddda",
            "avatarUrl": "/avatars/ea63de7348aaabc8cff44e76207ba65c.svg",
            "fullname": "Yurun Chen",
            "name": "yurun-chen",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.04995",
            "authors": [
                {
                    "_id": "68e4d00de4e093a7044e4e97",
                    "user": {
                        "_id": "65d836973381a5be278a475a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d836973381a5be278a475a/dgOfY5qZbuUY6HK6s1WsK.jpeg",
                        "isPro": false,
                        "fullname": "Xuefeng Xu",
                        "user": "xuefeng-xu",
                        "type": "user"
                    },
                    "name": "Xuefeng Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:25:26.590Z",
                    "hidden": false
                },
                {
                    "_id": "68e4d00de4e093a7044e4e98",
                    "name": "Graham Cormode",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T16:32:22.000Z",
            "submittedOnDailyAt": "2025-10-07T11:58:38.925Z",
            "title": "Power Transform Revisited: Numerically Stable, and Federated",
            "submittedOnDailyBy": {
                "_id": "65d836973381a5be278a475a",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d836973381a5be278a475a/dgOfY5qZbuUY6HK6s1WsK.jpeg",
                "isPro": false,
                "fullname": "Xuefeng Xu",
                "user": "xuefeng-xu",
                "type": "user"
            },
            "summary": "Power transforms are popular parametric techniques for making data more\nGaussian-like, and are widely used as preprocessing steps in statistical\nanalysis and machine learning. However, we find that direct implementations of\npower transforms suffer from severe numerical instabilities, which can lead to\nincorrect results or even crashes. In this paper, we provide a comprehensive\nanalysis of the sources of these instabilities and propose effective remedies.\nWe further extend power transforms to the federated learning setting,\naddressing both numerical and distributional challenges that arise in this\ncontext. Experiments on real-world datasets demonstrate that our methods are\nboth effective and robust, substantially improving stability compared to\nexisting approaches.",
            "upvotes": 0,
            "discussionId": "68e4d00ee4e093a7044e4e99",
            "projectPage": "https://xuefeng-xu.github.io/powertf.html",
            "githubRepo": "https://github.com/xuefeng-xu/powertf",
            "ai_summary": "Power transforms are extended to federated learning to improve numerical stability and robustness.",
            "ai_keywords": [
                "power transforms",
                "federated learning",
                "numerical instabilities",
                "distributional challenges"
            ],
            "githubStars": 0
        },
        "publishedAt": "2025-10-06T12:32:22.000Z",
        "title": "Power Transform Revisited: Numerically Stable, and Federated",
        "summary": "Power transforms are popular parametric techniques for making data more\nGaussian-like, and are widely used as preprocessing steps in statistical\nanalysis and machine learning. However, we find that direct implementations of\npower transforms suffer from severe numerical instabilities, which can lead to\nincorrect results or even crashes. In this paper, we provide a comprehensive\nanalysis of the sources of these instabilities and propose effective remedies.\nWe further extend power transforms to the federated learning setting,\naddressing both numerical and distributional challenges that arise in this\ncontext. Experiments on real-world datasets demonstrate that our methods are\nboth effective and robust, substantially improving stability compared to\nexisting approaches.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04995.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65d836973381a5be278a475a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d836973381a5be278a475a/dgOfY5qZbuUY6HK6s1WsK.jpeg",
            "fullname": "Xuefeng Xu",
            "name": "xuefeng-xu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04979",
            "authors": [
                {
                    "_id": "68e4cfd6e4e093a7044e4e93",
                    "user": {
                        "_id": "65d836973381a5be278a475a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d836973381a5be278a475a/dgOfY5qZbuUY6HK6s1WsK.jpeg",
                        "isPro": false,
                        "fullname": "Xuefeng Xu",
                        "user": "xuefeng-xu",
                        "type": "user"
                    },
                    "name": "Xuefeng Xu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:25:29.207Z",
                    "hidden": false
                },
                {
                    "_id": "68e4cfd6e4e093a7044e4e94",
                    "name": "Graham Cormode",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T16:16:46.000Z",
            "submittedOnDailyAt": "2025-10-07T11:57:42.508Z",
            "title": "Federated Computation of ROC and PR Curves",
            "submittedOnDailyBy": {
                "_id": "65d836973381a5be278a475a",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d836973381a5be278a475a/dgOfY5qZbuUY6HK6s1WsK.jpeg",
                "isPro": false,
                "fullname": "Xuefeng Xu",
                "user": "xuefeng-xu",
                "type": "user"
            },
            "summary": "Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves are\nfundamental tools for evaluating machine learning classifiers, offering\ndetailed insights into the trade-offs between true positive rate vs. false\npositive rate (ROC) or precision vs. recall (PR). However, in Federated\nLearning (FL) scenarios, where data is distributed across multiple clients,\ncomputing these curves is challenging due to privacy and communication\nconstraints. Specifically, the server cannot access raw prediction scores and\nclass labels, which are used to compute the ROC and PR curves in a centralized\nsetting. In this paper, we propose a novel method for approximating ROC and PR\ncurves in a federated setting by estimating quantiles of the prediction score\ndistribution under distributed differential privacy. We provide theoretical\nbounds on the Area Error (AE) between the true and estimated curves,\ndemonstrating the trade-offs between approximation accuracy, privacy, and\ncommunication cost. Empirical results on real-world datasets demonstrate that\nour method achieves high approximation accuracy with minimal communication and\nstrong privacy guarantees, making it practical for privacy-preserving model\nevaluation in federated systems.",
            "upvotes": 0,
            "discussionId": "68e4cfd7e4e093a7044e4e95",
            "projectPage": "https://xuefeng-xu.github.io/fedcurve.html",
            "githubRepo": "https://github.com/xuefeng-xu/fedcurve",
            "ai_summary": "A method for approximating ROC and PR curves in federated learning under distributed differential privacy ensures high accuracy, minimal communication, and strong privacy guarantees.",
            "ai_keywords": [
                "Receiver Operating Characteristic (ROC)",
                "Precision-Recall (PR) curves",
                "Federated Learning (FL)",
                "distributed differential privacy",
                "quantiles",
                "prediction score distribution",
                "Area Error (AE)"
            ],
            "githubStars": 0
        },
        "publishedAt": "2025-10-06T12:16:46.000Z",
        "title": "Federated Computation of ROC and PR Curves",
        "summary": "Receiver Operating Characteristic (ROC) and Precision-Recall (PR) curves are\nfundamental tools for evaluating machine learning classifiers, offering\ndetailed insights into the trade-offs between true positive rate vs. false\npositive rate (ROC) or precision vs. recall (PR). However, in Federated\nLearning (FL) scenarios, where data is distributed across multiple clients,\ncomputing these curves is challenging due to privacy and communication\nconstraints. Specifically, the server cannot access raw prediction scores and\nclass labels, which are used to compute the ROC and PR curves in a centralized\nsetting. In this paper, we propose a novel method for approximating ROC and PR\ncurves in a federated setting by estimating quantiles of the prediction score\ndistribution under distributed differential privacy. We provide theoretical\nbounds on the Area Error (AE) between the true and estimated curves,\ndemonstrating the trade-offs between approximation accuracy, privacy, and\ncommunication cost. Empirical results on real-world datasets demonstrate that\nour method achieves high approximation accuracy with minimal communication and\nstrong privacy guarantees, making it practical for privacy-preserving model\nevaluation in federated systems.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04979.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65d836973381a5be278a475a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65d836973381a5be278a475a/dgOfY5qZbuUY6HK6s1WsK.jpeg",
            "fullname": "Xuefeng Xu",
            "name": "xuefeng-xu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04694",
            "authors": [
                {
                    "_id": "68e5b0db975ac4c405ef1ffc",
                    "name": "Lucas Bandarkar",
                    "hidden": false
                },
                {
                    "_id": "68e5b0db975ac4c405ef1ffd",
                    "name": "Chenyuan Yang",
                    "hidden": false
                },
                {
                    "_id": "68e5b0db975ac4c405ef1ffe",
                    "name": "Mohsen Fayyaz",
                    "hidden": false
                },
                {
                    "_id": "68e5b0db975ac4c405ef1fff",
                    "name": "Junlin Hu",
                    "hidden": false
                },
                {
                    "_id": "68e5b0db975ac4c405ef2000",
                    "name": "Nanyun Peng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T11:09:20.000Z",
            "submittedOnDailyAt": "2025-10-07T23:08:52.612Z",
            "title": "Multilingual Routing in Mixture-of-Experts",
            "submittedOnDailyBy": {
                "_id": "6435b1d9aaef013d1aeea6a0",
                "avatarUrl": "/avatars/1f515c67f3d03f35aa6e06f93566bd21.svg",
                "isPro": false,
                "fullname": "Lucas Bandarkar",
                "user": "lucasbandarkar",
                "type": "user"
            },
            "summary": "Mixture-of-Experts (MoE) architectures have become the key to scaling modern\nLLMs, yet little is understood about how their sparse routing dynamics respond\nto multilingual data. In this work, we analyze expert routing patterns using\nparallel multilingual datasets and present highly interpretable layer-wise\nphenomena. We find that MoE models route tokens in language-specific ways in\nthe early and late decoder layers but exhibit significant cross-lingual routing\nalignment in middle layers, mirroring parameter-sharing trends observed in\ndense LLMs. In particular, we reveal a clear, strong correlation between a\nmodel's performance in a given language and how similarly its tokens are routed\nto English in these layers. Extending beyond correlation, we explore\ninference-time interventions that induce higher cross-lingual routing\nalignment. We introduce a method that steers the router by promoting\nmiddle-layer task experts frequently activated in English, and it successfully\nincreases multilingual performance. These 1-2% gains are remarkably consistent\nacross two evaluation tasks, three models, and 15+ languages, especially given\nthat these simple interventions override routers of extensively trained,\nstate-of-the-art LLMs. In comparison, interventions outside of the middle\nlayers or targeting multilingual-specialized experts only yield performance\ndegradation. Altogether, we present numerous findings that explain how MoEs\nprocess non-English text and demonstrate that generalization is limited by the\nmodel's ability to leverage language-universal experts in all languages.",
            "upvotes": 0,
            "discussionId": "68e5b0db975ac4c405ef2001",
            "ai_summary": "MoE architectures exhibit language-specific routing in early and late layers but cross-lingual alignment in middle layers, which can be enhanced to improve multilingual performance.",
            "ai_keywords": [
                "Mixture-of-Experts",
                "MoE",
                "parallel multilingual datasets",
                "layer-wise phenomena",
                "token routing",
                "language-specific routing",
                "cross-lingual routing alignment",
                "parameter-sharing",
                "middle-layer task experts",
                "inference-time interventions",
                "multilingual performance",
                "language-universal experts"
            ],
            "organization": {
                "_id": "67784c39dac147922d8d09f0",
                "name": "UCLA",
                "fullname": "University of California, Los Angeles",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67784bd637dfa531fbce95a2/Nf0seEMEn66sPL3QsJXj4.png"
            }
        },
        "publishedAt": "2025-10-06T07:09:20.000Z",
        "title": "Multilingual Routing in Mixture-of-Experts",
        "summary": "Mixture-of-Experts (MoE) architectures have become the key to scaling modern\nLLMs, yet little is understood about how their sparse routing dynamics respond\nto multilingual data. In this work, we analyze expert routing patterns using\nparallel multilingual datasets and present highly interpretable layer-wise\nphenomena. We find that MoE models route tokens in language-specific ways in\nthe early and late decoder layers but exhibit significant cross-lingual routing\nalignment in middle layers, mirroring parameter-sharing trends observed in\ndense LLMs. In particular, we reveal a clear, strong correlation between a\nmodel's performance in a given language and how similarly its tokens are routed\nto English in these layers. Extending beyond correlation, we explore\ninference-time interventions that induce higher cross-lingual routing\nalignment. We introduce a method that steers the router by promoting\nmiddle-layer task experts frequently activated in English, and it successfully\nincreases multilingual performance. These 1-2% gains are remarkably consistent\nacross two evaluation tasks, three models, and 15+ languages, especially given\nthat these simple interventions override routers of extensively trained,\nstate-of-the-art LLMs. In comparison, interventions outside of the middle\nlayers or targeting multilingual-specialized experts only yield performance\ndegradation. Altogether, we present numerous findings that explain how MoEs\nprocess non-English text and demonstrate that generalization is limited by the\nmodel's ability to leverage language-universal experts in all languages.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04694.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6435b1d9aaef013d1aeea6a0",
            "avatarUrl": "/avatars/1f515c67f3d03f35aa6e06f93566bd21.svg",
            "fullname": "Lucas Bandarkar",
            "name": "lucasbandarkar",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "organization": {
            "_id": "67784c39dac147922d8d09f0",
            "name": "UCLA",
            "fullname": "University of California, Los Angeles",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67784bd637dfa531fbce95a2/Nf0seEMEn66sPL3QsJXj4.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.03434",
            "authors": [
                {
                    "_id": "68e4735ce4e093a7044e4cd1",
                    "name": "Zhiying Jiang",
                    "hidden": false
                },
                {
                    "_id": "68e4735ce4e093a7044e4cd2",
                    "name": "Raihan Seraj",
                    "hidden": false
                },
                {
                    "_id": "68e4735ce4e093a7044e4cd3",
                    "name": "Marcos Villagra",
                    "hidden": false
                },
                {
                    "_id": "68e4735ce4e093a7044e4cd4",
                    "name": "Bidhan Roy",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-03T18:53:12.000Z",
            "submittedOnDailyAt": "2025-10-07T17:33:45.379Z",
            "title": "Paris: A Decentralized Trained Open-Weight Diffusion Model",
            "submittedOnDailyBy": {
                "_id": "651e96991b97c9f33d26bde6",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e96991b97c9f33d26bde6/-Bqs6qrmz0yCfwtB2e-6q.jpeg",
                "isPro": true,
                "fullname": "Elie Bakouch",
                "user": "eliebak",
                "type": "user"
            },
            "summary": "We present Paris, the first publicly released diffusion model pre-trained\nentirely through decentralized computation. Paris demonstrates that\nhigh-quality text-to-image generation can be achieved without centrally\ncoordinated infrastructure. Paris is open for research and commercial use.\nParis required implementing our Distributed Diffusion Training framework from\nscratch. The model consists of 8 expert diffusion models (129M-605M parameters\neach) trained in complete isolation with no gradient, parameter, or\nintermediate activation synchronization. Rather than requiring synchronized\ngradient updates across thousands of GPUs, we partition data into semantically\ncoherent clusters where each expert independently optimizes its subset while\ncollectively approximating the full distribution. A lightweight transformer\nrouter dynamically selects appropriate experts at inference, achieving\ngeneration quality comparable to centrally coordinated baselines. Eliminating\nsynchronization enables training on heterogeneous hardware without specialized\ninterconnects. Empirical validation confirms that Paris's decentralized\ntraining maintains generation quality while removing the dedicated GPU cluster\nrequirement for large-scale diffusion models. Paris achieves this using\n14times less training data and 16times less compute than the prior\ndecentralized baseline.",
            "upvotes": 0,
            "discussionId": "68e4735ce4e093a7044e4cd5",
            "ai_summary": "Paris, a decentralized diffusion model, achieves high-quality text-to-image generation without centralized infrastructure using a distributed training framework and a transformer router.",
            "ai_keywords": [
                "diffusion model",
                "decentralized computation",
                "Distributed Diffusion Training",
                "expert diffusion models",
                "parameter synchronization",
                "gradient updates",
                "semantically coherent clusters",
                "lightweight transformer router",
                "heterogeneous hardware",
                "decentralized training"
            ]
        },
        "publishedAt": "2025-10-03T14:53:12.000Z",
        "title": "Paris: A Decentralized Trained Open-Weight Diffusion Model",
        "summary": "We present Paris, the first publicly released diffusion model pre-trained\nentirely through decentralized computation. Paris demonstrates that\nhigh-quality text-to-image generation can be achieved without centrally\ncoordinated infrastructure. Paris is open for research and commercial use.\nParis required implementing our Distributed Diffusion Training framework from\nscratch. The model consists of 8 expert diffusion models (129M-605M parameters\neach) trained in complete isolation with no gradient, parameter, or\nintermediate activation synchronization. Rather than requiring synchronized\ngradient updates across thousands of GPUs, we partition data into semantically\ncoherent clusters where each expert independently optimizes its subset while\ncollectively approximating the full distribution. A lightweight transformer\nrouter dynamically selects appropriate experts at inference, achieving\ngeneration quality comparable to centrally coordinated baselines. Eliminating\nsynchronization enables training on heterogeneous hardware without specialized\ninterconnects. Empirical validation confirms that Paris's decentralized\ntraining maintains generation quality while removing the dedicated GPU cluster\nrequirement for large-scale diffusion models. Paris achieves this using\n14times less training data and 16times less compute than the prior\ndecentralized baseline.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03434.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "651e96991b97c9f33d26bde6",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/651e96991b97c9f33d26bde6/-Bqs6qrmz0yCfwtB2e-6q.jpeg",
            "fullname": "Elie Bakouch",
            "name": "eliebak",
            "type": "user",
            "isPro": true,
            "isHf": true,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 306
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.02387",
            "authors": [
                {
                    "_id": "68e57263975ac4c405ef1f60",
                    "name": "FAIR CodeGen team",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f61",
                    "name": "Quentin Carbonneaux",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f62",
                    "name": "Gal Cohen",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f63",
                    "name": "Jonas Gehring",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f64",
                    "name": "Jacob Kahn",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f65",
                    "name": "Jannik Kossen",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f66",
                    "name": "Felix Kreuk",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f67",
                    "name": "Emily McMilin",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f68",
                    "name": "Michel Meyer",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f69",
                    "name": "Yuxiang Wei",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f6a",
                    "name": "David Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f6b",
                    "name": "Kunhao Zheng",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f6c",
                    "name": "Jordi Armengol-Estapé",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f6d",
                    "name": "Pedram Bashiri",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f6e",
                    "name": "Maximilian Beck",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f6f",
                    "name": "Pierre Chambon",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f70",
                    "name": "Abhishek Charnalia",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f71",
                    "name": "Chris Cummins",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f72",
                    "name": "Juliette Decugis",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f73",
                    "name": "Zacharias V. Fisches",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f74",
                    "name": "François Fleuret",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f75",
                    "name": "Fabian Gloeckle",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f76",
                    "name": "Alex Gu",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f77",
                    "name": "Michael Hassid",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f78",
                    "name": "Daniel Haziza",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f79",
                    "name": "Badr Youbi Idrissi",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f7a",
                    "name": "Christian Keller",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f7b",
                    "name": "Rahul Kindi",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f7c",
                    "name": "Hugh Leather",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f7d",
                    "name": "Gallil Maimon",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f7e",
                    "name": "Aram Markosyan",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f7f",
                    "name": "Francisco Massa",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f80",
                    "name": "Pierre-Emmanuel Mazaré",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f81",
                    "name": "Vegard Mella",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f82",
                    "name": "Naila Murray",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f83",
                    "name": "Keyur Muzumdar",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f84",
                    "name": "Peter O'Hearn",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f85",
                    "name": "Matteo Pagliardini",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f86",
                    "name": "Dmitrii Pedchenko",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f87",
                    "name": "Tal Remez",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f88",
                    "name": "Volker Seeker",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f89",
                    "name": "Marco Selvi",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f8a",
                    "name": "Oren Sultan",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f8b",
                    "name": "Sida Wang",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f8c",
                    "name": "Luca Wehrstedt",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f8d",
                    "name": "Ori Yoran",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f8e",
                    "name": "Lingming Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f8f",
                    "name": "Taco Cohen",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f90",
                    "name": "Yossi Adi",
                    "hidden": false
                },
                {
                    "_id": "68e57263975ac4c405ef1f91",
                    "name": "Gabriel Synnaeve",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-30T21:47:10.000Z",
            "submittedOnDailyAt": "2025-10-07T18:36:01.837Z",
            "title": "CWM: An Open-Weights LLM for Research on Code Generation with World\n  Models",
            "submittedOnDailyBy": {
                "_id": "65f1eac292b7b4b9d59cb886",
                "avatarUrl": "/avatars/e7adb8a06860663c828501460cc092ae.svg",
                "isPro": false,
                "fullname": "Jacob Kahn",
                "user": "jacobkahn",
                "type": "user"
            },
            "summary": "We release Code World Model (CWM), a 32-billion-parameter open-weights LLM,\nto advance research on code generation with world models. To improve code\nunderstanding beyond what can be learned from training on static code alone, we\nmid-train CWM on a large amount of observation-action trajectories from Python\ninterpreter and agentic Docker environments, and perform extensive multi-task\nreasoning RL in verifiable coding, math, and multi-turn software engineering\nenvironments. With CWM, we provide a strong testbed for researchers to explore\nthe opportunities world modeling affords for improving code generation with\nreasoning and planning in computational environments. We present first steps of\nhow world models can benefit agentic coding, enable step-by-step simulation of\nPython code execution, and show early results of how reasoning can benefit from\nthe latter. CWM is a dense, decoder-only LLM trained with a context size of up\nto 131k tokens. Independent of its world modeling capabilities, CWM offers\nstrong performance on general coding and math tasks: it reaches pass@1 scores\nof 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on\nLiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further\nresearch on code world modeling, we release model checkpoints after\nmid-training, SFT, and RL.",
            "upvotes": 0,
            "discussionId": "68e57263975ac4c405ef1f92",
            "ai_summary": "Code World Model, a 32-billion-parameter LLM, enhances code generation through world modeling with observation-action trajectories and multi-task reasoning RL, offering strong performance on coding and math tasks.",
            "ai_keywords": [
                "Code World Model",
                "LLM",
                "observation-action trajectories",
                "Python interpreter",
                "agentic Docker environments",
                "multi-task reasoning RL",
                "world modeling",
                "step-by-step simulation",
                "SWE-bench Verified",
                "LiveCodeBench",
                "Math-500",
                "AIME 2024",
                "decoder-only LLM",
                "context size",
                "pass@1 scores"
            ],
            "organization": {
                "_id": "5e63d8713071d5be688861b8",
                "name": "facebook",
                "fullname": "AI at Meta",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1592839207516-noauth.png"
            }
        },
        "publishedAt": "2025-09-30T17:47:10.000Z",
        "title": "CWM: An Open-Weights LLM for Research on Code Generation with World\n  Models",
        "summary": "We release Code World Model (CWM), a 32-billion-parameter open-weights LLM,\nto advance research on code generation with world models. To improve code\nunderstanding beyond what can be learned from training on static code alone, we\nmid-train CWM on a large amount of observation-action trajectories from Python\ninterpreter and agentic Docker environments, and perform extensive multi-task\nreasoning RL in verifiable coding, math, and multi-turn software engineering\nenvironments. With CWM, we provide a strong testbed for researchers to explore\nthe opportunities world modeling affords for improving code generation with\nreasoning and planning in computational environments. We present first steps of\nhow world models can benefit agentic coding, enable step-by-step simulation of\nPython code execution, and show early results of how reasoning can benefit from\nthe latter. CWM is a dense, decoder-only LLM trained with a context size of up\nto 131k tokens. Independent of its world modeling capabilities, CWM offers\nstrong performance on general coding and math tasks: it reaches pass@1 scores\nof 65.8% on SWE-bench Verified (with test-time scaling), 68.6% on\nLiveCodeBench, 96.6% on Math-500, and 76.0% on AIME 2024. To support further\nresearch on code world modeling, we release model checkpoints after\nmid-training, SFT, and RL.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.02387.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65f1eac292b7b4b9d59cb886",
            "avatarUrl": "/avatars/e7adb8a06860663c828501460cc092ae.svg",
            "fullname": "Jacob Kahn",
            "name": "jacobkahn",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 10
        },
        "organization": {
            "_id": "5e63d8713071d5be688861b8",
            "name": "facebook",
            "fullname": "AI at Meta",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1592839207516-noauth.png"
        },
        "isAuthorParticipating": false
    }
]