[
    {
        "paper": {
            "id": "2510.04871",
            "authors": [
                {
                    "_id": "68e527e27e1f41b92bf8e9f9",
                    "name": "Alexia Jolicoeur-Martineau",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T14:58:08.000Z",
            "submittedOnDailyAt": "2025-10-08T11:20:49.242Z",
            "title": "Less is More: Recursive Reasoning with Tiny Networks",
            "submittedOnDailyBy": {
                "_id": "62f8ea1177b722f186611e8e",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660479589894-noauth.jpeg",
                "isPro": false,
                "fullname": "Alexia Jolicoeur-Martineau",
                "user": "AlexiaJM",
                "type": "user"
            },
            "summary": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,\nand ARC-AGI while trained with small models (27M parameters) on small data\n(around 1000 examples). HRM holds great promise for solving hard problems with\nsmall networks, but it is not yet well understood and may be suboptimal. We\npropose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach\nthat achieves significantly higher generalization than HRM, while using a\nsingle tiny network with only 2 layers. With only 7M parameters, TRM obtains\n45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs\n(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the\nparameters.",
            "upvotes": 83,
            "discussionId": "68e527e27e1f41b92bf8e9fa",
            "projectPage": "https://alexiajm.github.io/2025/09/29/tiny_recursive_models.html#",
            "githubRepo": "https://github.com/SamsungSAILMontreal/TinyRecursiveModels",
            "ai_summary": "Tiny Recursive Model (TRM) achieves high generalization on complex puzzle tasks using a small, two-layer network with minimal parameters, outperforming larger language models.",
            "ai_keywords": [
                "Hierarchical Reasoning Model",
                "HRM",
                "Tiny Recursive Model",
                "TRM",
                "recursive reasoning",
                "neural networks",
                "ARC-AGI",
                "Deepseek R1",
                "o3-mini",
                "Gemini 2.5 Pro"
            ],
            "githubStars": 1017,
            "organization": {
                "_id": "6406bcfea577649430c6c3ca",
                "name": "SamsungSAILMontreal",
                "fullname": "Samsung SAIT AI Lab, Montreal",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1678163236468-6406bcaca577649430c6bff4.png"
            }
        },
        "publishedAt": "2025-10-06T10:58:08.000Z",
        "title": "Less is More: Recursive Reasoning with Tiny Networks",
        "summary": "Hierarchical Reasoning Model (HRM) is a novel approach using two small neural\nnetworks recursing at different frequencies. This biologically inspired method\nbeats Large Language models (LLMs) on hard puzzle tasks such as Sudoku, Maze,\nand ARC-AGI while trained with small models (27M parameters) on small data\n(around 1000 examples). HRM holds great promise for solving hard problems with\nsmall networks, but it is not yet well understood and may be suboptimal. We\npropose Tiny Recursive Model (TRM), a much simpler recursive reasoning approach\nthat achieves significantly higher generalization than HRM, while using a\nsingle tiny network with only 2 layers. With only 7M parameters, TRM obtains\n45% test-accuracy on ARC-AGI-1 and 8% on ARC-AGI-2, higher than most LLMs\n(e.g., Deepseek R1, o3-mini, Gemini 2.5 Pro) with less than 0.01% of the\nparameters.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04871.png",
        "numComments": 4,
        "submittedBy": {
            "_id": "62f8ea1177b722f186611e8e",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1660479589894-noauth.jpeg",
            "fullname": "Alexia Jolicoeur-Martineau",
            "name": "AlexiaJM",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 14
        },
        "organization": {
            "_id": "6406bcfea577649430c6c3ca",
            "name": "SamsungSAILMontreal",
            "fullname": "Samsung SAIT AI Lab, Montreal",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1678163236468-6406bcaca577649430c6bff4.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06217",
            "authors": [
                {
                    "_id": "68e5bbf7975ac4c405ef200c",
                    "name": "Jiaru Zou",
                    "hidden": false
                },
                {
                    "_id": "68e5bbf7975ac4c405ef200d",
                    "user": {
                        "_id": "67c8c2526316c979bbfa2f3a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/1c8Jk7E-6BBPVoQ8nKe5N.png",
                        "isPro": false,
                        "fullname": "Soumya Roy",
                        "user": "roy-soumya-work",
                        "type": "user"
                    },
                    "name": "Soumya Roy",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T08:00:57.655Z",
                    "hidden": false
                },
                {
                    "_id": "68e5bbf7975ac4c405ef200e",
                    "user": {
                        "_id": "64c4c761958100e5bd302cfd",
                        "avatarUrl": "/avatars/dec3f49fb3c78dd4e029e1937b0202de.svg",
                        "isPro": false,
                        "fullname": "Vinay Kumar Verma",
                        "user": "vkvermaa",
                        "type": "user"
                    },
                    "name": "Vinay Kumar Verma",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T05:50:03.309Z",
                    "hidden": false
                },
                {
                    "_id": "68e5bbf7975ac4c405ef200f",
                    "name": "Ziyi Wang",
                    "hidden": false
                },
                {
                    "_id": "68e5bbf7975ac4c405ef2010",
                    "name": "David Wipf",
                    "hidden": false
                },
                {
                    "_id": "68e5bbf7975ac4c405ef2011",
                    "name": "Pan Lu",
                    "hidden": false
                },
                {
                    "_id": "68e5bbf7975ac4c405ef2012",
                    "name": "Sumit Negi",
                    "hidden": false
                },
                {
                    "_id": "68e5bbf7975ac4c405ef2013",
                    "name": "James Zou",
                    "hidden": false
                },
                {
                    "_id": "68e5bbf7975ac4c405ef2014",
                    "name": "Jingrui He",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T17:59:41.000Z",
            "submittedOnDailyAt": "2025-10-08T00:00:51.373Z",
            "title": "TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular\n  Reasoning",
            "submittedOnDailyBy": {
                "_id": "65c288280aa2d53135734a42",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65c288280aa2d53135734a42/5WHmau52EaRS01TOMI3Qg.jpeg",
                "isPro": false,
                "fullname": "Jiaru Zou",
                "user": "jiaruz2",
                "type": "user"
            },
            "summary": "Process Reward Models (PRMs) have recently emerged as a powerful framework\nfor enhancing the reasoning capabilities of large reasoning models (LRMs),\nparticularly in the context of test-time scaling (TTS). However, their\npotential for supervising LRMs on tabular reasoning domains remains\nunderexplored. Through detailed empirical analyses, we identify that existing\nPRMs, though widely adopted for supervising text-only reasoning steps, struggle\nwith table-specific operations such as sub-table retrieval and schema\ninteraction, leading to critical performance bottlenecks. To address this\nlimitation, we propose TaTToo, a novel table-grounded PRM framework that (i)\nreasons explicitly over tabular reasoning steps and (ii) integrates tool-based\nverification to provide precise reward supervision. Concretely, we first design\na scalable data curation pipeline that constructs over 60k high-quality\nstep-level annotations by integrating table verification rationales with\ntool-based executions. Building on the collected data, we train TaTToo with a\ndual-stage paradigm: cold-start supervised fine-tuning to capture tool-use\nreasoning patterns, followed by reinforcement learning with tool-grounded\nreward shaping to align our model with table-based verification. We provide a\ncomprehensive evaluation of the policy improvement induced by our newly\ndesigned PRM. Across 5 challenging tabular reasoning benchmarks covering\nnumerical reasoning, fact-checking, and data analysis, TaTToo improves\ndownstream policy LRMs by 30.9% at inference, surpasses strong PRM baselines\nsuch as Qwen-2.5-Math-PRM-72B with only 8B parameters, and demonstrates strong\ngeneralizability across diverse TTS strategies.",
            "upvotes": 59,
            "discussionId": "68e5bbf8975ac4c405ef2015",
            "ai_summary": "TaTToo, a novel table-grounded Process Reward Model, enhances tabular reasoning by explicitly addressing table-specific operations and integrating tool-based verification, leading to significant performance improvements over existing PRMs.",
            "ai_keywords": [
                "Process Reward Models",
                "large reasoning models",
                "test-time scaling",
                "tabular reasoning",
                "sub-table retrieval",
                "schema interaction",
                "TaTToo",
                "data curation pipeline",
                "step-level annotations",
                "tool-based verification",
                "dual-stage paradigm",
                "cold-start supervised fine-tuning",
                "reinforcement learning",
                "reward shaping",
                "policy improvement",
                "numerical reasoning",
                "fact-checking",
                "data analysis",
                "generalizability"
            ],
            "organization": {
                "_id": "5ffdfbadbba2ae614d771970",
                "name": "amazon",
                "fullname": "Amazon",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66f19ed428ae41c20c470792/8y7msN6A6W82LdQhQd85a.png"
            }
        },
        "publishedAt": "2025-10-07T13:59:41.000Z",
        "title": "TaTToo: Tool-Grounded Thinking PRM for Test-Time Scaling in Tabular\n  Reasoning",
        "summary": "Process Reward Models (PRMs) have recently emerged as a powerful framework\nfor enhancing the reasoning capabilities of large reasoning models (LRMs),\nparticularly in the context of test-time scaling (TTS). However, their\npotential for supervising LRMs on tabular reasoning domains remains\nunderexplored. Through detailed empirical analyses, we identify that existing\nPRMs, though widely adopted for supervising text-only reasoning steps, struggle\nwith table-specific operations such as sub-table retrieval and schema\ninteraction, leading to critical performance bottlenecks. To address this\nlimitation, we propose TaTToo, a novel table-grounded PRM framework that (i)\nreasons explicitly over tabular reasoning steps and (ii) integrates tool-based\nverification to provide precise reward supervision. Concretely, we first design\na scalable data curation pipeline that constructs over 60k high-quality\nstep-level annotations by integrating table verification rationales with\ntool-based executions. Building on the collected data, we train TaTToo with a\ndual-stage paradigm: cold-start supervised fine-tuning to capture tool-use\nreasoning patterns, followed by reinforcement learning with tool-grounded\nreward shaping to align our model with table-based verification. We provide a\ncomprehensive evaluation of the policy improvement induced by our newly\ndesigned PRM. Across 5 challenging tabular reasoning benchmarks covering\nnumerical reasoning, fact-checking, and data analysis, TaTToo improves\ndownstream policy LRMs by 30.9% at inference, surpasses strong PRM baselines\nsuch as Qwen-2.5-Math-PRM-72B with only 8B parameters, and demonstrates strong\ngeneralizability across diverse TTS strategies.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06217.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "65c288280aa2d53135734a42",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65c288280aa2d53135734a42/5WHmau52EaRS01TOMI3Qg.jpeg",
            "fullname": "Jiaru Zou",
            "name": "jiaruz2",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 6
        },
        "organization": {
            "_id": "5ffdfbadbba2ae614d771970",
            "name": "amazon",
            "fullname": "Amazon",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/66f19ed428ae41c20c470792/8y7msN6A6W82LdQhQd85a.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2509.24107",
            "authors": [
                {
                    "_id": "68db773ad2bf1f4b15ec770e",
                    "user": {
                        "_id": "66bb4ba002fd8eb58bdb2b5c",
                        "avatarUrl": "/avatars/47a624da769170d6d22a177a003a1f50.svg",
                        "isPro": false,
                        "fullname": "Shreyas Singh ",
                        "user": "shreyess",
                        "type": "user"
                    },
                    "name": "Shreyas Singh",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-06T12:49:13.075Z",
                    "hidden": false
                },
                {
                    "_id": "68db773ad2bf1f4b15ec770f",
                    "user": {
                        "_id": "64ccc06cf103036e23f0162f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ccc06cf103036e23f0162f/kLwjzbxNobLxwN_GUuPrP.jpeg",
                        "isPro": false,
                        "fullname": "Kunal Singh",
                        "user": "Ogkunal",
                        "type": "user"
                    },
                    "name": "Kunal Singh",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-01T10:24:35.967Z",
                    "hidden": false
                },
                {
                    "_id": "68db773ad2bf1f4b15ec7710",
                    "name": "Pradeep Moturi",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-28T22:58:11.000Z",
            "submittedOnDailyAt": "2025-10-08T03:39:49.572Z",
            "title": "Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and\n  Synthesis for SLMs",
            "submittedOnDailyBy": {
                "_id": "64ccc06cf103036e23f0162f",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ccc06cf103036e23f0162f/kLwjzbxNobLxwN_GUuPrP.jpeg",
                "isPro": false,
                "fullname": "Kunal Singh",
                "user": "Ogkunal",
                "type": "user"
            },
            "summary": "Tool-integrated reasoning has emerged as a key focus for enabling agentic\napplications. Among these, DeepResearch Agents have gained significant\nattention for their strong performance on complex, open-ended\ninformation-seeking tasks. We introduce Fathom-DeepResearch, an agentic system\ncomposed of two specialized models. The first is Fathom-Search-4B, a DeepSearch\nmodel trained from Qwen3-4B and optimized for evidence-based investigation\nthrough live web search and targeted webpage querying. Its training combines\nthree advances: (i) DUETQA, a 5K-sample dataset generated via multi-agent\nself-play that enforces strict web-search dependence and heterogeneous source\ngrounding; (ii) RAPO, a zero-overhead extension of GRPO that stabilizes\nmulti-turn Reinforcement Learning with Verifiable Rewards through curriculum\npruning, reward-aware advantage scaling, and per-prompt replay buffers; and\n(iii) a steerable step-level reward that classifies each tool call by cognitive\nbehavior and marginal utility, enabling explicit control over search trajectory\nbreadth, depth, and horizon. These improvements enable reliable extension of\ntool-calling beyond 20 calls when warranted. The second is\nFathom-Synthesizer-4B, trained from Qwen3-4B, which converts multi-turn\nDeepSearch traces into structured, citation-dense DeepResearch Reports for\ncomprehensive synthesis. Evaluated on DeepSearch benchmarks (SimpleQA, FRAMES,\nWebWalker, Seal0, MuSiQue) and DeepResearch-Bench, the system achieves\nstate-of-the-art performance in the open-weights category while demonstrating\nstrong generalization to diverse reasoning tasks including HLE, AIME-25,\nGPQA-Diamond, and MedQA.",
            "upvotes": 57,
            "discussionId": "68db773ad2bf1f4b15ec7711",
            "githubRepo": "https://github.com/FractalAIResearchLabs/Fathom-DeepResearch",
            "ai_summary": "Fathom-DeepResearch, an agentic system with specialized models for web search and report synthesis, achieves state-of-the-art performance on open-ended information-seeking tasks and diverse reasoning tasks.",
            "ai_keywords": [
                "DeepResearch Agents",
                "Fathom-DeepResearch",
                "Fathom-Search-4B",
                "DeepSearch",
                "Qwen3-4B",
                "DUETQA",
                "RAPO",
                "GRPO",
                "curriculum pruning",
                "reward-aware advantage scaling",
                "per-prompt replay buffers",
                "steerable step-level reward",
                "Fathom-Synthesizer-4B",
                "DeepResearch Reports",
                "SimpleQA",
                "FRAMES",
                "WebWalker",
                "Seal0",
                "MuSiQue",
                "DeepResearch-Bench",
                "HLE",
                "AIME-25",
                "GPQA-Diamond",
                "MedQA"
            ],
            "githubStars": 12,
            "organization": {
                "_id": "67ff911f97acbf357c65f129",
                "name": "FractalAIResearch",
                "fullname": "Fractal AI Research",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67ff900add7320db615695bc/K01LCMcPGn6QppOlYlDjF.png"
            }
        },
        "publishedAt": "2025-09-28T18:58:11.000Z",
        "title": "Fathom-DeepResearch: Unlocking Long Horizon Information Retrieval and\n  Synthesis for SLMs",
        "summary": "Tool-integrated reasoning has emerged as a key focus for enabling agentic\napplications. Among these, DeepResearch Agents have gained significant\nattention for their strong performance on complex, open-ended\ninformation-seeking tasks. We introduce Fathom-DeepResearch, an agentic system\ncomposed of two specialized models. The first is Fathom-Search-4B, a DeepSearch\nmodel trained from Qwen3-4B and optimized for evidence-based investigation\nthrough live web search and targeted webpage querying. Its training combines\nthree advances: (i) DUETQA, a 5K-sample dataset generated via multi-agent\nself-play that enforces strict web-search dependence and heterogeneous source\ngrounding; (ii) RAPO, a zero-overhead extension of GRPO that stabilizes\nmulti-turn Reinforcement Learning with Verifiable Rewards through curriculum\npruning, reward-aware advantage scaling, and per-prompt replay buffers; and\n(iii) a steerable step-level reward that classifies each tool call by cognitive\nbehavior and marginal utility, enabling explicit control over search trajectory\nbreadth, depth, and horizon. These improvements enable reliable extension of\ntool-calling beyond 20 calls when warranted. The second is\nFathom-Synthesizer-4B, trained from Qwen3-4B, which converts multi-turn\nDeepSearch traces into structured, citation-dense DeepResearch Reports for\ncomprehensive synthesis. Evaluated on DeepSearch benchmarks (SimpleQA, FRAMES,\nWebWalker, Seal0, MuSiQue) and DeepResearch-Bench, the system achieves\nstate-of-the-art performance in the open-weights category while demonstrating\nstrong generalization to diverse reasoning tasks including HLE, AIME-25,\nGPQA-Diamond, and MedQA.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.24107.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64ccc06cf103036e23f0162f",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/64ccc06cf103036e23f0162f/kLwjzbxNobLxwN_GUuPrP.jpeg",
            "fullname": "Kunal Singh",
            "name": "Ogkunal",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "organization": {
            "_id": "67ff911f97acbf357c65f129",
            "name": "FractalAIResearch",
            "fullname": "Fractal AI Research",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67ff900add7320db615695bc/K01LCMcPGn6QppOlYlDjF.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2509.26328",
            "authors": [
                {
                    "_id": "68e1e6d873e20ab577841e18",
                    "name": "Chengyue Wu",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e19",
                    "name": "Hao Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e1a",
                    "name": "Shuchen Xue",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e1b",
                    "name": "Shizhe Diao",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e1c",
                    "name": "Yonggan Fu",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e1d",
                    "user": {
                        "_id": "650dac79b959b0e1d41d7378",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/650dac79b959b0e1d41d7378/mzbN0MFk3k8b94FQ40I7L.jpeg",
                        "isPro": false,
                        "fullname": "Zhijian Liu",
                        "user": "zhijianliu",
                        "type": "user"
                    },
                    "name": "Zhijian Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T08:03:25.561Z",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e1e",
                    "name": "Pavlo Molchanov",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e1f",
                    "name": "Ping Luo",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e20",
                    "name": "Song Han",
                    "hidden": false
                },
                {
                    "_id": "68e1e6d873e20ab577841e21",
                    "name": "Enze Xie",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-30T14:40:18.000Z",
            "submittedOnDailyAt": "2025-10-08T00:26:14.372Z",
            "title": "Fast-dLLM v2: Efficient Block-Diffusion LLM",
            "submittedOnDailyBy": {
                "_id": "617526c9de8feb54b0ce45ad",
                "avatarUrl": "/avatars/7faf8c6f71fc318a0113d780d376c381.svg",
                "isPro": false,
                "fullname": "Wu Chengyue",
                "user": "WuChengyue",
                "type": "user"
            },
            "summary": "Autoregressive (AR) large language models (LLMs) have achieved remarkable\nperformance across a wide range of natural language tasks, yet their inherent\nsequential decoding limits inference efficiency. In this work, we propose\nFast-dLLM v2, a carefully designed block diffusion language model (dLLM) that\nefficiently adapts pretrained AR models into dLLMs for parallel text\ngeneration, requiring only approximately 1B tokens of fine-tuning. This\nrepresents a 500x reduction in training data compared to full-attention\ndiffusion LLMs such as Dream (580B tokens), while preserving the original\nmodel's performance. Our approach introduces a novel training recipe that\ncombines a block diffusion mechanism with a complementary attention mask,\nenabling blockwise bidirectional context modeling without sacrificing AR\ntraining objectives. To further accelerate decoding, we design a hierarchical\ncaching mechanism: a block-level cache that stores historical context\nrepresentations across blocks, and a sub-block cache that enables efficient\nparallel generation within partially decoded blocks. Coupled with our parallel\ndecoding pipeline, Fast-dLLM v2 achieves up to 2.5x speedup over standard AR\ndecoding without compromising generation quality. Extensive experiments across\ndiverse benchmarks demonstrate that Fast-dLLM v2 matches or surpasses AR\nbaselines in accuracy, while delivering state-of-the-art efficiency among dLLMs\n- marking a significant step toward the practical deployment of fast and\naccurate LLMs. Code and model will be publicly released.",
            "upvotes": 33,
            "discussionId": "68e1e6d873e20ab577841e22",
            "projectPage": "https://nvlabs.github.io/Fast-dLLM/v2/",
            "githubRepo": "https://github.com/NVlabs/Fast-dLLM",
            "ai_summary": "Fast-dLLM v2, a block diffusion language model, efficiently converts pretrained autoregressive models for parallel text generation, achieving significant speedup without compromising accuracy.",
            "ai_keywords": [
                "autoregressive models",
                "large language models",
                "diffusion language models",
                "block diffusion mechanism",
                "attention mask",
                "blockwise bidirectional context modeling",
                "hierarchical caching",
                "block-level cache",
                "sub-block cache",
                "parallel decoding pipeline"
            ],
            "githubStars": 527,
            "organization": {
                "_id": "60262b67268c201cdc8b7d43",
                "name": "nvidia",
                "fullname": "NVIDIA",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"
            }
        },
        "publishedAt": "2025-09-30T10:40:18.000Z",
        "title": "Fast-dLLM v2: Efficient Block-Diffusion LLM",
        "summary": "Autoregressive (AR) large language models (LLMs) have achieved remarkable\nperformance across a wide range of natural language tasks, yet their inherent\nsequential decoding limits inference efficiency. In this work, we propose\nFast-dLLM v2, a carefully designed block diffusion language model (dLLM) that\nefficiently adapts pretrained AR models into dLLMs for parallel text\ngeneration, requiring only approximately 1B tokens of fine-tuning. This\nrepresents a 500x reduction in training data compared to full-attention\ndiffusion LLMs such as Dream (580B tokens), while preserving the original\nmodel's performance. Our approach introduces a novel training recipe that\ncombines a block diffusion mechanism with a complementary attention mask,\nenabling blockwise bidirectional context modeling without sacrificing AR\ntraining objectives. To further accelerate decoding, we design a hierarchical\ncaching mechanism: a block-level cache that stores historical context\nrepresentations across blocks, and a sub-block cache that enables efficient\nparallel generation within partially decoded blocks. Coupled with our parallel\ndecoding pipeline, Fast-dLLM v2 achieves up to 2.5x speedup over standard AR\ndecoding without compromising generation quality. Extensive experiments across\ndiverse benchmarks demonstrate that Fast-dLLM v2 matches or surpasses AR\nbaselines in accuracy, while delivering state-of-the-art efficiency among dLLMs\n- marking a significant step toward the practical deployment of fast and\naccurate LLMs. Code and model will be publicly released.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.26328.png",
        "numComments": 5,
        "submittedBy": {
            "_id": "617526c9de8feb54b0ce45ad",
            "avatarUrl": "/avatars/7faf8c6f71fc318a0113d780d376c381.svg",
            "fullname": "Wu Chengyue",
            "name": "WuChengyue",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 163
        },
        "organization": {
            "_id": "60262b67268c201cdc8b7d43",
            "name": "nvidia",
            "fullname": "NVIDIA",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1613114437487-60262a8e0703121c822a80b6.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05592",
            "authors": [
                {
                    "_id": "68e5c595975ac4c405ef20d4",
                    "user": {
                        "_id": "66349404f2c753240d02952a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66349404f2c753240d02952a/xKBKicwyk7BoOITQPwBJn.png",
                        "isPro": true,
                        "fullname": "ZhuofengLi",
                        "user": "ZhuofengLi",
                        "type": "user"
                    },
                    "name": "Zhuofeng Li",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T13:49:36.168Z",
                    "hidden": false
                },
                {
                    "_id": "68e5c595975ac4c405ef20d5",
                    "name": "Haoxiang Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e5c595975ac4c405ef20d6",
                    "name": "Seungju Han",
                    "hidden": false
                },
                {
                    "_id": "68e5c595975ac4c405ef20d7",
                    "name": "Sheng Liu",
                    "hidden": false
                },
                {
                    "_id": "68e5c595975ac4c405ef20d8",
                    "name": "Jianwen Xie",
                    "hidden": false
                },
                {
                    "_id": "68e5c595975ac4c405ef20d9",
                    "name": "Yu Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e5c595975ac4c405ef20da",
                    "name": "Yejin Choi",
                    "hidden": false
                },
                {
                    "_id": "68e5c595975ac4c405ef20db",
                    "name": "James Zou",
                    "hidden": false
                },
                {
                    "_id": "68e5c595975ac4c405ef20dc",
                    "name": "Pan Lu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T05:32:44.000Z",
            "submittedOnDailyAt": "2025-10-08T10:42:07.005Z",
            "title": "In-the-Flow Agentic System Optimization for Effective Planning and Tool\n  Use",
            "submittedOnDailyBy": {
                "_id": "66349404f2c753240d02952a",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66349404f2c753240d02952a/xKBKicwyk7BoOITQPwBJn.png",
                "isPro": true,
                "fullname": "ZhuofengLi",
                "user": "ZhuofengLi",
                "type": "user"
            },
            "summary": "Outcome-driven reinforcement learning has advanced reasoning in large\nlanguage models (LLMs), but prevailing tool-augmented approaches train a\nsingle, monolithic policy that interleaves thoughts and tool calls under full\ncontext; this scales poorly with long horizons and diverse tools and\ngeneralizes weakly to new scenarios. Agentic systems offer a promising\nalternative by decomposing work across specialized modules, yet most remain\ntraining-free or rely on offline training decoupled from the live dynamics of\nmulti-turn interaction. We introduce AgentFlow, a trainable, in-the-flow\nagentic framework that coordinates four modules (planner, executor, verifier,\ngenerator) through an evolving memory and directly optimizes its planner inside\nthe multi-turn loop. To train on-policy in live environments, we propose\nFlow-based Group Refined Policy Optimization (Flow-GRPO), which tackles\nlong-horizon, sparse-reward credit assignment by converting multi-turn\noptimization into a sequence of tractable single-turn policy updates. It\nbroadcasts a single, verifiable trajectory-level outcome to every turn to align\nlocal planner decisions with global success and stabilizes learning with\ngroup-normalized advantages. Across ten benchmarks, AgentFlow with a 7B-scale\nbackbone outperforms top-performing baselines with average accuracy gains of\n14.9% on search, 14.0% on agentic, 14.5% on mathematical, and 4.1% on\nscientific tasks, even surpassing larger proprietary models like GPT-4o.\nFurther analyses confirm the benefits of in-the-flow optimization, showing\nimproved planning, enhanced tool-calling reliability, and positive scaling with\nmodel size and reasoning turns.",
            "upvotes": 31,
            "discussionId": "68e5c595975ac4c405ef20dd",
            "projectPage": "https://agentflow.stanford.edu/",
            "githubRepo": "https://github.com/lupantech/AgentFlow",
            "ai_summary": "AgentFlow, a trainable agentic framework with in-the-flow optimization, enhances reasoning in large language models by coordinating specialized modules and outperforms top baselines across various tasks.",
            "ai_keywords": [
                "reinforcement learning",
                "large language models",
                "tool-augmented approaches",
                "monolithic policy",
                "agentic systems",
                "specialized modules",
                "trainable framework",
                "planner",
                "executor",
                "verifier",
                "generator",
                "evolving memory",
                "on-policy training",
                "multi-turn interaction",
                "Flow-based Group Refined Policy Optimization",
                "Flow-GRPO",
                "long-horizon",
                "sparse-reward credit assignment",
                "single-turn policy updates",
                "trajectory-level outcome",
                "group-normalized advantages",
                "search tasks",
                "agentic tasks",
                "mathematical tasks",
                "scientific tasks",
                "GPT-4o"
            ],
            "githubStars": 16,
            "organization": {
                "_id": "636025b83605bd411c1889d9",
                "name": "Stanford",
                "fullname": "Stanford AI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/604d2f473050a33ebb17ef51/Z-vDTyG_6-yZhzfXklqAK.jpeg"
            }
        },
        "publishedAt": "2025-10-07T01:32:44.000Z",
        "title": "In-the-Flow Agentic System Optimization for Effective Planning and Tool\n  Use",
        "summary": "Outcome-driven reinforcement learning has advanced reasoning in large\nlanguage models (LLMs), but prevailing tool-augmented approaches train a\nsingle, monolithic policy that interleaves thoughts and tool calls under full\ncontext; this scales poorly with long horizons and diverse tools and\ngeneralizes weakly to new scenarios. Agentic systems offer a promising\nalternative by decomposing work across specialized modules, yet most remain\ntraining-free or rely on offline training decoupled from the live dynamics of\nmulti-turn interaction. We introduce AgentFlow, a trainable, in-the-flow\nagentic framework that coordinates four modules (planner, executor, verifier,\ngenerator) through an evolving memory and directly optimizes its planner inside\nthe multi-turn loop. To train on-policy in live environments, we propose\nFlow-based Group Refined Policy Optimization (Flow-GRPO), which tackles\nlong-horizon, sparse-reward credit assignment by converting multi-turn\noptimization into a sequence of tractable single-turn policy updates. It\nbroadcasts a single, verifiable trajectory-level outcome to every turn to align\nlocal planner decisions with global success and stabilizes learning with\ngroup-normalized advantages. Across ten benchmarks, AgentFlow with a 7B-scale\nbackbone outperforms top-performing baselines with average accuracy gains of\n14.9% on search, 14.0% on agentic, 14.5% on mathematical, and 4.1% on\nscientific tasks, even surpassing larger proprietary models like GPT-4o.\nFurther analyses confirm the benefits of in-the-flow optimization, showing\nimproved planning, enhanced tool-calling reliability, and positive scaling with\nmodel size and reasoning turns.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05592.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "66349404f2c753240d02952a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66349404f2c753240d02952a/xKBKicwyk7BoOITQPwBJn.png",
            "fullname": "ZhuofengLi",
            "name": "ZhuofengLi",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "organization": {
            "_id": "636025b83605bd411c1889d9",
            "name": "Stanford",
            "fullname": "Stanford AI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/604d2f473050a33ebb17ef51/Z-vDTyG_6-yZhzfXklqAK.jpeg"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.03270",
            "authors": [
                {
                    "_id": "68e4787be4e093a7044e4ceb",
                    "name": "Haolin Chen",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cec",
                    "name": "Shiyu Wang",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4ced",
                    "name": "Can Qin",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cee",
                    "name": "Bo Pang",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cef",
                    "name": "Zuxin Liu",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf0",
                    "name": "Jielin Qiu",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf1",
                    "name": "Jianguo Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf2",
                    "name": "Yingbo Zhou",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf3",
                    "name": "Zeyuan Chen",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf4",
                    "name": "Ran Xu",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf5",
                    "name": "Shelby Heinecke",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf6",
                    "name": "Silvio Savarese",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf7",
                    "name": "Caiming Xiong",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf8",
                    "name": "Huan Wang",
                    "hidden": false
                },
                {
                    "_id": "68e4787be4e093a7044e4cf9",
                    "user": {
                        "_id": "661573234c2f29635e93bb71",
                        "avatarUrl": "/avatars/fba95e382454485766b6349d6281b715.svg",
                        "isPro": false,
                        "fullname": "Weiran Yao",
                        "user": "weiranyao",
                        "type": "user"
                    },
                    "name": "Weiran Yao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T08:03:10.713Z",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/632cdea254e2c512c8f95b12/Hce9DQBwDnat1pLoOeZk4.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/632cdea254e2c512c8f95b12/21y3b_qaKDlIi-Os-vaKD.png"
            ],
            "publishedAt": "2025-09-27T05:41:55.000Z",
            "submittedOnDailyAt": "2025-10-08T00:27:46.813Z",
            "title": "CoDA: Coding LM via Diffusion Adaptation",
            "submittedOnDailyBy": {
                "_id": "632cdea254e2c512c8f95b12",
                "avatarUrl": "/avatars/a6d06cdd75861ae7d589f1343d81a5c5.svg",
                "isPro": false,
                "fullname": "Weiran Yao",
                "user": "weirayao",
                "type": "user"
            },
            "summary": "Diffusion language models promise bidirectional context and infilling\ncapabilities that autoregressive coders lack, yet practical systems remain\nheavyweight. We introduce CoDA, a 1.7B-parameter diffusion coder trained on TPU\nwith a fully open-source training pipeline. CoDA pairs large-scale diffusion\npre-training with code-centric mid-training and instruction tuning, enabling\nconfidence-guided sampling that keeps inference latency competitive. On\nHumaneval, MBPP, and EvalPlus, CoDA-1.7B-Instruct matches or surpasses\ndiffusion models up to 7B parameters. Our release includes model checkpoints,\nevaluation harnesses, and TPU training pipelines to accelerate research on\nlightweight diffusion-based coding assistants.",
            "upvotes": 25,
            "discussionId": "68e4787ce4e093a7044e4cfa",
            "projectPage": "https://huggingface.co/Salesforce/CoDA-v0-Instruct",
            "githubRepo": "https://github.com/SalesforceAIResearch/CoDA/",
            "ai_summary": "CoDA, a 1.7B-parameter diffusion coder, achieves competitive performance with smaller models through confidence-guided sampling and is released with open-source tools.",
            "ai_keywords": [
                "diffusion language models",
                "bidirectional context",
                "infilling capabilities",
                "autoregressive coders",
                "diffusion coder",
                "large-scale diffusion pre-training",
                "code-centric mid-training",
                "instruction tuning",
                "confidence-guided sampling",
                "inference latency",
                "Humaneval",
                "MBPP",
                "EvalPlus",
                "diffusion-based coding assistants"
            ],
            "githubStars": 20,
            "organization": {
                "_id": "5f6d64475e78cc6b0ed31e4c",
                "name": "Salesforce",
                "fullname": "Salesforce",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1602756670970-noauth.jpeg"
            }
        },
        "publishedAt": "2025-09-27T01:41:55.000Z",
        "title": "CoDA: Coding LM via Diffusion Adaptation",
        "summary": "Diffusion language models promise bidirectional context and infilling\ncapabilities that autoregressive coders lack, yet practical systems remain\nheavyweight. We introduce CoDA, a 1.7B-parameter diffusion coder trained on TPU\nwith a fully open-source training pipeline. CoDA pairs large-scale diffusion\npre-training with code-centric mid-training and instruction tuning, enabling\nconfidence-guided sampling that keeps inference latency competitive. On\nHumaneval, MBPP, and EvalPlus, CoDA-1.7B-Instruct matches or surpasses\ndiffusion models up to 7B parameters. Our release includes model checkpoints,\nevaluation harnesses, and TPU training pipelines to accelerate research on\nlightweight diffusion-based coding assistants.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/632cdea254e2c512c8f95b12/Hce9DQBwDnat1pLoOeZk4.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/632cdea254e2c512c8f95b12/21y3b_qaKDlIi-Os-vaKD.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03270.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "632cdea254e2c512c8f95b12",
            "avatarUrl": "/avatars/a6d06cdd75861ae7d589f1343d81a5c5.svg",
            "fullname": "Weiran Yao",
            "name": "weirayao",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "5f6d64475e78cc6b0ed31e4c",
            "name": "Salesforce",
            "fullname": "Salesforce",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1602756670970-noauth.jpeg"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.04162",
            "authors": [
                {
                    "_id": "68e55fb1975ac4c405ef1f2f",
                    "name": "Aviv Navon",
                    "hidden": false
                },
                {
                    "_id": "68e55fb1975ac4c405ef1f30",
                    "name": "Aviv Shamsian",
                    "hidden": false
                },
                {
                    "_id": "68e55fb1975ac4c405ef1f31",
                    "name": "Neta Glazer",
                    "hidden": false
                },
                {
                    "_id": "68e55fb1975ac4c405ef1f32",
                    "name": "Yael Segal-Feldman",
                    "hidden": false
                },
                {
                    "_id": "68e55fb1975ac4c405ef1f33",
                    "name": "Gill Hetz",
                    "hidden": false
                },
                {
                    "_id": "68e55fb1975ac4c405ef1f34",
                    "name": "Joseph Keshet",
                    "hidden": false
                },
                {
                    "_id": "68e55fb1975ac4c405ef1f35",
                    "name": "Ethan Fetaya",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/63563ac12d14fcd7d83729d6/ns0VvTrmXIJ8sJYNHY3mw.png"
            ],
            "publishedAt": "2025-10-05T11:38:01.000Z",
            "submittedOnDailyAt": "2025-10-08T10:55:40.157Z",
            "title": "Drax: Speech Recognition with Discrete Flow Matching",
            "submittedOnDailyBy": {
                "_id": "63563ac12d14fcd7d83729d6",
                "avatarUrl": "/avatars/4e78baf7edb286b2518fb4a2fa6dbe04.svg",
                "isPro": false,
                "fullname": "Aviv Navon",
                "user": "AvivNavon",
                "type": "user"
            },
            "summary": "Diffusion and flow-based non-autoregressive (NAR) models have shown strong\npromise in large language modeling, however, their potential for automatic\nspeech recognition (ASR) remains largely unexplored. We propose Drax, a\ndiscrete flow matching framework for ASR that enables efficient parallel\ndecoding. To better align training with inference, we construct an\naudio-conditioned probability path that guides the model through trajectories\nresembling likely intermediate inference errors, rather than direct random\nnoise to target transitions. Our theoretical analysis links the generalization\ngap to divergences between training and inference occupancies, controlled by\ncumulative velocity errors, thereby motivating our design choice. Empirical\nevaluation demonstrates that our approach attains recognition accuracy on par\nwith state-of-the-art speech models while offering improved accuracy-efficiency\ntrade-offs, highlighting discrete flow matching as a promising direction for\nadvancing NAR ASR.",
            "upvotes": 22,
            "discussionId": "68e55fb2975ac4c405ef1f36",
            "githubRepo": "https://github.com/aiola-lab/drax",
            "ai_summary": "Drax, a discrete flow matching framework for ASR, achieves state-of-the-art recognition accuracy with improved efficiency by constructing an audio-conditioned probability path.",
            "ai_keywords": [
                "diffusion models",
                "flow-based models",
                "non-autoregressive models",
                "discrete flow matching",
                "audio-conditioned probability path",
                "generalization gap",
                "divergences",
                "cumulative velocity errors",
                "ASR",
                "recognition accuracy",
                "accuracy-efficiency trade-offs"
            ],
            "githubStars": 15,
            "organization": {
                "_id": "6281191552815a0dc73a434c",
                "name": "aiola-lab",
                "fullname": "aiOla",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1652627718946-628116b7eeb155799468ef92.png"
            }
        },
        "publishedAt": "2025-10-05T07:38:01.000Z",
        "title": "Drax: Speech Recognition with Discrete Flow Matching",
        "summary": "Diffusion and flow-based non-autoregressive (NAR) models have shown strong\npromise in large language modeling, however, their potential for automatic\nspeech recognition (ASR) remains largely unexplored. We propose Drax, a\ndiscrete flow matching framework for ASR that enables efficient parallel\ndecoding. To better align training with inference, we construct an\naudio-conditioned probability path that guides the model through trajectories\nresembling likely intermediate inference errors, rather than direct random\nnoise to target transitions. Our theoretical analysis links the generalization\ngap to divergences between training and inference occupancies, controlled by\ncumulative velocity errors, thereby motivating our design choice. Empirical\nevaluation demonstrates that our approach attains recognition accuracy on par\nwith state-of-the-art speech models while offering improved accuracy-efficiency\ntrade-offs, highlighting discrete flow matching as a promising direction for\nadvancing NAR ASR.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/63563ac12d14fcd7d83729d6/ns0VvTrmXIJ8sJYNHY3mw.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04162.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "63563ac12d14fcd7d83729d6",
            "avatarUrl": "/avatars/4e78baf7edb286b2518fb4a2fa6dbe04.svg",
            "fullname": "Aviv Navon",
            "name": "AvivNavon",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "6281191552815a0dc73a434c",
            "name": "aiola-lab",
            "fullname": "aiOla",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1652627718946-628116b7eeb155799468ef92.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.04081",
            "authors": [
                {
                    "_id": "68e5cffd975ac4c405ef210e",
                    "name": "Honglin Lin",
                    "hidden": false
                },
                {
                    "_id": "68e5cffd975ac4c405ef210f",
                    "name": "Qizhi Pei",
                    "hidden": false
                },
                {
                    "_id": "68e5cffd975ac4c405ef2110",
                    "name": "Xin Gao",
                    "hidden": false
                },
                {
                    "_id": "68e5cffd975ac4c405ef2111",
                    "name": "Zhuoshi Pan",
                    "hidden": false
                },
                {
                    "_id": "68e5cffd975ac4c405ef2112",
                    "name": "Yu Li",
                    "hidden": false
                },
                {
                    "_id": "68e5cffd975ac4c405ef2113",
                    "name": "Juntao Li",
                    "hidden": false
                },
                {
                    "_id": "68e5cffd975ac4c405ef2114",
                    "name": "Conghui He",
                    "hidden": false
                },
                {
                    "_id": "68e5cffd975ac4c405ef2115",
                    "user": {
                        "_id": "643e60d96db6ba8c5ee177ad",
                        "avatarUrl": "/avatars/73ac7740e462ba0b53a2f2480d9f1e3e.svg",
                        "isPro": false,
                        "fullname": "Lijun Wu",
                        "user": "apeters",
                        "type": "user"
                    },
                    "name": "Lijun Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T11:49:05.353Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-05T07:59:24.000Z",
            "submittedOnDailyAt": "2025-10-08T01:17:31.925Z",
            "title": "Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model\n  Reasoning",
            "submittedOnDailyBy": {
                "_id": "640d99628512ec51d7ef71c7",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640d99628512ec51d7ef71c7/fcBkqnxfxuuuZTqfN_BGy.jpeg",
                "isPro": false,
                "fullname": "Honglin Lin",
                "user": "LHL3341",
                "type": "user"
            },
            "summary": "Reasoning capability is pivotal for Large Language Models (LLMs) to solve\ncomplex tasks, yet achieving reliable and scalable reasoning remains\nchallenging. While Chain-of-Thought (CoT) prompting has become a mainstream\napproach, existing methods often suffer from uncontrolled generation,\ninsufficient quality, and limited diversity in reasoning paths. Recent efforts\nleverage code to enhance CoT by grounding reasoning in executable steps, but\nsuch methods are typically constrained to predefined mathematical problems,\nhindering scalability and generalizability. In this work, we propose Caco\n(Code-Assisted Chain-of-ThOught), a novel framework that automates the\nsynthesis of high-quality, verifiable, and diverse instruction-CoT reasoning\ndata through code-driven augmentation. Unlike prior work, Caco first fine-tunes\na code-based CoT generator on existing math and programming solutions in a\nunified code format, then scales the data generation to a large amount of\ndiverse reasoning traces. Crucially, we introduce automated validation via code\nexecution and rule-based filtering to ensure logical correctness and structural\ndiversity, followed by reverse-engineering filtered outputs into natural\nlanguage instructions and language CoTs to enrich task adaptability. This\nclosed-loop process enables fully automated, scalable synthesis of reasoning\ndata with guaranteed executability. Experiments on our created Caco-1.3M\ndataset demonstrate that Caco-trained models achieve strong competitive\nperformance on mathematical reasoning benchmarks, outperforming existing strong\nbaselines. Further analysis reveals that Caco's code-anchored verification and\ninstruction diversity contribute to superior generalization across unseen\ntasks. Our work establishes a paradigm for building self-sustaining,\ntrustworthy reasoning systems without human intervention.",
            "upvotes": 18,
            "discussionId": "68e5cffd975ac4c405ef2116",
            "githubRepo": "https://github.com/LHL3341/Caco",
            "ai_summary": "Caco, a code-assisted chain-of-thought framework, automates the generation of high-quality, verifiable, and diverse reasoning data, enhancing the performance of large language models on mathematical reasoning tasks.",
            "ai_keywords": [
                "Chain-of-Thought",
                "CoT prompting",
                "code-based CoT generator",
                "code-driven augmentation",
                "automated validation",
                "code execution",
                "rule-based filtering",
                "reverse-engineering",
                "natural language instructions",
                "language CoTs",
                "Caco-1.3M dataset",
                "mathematical reasoning benchmarks",
                "self-sustaining",
                "trustworthy reasoning systems"
            ],
            "githubStars": 6
        },
        "publishedAt": "2025-10-05T03:59:24.000Z",
        "title": "Scaling Code-Assisted Chain-of-Thoughts and Instructions for Model\n  Reasoning",
        "summary": "Reasoning capability is pivotal for Large Language Models (LLMs) to solve\ncomplex tasks, yet achieving reliable and scalable reasoning remains\nchallenging. While Chain-of-Thought (CoT) prompting has become a mainstream\napproach, existing methods often suffer from uncontrolled generation,\ninsufficient quality, and limited diversity in reasoning paths. Recent efforts\nleverage code to enhance CoT by grounding reasoning in executable steps, but\nsuch methods are typically constrained to predefined mathematical problems,\nhindering scalability and generalizability. In this work, we propose Caco\n(Code-Assisted Chain-of-ThOught), a novel framework that automates the\nsynthesis of high-quality, verifiable, and diverse instruction-CoT reasoning\ndata through code-driven augmentation. Unlike prior work, Caco first fine-tunes\na code-based CoT generator on existing math and programming solutions in a\nunified code format, then scales the data generation to a large amount of\ndiverse reasoning traces. Crucially, we introduce automated validation via code\nexecution and rule-based filtering to ensure logical correctness and structural\ndiversity, followed by reverse-engineering filtered outputs into natural\nlanguage instructions and language CoTs to enrich task adaptability. This\nclosed-loop process enables fully automated, scalable synthesis of reasoning\ndata with guaranteed executability. Experiments on our created Caco-1.3M\ndataset demonstrate that Caco-trained models achieve strong competitive\nperformance on mathematical reasoning benchmarks, outperforming existing strong\nbaselines. Further analysis reveals that Caco's code-anchored verification and\ninstruction diversity contribute to superior generalization across unseen\ntasks. Our work establishes a paradigm for building self-sustaining,\ntrustworthy reasoning systems without human intervention.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04081.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "640d99628512ec51d7ef71c7",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640d99628512ec51d7ef71c7/fcBkqnxfxuuuZTqfN_BGy.jpeg",
            "fullname": "Honglin Lin",
            "name": "LHL3341",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06052",
            "authors": [
                {
                    "_id": "68e6066c975ac4c405ef2187",
                    "user": {
                        "_id": "689cb792f522165a63e55e4f",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/689cb792f522165a63e55e4f/LIQv_bkx7rqZLax8CAuyV.jpeg",
                        "isPro": false,
                        "fullname": "Haiquan Lu",
                        "user": "haiquanlu",
                        "type": "user"
                    },
                    "name": "Haiquan Lu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T08:00:55.284Z",
                    "hidden": false
                },
                {
                    "_id": "68e6066c975ac4c405ef2188",
                    "name": "Gongfan Fang",
                    "hidden": false
                },
                {
                    "_id": "68e6066c975ac4c405ef2189",
                    "name": "Xinyin Ma",
                    "hidden": false
                },
                {
                    "_id": "68e6066c975ac4c405ef218a",
                    "name": "Qi Li",
                    "hidden": false
                },
                {
                    "_id": "68e6066c975ac4c405ef218b",
                    "name": "Xinchao Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T15:46:34.000Z",
            "submittedOnDailyAt": "2025-10-08T05:08:08.970Z",
            "title": "MixReasoning: Switching Modes to Think",
            "submittedOnDailyBy": {
                "_id": "640ebdfefdeaae139086f4d8",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640ebdfefdeaae139086f4d8/2N94gbHubplYD8njmUTPf.jpeg",
                "isPro": true,
                "fullname": "Yuanshi",
                "user": "Yuanshi",
                "type": "user"
            },
            "summary": "Reasoning models enhance performance by tackling problems in a step-by-step\nmanner, decomposing them into sub-problems and exploring long chains of thought\nbefore producing an answer. However, applying extended reasoning to every step\nintroduces substantial redundancy, as sub-problems vary widely in difficulty\nand complexity: a small number of pivotal steps are genuinely challenging and\ndecisive for the final answer, while many others only involve straightforward\nrevisions or simple computations. Therefore, a natural idea is to endow\nreasoning models with the ability to adaptively respond to this variation,\nrather than treating all steps with the same level of elaboration. To this end,\nwe propose MixReasoning, a framework that dynamically adjusts the depth of\nreasoning within a single response. The resulting chain of thought then becomes\na mixture of detailed reasoning on difficult steps and concise inference on\nsimpler ones. Experiments on GSM8K, MATH-500, and AIME show that MixReasoning\nshortens reasoning length and substantially improves efficiency without\ncompromising accuracy.",
            "upvotes": 16,
            "discussionId": "68e6066c975ac4c405ef218c",
            "ai_summary": "MixReasoning dynamically adjusts reasoning depth in models to improve efficiency without sacrificing accuracy.",
            "ai_keywords": [
                "reasoning models",
                "step-by-step",
                "sub-problems",
                "long chains of thought",
                "adaptive response",
                "dynamic adjustment",
                "depth of reasoning",
                "chain of thought",
                "detailed reasoning",
                "concise inference",
                "GSM8K",
                "MATH-500",
                "AIME"
            ],
            "organization": {
                "_id": "6508ab2b349930913196378b",
                "name": "NationalUniversityofSingapore",
                "fullname": "National University of Singapore",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/630ca0817dacb93b33506ce7/ZYUmpSMsa5Whihw3me2Bw.png"
            }
        },
        "publishedAt": "2025-10-07T11:46:34.000Z",
        "title": "MixReasoning: Switching Modes to Think",
        "summary": "Reasoning models enhance performance by tackling problems in a step-by-step\nmanner, decomposing them into sub-problems and exploring long chains of thought\nbefore producing an answer. However, applying extended reasoning to every step\nintroduces substantial redundancy, as sub-problems vary widely in difficulty\nand complexity: a small number of pivotal steps are genuinely challenging and\ndecisive for the final answer, while many others only involve straightforward\nrevisions or simple computations. Therefore, a natural idea is to endow\nreasoning models with the ability to adaptively respond to this variation,\nrather than treating all steps with the same level of elaboration. To this end,\nwe propose MixReasoning, a framework that dynamically adjusts the depth of\nreasoning within a single response. The resulting chain of thought then becomes\na mixture of detailed reasoning on difficult steps and concise inference on\nsimpler ones. Experiments on GSM8K, MATH-500, and AIME show that MixReasoning\nshortens reasoning length and substantially improves efficiency without\ncompromising accuracy.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06052.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "640ebdfefdeaae139086f4d8",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/640ebdfefdeaae139086f4d8/2N94gbHubplYD8njmUTPf.jpeg",
            "fullname": "Yuanshi",
            "name": "Yuanshi",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 160
        },
        "organization": {
            "_id": "6508ab2b349930913196378b",
            "name": "NationalUniversityofSingapore",
            "fullname": "National University of Singapore",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/630ca0817dacb93b33506ce7/ZYUmpSMsa5Whihw3me2Bw.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06062",
            "authors": [
                {
                    "_id": "68e5e643975ac4c405ef213b",
                    "name": "Jiakang Wang",
                    "hidden": false
                },
                {
                    "_id": "68e5e643975ac4c405ef213c",
                    "user": {
                        "_id": "667187ba9ab144eb3ac43a1b",
                        "avatarUrl": "/avatars/db5558aa1c5160b9aee8b58573271959.svg",
                        "isPro": false,
                        "fullname": "Runze Liu",
                        "user": "RyanLiu112",
                        "type": "user"
                    },
                    "name": "Runze Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T05:49:12.082Z",
                    "hidden": false
                },
                {
                    "_id": "68e5e643975ac4c405ef213d",
                    "name": "Lei Lin",
                    "hidden": false
                },
                {
                    "_id": "68e5e643975ac4c405ef213e",
                    "name": "Wenping Hu",
                    "hidden": false
                },
                {
                    "_id": "68e5e643975ac4c405ef213f",
                    "name": "Xiu Li",
                    "hidden": false
                },
                {
                    "_id": "68e5e643975ac4c405ef2140",
                    "name": "Fuzheng Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e5e643975ac4c405ef2141",
                    "name": "Guorui Zhou",
                    "hidden": false
                },
                {
                    "_id": "68e5e643975ac4c405ef2142",
                    "name": "Kun Gai",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T15:54:24.000Z",
            "submittedOnDailyAt": "2025-10-08T02:51:52.415Z",
            "title": "ASPO: Asymmetric Importance Sampling Policy Optimization",
            "submittedOnDailyBy": {
                "_id": "667187ba9ab144eb3ac43a1b",
                "avatarUrl": "/avatars/db5558aa1c5160b9aee8b58573271959.svg",
                "isPro": false,
                "fullname": "Runze Liu",
                "user": "RyanLiu112",
                "type": "user"
            },
            "summary": "Recent Large Language Model (LLM) post-training methods rely on token-level\nclipping mechanisms during Reinforcement Learning (RL). However, we identify a\nfundamental flaw in this Outcome-Supervised RL (OSRL) paradigm: the Importance\nSampling (IS) ratios of positive-advantage tokens are mismatched, leading to\nunbalanced token weighting for positive and negative tokens. This mismatch\nsuppresses the update of low-probability tokens while over-amplifying already\nhigh-probability ones. To address this, we propose Asymmetric Importance\nSampling Policy Optimization (ASPO), which uses a simple yet effective strategy\nthat flips the IS ratios of positive-advantage tokens, aligning their update\ndirection with the learning dynamics of negative ones. AIS further incorporates\na soft dual-clipping mechanism to stabilize extreme updates while maintaining\ngradient flow. Comprehensive experiments on coding and mathematical reasoning\nbenchmarks demonstrate that ASPO significantly mitigates premature convergence,\nimproves training stability, and enhances final performance over strong\nGRPO-based baselines. Our analysis provides new insights into the role of\ntoken-level weighting in OSRL and highlights the critical importance of\ncorrecting IS in LLM RL. The code and models of ASPO are available at\nhttps://github.com/wizard-III/Archer2.0.",
            "upvotes": 10,
            "discussionId": "68e5e643975ac4c405ef2143",
            "githubRepo": "https://github.com/wizard-III/Archer2.0",
            "ai_summary": "ASPO addresses the imbalance in token weighting during OSRL by flipping Importance Sampling ratios and incorporating a soft dual-clipping mechanism, improving training stability and performance in LLMs.",
            "ai_keywords": [
                "Outcome-Supervised RL",
                "Importance Sampling",
                "Asymmetric Importance Sampling Policy Optimization",
                "soft dual-clipping mechanism",
                "token-level clipping",
                "low-probability tokens",
                "high-probability tokens",
                "premature convergence",
                "training stability",
                "GRPO-based baselines"
            ],
            "githubStars": 5
        },
        "publishedAt": "2025-10-07T11:54:24.000Z",
        "title": "ASPO: Asymmetric Importance Sampling Policy Optimization",
        "summary": "Recent Large Language Model (LLM) post-training methods rely on token-level\nclipping mechanisms during Reinforcement Learning (RL). However, we identify a\nfundamental flaw in this Outcome-Supervised RL (OSRL) paradigm: the Importance\nSampling (IS) ratios of positive-advantage tokens are mismatched, leading to\nunbalanced token weighting for positive and negative tokens. This mismatch\nsuppresses the update of low-probability tokens while over-amplifying already\nhigh-probability ones. To address this, we propose Asymmetric Importance\nSampling Policy Optimization (ASPO), which uses a simple yet effective strategy\nthat flips the IS ratios of positive-advantage tokens, aligning their update\ndirection with the learning dynamics of negative ones. AIS further incorporates\na soft dual-clipping mechanism to stabilize extreme updates while maintaining\ngradient flow. Comprehensive experiments on coding and mathematical reasoning\nbenchmarks demonstrate that ASPO significantly mitigates premature convergence,\nimproves training stability, and enhances final performance over strong\nGRPO-based baselines. Our analysis provides new insights into the role of\ntoken-level weighting in OSRL and highlights the critical importance of\ncorrecting IS in LLM RL. The code and models of ASPO are available at\nhttps://github.com/wizard-III/Archer2.0.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06062.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "667187ba9ab144eb3ac43a1b",
            "avatarUrl": "/avatars/db5558aa1c5160b9aee8b58573271959.svg",
            "fullname": "Runze Liu",
            "name": "RyanLiu112",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05571",
            "authors": [
                {
                    "_id": "68e5cce3975ac4c405ef20fd",
                    "name": "Chengzhi Liu",
                    "hidden": false
                },
                {
                    "_id": "68e5cce3975ac4c405ef20fe",
                    "name": "Yuzhe Yang",
                    "hidden": false
                },
                {
                    "_id": "68e5cce3975ac4c405ef20ff",
                    "name": "Kaiwen Zhou",
                    "hidden": false
                },
                {
                    "_id": "68e5cce3975ac4c405ef2100",
                    "name": "Zhen Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e5cce3975ac4c405ef2101",
                    "name": "Yue Fan",
                    "hidden": false
                },
                {
                    "_id": "68e5cce3975ac4c405ef2102",
                    "name": "Yannan Xie",
                    "hidden": false
                },
                {
                    "_id": "68e5cce3975ac4c405ef2103",
                    "name": "Peng Qi",
                    "hidden": false
                },
                {
                    "_id": "68e5cce3975ac4c405ef2104",
                    "name": "Xin Eric Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T04:24:26.000Z",
            "submittedOnDailyAt": "2025-10-08T11:19:37.991Z",
            "title": "Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for\n  Academic Presentations",
            "submittedOnDailyBy": {
                "_id": "64679a226192d39142245e5e",
                "avatarUrl": "/avatars/05abee0b6317f100923936ca2099e9eb.svg",
                "isPro": false,
                "fullname": "Xin Eric Wang",
                "user": "xw-eric",
                "type": "user"
            },
            "summary": "The promotion of academic papers has become an important means of enhancing\nresearch visibility. However, existing automated methods struggle limited\nstorytelling, insufficient aesthetic quality, and constrained self-adjustment,\nmaking it difficult to achieve efficient and engaging dissemination. At the\nheart of those challenges is a simple principle: there is no way to\nimprove it when you cannot evaluate it right. To address this, we introduce\nEvoPresent, a self-improvement agent framework that unifies coherent\nnarratives, aesthetic-aware designs, and realistic presentation delivery via\nvirtual characters. Central to EvoPresent is PresAesth, a multi-task\nreinforcement learning (RL) aesthetic model that provides reliable aesthetic\nscoring, defect adjustment, and comparative feedback, enabling iterative\nself-improvement even under limited aesthetic training data. To systematically\nevaluate the methods, we introduce EvoPresent Benchmark, a\ncomprehensive benchmark comprising: Presentation Generation Quality,\nbuilt on 650 top-tier AI conference papers with multimodal resources (slides,\nvideos and scripts) to assess both content and design; and Aesthetic\nAwareness, consisting of 2,000 slide pairs with varying aesthetic levels,\nsupporting joint training and evaluation on scoring, defect adjustment, and\ncomparison. Our findings highlight that (i) High-quality feedback is essential\nfor agent self-improvement, while initial capability alone does not guarantee\neffective self-correction. (ii) Automated generation pipelines exhibit a\ntrade-off between visual design and content construction. (iii) Multi-task RL\ntraining shows stronger generalization in aesthetic awareness tasks.",
            "upvotes": 10,
            "discussionId": "68e5cce3975ac4c405ef2105",
            "projectPage": "https://evopresent.github.io/#demo",
            "ai_summary": "EvoPresent, a self-improvement agent framework using multi-task reinforcement learning, enhances academic paper promotion by generating coherent narratives, aesthetically pleasing designs, and realistic presentations, supported by a comprehensive benchmark.",
            "ai_keywords": [
                "self-improvement agent framework",
                "PresAesth",
                "multi-task reinforcement learning",
                "aesthetic model",
                "aesthetic scoring",
                "defect adjustment",
                "comparative feedback",
                "EvoPresent Benchmark",
                "Presentation Generation Quality",
                "Aesthetic Awareness"
            ],
            "organization": {
                "_id": "65861edfe3f7a2dcf04230f8",
                "name": "ucsbnlp",
                "fullname": "UC Santa Barbara NLP Group",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6002c1db698168af3bb9f4a5/WQYUIGXIycUiVr_J5X2n0.jpeg"
            }
        },
        "publishedAt": "2025-10-07T00:24:26.000Z",
        "title": "Presenting a Paper is an Art: Self-Improvement Aesthetic Agents for\n  Academic Presentations",
        "summary": "The promotion of academic papers has become an important means of enhancing\nresearch visibility. However, existing automated methods struggle limited\nstorytelling, insufficient aesthetic quality, and constrained self-adjustment,\nmaking it difficult to achieve efficient and engaging dissemination. At the\nheart of those challenges is a simple principle: there is no way to\nimprove it when you cannot evaluate it right. To address this, we introduce\nEvoPresent, a self-improvement agent framework that unifies coherent\nnarratives, aesthetic-aware designs, and realistic presentation delivery via\nvirtual characters. Central to EvoPresent is PresAesth, a multi-task\nreinforcement learning (RL) aesthetic model that provides reliable aesthetic\nscoring, defect adjustment, and comparative feedback, enabling iterative\nself-improvement even under limited aesthetic training data. To systematically\nevaluate the methods, we introduce EvoPresent Benchmark, a\ncomprehensive benchmark comprising: Presentation Generation Quality,\nbuilt on 650 top-tier AI conference papers with multimodal resources (slides,\nvideos and scripts) to assess both content and design; and Aesthetic\nAwareness, consisting of 2,000 slide pairs with varying aesthetic levels,\nsupporting joint training and evaluation on scoring, defect adjustment, and\ncomparison. Our findings highlight that (i) High-quality feedback is essential\nfor agent self-improvement, while initial capability alone does not guarantee\neffective self-correction. (ii) Automated generation pipelines exhibit a\ntrade-off between visual design and content construction. (iii) Multi-task RL\ntraining shows stronger generalization in aesthetic awareness tasks.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05571.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64679a226192d39142245e5e",
            "avatarUrl": "/avatars/05abee0b6317f100923936ca2099e9eb.svg",
            "fullname": "Xin Eric Wang",
            "name": "xw-eric",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 5
        },
        "organization": {
            "_id": "65861edfe3f7a2dcf04230f8",
            "name": "ucsbnlp",
            "fullname": "UC Santa Barbara NLP Group",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6002c1db698168af3bb9f4a5/WQYUIGXIycUiVr_J5X2n0.jpeg"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2509.23379",
            "authors": [
                {
                    "_id": "68dbdbea4159d1f2418f975b",
                    "user": {
                        "_id": "652ebdcc76365388909b06cf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/652ebdcc76365388909b06cf/MnIVVuTphX8buEER9EkCY.jpeg",
                        "isPro": false,
                        "fullname": "Xi Zhang",
                        "user": "X-iZhang",
                        "type": "user"
                    },
                    "name": "Xi Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-01T10:24:22.580Z",
                    "hidden": false
                },
                {
                    "_id": "68dbdbea4159d1f2418f975c",
                    "name": "Zaiqiao Meng",
                    "hidden": false
                },
                {
                    "_id": "68dbdbea4159d1f2418f975d",
                    "name": "Jake Lever",
                    "hidden": false
                },
                {
                    "_id": "68dbdbea4159d1f2418f975e",
                    "name": "Edmond S. L. Ho",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-27T16:01:09.000Z",
            "submittedOnDailyAt": "2025-10-08T09:58:55.759Z",
            "title": "CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical\n  Contrastive Decoding",
            "submittedOnDailyBy": {
                "_id": "652ebdcc76365388909b06cf",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/652ebdcc76365388909b06cf/MnIVVuTphX8buEER9EkCY.jpeg",
                "isPro": false,
                "fullname": "Xi Zhang",
                "user": "X-iZhang",
                "type": "user"
            },
            "summary": "Multimodal large language models (MLLMs) have recently achieved remarkable\nprogress in radiology by integrating visual perception with natural language\nunderstanding. However, they often generate clinically unsupported\ndescriptions, known as medical hallucinations, which pose serious risks in\nmedical applications that demand accuracy and image-grounded outputs. Through\nempirical analysis, we find that prompt-induced hallucinations remain prevalent\nin radiology MLLMs, largely due to over-sensitivity to clinical sections. To\naddress this, we introduce Clinical Contrastive Cecoding (CCD), a training-free\nand retrieval-free inference framework that integrates structured clinical\nsignals from task-specific radiology expert models. CCD introduces a dual-stage\ncontrastive mechanism to refine token-level logits during generation, thereby\nenhancing clinical fidelity without modifying the base MLLM. Experiments on\nthree datasets and multiple models demonstrate that CCD consistently improves\noverall performance on radiology report generation (RRG). On the MIMIC-CXR\ndataset, it yields up to a 17% improvement in RadGraph-F1 when applied to\nstate-of-the-art RRG models. Our approach provides a lightweight and\ngeneralisable solution for mitigating medical hallucinations, effectively\nbridging expert models and MLLMs in radiology.",
            "upvotes": 10,
            "discussionId": "68dbdbeb4159d1f2418f975f",
            "projectPage": "https://x-izhang.github.io/CCD/",
            "githubRepo": "https://github.com/X-iZhang/CCD",
            "ai_summary": "Clinical Contrastive Cecoding (CCD) enhances radiology report generation by integrating structured clinical signals, reducing medical hallucinations without altering the base MLLM.",
            "ai_keywords": [
                "multimodal large language models",
                "MLLMs",
                "radiology",
                "visual perception",
                "natural language understanding",
                "medical hallucinations",
                "prompt-induced hallucinations",
                "clinical sections",
                "Clinical Contrastive Cecoding",
                "CCD",
                "dual-stage contrastive mechanism",
                "token-level logits",
                "radiology report generation",
                "RRG",
                "MIMIC-CXR dataset",
                "RadGraph-F1"
            ],
            "githubStars": 2,
            "organization": {
                "_id": "6669eb42ccb8104854beffab",
                "name": "UniversityofGlasgow",
                "fullname": "University of Glasgow",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/pUhbuhjywJfjTIHdEsiwN.jpeg"
            }
        },
        "publishedAt": "2025-09-27T12:01:09.000Z",
        "title": "CCD: Mitigating Hallucinations in Radiology MLLMs via Clinical\n  Contrastive Decoding",
        "summary": "Multimodal large language models (MLLMs) have recently achieved remarkable\nprogress in radiology by integrating visual perception with natural language\nunderstanding. However, they often generate clinically unsupported\ndescriptions, known as medical hallucinations, which pose serious risks in\nmedical applications that demand accuracy and image-grounded outputs. Through\nempirical analysis, we find that prompt-induced hallucinations remain prevalent\nin radiology MLLMs, largely due to over-sensitivity to clinical sections. To\naddress this, we introduce Clinical Contrastive Cecoding (CCD), a training-free\nand retrieval-free inference framework that integrates structured clinical\nsignals from task-specific radiology expert models. CCD introduces a dual-stage\ncontrastive mechanism to refine token-level logits during generation, thereby\nenhancing clinical fidelity without modifying the base MLLM. Experiments on\nthree datasets and multiple models demonstrate that CCD consistently improves\noverall performance on radiology report generation (RRG). On the MIMIC-CXR\ndataset, it yields up to a 17% improvement in RadGraph-F1 when applied to\nstate-of-the-art RRG models. Our approach provides a lightweight and\ngeneralisable solution for mitigating medical hallucinations, effectively\nbridging expert models and MLLMs in radiology.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.23379.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "652ebdcc76365388909b06cf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/652ebdcc76365388909b06cf/MnIVVuTphX8buEER9EkCY.jpeg",
            "fullname": "Xi Zhang",
            "name": "X-iZhang",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 5
        },
        "organization": {
            "_id": "6669eb42ccb8104854beffab",
            "name": "UniversityofGlasgow",
            "fullname": "University of Glasgow",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/pUhbuhjywJfjTIHdEsiwN.jpeg"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.06208",
            "authors": [
                {
                    "_id": "68e654fc975ac4c405ef2275",
                    "name": "Jiraphon Yenphraphai",
                    "hidden": false
                },
                {
                    "_id": "68e654fc975ac4c405ef2276",
                    "name": "Ashkan Mirzaei",
                    "hidden": false
                },
                {
                    "_id": "68e654fc975ac4c405ef2277",
                    "name": "Jianqi Chen",
                    "hidden": false
                },
                {
                    "_id": "68e654fc975ac4c405ef2278",
                    "name": "Jiaxu Zou",
                    "hidden": false
                },
                {
                    "_id": "68e654fc975ac4c405ef2279",
                    "name": "Sergey Tulyakov",
                    "hidden": false
                },
                {
                    "_id": "68e654fc975ac4c405ef227a",
                    "name": "Raymond A. Yeh",
                    "hidden": false
                },
                {
                    "_id": "68e654fc975ac4c405ef227b",
                    "name": "Peter Wonka",
                    "hidden": false
                },
                {
                    "_id": "68e654fc975ac4c405ef227c",
                    "name": "Chaoyang Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T17:58:11.000Z",
            "submittedOnDailyAt": "2025-10-08T10:44:28.526Z",
            "title": "ShapeGen4D: Towards High Quality 4D Shape Generation from Videos",
            "submittedOnDailyBy": {
                "_id": "63daa44df03c3d71ef33da2d",
                "avatarUrl": "/avatars/3193967d40b82a7d678b58a8e4d0ec1a.svg",
                "isPro": false,
                "fullname": "Jiraphon Yenphraphai",
                "user": "domejiraphon",
                "type": "user"
            },
            "summary": "Video-conditioned 4D shape generation aims to recover time-varying 3D\ngeometry and view-consistent appearance directly from an input video. In this\nwork, we introduce a native video-to-4D shape generation framework that\nsynthesizes a single dynamic 3D representation end-to-end from the video. Our\nframework introduces three key components based on large-scale pre-trained 3D\nmodels: (i) a temporal attention that conditions generation on all frames while\nproducing a time-indexed dynamic representation; (ii) a time-aware point\nsampling and 4D latent anchoring that promote temporally consistent geometry\nand texture; and (iii) noise sharing across frames to enhance temporal\nstability. Our method accurately captures non-rigid motion, volume changes, and\neven topological transitions without per-frame optimization. Across diverse\nin-the-wild videos, our method improves robustness and perceptual fidelity and\nreduces failure modes compared with the baselines.",
            "upvotes": 9,
            "discussionId": "68e6550e975ac4c405ef227d",
            "projectPage": "https://shapegen4d.github.io/",
            "ai_summary": "A video-to-4D shape generation framework uses temporal attention, time-aware point sampling, and noise sharing to produce dynamic 3D representations from videos, enhancing temporal stability and perceptual fidelity.",
            "ai_keywords": [
                "temporal attention",
                "time-aware point sampling",
                "4D latent anchoring",
                "noise sharing",
                "non-rigid motion",
                "volume changes",
                "topological transitions",
                "dynamic 3D representation"
            ]
        },
        "publishedAt": "2025-10-07T13:58:11.000Z",
        "title": "ShapeGen4D: Towards High Quality 4D Shape Generation from Videos",
        "summary": "Video-conditioned 4D shape generation aims to recover time-varying 3D\ngeometry and view-consistent appearance directly from an input video. In this\nwork, we introduce a native video-to-4D shape generation framework that\nsynthesizes a single dynamic 3D representation end-to-end from the video. Our\nframework introduces three key components based on large-scale pre-trained 3D\nmodels: (i) a temporal attention that conditions generation on all frames while\nproducing a time-indexed dynamic representation; (ii) a time-aware point\nsampling and 4D latent anchoring that promote temporally consistent geometry\nand texture; and (iii) noise sharing across frames to enhance temporal\nstability. Our method accurately captures non-rigid motion, volume changes, and\neven topological transitions without per-frame optimization. Across diverse\nin-the-wild videos, our method improves robustness and perceptual fidelity and\nreduces failure modes compared with the baselines.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06208.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63daa44df03c3d71ef33da2d",
            "avatarUrl": "/avatars/3193967d40b82a7d678b58a8e4d0ec1a.svg",
            "fullname": "Jiraphon Yenphraphai",
            "name": "domejiraphon",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06131",
            "authors": [
                {
                    "_id": "68e5d525975ac4c405ef2118",
                    "name": "Jiawei Mao",
                    "hidden": false
                },
                {
                    "_id": "68e5d525975ac4c405ef2119",
                    "name": "Yuhan Wang",
                    "hidden": false
                },
                {
                    "_id": "68e5d525975ac4c405ef211a",
                    "name": "Lifeng Chen",
                    "hidden": false
                },
                {
                    "_id": "68e5d525975ac4c405ef211b",
                    "name": "Can Zhao",
                    "hidden": false
                },
                {
                    "_id": "68e5d525975ac4c405ef211c",
                    "name": "Yucheng Tang",
                    "hidden": false
                },
                {
                    "_id": "68e5d525975ac4c405ef211d",
                    "name": "Dong Yang",
                    "hidden": false
                },
                {
                    "_id": "68e5d525975ac4c405ef211e",
                    "name": "Liangqiong Qu",
                    "hidden": false
                },
                {
                    "_id": "68e5d525975ac4c405ef211f",
                    "name": "Daguang Xu",
                    "hidden": false
                },
                {
                    "_id": "68e5d525975ac4c405ef2120",
                    "name": "Yuyin Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T17:06:57.000Z",
            "submittedOnDailyAt": "2025-10-08T01:38:57.201Z",
            "title": "Discrete Diffusion Models with MLLMs for Unified Medical Multimodal\n  Generation",
            "submittedOnDailyBy": {
                "_id": "65f261116c60cd168b05433c",
                "avatarUrl": "/avatars/0515bef9df2514707cbd3fc281891e2d.svg",
                "isPro": false,
                "fullname": "Jiawei Mao",
                "user": "JohnWeck",
                "type": "user"
            },
            "summary": "Recent advances in generative medical models are constrained by\nmodality-specific scenarios that hinder the integration of complementary\nevidence from imaging, pathology, and clinical notes. This fragmentation limits\ntheir evolution into foundation models that can learn and reason across the\nfull spectrum of biomedical data. We propose MeDiM, the first medical discrete\ndiffusion model that learns shared distributions across modalities without\nmodality-specific components. MeDiM unifies multiple generative tasks:\ntranslating between images and text, and jointly producing image-report pairs\nacross domains in response to prompts. Built on a discrete diffusion framework,\nMeDiM bridges vision and language representations through a shared\nprobabilistic space. To enable unified and flexible medical generation, we\nemploy a multimodal large language model (MLLM) as the diffusion backbone,\nleveraging its prior knowledge and cross-modal reasoning. Two key designs are\nintroduced: (1) removing the causal attention mask for bidirectional context,\nand (2) injecting continuous timestep embeddings for diffusion awareness.\nExperiments demonstrate high-fidelity medical generation (FID 16.60 on\nMIMIC-CXR and FID 24.19 on PathGen) and accurate report generation (METEOR\n0.2650 and 0.2580). Jointly generated image-report pairs further enhance\ndownstream performance (plus6.43 percent BLEU-1, plus18.57 percent BLEU-2,\nplus31.58 percent BLEU-3, plus4.80 percent METEOR), showing that MeDiM supports\ncoherent and clinically grounded multimodal outputs.",
            "upvotes": 9,
            "discussionId": "68e5d526975ac4c405ef2121",
            "projectPage": "https://github.com/UCSC-VLAA/MeDiM",
            "githubRepo": "https://github.com/UCSC-VLAA/MeDiM",
            "ai_summary": "MeDiM, a medical discrete diffusion model, integrates multimodal biomedical data by learning shared distributions across images, text, and clinical notes, achieving high-fidelity generation and enhanced downstream performance.",
            "ai_keywords": [
                "discrete diffusion model",
                "multimodal large language model",
                "bidirectional context",
                "continuous timestep embeddings",
                "FID",
                "METEOR",
                "BLEU"
            ],
            "githubStars": 8,
            "organization": {
                "_id": "65346047b3852ed1cec0c2f4",
                "name": "UCSC-VLAA",
                "fullname": "UCSC-VLAA",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/645eb61da3c5cd8a16efffff/E7m3g_fFhz32pGsnK0eqX.png"
            }
        },
        "publishedAt": "2025-10-07T13:06:57.000Z",
        "title": "Discrete Diffusion Models with MLLMs for Unified Medical Multimodal\n  Generation",
        "summary": "Recent advances in generative medical models are constrained by\nmodality-specific scenarios that hinder the integration of complementary\nevidence from imaging, pathology, and clinical notes. This fragmentation limits\ntheir evolution into foundation models that can learn and reason across the\nfull spectrum of biomedical data. We propose MeDiM, the first medical discrete\ndiffusion model that learns shared distributions across modalities without\nmodality-specific components. MeDiM unifies multiple generative tasks:\ntranslating between images and text, and jointly producing image-report pairs\nacross domains in response to prompts. Built on a discrete diffusion framework,\nMeDiM bridges vision and language representations through a shared\nprobabilistic space. To enable unified and flexible medical generation, we\nemploy a multimodal large language model (MLLM) as the diffusion backbone,\nleveraging its prior knowledge and cross-modal reasoning. Two key designs are\nintroduced: (1) removing the causal attention mask for bidirectional context,\nand (2) injecting continuous timestep embeddings for diffusion awareness.\nExperiments demonstrate high-fidelity medical generation (FID 16.60 on\nMIMIC-CXR and FID 24.19 on PathGen) and accurate report generation (METEOR\n0.2650 and 0.2580). Jointly generated image-report pairs further enhance\ndownstream performance (plus6.43 percent BLEU-1, plus18.57 percent BLEU-2,\nplus31.58 percent BLEU-3, plus4.80 percent METEOR), showing that MeDiM supports\ncoherent and clinically grounded multimodal outputs.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06131.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65f261116c60cd168b05433c",
            "avatarUrl": "/avatars/0515bef9df2514707cbd3fc281891e2d.svg",
            "fullname": "Jiawei Mao",
            "name": "JohnWeck",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "65346047b3852ed1cec0c2f4",
            "name": "UCSC-VLAA",
            "fullname": "UCSC-VLAA",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/645eb61da3c5cd8a16efffff/E7m3g_fFhz32pGsnK0eqX.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06182",
            "authors": [
                {
                    "_id": "68e5e202975ac4c405ef212c",
                    "user": {
                        "_id": "621febb6c7f47c5eb5df001d",
                        "avatarUrl": "/avatars/6096101dc01f1a7e39b1d0826170412d.svg",
                        "isPro": false,
                        "fullname": "Yoav Gur Arieh",
                        "user": "yoavgur",
                        "type": "user"
                    },
                    "name": "Yoav Gur-Arieh",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T05:49:18.548Z",
                    "hidden": false
                },
                {
                    "_id": "68e5e202975ac4c405ef212d",
                    "name": "Mor Geva",
                    "hidden": false
                },
                {
                    "_id": "68e5e202975ac4c405ef212e",
                    "name": "Atticus Geiger",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/621febb6c7f47c5eb5df001d/30SxKYBuFmFThUoGhgoUr.gif"
            ],
            "publishedAt": "2025-10-07T17:44:30.000Z",
            "submittedOnDailyAt": "2025-10-08T02:37:54.761Z",
            "title": "Mixing Mechanisms: How Language Models Retrieve Bound Entities\n  In-Context",
            "submittedOnDailyBy": {
                "_id": "621febb6c7f47c5eb5df001d",
                "avatarUrl": "/avatars/6096101dc01f1a7e39b1d0826170412d.svg",
                "isPro": false,
                "fullname": "Yoav Gur Arieh",
                "user": "yoavgur",
                "type": "user"
            },
            "summary": "A key component of in-context reasoning is the ability of language models\n(LMs) to bind entities for later retrieval. For example, an LM might represent\n\"Ann loves pie\" by binding \"Ann\" to \"pie\", allowing it to later retrieve \"Ann\"\nwhen asked \"Who loves pie?\" Prior research on short lists of bound entities\nfound strong evidence that LMs implement such retrieval via a positional\nmechanism, where \"Ann\" is retrieved based on its position in context. In this\nwork, we find that this mechanism generalizes poorly to more complex settings;\nas the number of bound entities in context increases, the positional mechanism\nbecomes noisy and unreliable in middle positions. To compensate for this, we\nfind that LMs supplement the positional mechanism with a lexical mechanism\n(retrieving \"Ann\" using its bound counterpart \"pie\") and a reflexive mechanism\n(retrieving \"Ann\" through a direct pointer). Through extensive experiments on\nnine models and ten binding tasks, we uncover a consistent pattern in how LMs\nmix these mechanisms to drive model behavior. We leverage these insights to\ndevelop a causal model combining all three mechanisms that estimates next token\ndistributions with 95% agreement. Finally, we show that our model generalizes\nto substantially longer inputs of open-ended text interleaved with entity\ngroups, further demonstrating the robustness of our findings in more natural\nsettings. Overall, our study establishes a more complete picture of how LMs\nbind and retrieve entities in-context.",
            "upvotes": 8,
            "discussionId": "68e5e202975ac4c405ef212f",
            "projectPage": "https://yoav.ml/blog/2025/mixing-mechs/",
            "githubRepo": "https://github.com/yoavgur/mixing-mechs",
            "ai_summary": "Language models use positional, lexical, and reflexive mechanisms to bind and retrieve entities, with a causal model achieving high accuracy in predicting next tokens across various tasks and input lengths.",
            "ai_keywords": [
                "in-context reasoning",
                "language models",
                "entity binding",
                "positional mechanism",
                "lexical mechanism",
                "reflexive mechanism",
                "causal model",
                "next token distributions"
            ],
            "githubStars": 1,
            "organization": {
                "_id": "6107dfc57602f8e9ed8bb5cb",
                "name": "tau",
                "fullname": "Tel Aviv University",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1628143727824-610b729f9da682cd54ad9adf.png"
            }
        },
        "publishedAt": "2025-10-07T13:44:30.000Z",
        "title": "Mixing Mechanisms: How Language Models Retrieve Bound Entities\n  In-Context",
        "summary": "A key component of in-context reasoning is the ability of language models\n(LMs) to bind entities for later retrieval. For example, an LM might represent\n\"Ann loves pie\" by binding \"Ann\" to \"pie\", allowing it to later retrieve \"Ann\"\nwhen asked \"Who loves pie?\" Prior research on short lists of bound entities\nfound strong evidence that LMs implement such retrieval via a positional\nmechanism, where \"Ann\" is retrieved based on its position in context. In this\nwork, we find that this mechanism generalizes poorly to more complex settings;\nas the number of bound entities in context increases, the positional mechanism\nbecomes noisy and unreliable in middle positions. To compensate for this, we\nfind that LMs supplement the positional mechanism with a lexical mechanism\n(retrieving \"Ann\" using its bound counterpart \"pie\") and a reflexive mechanism\n(retrieving \"Ann\" through a direct pointer). Through extensive experiments on\nnine models and ten binding tasks, we uncover a consistent pattern in how LMs\nmix these mechanisms to drive model behavior. We leverage these insights to\ndevelop a causal model combining all three mechanisms that estimates next token\ndistributions with 95% agreement. Finally, we show that our model generalizes\nto substantially longer inputs of open-ended text interleaved with entity\ngroups, further demonstrating the robustness of our findings in more natural\nsettings. Overall, our study establishes a more complete picture of how LMs\nbind and retrieve entities in-context.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/621febb6c7f47c5eb5df001d/30SxKYBuFmFThUoGhgoUr.gif"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06182.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "621febb6c7f47c5eb5df001d",
            "avatarUrl": "/avatars/6096101dc01f1a7e39b1d0826170412d.svg",
            "fullname": "Yoav Gur Arieh",
            "name": "yoavgur",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "6107dfc57602f8e9ed8bb5cb",
            "name": "tau",
            "fullname": "Tel Aviv University",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1628143727824-610b729f9da682cd54ad9adf.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.03506",
            "authors": [
                {
                    "_id": "68e5625d975ac4c405ef1f40",
                    "user": {
                        "_id": "648a14e002c8497f58ebff62",
                        "avatarUrl": "/avatars/0d30f7bd843ac94f317d8cfc53256450.svg",
                        "isPro": false,
                        "fullname": "John Nguyen",
                        "user": "ngjhn",
                        "type": "user"
                    },
                    "name": "John Nguyen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T08:01:17.940Z",
                    "hidden": false
                },
                {
                    "_id": "68e5625d975ac4c405ef1f41",
                    "name": "Marton Havasi",
                    "hidden": false
                },
                {
                    "_id": "68e5625d975ac4c405ef1f42",
                    "name": "Tariq Berrada",
                    "hidden": false
                },
                {
                    "_id": "68e5625d975ac4c405ef1f43",
                    "name": "Luke Zettlemoyer",
                    "hidden": false
                },
                {
                    "_id": "68e5625d975ac4c405ef1f44",
                    "name": "Ricky T. Q. Chen",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-03T20:40:30.000Z",
            "submittedOnDailyAt": "2025-10-08T08:41:10.014Z",
            "title": "OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit\n  Flows",
            "submittedOnDailyBy": {
                "_id": "5f1158120c833276f61f1a84",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
                "isPro": true,
                "fullname": "Niels Rogge",
                "user": "nielsr",
                "type": "user"
            },
            "summary": "We present OneFlow, the first non-autoregressive multimodal model that\nenables variable-length and concurrent mixed-modal generation. Unlike\nautoregressive models that enforce rigid causal ordering between text and image\ngeneration, OneFlow combines an insertion-based Edit Flow for discrete text\ntokens with Flow Matching for image latents. OneFlow enables concurrent\ntext-image synthesis with hierarchical sampling that prioritizes content over\ngrammar. Through controlled experiments across model sizes from 1B to 8B, we\ndemonstrate that OneFlow outperforms autoregressive baselines on both\ngeneration and understanding tasks while using up to 50% fewer training FLOPs.\nOneFlow surpasses both autoregressive and diffusion-based approaches while\nunlocking new capabilities for concurrent generation, iterative refinement, and\nnatural reasoning-like generation.",
            "upvotes": 8,
            "discussionId": "68e5625d975ac4c405ef1f45",
            "projectPage": "https://johnlnguyen.com/oneflow/",
            "ai_summary": "OneFlow, a non-autoregressive multimodal model, achieves superior performance in text-image generation and understanding tasks with reduced computational cost compared to autoregressive and diffusion-based models.",
            "ai_keywords": [
                "non-autoregressive",
                "multimodal model",
                "variable-length",
                "concurrent mixed-modal generation",
                "insertion-based Edit Flow",
                "discrete text tokens",
                "Flow Matching",
                "image latents",
                "hierarchical sampling",
                "content over grammar",
                "training FLOPs",
                "autoregressive baselines",
                "diffusion-based approaches",
                "iterative refinement",
                "natural reasoning-like generation"
            ],
            "organization": {
                "_id": "5e63d8713071d5be688861b8",
                "name": "facebook",
                "fullname": "AI at Meta",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1592839207516-noauth.png"
            }
        },
        "publishedAt": "2025-10-03T16:40:30.000Z",
        "title": "OneFlow: Concurrent Mixed-Modal and Interleaved Generation with Edit\n  Flows",
        "summary": "We present OneFlow, the first non-autoregressive multimodal model that\nenables variable-length and concurrent mixed-modal generation. Unlike\nautoregressive models that enforce rigid causal ordering between text and image\ngeneration, OneFlow combines an insertion-based Edit Flow for discrete text\ntokens with Flow Matching for image latents. OneFlow enables concurrent\ntext-image synthesis with hierarchical sampling that prioritizes content over\ngrammar. Through controlled experiments across model sizes from 1B to 8B, we\ndemonstrate that OneFlow outperforms autoregressive baselines on both\ngeneration and understanding tasks while using up to 50% fewer training FLOPs.\nOneFlow surpasses both autoregressive and diffusion-based approaches while\nunlocking new capabilities for concurrent generation, iterative refinement, and\nnatural reasoning-like generation.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03506.png",
        "numComments": 4,
        "submittedBy": {
            "_id": "5f1158120c833276f61f1a84",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
            "fullname": "Niels Rogge",
            "name": "nielsr",
            "type": "user",
            "isPro": true,
            "isHf": true,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 990
        },
        "organization": {
            "_id": "5e63d8713071d5be688861b8",
            "name": "facebook",
            "fullname": "AI at Meta",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/1592839207516-noauth.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05485",
            "authors": [
                {
                    "_id": "68e63237975ac4c405ef220b",
                    "user": {
                        "_id": "675197c3ae96d7ba4b4a6c66",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/I2GHgrv70cfT8C5EbK6Q5.png",
                        "isPro": false,
                        "fullname": "Adam Filipek",
                        "user": "AdamF92",
                        "type": "user"
                    },
                    "name": "Adam Filipek",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T11:48:51.316Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T01:02:46.000Z",
            "submittedOnDailyAt": "2025-10-08T08:24:42.448Z",
            "title": "TensorBLEU: Vectorized GPU-based BLEU Score Implementation for\n  Per-Sentence In-Training Evaluation",
            "submittedOnDailyBy": {
                "_id": "675197c3ae96d7ba4b4a6c66",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/I2GHgrv70cfT8C5EbK6Q5.png",
                "isPro": false,
                "fullname": "Adam Filipek",
                "user": "AdamF92",
                "type": "user"
            },
            "summary": "Modern natural language processing models have achieved unprecedented scale,\nyet the tools for their evaluation often remain a computational bottleneck,\nlimiting the pace of research. This is particularly acute for in-training\nevaluation metrics, such as per-sentence reward signals in Reinforcement\nLearning, which must operate efficiently on batches of token IDs directly on\nthe GPU. In this paper, we introduce TensorBLEU, a novel implementation of the\nBLEU metric designed from the ground up for this specific use case. Our\napproach is fully vectorized for GPU-accelerated, per-sentence computation\nwithin PyTorch and introduces a memory-efficient counting mechanism. By\ncreating a compact, batch-specific dictionary of n-grams using\ntorch.unique, our method avoids the prohibitive memory costs of\ntraditional hashing-based vectorization, making it practical for\nlarge-vocabulary models. We benchmark TensorBLEU against NLTK, the standard\nlibrary for token-ID-based BLEU calculation on the CPU. Experiments show that\nTensorBLEU provides speedups of over 13x on consumer-grade GPUs (NVIDIA T4) and\nexceeding 40x on data-center-class hardware (NVIDIA A100). This performance\ntransforms a significant bottleneck into a negligible part of the training\nloop. By clearly defining its role as a \"Token-ID BLEU\" for development\npurposes and open-sourcing our implementation, we provide a powerful tool for\naccelerating research in areas like RL-based model fine-tuning.",
            "upvotes": 7,
            "discussionId": "68e63238975ac4c405ef220c",
            "projectPage": "https://rxai.dev",
            "githubRepo": "https://github.com/RxAI-dev/rxlm/blob/main/python/src/rxlm/metrics/tensorbleu.py",
            "ai_summary": "TensorBLEU is a GPU-accelerated BLEU metric implementation for efficient in-training evaluation of natural language processing models, offering significant speedups over CPU-based methods.",
            "ai_keywords": [
                "TensorBLEU",
                "BLEU metric",
                "GPU-accelerated",
                "per-sentence computation",
                "PyTorch",
                "memory-efficient",
                "n-grams",
                "torch.unique",
                "token-ID BLEU",
                "RL-based model fine-tuning"
            ],
            "githubStars": 13,
            "organization": {
                "_id": "675776b060e4100500aeb4c8",
                "name": "ReactiveAI",
                "fullname": "Reactive AI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/675197c3ae96d7ba4b4a6c66/AJDkLuavcYfENIRDzxjqR.png"
            }
        },
        "publishedAt": "2025-10-06T21:02:46.000Z",
        "title": "TensorBLEU: Vectorized GPU-based BLEU Score Implementation for\n  Per-Sentence In-Training Evaluation",
        "summary": "Modern natural language processing models have achieved unprecedented scale,\nyet the tools for their evaluation often remain a computational bottleneck,\nlimiting the pace of research. This is particularly acute for in-training\nevaluation metrics, such as per-sentence reward signals in Reinforcement\nLearning, which must operate efficiently on batches of token IDs directly on\nthe GPU. In this paper, we introduce TensorBLEU, a novel implementation of the\nBLEU metric designed from the ground up for this specific use case. Our\napproach is fully vectorized for GPU-accelerated, per-sentence computation\nwithin PyTorch and introduces a memory-efficient counting mechanism. By\ncreating a compact, batch-specific dictionary of n-grams using\ntorch.unique, our method avoids the prohibitive memory costs of\ntraditional hashing-based vectorization, making it practical for\nlarge-vocabulary models. We benchmark TensorBLEU against NLTK, the standard\nlibrary for token-ID-based BLEU calculation on the CPU. Experiments show that\nTensorBLEU provides speedups of over 13x on consumer-grade GPUs (NVIDIA T4) and\nexceeding 40x on data-center-class hardware (NVIDIA A100). This performance\ntransforms a significant bottleneck into a negligible part of the training\nloop. By clearly defining its role as a \"Token-ID BLEU\" for development\npurposes and open-sourcing our implementation, we provide a powerful tool for\naccelerating research in areas like RL-based model fine-tuning.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05485.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "675197c3ae96d7ba4b4a6c66",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/I2GHgrv70cfT8C5EbK6Q5.png",
            "fullname": "Adam Filipek",
            "name": "AdamF92",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 47
        },
        "organization": {
            "_id": "675776b060e4100500aeb4c8",
            "name": "ReactiveAI",
            "fullname": "Reactive AI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/675197c3ae96d7ba4b4a6c66/AJDkLuavcYfENIRDzxjqR.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04506",
            "authors": [
                {
                    "_id": "68e68dbc975ac4c405ef23a0",
                    "name": "Jiashuo Sun",
                    "hidden": false
                },
                {
                    "_id": "68e68dbc975ac4c405ef23a1",
                    "name": "Shixuan Liu",
                    "hidden": false
                },
                {
                    "_id": "68e68dbc975ac4c405ef23a2",
                    "name": "Zhaochen Su",
                    "hidden": false
                },
                {
                    "_id": "68e68dbc975ac4c405ef23a3",
                    "name": "Xianrui Zhong",
                    "hidden": false
                },
                {
                    "_id": "68e68dbc975ac4c405ef23a4",
                    "name": "Pengcheng Jiang",
                    "hidden": false
                },
                {
                    "_id": "68e68dbc975ac4c405ef23a5",
                    "name": "Bowen Jin",
                    "hidden": false
                },
                {
                    "_id": "68e68dbc975ac4c405ef23a6",
                    "name": "Peiran Li",
                    "hidden": false
                },
                {
                    "_id": "68e68dbc975ac4c405ef23a7",
                    "name": "Weijia Shi",
                    "hidden": false
                },
                {
                    "_id": "68e68dbc975ac4c405ef23a8",
                    "name": "Jiawei Han",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T05:46:56.000Z",
            "submittedOnDailyAt": "2025-10-08T14:46:12.876Z",
            "title": "GRACE: Generative Representation Learning via Contrastive Policy\n  Optimization",
            "submittedOnDailyBy": {
                "_id": "64527f701a57e1179c1c3693",
                "avatarUrl": "/avatars/25b2632d7aa9ce26d5d4924ecb00c4f4.svg",
                "isPro": false,
                "fullname": "Jiashuo Sun",
                "user": "gasolsun",
                "type": "user"
            },
            "summary": "Prevailing methods for training Large Language Models (LLMs) as text encoders\nrely on contrastive losses that treat the model as a black box function,\ndiscarding its generative and reasoning capabilities in favor of static\nembeddings. We introduce GRACE (Generative Representation Learning via\nContrastive Policy Optimization), a novel framework that reimagines contrastive\nsignals not as losses to be minimized, but as rewards that guide a generative\npolicy. In GRACE, the LLM acts as a policy that produces explicit,\nhuman-interpretable rationales--structured natural language explanations of its\nsemantic understanding. These rationales are then encoded into high-quality\nembeddings via mean pooling. Using policy gradient optimization, we train the\nmodel with a multi-component reward function that maximizes similarity between\nquery positive pairs and minimizes similarity with negatives. This transforms\nthe LLM from an opaque encoder into an interpretable agent whose reasoning\nprocess is transparent and inspectable. On MTEB benchmark, GRACE yields broad\ncross category gains: averaged over four backbones, the supervised setting\nimproves overall score by 11.5% over base models, and the unsupervised variant\nadds 6.9%, while preserving general capabilities. This work treats contrastive\nobjectives as rewards over rationales, unifying representation learning with\ngeneration to produce stronger embeddings and transparent rationales. The\nmodel, data and code are available at https://github.com/GasolSun36/GRACE.",
            "upvotes": 7,
            "discussionId": "68e68dbd975ac4c405ef23a9",
            "ai_summary": "GRACE uses contrastive policy optimization to train LLMs as generative agents that produce interpretable rationales, improving embeddings and transparency.",
            "ai_keywords": [
                "contrastive losses",
                "generative representation learning",
                "contrastive policy optimization",
                "generative policy",
                "human-interpretable rationales",
                "mean pooling",
                "policy gradient optimization",
                "multi-component reward function",
                "MTEB benchmark",
                "supervised setting",
                "unsupervised variant",
                "representation learning",
                "generation"
            ],
            "organization": {
                "_id": "65448bef5b5d9185ba3202b9",
                "name": "UIUC-CS",
                "fullname": "University of Illinois at Urbana-Champaign",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/65448b21fcb96b8b48733729/ycqcXFayMTTD_KpE37067.jpeg"
            }
        },
        "publishedAt": "2025-10-06T01:46:56.000Z",
        "title": "GRACE: Generative Representation Learning via Contrastive Policy\n  Optimization",
        "summary": "Prevailing methods for training Large Language Models (LLMs) as text encoders\nrely on contrastive losses that treat the model as a black box function,\ndiscarding its generative and reasoning capabilities in favor of static\nembeddings. We introduce GRACE (Generative Representation Learning via\nContrastive Policy Optimization), a novel framework that reimagines contrastive\nsignals not as losses to be minimized, but as rewards that guide a generative\npolicy. In GRACE, the LLM acts as a policy that produces explicit,\nhuman-interpretable rationales--structured natural language explanations of its\nsemantic understanding. These rationales are then encoded into high-quality\nembeddings via mean pooling. Using policy gradient optimization, we train the\nmodel with a multi-component reward function that maximizes similarity between\nquery positive pairs and minimizes similarity with negatives. This transforms\nthe LLM from an opaque encoder into an interpretable agent whose reasoning\nprocess is transparent and inspectable. On MTEB benchmark, GRACE yields broad\ncross category gains: averaged over four backbones, the supervised setting\nimproves overall score by 11.5% over base models, and the unsupervised variant\nadds 6.9%, while preserving general capabilities. This work treats contrastive\nobjectives as rewards over rationales, unifying representation learning with\ngeneration to produce stronger embeddings and transparent rationales. The\nmodel, data and code are available at https://github.com/GasolSun36/GRACE.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04506.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "64527f701a57e1179c1c3693",
            "avatarUrl": "/avatars/25b2632d7aa9ce26d5d4924ecb00c4f4.svg",
            "fullname": "Jiashuo Sun",
            "name": "gasolsun",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "organization": {
            "_id": "65448bef5b5d9185ba3202b9",
            "name": "UIUC-CS",
            "fullname": "University of Illinois at Urbana-Champaign",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/65448b21fcb96b8b48733729/ycqcXFayMTTD_KpE37067.jpeg"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05560",
            "authors": [
                {
                    "_id": "68e5ca4e975ac4c405ef20e9",
                    "name": "Hongchi Xia",
                    "hidden": false
                },
                {
                    "_id": "68e5ca4e975ac4c405ef20ea",
                    "name": "Chih-Hao Lin",
                    "hidden": false
                },
                {
                    "_id": "68e5ca4e975ac4c405ef20eb",
                    "name": "Hao-Yu Hsu",
                    "hidden": false
                },
                {
                    "_id": "68e5ca4e975ac4c405ef20ec",
                    "name": "Quentin Leboutet",
                    "hidden": false
                },
                {
                    "_id": "68e5ca4e975ac4c405ef20ed",
                    "name": "Katelyn Gao",
                    "hidden": false
                },
                {
                    "_id": "68e5ca4e975ac4c405ef20ee",
                    "name": "Michael Paulitsch",
                    "hidden": false
                },
                {
                    "_id": "68e5ca4e975ac4c405ef20ef",
                    "name": "Benjamin Ummenhofer",
                    "hidden": false
                },
                {
                    "_id": "68e5ca4e975ac4c405ef20f0",
                    "name": "Shenlong Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T04:12:18.000Z",
            "submittedOnDailyAt": "2025-10-08T00:50:15.531Z",
            "title": "HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Digitizing the physical world into accurate simulation-ready virtual\nenvironments offers significant opportunities in a variety of fields such as\naugmented and virtual reality, gaming, and robotics. However, current 3D\nreconstruction and scene-understanding methods commonly fall short in one or\nmore critical aspects, such as geometry completeness, object interactivity,\nphysical plausibility, photorealistic rendering, or realistic physical\nproperties for reliable dynamic simulation. To address these limitations, we\nintroduce HoloScene, a novel interactive 3D reconstruction framework that\nsimultaneously achieves these requirements. HoloScene leverages a comprehensive\ninteractive scene-graph representation, encoding object geometry, appearance,\nand physical properties alongside hierarchical and inter-object relationships.\nReconstruction is formulated as an energy-based optimization problem,\nintegrating observational data, physical constraints, and generative priors\ninto a unified, coherent objective. Optimization is efficiently performed via a\nhybrid approach combining sampling-based exploration with gradient-based\nrefinement. The resulting digital twins exhibit complete and precise geometry,\nphysical stability, and realistic rendering from novel viewpoints. Evaluations\nconducted on multiple benchmark datasets demonstrate superior performance,\nwhile practical use-cases in interactive gaming and real-time digital-twin\nmanipulation illustrate HoloScene's broad applicability and effectiveness.\nProject page: https://xiahongchi.github.io/HoloScene.",
            "upvotes": 6,
            "discussionId": "68e5ca4e975ac4c405ef20f1",
            "projectPage": "https://xiahongchi.github.io/HoloScene/",
            "githubRepo": "https://github.com/xiahongchi/HoloScene",
            "ai_summary": "HoloScene is an interactive 3D reconstruction framework that achieves geometry completeness, object interactivity, physical plausibility, photorealistic rendering, and realistic physical properties through an energy-based optimization problem.",
            "ai_keywords": [
                "interactive 3D reconstruction",
                "scene-graph representation",
                "energy-based optimization",
                "sampling-based exploration",
                "gradient-based refinement",
                "digital twins",
                "geometry completeness",
                "physical stability",
                "photorealistic rendering"
            ],
            "githubStars": 10
        },
        "publishedAt": "2025-10-07T00:12:18.000Z",
        "title": "HoloScene: Simulation-Ready Interactive 3D Worlds from a Single Video",
        "summary": "Digitizing the physical world into accurate simulation-ready virtual\nenvironments offers significant opportunities in a variety of fields such as\naugmented and virtual reality, gaming, and robotics. However, current 3D\nreconstruction and scene-understanding methods commonly fall short in one or\nmore critical aspects, such as geometry completeness, object interactivity,\nphysical plausibility, photorealistic rendering, or realistic physical\nproperties for reliable dynamic simulation. To address these limitations, we\nintroduce HoloScene, a novel interactive 3D reconstruction framework that\nsimultaneously achieves these requirements. HoloScene leverages a comprehensive\ninteractive scene-graph representation, encoding object geometry, appearance,\nand physical properties alongside hierarchical and inter-object relationships.\nReconstruction is formulated as an energy-based optimization problem,\nintegrating observational data, physical constraints, and generative priors\ninto a unified, coherent objective. Optimization is efficiently performed via a\nhybrid approach combining sampling-based exploration with gradient-based\nrefinement. The resulting digital twins exhibit complete and precise geometry,\nphysical stability, and realistic rendering from novel viewpoints. Evaluations\nconducted on multiple benchmark datasets demonstrate superior performance,\nwhile practical use-cases in interactive gaming and real-time digital-twin\nmanipulation illustrate HoloScene's broad applicability and effectiveness.\nProject page: https://xiahongchi.github.io/HoloScene.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05560.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 120
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05432",
            "authors": [
                {
                    "_id": "68e5c1aa975ac4c405ef20a0",
                    "name": "Shambhavi Mishra",
                    "hidden": false
                },
                {
                    "_id": "68e5c1aa975ac4c405ef20a1",
                    "name": "Gaurav Sahu",
                    "hidden": false
                },
                {
                    "_id": "68e5c1aa975ac4c405ef20a2",
                    "name": "Marco Pedersoli",
                    "hidden": false
                },
                {
                    "_id": "68e5c1aa975ac4c405ef20a3",
                    "name": "Laurent Charlin",
                    "hidden": false
                },
                {
                    "_id": "68e5c1aa975ac4c405ef20a4",
                    "name": "Jose Dolz",
                    "hidden": false
                },
                {
                    "_id": "68e5c1aa975ac4c405ef20a5",
                    "name": "Christopher Pal",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T22:50:41.000Z",
            "submittedOnDailyAt": "2025-10-08T00:13:51.660Z",
            "title": "AInstein: Assessing the Feasibility of AI-Generated Approaches to\n  Research Problems",
            "submittedOnDailyBy": {
                "_id": "6377ac12f5fe4a39f783b05d",
                "avatarUrl": "/avatars/5f8b6d999cf48dd4703bbd70236c38c8.svg",
                "isPro": false,
                "fullname": "G Sahu",
                "user": "demfier",
                "type": "user"
            },
            "summary": "Large language models (LLMs) demonstrate impressive capabilities across a\nwide range of tasks, yet it remains unclear whether such success reflects\ngenuine reasoning or sophisticated recall. We introduce AInstein, a framework\nfor testing whether LLMs can generate valid solutions to AI research problems\nusing only their pretrained parametric knowledge -- without domain-specific\nfine-tuning, retrieval augmentation, or other external aids. Our approach\nextracts distilled problem statements from high-quality ICLR 2025 submissions,\nthen tasks specialized solver agents with proposing and refining technical\nsolutions through iterative critique loops, mimicking the cycles of proposal,\nreview, and revision central to scientific inquiry. We evaluate AInstein on\n1,214 ICLR papers stratified by acceptance tier (Oral, Spotlight, Poster),\nusing an LLM-as-a-judge paradigm guided by a structured rubric, complemented by\ntargeted manual checks. Performance is assessed with three metrics: Success\nRate (does the solution address the problem?), Rediscovery (does it align with\nhuman-proposed methods?), and Novelty (does it yield valid, original\napproaches?). Our results reveal that while LLMs can rediscover feasible\nsolutions and occasionally propose creative alternatives, their problem-solving\nability remains fragile and highly sensitive to framing. These findings provide\nthe first large-scale evidence on the extent to which LLMs can act as\nautonomous scientific problem-solvers, highlighting both their latent potential\nand their current limitations.",
            "upvotes": 6,
            "discussionId": "68e5c1aa975ac4c405ef20a6",
            "ai_summary": "AInstein evaluates the problem-solving capabilities of large language models by testing their ability to generate valid solutions to AI research problems using only pretrained knowledge, revealing both their potential and limitations.",
            "ai_keywords": [
                "large language models",
                "LLMs",
                "AInstein",
                "pretrained parametric knowledge",
                "domain-specific fine-tuning",
                "retrieval augmentation",
                "ICLR 2025 submissions",
                "solver agents",
                "iterative critique loops",
                "scientific inquiry",
                "LLM-as-a-judge",
                "structured rubric",
                "targeted manual checks",
                "Success Rate",
                "Rediscovery",
                "Novelty"
            ]
        },
        "publishedAt": "2025-10-06T18:50:41.000Z",
        "title": "AInstein: Assessing the Feasibility of AI-Generated Approaches to\n  Research Problems",
        "summary": "Large language models (LLMs) demonstrate impressive capabilities across a\nwide range of tasks, yet it remains unclear whether such success reflects\ngenuine reasoning or sophisticated recall. We introduce AInstein, a framework\nfor testing whether LLMs can generate valid solutions to AI research problems\nusing only their pretrained parametric knowledge -- without domain-specific\nfine-tuning, retrieval augmentation, or other external aids. Our approach\nextracts distilled problem statements from high-quality ICLR 2025 submissions,\nthen tasks specialized solver agents with proposing and refining technical\nsolutions through iterative critique loops, mimicking the cycles of proposal,\nreview, and revision central to scientific inquiry. We evaluate AInstein on\n1,214 ICLR papers stratified by acceptance tier (Oral, Spotlight, Poster),\nusing an LLM-as-a-judge paradigm guided by a structured rubric, complemented by\ntargeted manual checks. Performance is assessed with three metrics: Success\nRate (does the solution address the problem?), Rediscovery (does it align with\nhuman-proposed methods?), and Novelty (does it yield valid, original\napproaches?). Our results reveal that while LLMs can rediscover feasible\nsolutions and occasionally propose creative alternatives, their problem-solving\nability remains fragile and highly sensitive to framing. These findings provide\nthe first large-scale evidence on the extent to which LLMs can act as\nautonomous scientific problem-solvers, highlighting both their latent potential\nand their current limitations.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05432.png",
        "numComments": 4,
        "submittedBy": {
            "_id": "6377ac12f5fe4a39f783b05d",
            "avatarUrl": "/avatars/5f8b6d999cf48dd4703bbd70236c38c8.svg",
            "fullname": "G Sahu",
            "name": "demfier",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06036",
            "authors": [
                {
                    "_id": "68e5ee60975ac4c405ef2167",
                    "name": "Qingyu Yin",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef2168",
                    "name": "Chak Tou Leong",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef2169",
                    "user": {
                        "_id": "64895683f534abe18eec264b",
                        "avatarUrl": "/avatars/73cc9e6db6db86793787750776b57c63.svg",
                        "isPro": false,
                        "fullname": "Linyi Yang",
                        "user": "linyiyang2023",
                        "type": "user"
                    },
                    "name": "Linyi Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T05:49:08.431Z",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef216a",
                    "name": "Wenxuan Huang",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef216b",
                    "name": "Wenjie Li",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef216c",
                    "name": "Xiting Wang",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef216d",
                    "name": "Jaehong Yoon",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef216e",
                    "name": "YunXing",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef216f",
                    "name": "XingYu",
                    "hidden": false
                },
                {
                    "_id": "68e5ee60975ac4c405ef2170",
                    "name": "Jinjin Gu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T15:32:59.000Z",
            "submittedOnDailyAt": "2025-10-08T03:24:37.923Z",
            "title": "Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?",
            "submittedOnDailyBy": {
                "_id": "6453cb22908e259483c0a061",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6453cb22908e259483c0a061/hMgdwZUsUbgquGalzPGzV.jpeg",
                "isPro": false,
                "fullname": "Qingyu_Yin",
                "user": "MikaStars39",
                "type": "user"
            },
            "summary": "Large reasoning models (LRMs) with multi-step reasoning capabilities have\nshown remarkable problem-solving abilities, yet they exhibit concerning safety\nvulnerabilities that remain poorly understood. In this work, we investigate why\nsafety alignment fails in reasoning models through a mechanistic\ninterpretability lens. Using a linear probing approach to trace refusal\nintentions across token positions, we discover a striking phenomenon termed as\nrefusal cliff: many poorly-aligned reasoning models correctly identify\nharmful prompts and maintain strong refusal intentions during their thinking\nprocess, but experience a sharp drop in refusal scores at the final tokens\nbefore output generation. This suggests that these models are not inherently\nunsafe; rather, their refusal intentions are systematically suppressed. Through\ncausal intervention analysis, we identify a sparse set of attention heads that\nnegatively contribute to refusal behavior. Ablating just 3\\% of these heads can\nreduce attack success rates below 10\\%. Building on these mechanistic insights,\nwe propose Cliff-as-a-Judge, a novel data selection method that\nidentifies training examples exhibiting the largest refusal cliff to\nefficiently repair reasoning models' safety alignment. This approach achieves\ncomparable safety improvements using only 1.7\\% of the vanilla safety training\ndata, demonstrating a less-is-more effect in safety alignment.",
            "upvotes": 5,
            "discussionId": "68e5ee60975ac4c405ef2171",
            "githubRepo": "https://github.com/MikaStars39/RefusalCliff",
            "ai_summary": "Research identifies a mechanism called the refusal cliff in large reasoning models, where refusal intentions drop sharply before output generation, and proposes a method to improve safety by focusing on specific attention heads and training examples.",
            "ai_keywords": [
                "large reasoning models",
                "multi-step reasoning",
                "safety vulnerabilities",
                "mechanistic interpretability",
                "linear probing",
                "refusal cliff",
                "token positions",
                "refusal intentions",
                "causal intervention analysis",
                "attention heads",
                "Cliff-as-a-Judge",
                "data selection method",
                "safety alignment"
            ],
            "githubStars": 4,
            "organization": {
                "_id": "68246a0a98117c02df67a547",
                "name": "rednote-hilab",
                "fullname": "rednote-hilab",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6807a1d6504547b3554b9c73/WgnnQDsz7FqnyTtv8mmRO.png"
            }
        },
        "publishedAt": "2025-10-07T11:32:59.000Z",
        "title": "Refusal Falls off a Cliff: How Safety Alignment Fails in Reasoning?",
        "summary": "Large reasoning models (LRMs) with multi-step reasoning capabilities have\nshown remarkable problem-solving abilities, yet they exhibit concerning safety\nvulnerabilities that remain poorly understood. In this work, we investigate why\nsafety alignment fails in reasoning models through a mechanistic\ninterpretability lens. Using a linear probing approach to trace refusal\nintentions across token positions, we discover a striking phenomenon termed as\nrefusal cliff: many poorly-aligned reasoning models correctly identify\nharmful prompts and maintain strong refusal intentions during their thinking\nprocess, but experience a sharp drop in refusal scores at the final tokens\nbefore output generation. This suggests that these models are not inherently\nunsafe; rather, their refusal intentions are systematically suppressed. Through\ncausal intervention analysis, we identify a sparse set of attention heads that\nnegatively contribute to refusal behavior. Ablating just 3\\% of these heads can\nreduce attack success rates below 10\\%. Building on these mechanistic insights,\nwe propose Cliff-as-a-Judge, a novel data selection method that\nidentifies training examples exhibiting the largest refusal cliff to\nefficiently repair reasoning models' safety alignment. This approach achieves\ncomparable safety improvements using only 1.7\\% of the vanilla safety training\ndata, demonstrating a less-is-more effect in safety alignment.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06036.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6453cb22908e259483c0a061",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6453cb22908e259483c0a061/hMgdwZUsUbgquGalzPGzV.jpeg",
            "fullname": "Qingyu_Yin",
            "name": "MikaStars39",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 5
        },
        "organization": {
            "_id": "68246a0a98117c02df67a547",
            "name": "rednote-hilab",
            "fullname": "rednote-hilab",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6807a1d6504547b3554b9c73/WgnnQDsz7FqnyTtv8mmRO.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05367",
            "authors": [
                {
                    "_id": "68e5caa3975ac4c405ef20f3",
                    "name": "Yang Xiao",
                    "hidden": false
                },
                {
                    "_id": "68e5caa3975ac4c405ef20f4",
                    "name": "Gen Li",
                    "hidden": false
                },
                {
                    "_id": "68e5caa3975ac4c405ef20f5",
                    "name": "Kaiyuan Deng",
                    "hidden": false
                },
                {
                    "_id": "68e5caa3975ac4c405ef20f6",
                    "name": "Yushu Wu",
                    "hidden": false
                },
                {
                    "_id": "68e5caa3975ac4c405ef20f7",
                    "name": "Zheng Zhan",
                    "hidden": false
                },
                {
                    "_id": "68e5caa3975ac4c405ef20f8",
                    "name": "Yanzhi Wang",
                    "hidden": false
                },
                {
                    "_id": "68e5caa3975ac4c405ef20f9",
                    "name": "Xiaolong Ma",
                    "hidden": false
                },
                {
                    "_id": "68e5caa3975ac4c405ef20fa",
                    "name": "Bo Hui",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T20:54:44.000Z",
            "submittedOnDailyAt": "2025-10-08T00:51:38.299Z",
            "title": "LightCache: Memory-Efficient, Training-Free Acceleration for Video\n  Generation",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Training-free acceleration has emerged as an advanced research area in video\ngeneration based on diffusion models. The redundancy of latents in diffusion\nmodel inference provides a natural entry point for acceleration. In this paper,\nwe decompose the inference process into the encoding, denoising, and decoding\nstages, and observe that cache-based acceleration methods often lead to\nsubstantial memory surges in the latter two stages. To address this problem, we\nanalyze the characteristics of inference across different stages and propose\nstage-specific strategies for reducing memory consumption: 1) Asynchronous\nCache Swapping. 2) Feature chunk. 3) Slicing latents to decode. At the same\ntime, we ensure that the time overhead introduced by these three strategies\nremains lower than the acceleration gains themselves. Compared with the\nbaseline, our approach achieves faster inference speed and lower memory usage,\nwhile maintaining quality degradation within an acceptable range. The Code is\navailable at https://github.com/NKUShaw/LightCache .",
            "upvotes": 5,
            "discussionId": "68e5caa3975ac4c405ef20fb",
            "githubRepo": "https://github.com/NKUShaw/LightCache",
            "ai_summary": "The paper proposes stage-specific strategies to accelerate diffusion model inference in video generation, reducing memory usage and maintaining quality.",
            "ai_keywords": [
                "diffusion models",
                "inference process",
                "encoding",
                "denoising",
                "decoding",
                "cache-based acceleration",
                "memory surges",
                "asynchronous cache swapping",
                "feature chunk",
                "slicing latents"
            ],
            "githubStars": 7
        },
        "publishedAt": "2025-10-06T16:54:44.000Z",
        "title": "LightCache: Memory-Efficient, Training-Free Acceleration for Video\n  Generation",
        "summary": "Training-free acceleration has emerged as an advanced research area in video\ngeneration based on diffusion models. The redundancy of latents in diffusion\nmodel inference provides a natural entry point for acceleration. In this paper,\nwe decompose the inference process into the encoding, denoising, and decoding\nstages, and observe that cache-based acceleration methods often lead to\nsubstantial memory surges in the latter two stages. To address this problem, we\nanalyze the characteristics of inference across different stages and propose\nstage-specific strategies for reducing memory consumption: 1) Asynchronous\nCache Swapping. 2) Feature chunk. 3) Slicing latents to decode. At the same\ntime, we ensure that the time overhead introduced by these three strategies\nremains lower than the acceleration gains themselves. Compared with the\nbaseline, our approach achieves faster inference speed and lower memory usage,\nwhile maintaining quality degradation within an acceptable range. The Code is\navailable at https://github.com/NKUShaw/LightCache .",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05367.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 120
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05342",
            "authors": [
                {
                    "_id": "68e5b6f9975ac4c405ef2003",
                    "user": {
                        "_id": "6642dafed48363a46ddb69ed",
                        "avatarUrl": "/avatars/111fb26ea38fb2e6f8470f7ed513d48d.svg",
                        "isPro": false,
                        "fullname": "hyung gyu rho",
                        "user": "sirano1004",
                        "type": "user"
                    },
                    "name": "Hyung Gyu Rho",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T08:00:52.339Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T20:09:37.000Z",
            "submittedOnDailyAt": "2025-10-08T00:16:22.419Z",
            "title": "Margin Adaptive DPO: Leveraging Reward Model for Granular Control in\n  Preference Optimization",
            "submittedOnDailyBy": {
                "_id": "6642dafed48363a46ddb69ed",
                "avatarUrl": "/avatars/111fb26ea38fb2e6f8470f7ed513d48d.svg",
                "isPro": false,
                "fullname": "hyung gyu rho",
                "user": "sirano1004",
                "type": "user"
            },
            "summary": "Direct Preference Optimization (DPO) has emerged as a simple and effective\nmethod for aligning large language models. However, its reliance on a fixed\ntemperature parameter leads to suboptimal training on diverse preference data,\ncausing overfitting on easy examples and under-learning from informative ones.\nRecent methods have emerged to counter this. While IPO addresses general\noverfitting, its uniform regularization can be overly conservative. The more\ntargeted approach of beta-DPO suffers from its own limitations: its\nbatch-level adaptation applies a single, compromised temperature to\nmixed-margin pairs, its linear update rule can produce unstable negative\nbeta values, and its filtering mechanism discards potentially useful\ntraining signals. In this work, we introduce Margin-Adaptive Direct Preference\nOptimization (MADPO), a method that provides a stable, data-preserving, and\ninstance-level solution. MADPO employs a practical two-step approach: it first\ntrains a reward model to estimate preference margins and then uses these\nmargins to apply a continuous, adaptive weight to the DPO loss for each\nindividual training sample. This re-weighting scheme creates an effective\ntarget margin that is amplified for hard pairs and dampened for easy pairs,\nallowing for granular control over the learning signal. We provide a\ncomprehensive theoretical analysis, proving that MADPO has a well-behaved\noptimization landscape and is robust to reward model estimation errors. We\nvalidate our theory with experiments on a sentiment generation task, where\nMADPO consistently and significantly outperforms strong baselines across\ndatasets of varying quality. It achieves performance gains of up to +33.3\\% on\nHigh Quality data and +10.5\\% on Low Quality data over the next-best method.\nOur results establish MADPO as a more robust and principled approach to\npreference alignment.",
            "upvotes": 5,
            "discussionId": "68e5b6f9975ac4c405ef2004",
            "githubRepo": "https://github.com/sirano1004/\nMargin-Apative-Direct-Preference-Optimization",
            "ai_summary": "MADPO, a margin-adaptive method, enhances preference alignment in large language models by providing instance-level adaptive weighting to the DPO loss, improving performance across datasets.",
            "ai_keywords": [
                "Direct Preference Optimization",
                "DPO",
                "IPO",
                "β-DPO",
                "reward model",
                "preference margins",
                "DPO loss",
                "optimization landscape",
                "reward model estimation errors",
                "sentiment generation task"
            ],
            "githubStars": 0
        },
        "publishedAt": "2025-10-06T16:09:37.000Z",
        "title": "Margin Adaptive DPO: Leveraging Reward Model for Granular Control in\n  Preference Optimization",
        "summary": "Direct Preference Optimization (DPO) has emerged as a simple and effective\nmethod for aligning large language models. However, its reliance on a fixed\ntemperature parameter leads to suboptimal training on diverse preference data,\ncausing overfitting on easy examples and under-learning from informative ones.\nRecent methods have emerged to counter this. While IPO addresses general\noverfitting, its uniform regularization can be overly conservative. The more\ntargeted approach of beta-DPO suffers from its own limitations: its\nbatch-level adaptation applies a single, compromised temperature to\nmixed-margin pairs, its linear update rule can produce unstable negative\nbeta values, and its filtering mechanism discards potentially useful\ntraining signals. In this work, we introduce Margin-Adaptive Direct Preference\nOptimization (MADPO), a method that provides a stable, data-preserving, and\ninstance-level solution. MADPO employs a practical two-step approach: it first\ntrains a reward model to estimate preference margins and then uses these\nmargins to apply a continuous, adaptive weight to the DPO loss for each\nindividual training sample. This re-weighting scheme creates an effective\ntarget margin that is amplified for hard pairs and dampened for easy pairs,\nallowing for granular control over the learning signal. We provide a\ncomprehensive theoretical analysis, proving that MADPO has a well-behaved\noptimization landscape and is robust to reward model estimation errors. We\nvalidate our theory with experiments on a sentiment generation task, where\nMADPO consistently and significantly outperforms strong baselines across\ndatasets of varying quality. It achieves performance gains of up to +33.3\\% on\nHigh Quality data and +10.5\\% on Low Quality data over the next-best method.\nOur results establish MADPO as a more robust and principled approach to\npreference alignment.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05342.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6642dafed48363a46ddb69ed",
            "avatarUrl": "/avatars/111fb26ea38fb2e6f8470f7ed513d48d.svg",
            "fullname": "hyung gyu rho",
            "name": "sirano1004",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05318",
            "authors": [
                {
                    "_id": "68e62536975ac4c405ef21d1",
                    "name": "Nan Huo",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21d2",
                    "name": "Xiaohan Xu",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21d3",
                    "name": "Jinyang Li",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21d4",
                    "name": "Per Jacobsson",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21d5",
                    "name": "Shipei Lin",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21d6",
                    "name": "Bowen Qin",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21d7",
                    "name": "Binyuan Hui",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21d8",
                    "name": "Xiaolong Li",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21d9",
                    "name": "Ge Qu",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21da",
                    "name": "Shuzheng Si",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21db",
                    "name": "Linheng Han",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21dc",
                    "name": "Edward Alexander",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21dd",
                    "name": "Xintong Zhu",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21de",
                    "name": "Rui Qin",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21df",
                    "name": "Ruihan Yu",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e0",
                    "name": "Yiyao Jin",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e1",
                    "name": "Feige Zhou",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e2",
                    "name": "Weihao Zhong",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e3",
                    "name": "Yun Chen",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e4",
                    "name": "Hongyu Liu",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e5",
                    "name": "Chenhao Ma",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e6",
                    "name": "Fatma Ozcan",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e7",
                    "name": "Yannis Papakonstantinou",
                    "hidden": false
                },
                {
                    "_id": "68e62536975ac4c405ef21e8",
                    "name": "Reynold Cheng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T19:31:47.000Z",
            "submittedOnDailyAt": "2025-10-08T07:20:35.605Z",
            "title": "BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language\n  Models via Lens of Dynamic Interactions",
            "submittedOnDailyBy": {
                "_id": "60adfff0306d6873ec42d545",
                "avatarUrl": "/avatars/4a63f90638dbffebfeeee181a6d0220c.svg",
                "isPro": false,
                "fullname": "Nan",
                "user": "NanHUO",
                "type": "user"
            },
            "summary": "Large language models (LLMs) have demonstrated remarkable performance on\nsingle-turn text-to-SQL tasks, but real-world database applications\npredominantly require multi-turn interactions to handle ambiguous queries,\nexecution errors, and evolving user requirements. Existing multi-turn\nbenchmarks fall short by treating conversation histories as static context or\nlimiting evaluation to read-only operations, failing to reflect\nproduction-grade database assistant challenges. We introduce BIRD-INTERACT, a\nbenchmark that restores this realism through: (1) a comprehensive interaction\nenvironment coupling each database with a hierarchical knowledge base, metadata\nfiles, and a function-driven user simulator, enabling models to solicit\nclarifications, retrieve knowledge, and recover from errors without human\nsupervision; (2) two evaluation settings consisting of a pre-defined\nconversational protocol (c-Interact) and an open-ended agentic setting\n(a-Interact) where models autonomously decide when to query the user simulator\nor explore the environment; (3) a challenging task suite covering the full CRUD\nspectrum for business-intelligence and operational use cases, guarded by\nexecutable test cases. Each task features ambiguous and follow-up sub-tasks\nrequiring dynamic interaction. The suite comprises BIRD-INTERACT-FULL (600\ntasks, up to 11,796 interactions) for comprehensive performance assessment, and\nBIRD-INTERACT-LITE (300 tasks with simplified databases) for detailed\nbehavioral analysis and rapid method development. Our empirical results\nhighlight BIRD-INTERACT's difficulty: GPT-5 completes only 8.67% of tasks in\nc-Interact and 17.00% in a-Interact. Analysis via memory grafting and\nInteraction Test-time Scaling validates the importance of effective interaction\nfor complex, dynamic text-to-SQL tasks.",
            "upvotes": 5,
            "discussionId": "68e62536975ac4c405ef21e9",
            "projectPage": "https://bird-interact.github.io/",
            "githubRepo": "https://github.com/bird-bench/BIRD-Interact",
            "ai_summary": "BIRD-INTERACT is a benchmark for multi-turn text-to-SQL tasks that simulates realistic database assistant challenges through dynamic interactions, hierarchical knowledge bases, and autonomous decision-making.",
            "ai_keywords": [
                "large language models",
                "text-to-SQL",
                "multi-turn interactions",
                "conversation histories",
                "hierarchical knowledge base",
                "metadata files",
                "user simulator",
                "CRUD",
                "business-intelligence",
                "operational use cases",
                "memory grafting",
                "Interaction Test-time Scaling"
            ],
            "githubStars": 262,
            "organization": {
                "_id": "678a025d667b3f22b944bb2c",
                "name": "birdsql",
                "fullname": "The BIRD Team",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/653693cb8ee17cfd44eed8ce/0GCwkiHYCtI-W9u1APpBk.jpeg"
            }
        },
        "publishedAt": "2025-10-06T15:31:47.000Z",
        "title": "BIRD-INTERACT: Re-imagining Text-to-SQL Evaluation for Large Language\n  Models via Lens of Dynamic Interactions",
        "summary": "Large language models (LLMs) have demonstrated remarkable performance on\nsingle-turn text-to-SQL tasks, but real-world database applications\npredominantly require multi-turn interactions to handle ambiguous queries,\nexecution errors, and evolving user requirements. Existing multi-turn\nbenchmarks fall short by treating conversation histories as static context or\nlimiting evaluation to read-only operations, failing to reflect\nproduction-grade database assistant challenges. We introduce BIRD-INTERACT, a\nbenchmark that restores this realism through: (1) a comprehensive interaction\nenvironment coupling each database with a hierarchical knowledge base, metadata\nfiles, and a function-driven user simulator, enabling models to solicit\nclarifications, retrieve knowledge, and recover from errors without human\nsupervision; (2) two evaluation settings consisting of a pre-defined\nconversational protocol (c-Interact) and an open-ended agentic setting\n(a-Interact) where models autonomously decide when to query the user simulator\nor explore the environment; (3) a challenging task suite covering the full CRUD\nspectrum for business-intelligence and operational use cases, guarded by\nexecutable test cases. Each task features ambiguous and follow-up sub-tasks\nrequiring dynamic interaction. The suite comprises BIRD-INTERACT-FULL (600\ntasks, up to 11,796 interactions) for comprehensive performance assessment, and\nBIRD-INTERACT-LITE (300 tasks with simplified databases) for detailed\nbehavioral analysis and rapid method development. Our empirical results\nhighlight BIRD-INTERACT's difficulty: GPT-5 completes only 8.67% of tasks in\nc-Interact and 17.00% in a-Interact. Analysis via memory grafting and\nInteraction Test-time Scaling validates the importance of effective interaction\nfor complex, dynamic text-to-SQL tasks.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05318.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60adfff0306d6873ec42d545",
            "avatarUrl": "/avatars/4a63f90638dbffebfeeee181a6d0220c.svg",
            "fullname": "Nan",
            "name": "NanHUO",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "678a025d667b3f22b944bb2c",
            "name": "birdsql",
            "fullname": "The BIRD Team",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/653693cb8ee17cfd44eed8ce/0GCwkiHYCtI-W9u1APpBk.jpeg"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05251",
            "authors": [
                {
                    "_id": "68e692c60d37f65d7721a604",
                    "name": "Chenghao Yang",
                    "hidden": false
                },
                {
                    "_id": "68e692c60d37f65d7721a605",
                    "name": "Lin Gui",
                    "hidden": false
                },
                {
                    "_id": "68e692c60d37f65d7721a606",
                    "name": "Chenxiao Yang",
                    "hidden": false
                },
                {
                    "_id": "68e692c60d37f65d7721a607",
                    "name": "Victor Veitch",
                    "hidden": false
                },
                {
                    "_id": "68e692c60d37f65d7721a608",
                    "name": "Lizhu Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e692c60d37f65d7721a609",
                    "name": "Zhuokai Zhao",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/lznWNTpQexTVF9sCwaWZd.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/U43FtWiVhVDorLVBgVYrZ.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/7zFt5W7TNhHLOI2c5SALF.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/cWBGHwqJOSpNPhovLxdOV.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/9f77EHAsTcWOAaAT2qVHq.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/aXmtZh7oGb2i39cOz_C-D.png",
                "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/FGlGl4TvDqxSHx1W5n8Bf.png"
            ],
            "publishedAt": "2025-10-06T18:15:43.000Z",
            "submittedOnDailyAt": "2025-10-08T15:17:03.496Z",
            "title": "Let it Calm: Exploratory Annealed Decoding for Verifiable Reinforcement\n  Learning",
            "submittedOnDailyBy": {
                "_id": "62fb49bafcce44435d7e079a",
                "avatarUrl": "/avatars/116cb4371206ee7010e161c986b09e85.svg",
                "isPro": false,
                "fullname": "Chenghao Yang",
                "user": "chromeNLP",
                "type": "user"
            },
            "summary": "Reinforcement learning with verifiable rewards (RLVR) is a powerful paradigm\nfor enhancing the reasoning capabilities of large language models (LLMs), yet\nits success hinges on effective exploration. An ideal exploration strategy must\nnavigate two fundamental challenges: it must preserve sample quality while also\nensuring training stability. While standard fixed-temperature sampling is\nsimple, it struggles to balance these competing demands, as high temperatures\ndegrade sample quality and low temperatures limit discovery. In this work, we\npropose a simpler and more effective strategy, Exploratory Annealed Decoding\n(EAD), grounded in the insight that exploration is most impactful on early\ntokens which define a sequence's semantic direction. EAD implements an\nintuitive **explore-at-the-beginning, exploit-at-the-end** strategy by\nannealing the sampling temperature from high to low during generation. This\ndynamic schedule encourages meaningful, high-level diversity at the start, then\ngradually lowers the temperature to preserve sample quality and keep the\nsampling distribution close to the target policy, which is essential for stable\ntraining. We demonstrate that EAD is a lightweight, plug-and-play method that\nsignificantly improves sample efficiency, consistently outperforming\nfixed-temperature sampling across various RLVR algorithms and model sizes. Our\nwork suggests that aligning exploration with the natural dynamics of sequential\ngeneration offers a robust path to improving LLM reasoning.",
            "upvotes": 5,
            "discussionId": "68e692c60d37f65d7721a60a",
            "projectPage": "https://yangalan123.github.io/ead_rlvr/",
            "githubRepo": "https://github.com/yangalan123/EAD-RLVR/tree/annealed_sampling/recipe/ead",
            "ai_summary": "Exploratory Annealed Decoding (EAD) improves sample efficiency in reinforcement learning with verifiable rewards by dynamically adjusting the sampling temperature during generation.",
            "ai_keywords": [
                "reinforcement learning with verifiable rewards",
                "large language models",
                "exploration strategy",
                "sample quality",
                "training stability",
                "fixed-temperature sampling",
                "exploratory annealed decoding",
                "explore-at-the-beginning",
                "exploit-at-the-end",
                "sampling temperature",
                "target policy",
                "sample efficiency",
                "sequential generation"
            ],
            "githubStars": 0
        },
        "publishedAt": "2025-10-06T14:15:43.000Z",
        "title": "Let it Calm: Exploratory Annealed Decoding for Verifiable Reinforcement\n  Learning",
        "summary": "Reinforcement learning with verifiable rewards (RLVR) is a powerful paradigm\nfor enhancing the reasoning capabilities of large language models (LLMs), yet\nits success hinges on effective exploration. An ideal exploration strategy must\nnavigate two fundamental challenges: it must preserve sample quality while also\nensuring training stability. While standard fixed-temperature sampling is\nsimple, it struggles to balance these competing demands, as high temperatures\ndegrade sample quality and low temperatures limit discovery. In this work, we\npropose a simpler and more effective strategy, Exploratory Annealed Decoding\n(EAD), grounded in the insight that exploration is most impactful on early\ntokens which define a sequence's semantic direction. EAD implements an\nintuitive **explore-at-the-beginning, exploit-at-the-end** strategy by\nannealing the sampling temperature from high to low during generation. This\ndynamic schedule encourages meaningful, high-level diversity at the start, then\ngradually lowers the temperature to preserve sample quality and keep the\nsampling distribution close to the target policy, which is essential for stable\ntraining. We demonstrate that EAD is a lightweight, plug-and-play method that\nsignificantly improves sample efficiency, consistently outperforming\nfixed-temperature sampling across various RLVR algorithms and model sizes. Our\nwork suggests that aligning exploration with the natural dynamics of sequential\ngeneration offers a robust path to improving LLM reasoning.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/lznWNTpQexTVF9sCwaWZd.png",
            "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/U43FtWiVhVDorLVBgVYrZ.png",
            "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/7zFt5W7TNhHLOI2c5SALF.png",
            "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/cWBGHwqJOSpNPhovLxdOV.png",
            "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/9f77EHAsTcWOAaAT2qVHq.png",
            "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/aXmtZh7oGb2i39cOz_C-D.png",
            "https://cdn-uploads.huggingface.co/production/uploads/62fb49bafcce44435d7e079a/FGlGl4TvDqxSHx1W5n8Bf.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05251.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "62fb49bafcce44435d7e079a",
            "avatarUrl": "/avatars/116cb4371206ee7010e161c986b09e85.svg",
            "fullname": "Chenghao Yang",
            "name": "chromeNLP",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.02300",
            "authors": [
                {
                    "_id": "68e42cbee4e093a7044e4c40",
                    "name": "Runqian Wang",
                    "hidden": false
                },
                {
                    "_id": "68e42cbee4e093a7044e4c41",
                    "name": "Yilun Du",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-02T17:59:06.000Z",
            "submittedOnDailyAt": "2025-10-08T08:36:50.885Z",
            "title": "Equilibrium Matching: Generative Modeling with Implicit Energy-Based\n  Models",
            "submittedOnDailyBy": {
                "_id": "5f1158120c833276f61f1a84",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
                "isPro": true,
                "fullname": "Niels Rogge",
                "user": "nielsr",
                "type": "user"
            },
            "summary": "We introduce Equilibrium Matching (EqM), a generative modeling framework\nbuilt from an equilibrium dynamics perspective. EqM discards the\nnon-equilibrium, time-conditional dynamics in traditional diffusion and\nflow-based generative models and instead learns the equilibrium gradient of an\nimplicit energy landscape. Through this approach, we can adopt an\noptimization-based sampling process at inference time, where samples are\nobtained by gradient descent on the learned landscape with adjustable step\nsizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation\nperformance of diffusion/flow models empirically, achieving an FID of 1.90 on\nImageNet 256times256. EqM is also theoretically justified to learn and\nsample from the data manifold. Beyond generation, EqM is a flexible framework\nthat naturally handles tasks including partially noised image denoising, OOD\ndetection, and image composition. By replacing time-conditional velocities with\na unified equilibrium landscape, EqM offers a tighter bridge between flow and\nenergy-based models and a simple route to optimization-driven inference.",
            "upvotes": 4,
            "discussionId": "68e42cbee4e093a7044e4c42",
            "projectPage": "https://raywang4.github.io/equilibrium_matching/",
            "githubRepo": "https://github.com/raywang4/EqM",
            "ai_summary": "Equilibrium Matching (EqM) is a generative modeling framework that learns an equilibrium gradient of an implicit energy landscape, enabling efficient sampling and outperforming traditional diffusion and flow models.",
            "ai_keywords": [
                "Equilibrium Matching",
                "EqM",
                "equilibrium dynamics",
                "diffusion models",
                "flow-based generative models",
                "implicit energy landscape",
                "gradient descent",
                "data manifold",
                "partially noised image denoising",
                "OOD detection",
                "image composition",
                "energy-based models"
            ],
            "githubStars": 77,
            "organization": {
                "_id": "63728bde14d543d507ae970d",
                "name": "MIT",
                "fullname": "Massachusetts Institute of Technology",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/noauth/S90qoeEJeEYaYf-c7Zs8g.png"
            }
        },
        "publishedAt": "2025-10-02T13:59:06.000Z",
        "title": "Equilibrium Matching: Generative Modeling with Implicit Energy-Based\n  Models",
        "summary": "We introduce Equilibrium Matching (EqM), a generative modeling framework\nbuilt from an equilibrium dynamics perspective. EqM discards the\nnon-equilibrium, time-conditional dynamics in traditional diffusion and\nflow-based generative models and instead learns the equilibrium gradient of an\nimplicit energy landscape. Through this approach, we can adopt an\noptimization-based sampling process at inference time, where samples are\nobtained by gradient descent on the learned landscape with adjustable step\nsizes, adaptive optimizers, and adaptive compute. EqM surpasses the generation\nperformance of diffusion/flow models empirically, achieving an FID of 1.90 on\nImageNet 256times256. EqM is also theoretically justified to learn and\nsample from the data manifold. Beyond generation, EqM is a flexible framework\nthat naturally handles tasks including partially noised image denoising, OOD\ndetection, and image composition. By replacing time-conditional velocities with\na unified equilibrium landscape, EqM offers a tighter bridge between flow and\nenergy-based models and a simple route to optimization-driven inference.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.02300.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "5f1158120c833276f61f1a84",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1608042047613-5f1158120c833276f61f1a84.jpeg",
            "fullname": "Niels Rogge",
            "name": "nielsr",
            "type": "user",
            "isPro": true,
            "isHf": true,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 990
        },
        "organization": {
            "_id": "63728bde14d543d507ae970d",
            "name": "MIT",
            "fullname": "Massachusetts Institute of Technology",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/noauth/S90qoeEJeEYaYf-c7Zs8g.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05137",
            "authors": [
                {
                    "_id": "68e5bde7975ac4c405ef2031",
                    "name": "Maojia Song",
                    "hidden": false
                },
                {
                    "_id": "68e5bde7975ac4c405ef2032",
                    "name": "Renhang Liu",
                    "hidden": false
                },
                {
                    "_id": "68e5bde7975ac4c405ef2033",
                    "name": "Xinyu Wang",
                    "hidden": false
                },
                {
                    "_id": "68e5bde7975ac4c405ef2034",
                    "name": "Yong Jiang",
                    "hidden": false
                },
                {
                    "_id": "68e5bde7975ac4c405ef2035",
                    "name": "Pengjun Xie",
                    "hidden": false
                },
                {
                    "_id": "68e5bde7975ac4c405ef2036",
                    "name": "Fei Huang",
                    "hidden": false
                },
                {
                    "_id": "68e5bde7975ac4c405ef2037",
                    "name": "Soujanya Poria",
                    "hidden": false
                },
                {
                    "_id": "68e5bde7975ac4c405ef2038",
                    "name": "Jingren Zhou",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-01T07:59:03.000Z",
            "submittedOnDailyAt": "2025-10-08T00:02:07.560Z",
            "title": "Demystifying deep search: a holistic evaluation with hint-free multi-hop\n  questions and factorised metrics",
            "submittedOnDailyBy": {
                "_id": "626b626405fe1cb65725aca1",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626b626405fe1cb65725aca1/ZVSbhynzpQhVGq9kGywW6.png",
                "isPro": false,
                "fullname": "Soujanya Poria",
                "user": "soujanyaporia",
                "type": "user"
            },
            "summary": "RAG (Retrieval-Augmented Generation) systems and web agents are increasingly\nevaluated on multi-hop deep search tasks, yet current practice suffers from two\nmajor limitations. First, most benchmarks leak the reasoning path in the\nquestion text, allowing models to follow surface cues rather than discover\nreasoning chains autonomously. Second, evaluation is typically reduced to a\nsingle pass rate, which collapses diverse behaviours into one score and\nobscures whether failures stem from inadequate search, poor knowledge use, or\ninappropriate refusal. To address these issues, we present WebDetective, a\nbenchmark of hint-free multi-hop questions paired with a controlled Wikipedia\nsandbox that ensures full traceability of model actions, and a holistic\nevaluation framework that separates search sufficiency, knowledge utilisation,\nand refusal behaviour. Our evaluation of 25 state-of-the-art models reveals\nsystematic weaknesses across all architectures: models struggle with knowledge\nutilisation despite having sufficient evidence and demonstrate near-absent\nappropriate refusal when evidence is lacking. These patterns expose a\nfundamental gap: today's systems excel at executing given reasoning paths but\nfail when required to discover them. We develop an agentic workflow,\nEvidenceLoop, that explicitly targets the challenges our benchmark identifies,\nincorporating verification loops and systematic evidence tracking that improve\nboth search and synthesis capabilities. This baseline demonstrates that\nWebDetective's diagnostic framework can guide concrete architectural\nimprovements, establishing our benchmark as a critical tool for developing\ngenuinely autonomous reasoning systems rather than pattern-following agents.",
            "upvotes": 4,
            "discussionId": "68e5bde7975ac4c405ef2039",
            "ai_summary": "WebDetective is a benchmark for evaluating multi-hop reasoning in RAG systems and web agents, addressing issues of reasoning path leakage and single-pass evaluation, and introducing a framework to improve knowledge utilization and refusal behavior.",
            "ai_keywords": [
                "RAG",
                "Retrieval-Augmented Generation",
                "multi-hop deep search",
                "reasoning path",
                "knowledge utilisation",
                "refusal behaviour",
                "Wikipedia sandbox",
                "EvidenceLoop",
                "verification loops",
                "evidence tracking"
            ],
            "organization": {
                "_id": "626ab9dac804c432c1b27a48",
                "name": "declare-lab",
                "fullname": "Deep Cognition and Language Research (DeCLaRe) Lab",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/grq3rj2uj0WRjjPjAtR1I.png"
            }
        },
        "publishedAt": "2025-10-01T03:59:03.000Z",
        "title": "Demystifying deep search: a holistic evaluation with hint-free multi-hop\n  questions and factorised metrics",
        "summary": "RAG (Retrieval-Augmented Generation) systems and web agents are increasingly\nevaluated on multi-hop deep search tasks, yet current practice suffers from two\nmajor limitations. First, most benchmarks leak the reasoning path in the\nquestion text, allowing models to follow surface cues rather than discover\nreasoning chains autonomously. Second, evaluation is typically reduced to a\nsingle pass rate, which collapses diverse behaviours into one score and\nobscures whether failures stem from inadequate search, poor knowledge use, or\ninappropriate refusal. To address these issues, we present WebDetective, a\nbenchmark of hint-free multi-hop questions paired with a controlled Wikipedia\nsandbox that ensures full traceability of model actions, and a holistic\nevaluation framework that separates search sufficiency, knowledge utilisation,\nand refusal behaviour. Our evaluation of 25 state-of-the-art models reveals\nsystematic weaknesses across all architectures: models struggle with knowledge\nutilisation despite having sufficient evidence and demonstrate near-absent\nappropriate refusal when evidence is lacking. These patterns expose a\nfundamental gap: today's systems excel at executing given reasoning paths but\nfail when required to discover them. We develop an agentic workflow,\nEvidenceLoop, that explicitly targets the challenges our benchmark identifies,\nincorporating verification loops and systematic evidence tracking that improve\nboth search and synthesis capabilities. This baseline demonstrates that\nWebDetective's diagnostic framework can guide concrete architectural\nimprovements, establishing our benchmark as a critical tool for developing\ngenuinely autonomous reasoning systems rather than pattern-following agents.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05137.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "626b626405fe1cb65725aca1",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/626b626405fe1cb65725aca1/ZVSbhynzpQhVGq9kGywW6.png",
            "fullname": "Soujanya Poria",
            "name": "soujanyaporia",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 9
        },
        "organization": {
            "_id": "626ab9dac804c432c1b27a48",
            "name": "declare-lab",
            "fullname": "Deep Cognition and Language Research (DeCLaRe) Lab",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/626b626405fe1cb65725aca1/grq3rj2uj0WRjjPjAtR1I.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06219",
            "authors": [
                {
                    "_id": "68e608e8975ac4c405ef21a6",
                    "name": "Yue Chen",
                    "hidden": false
                },
                {
                    "_id": "68e608e8975ac4c405ef21a7",
                    "name": "Xingyu Chen",
                    "hidden": false
                },
                {
                    "_id": "68e608e8975ac4c405ef21a8",
                    "name": "Yuxuan Xue",
                    "hidden": false
                },
                {
                    "_id": "68e608e8975ac4c405ef21a9",
                    "name": "Anpei Chen",
                    "hidden": false
                },
                {
                    "_id": "68e608e8975ac4c405ef21aa",
                    "name": "Yuliang Xiu",
                    "hidden": false
                },
                {
                    "_id": "68e608e8975ac4c405ef21ab",
                    "name": "Gerard Pons-Moll",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/q-FHSnYwa6rl1hD77lxQS.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/slxqsAT2pCoITK315wKU4.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/CgxL9tNNtDEQ0jsLfcZxs.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/HzIj7SDVuMrifZriWNrNg.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/sldss4gsSWWS66g511jyL.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/BHGzqCnde0dNn8fRLAVMs.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/CqCbj4pc7R6OsRrtrKrAJ.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/jDisi768sZ7Pa7q95pU5o.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/qUZx2_QV14LBnzYkT0j-F.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/sj_KbyAyKrkY7Zvdfz2nN.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/cSx1EbkwvDqDd89f46qSP.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/m1mS9R1b59GtIGWopZBMa.mp4",
                "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/_EMw_Ho9nWfxwk9KdWj5O.mp4"
            ],
            "publishedAt": "2025-10-07T17:59:52.000Z",
            "submittedOnDailyAt": "2025-10-08T06:01:34.069Z",
            "title": "Human3R: Everyone Everywhere All at Once",
            "submittedOnDailyBy": {
                "_id": "66f80281d88dc2ad510663e9",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/5HV3mTu-cxPCnWlCi_2wB.jpeg",
                "isPro": false,
                "fullname": "Yue Chen",
                "user": "faneggg",
                "type": "user"
            },
            "summary": "We present Human3R, a unified, feed-forward framework for online 4D\nhuman-scene reconstruction, in the world frame, from casually captured\nmonocular videos. Unlike previous approaches that rely on multi-stage\npipelines, iterative contact-aware refinement between humans and scenes, and\nheavy dependencies, e.g., human detection, depth estimation, and SLAM\npre-processing, Human3R jointly recovers global multi-person SMPL-X bodies\n(\"everyone\"), dense 3D scene (\"everywhere\"), and camera trajectories in a\nsingle forward pass (\"all-at-once\"). Our method builds upon the 4D online\nreconstruction model CUT3R, and uses parameter-efficient visual prompt tuning,\nto strive to preserve CUT3R's rich spatiotemporal priors, while enabling direct\nreadout of multiple SMPL-X bodies. Human3R is a unified model that eliminates\nheavy dependencies and iterative refinement. After being trained on the\nrelatively small-scale synthetic dataset BEDLAM for just one day on one GPU, it\nachieves superior performance with remarkable efficiency: it reconstructs\nmultiple humans in a one-shot manner, along with 3D scenes, in one stage, at\nreal-time speed (15 FPS) with a low memory footprint (8 GB). Extensive\nexperiments demonstrate that Human3R delivers state-of-the-art or competitive\nperformance across tasks, including global human motion estimation, local human\nmesh recovery, video depth estimation, and camera pose estimation, with a\nsingle unified model. We hope that Human3R will serve as a simple yet strong\nbaseline, be easily extended for downstream applications.Code available in\nhttps://fanegg.github.io/Human3R",
            "upvotes": 3,
            "discussionId": "68e608e9975ac4c405ef21ac",
            "ai_summary": "Human3R is a unified, feed-forward framework for real-time 4D human-scene reconstruction from monocular videos, achieving state-of-the-art performance with a single model and minimal dependencies.",
            "ai_keywords": [
                "feed-forward framework",
                "4D reconstruction",
                "monocular videos",
                "SMPL-X bodies",
                "dense 3D scene",
                "camera trajectories",
                "CUT3R",
                "parameter-efficient visual prompt tuning",
                "spatiotemporal priors",
                "real-time speed",
                "memory footprint",
                "global human motion estimation",
                "local human mesh recovery",
                "video depth estimation",
                "camera pose estimation"
            ]
        },
        "publishedAt": "2025-10-07T13:59:52.000Z",
        "title": "Human3R: Everyone Everywhere All at Once",
        "summary": "We present Human3R, a unified, feed-forward framework for online 4D\nhuman-scene reconstruction, in the world frame, from casually captured\nmonocular videos. Unlike previous approaches that rely on multi-stage\npipelines, iterative contact-aware refinement between humans and scenes, and\nheavy dependencies, e.g., human detection, depth estimation, and SLAM\npre-processing, Human3R jointly recovers global multi-person SMPL-X bodies\n(\"everyone\"), dense 3D scene (\"everywhere\"), and camera trajectories in a\nsingle forward pass (\"all-at-once\"). Our method builds upon the 4D online\nreconstruction model CUT3R, and uses parameter-efficient visual prompt tuning,\nto strive to preserve CUT3R's rich spatiotemporal priors, while enabling direct\nreadout of multiple SMPL-X bodies. Human3R is a unified model that eliminates\nheavy dependencies and iterative refinement. After being trained on the\nrelatively small-scale synthetic dataset BEDLAM for just one day on one GPU, it\nachieves superior performance with remarkable efficiency: it reconstructs\nmultiple humans in a one-shot manner, along with 3D scenes, in one stage, at\nreal-time speed (15 FPS) with a low memory footprint (8 GB). Extensive\nexperiments demonstrate that Human3R delivers state-of-the-art or competitive\nperformance across tasks, including global human motion estimation, local human\nmesh recovery, video depth estimation, and camera pose estimation, with a\nsingle unified model. We hope that Human3R will serve as a simple yet strong\nbaseline, be easily extended for downstream applications.Code available in\nhttps://fanegg.github.io/Human3R",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/q-FHSnYwa6rl1hD77lxQS.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/slxqsAT2pCoITK315wKU4.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/CgxL9tNNtDEQ0jsLfcZxs.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/HzIj7SDVuMrifZriWNrNg.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/sldss4gsSWWS66g511jyL.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/BHGzqCnde0dNn8fRLAVMs.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/CqCbj4pc7R6OsRrtrKrAJ.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/jDisi768sZ7Pa7q95pU5o.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/qUZx2_QV14LBnzYkT0j-F.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/sj_KbyAyKrkY7Zvdfz2nN.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/cSx1EbkwvDqDd89f46qSP.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/m1mS9R1b59GtIGWopZBMa.mp4",
            "https://cdn-uploads.huggingface.co/production/uploads/66f80281d88dc2ad510663e9/_EMw_Ho9nWfxwk9KdWj5O.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06219.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "66f80281d88dc2ad510663e9",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/noauth/5HV3mTu-cxPCnWlCi_2wB.jpeg",
            "fullname": "Yue Chen",
            "name": "faneggg",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06218",
            "authors": [
                {
                    "_id": "68e5c2e8975ac4c405ef20bd",
                    "user": {
                        "_id": "6814b27fdc0f8971ef7cd574",
                        "avatarUrl": "/avatars/590ed5d0f2f9933c90df71cc69b9401e.svg",
                        "isPro": false,
                        "fullname": "Deheng Zhang",
                        "user": "dehezhang2",
                        "type": "user"
                    },
                    "name": "Deheng Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T11:49:07.341Z",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20be",
                    "name": "Yuqian Fu",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20bf",
                    "name": "Runyi Yang",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c0",
                    "name": "Yang Miao",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c1",
                    "name": "Tianwen Qian",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c2",
                    "name": "Xu Zheng",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c3",
                    "name": "Guolei Sun",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c4",
                    "name": "Ajad Chhatkuli",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c5",
                    "name": "Xuanjing Huang",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c6",
                    "name": "Yu-Gang Jiang",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c7",
                    "name": "Luc Van Gool",
                    "hidden": false
                },
                {
                    "_id": "68e5c2e8975ac4c405ef20c8",
                    "name": "Danda Pani Paudel",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T17:59:47.000Z",
            "submittedOnDailyAt": "2025-10-08T00:18:35.291Z",
            "title": "EgoNight: Towards Egocentric Vision Understanding at Night with a\n  Challenging Benchmark",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Most existing benchmarks for egocentric vision understanding focus primarily\non daytime scenarios, overlooking the low-light conditions that are inevitable\nin real-world applications. To investigate this gap, we present EgoNight, the\nfirst comprehensive benchmark for nighttime egocentric vision, with visual\nquestion answering (VQA) as the core task. A key feature of EgoNight is the\nintroduction of day-night aligned videos, which enhance night annotation\nquality using the daytime data and reveal clear performance gaps between\nlighting conditions. To achieve this, we collect both synthetic videos rendered\nby Blender and real-world recordings, ensuring that scenes and actions are\nvisually and temporally aligned. Leveraging these paired videos, we construct\nEgoNight-VQA, supported by a novel day-augmented night auto-labeling engine and\nrefinement through extensive human verification. Each QA pair is double-checked\nby annotators for reliability. In total, EgoNight-VQA contains 3658 QA pairs\nacross 90 videos, spanning 12 diverse QA types, with more than 300 hours of\nhuman work. Evaluations of state-of-the-art multimodal large language models\n(MLLMs) reveal substantial performance drops when transferring from day to\nnight, underscoring the challenges of reasoning under low-light conditions.\nBeyond VQA, EgoNight also introduces two auxiliary tasks, day-night\ncorrespondence retrieval and egocentric depth estimation at night, that further\nexplore the boundaries of existing models. We believe EgoNight-VQA provides a\nstrong foundation for advancing application-driven egocentric vision research\nand for developing models that generalize across illumination domains. All the\ndata and code will be made available upon acceptance.",
            "upvotes": 3,
            "discussionId": "68e5c2e8975ac4c405ef20c9",
            "ai_summary": "EgoNight is a comprehensive benchmark for nighttime egocentric vision, focusing on visual question answering and revealing performance gaps between day and night conditions for multimodal large language models.",
            "ai_keywords": [
                "egocentric vision",
                "visual question answering",
                "day-night aligned videos",
                "synthetic videos",
                "real-world recordings",
                "day-augmented night auto-labeling",
                "multimodal large language models",
                "day-night correspondence retrieval",
                "egocentric depth estimation"
            ]
        },
        "publishedAt": "2025-10-07T13:59:47.000Z",
        "title": "EgoNight: Towards Egocentric Vision Understanding at Night with a\n  Challenging Benchmark",
        "summary": "Most existing benchmarks for egocentric vision understanding focus primarily\non daytime scenarios, overlooking the low-light conditions that are inevitable\nin real-world applications. To investigate this gap, we present EgoNight, the\nfirst comprehensive benchmark for nighttime egocentric vision, with visual\nquestion answering (VQA) as the core task. A key feature of EgoNight is the\nintroduction of day-night aligned videos, which enhance night annotation\nquality using the daytime data and reveal clear performance gaps between\nlighting conditions. To achieve this, we collect both synthetic videos rendered\nby Blender and real-world recordings, ensuring that scenes and actions are\nvisually and temporally aligned. Leveraging these paired videos, we construct\nEgoNight-VQA, supported by a novel day-augmented night auto-labeling engine and\nrefinement through extensive human verification. Each QA pair is double-checked\nby annotators for reliability. In total, EgoNight-VQA contains 3658 QA pairs\nacross 90 videos, spanning 12 diverse QA types, with more than 300 hours of\nhuman work. Evaluations of state-of-the-art multimodal large language models\n(MLLMs) reveal substantial performance drops when transferring from day to\nnight, underscoring the challenges of reasoning under low-light conditions.\nBeyond VQA, EgoNight also introduces two auxiliary tasks, day-night\ncorrespondence retrieval and egocentric depth estimation at night, that further\nexplore the boundaries of existing models. We believe EgoNight-VQA provides a\nstrong foundation for advancing application-driven egocentric vision research\nand for developing models that generalize across illumination domains. All the\ndata and code will be made available upon acceptance.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06218.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 120
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05156",
            "authors": [
                {
                    "_id": "68e5dda9975ac4c405ef2123",
                    "name": "Lesly Miculicich",
                    "hidden": false
                },
                {
                    "_id": "68e5dda9975ac4c405ef2124",
                    "name": "Mihir Parmar",
                    "hidden": false
                },
                {
                    "_id": "68e5dda9975ac4c405ef2125",
                    "name": "Hamid Palangi",
                    "hidden": false
                },
                {
                    "_id": "68e5dda9975ac4c405ef2126",
                    "name": "Krishnamurthy Dj Dvijotham",
                    "hidden": false
                },
                {
                    "_id": "68e5dda9975ac4c405ef2127",
                    "name": "Mirko Montanari",
                    "hidden": false
                },
                {
                    "_id": "68e5dda9975ac4c405ef2128",
                    "name": "Tomas Pfister",
                    "hidden": false
                },
                {
                    "_id": "68e5dda9975ac4c405ef2129",
                    "name": "Long T. Le",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-03T04:11:43.000Z",
            "submittedOnDailyAt": "2025-10-08T02:12:45.309Z",
            "title": "VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "The deployment of autonomous AI agents in sensitive domains, such as\nhealthcare, introduces critical risks to safety, security, and privacy. These\nagents may deviate from user objectives, violate data handling policies, or be\ncompromised by adversarial attacks. Mitigating these dangers necessitates a\nmechanism to formally guarantee that an agent's actions adhere to predefined\nsafety constraints, a challenge that existing systems do not fully address. We\nintroduce VeriGuard, a novel framework that provides formal safety guarantees\nfor LLM-based agents through a dual-stage architecture designed for robust and\nverifiable correctness. The initial offline stage involves a comprehensive\nvalidation process. It begins by clarifying user intent to establish precise\nsafety specifications. VeriGuard then synthesizes a behavioral policy and\nsubjects it to both testing and formal verification to prove its compliance\nwith these specifications. This iterative process refines the policy until it\nis deemed correct. Subsequently, the second stage provides online action\nmonitoring, where VeriGuard operates as a runtime monitor to validate each\nproposed agent action against the pre-verified policy before execution. This\nseparation of the exhaustive offline validation from the lightweight online\nmonitoring allows formal guarantees to be practically applied, providing a\nrobust safeguard that substantially improves the trustworthiness of LLM agents.",
            "upvotes": 3,
            "discussionId": "68e5ddaa975ac4c405ef212a",
            "ai_summary": "VeriGuard is a framework that ensures formal safety guarantees for LLM-based agents through offline validation and online monitoring.",
            "ai_keywords": [
                "LLM-based agents",
                "formal safety guarantees",
                "dual-stage architecture",
                "offline stage",
                "user intent",
                "safety specifications",
                "behavioral policy",
                "formal verification",
                "online stage",
                "runtime monitor"
            ],
            "organization": {
                "_id": "5e6aca39878b8b2bf9806447",
                "name": "google",
                "fullname": "Google",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/WtA3YYitedOr9n02eHfJe.png"
            }
        },
        "publishedAt": "2025-10-03T00:11:43.000Z",
        "title": "VeriGuard: Enhancing LLM Agent Safety via Verified Code Generation",
        "summary": "The deployment of autonomous AI agents in sensitive domains, such as\nhealthcare, introduces critical risks to safety, security, and privacy. These\nagents may deviate from user objectives, violate data handling policies, or be\ncompromised by adversarial attacks. Mitigating these dangers necessitates a\nmechanism to formally guarantee that an agent's actions adhere to predefined\nsafety constraints, a challenge that existing systems do not fully address. We\nintroduce VeriGuard, a novel framework that provides formal safety guarantees\nfor LLM-based agents through a dual-stage architecture designed for robust and\nverifiable correctness. The initial offline stage involves a comprehensive\nvalidation process. It begins by clarifying user intent to establish precise\nsafety specifications. VeriGuard then synthesizes a behavioral policy and\nsubjects it to both testing and formal verification to prove its compliance\nwith these specifications. This iterative process refines the policy until it\nis deemed correct. Subsequently, the second stage provides online action\nmonitoring, where VeriGuard operates as a runtime monitor to validate each\nproposed agent action against the pre-verified policy before execution. This\nseparation of the exhaustive offline validation from the lightweight online\nmonitoring allows formal guarantees to be practically applied, providing a\nrobust safeguard that substantially improves the trustworthiness of LLM agents.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05156.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 120
        },
        "organization": {
            "_id": "5e6aca39878b8b2bf9806447",
            "name": "google",
            "fullname": "Google",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/WtA3YYitedOr9n02eHfJe.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05122",
            "authors": [
                {
                    "_id": "68e5e55c975ac4c405ef2131",
                    "user": {
                        "_id": "642656cbad1e3b0e6e91b752",
                        "avatarUrl": "/avatars/3bf0ee15fd528e09b2b889f5cce3cbd0.svg",
                        "isPro": false,
                        "fullname": "Jie Zhu",
                        "user": "amazingj",
                        "type": "user"
                    },
                    "name": "Jie Zhu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T05:49:16.107Z",
                    "hidden": false
                },
                {
                    "_id": "68e5e55c975ac4c405ef2132",
                    "name": "Yuanchen Zhou",
                    "hidden": false
                },
                {
                    "_id": "68e5e55c975ac4c405ef2133",
                    "name": "Shuo Jiang",
                    "hidden": false
                },
                {
                    "_id": "68e5e55c975ac4c405ef2134",
                    "name": "Junhui Li",
                    "hidden": false
                },
                {
                    "_id": "68e5e55c975ac4c405ef2135",
                    "name": "Lifan Guo",
                    "hidden": false
                },
                {
                    "_id": "68e5e55c975ac4c405ef2136",
                    "name": "Feng Chen",
                    "hidden": false
                },
                {
                    "_id": "68e5e55c975ac4c405ef2137",
                    "name": "Chi Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e5e55c975ac4c405ef2138",
                    "name": "Fang Kong",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-30T03:19:50.000Z",
            "submittedOnDailyAt": "2025-10-08T02:47:57.346Z",
            "title": "CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support\n  Conversation",
            "submittedOnDailyBy": {
                "_id": "642656cbad1e3b0e6e91b752",
                "avatarUrl": "/avatars/3bf0ee15fd528e09b2b889f5cce3cbd0.svg",
                "isPro": false,
                "fullname": "Jie Zhu",
                "user": "amazingj",
                "type": "user"
            },
            "summary": "Emotional Support Conversation (ESC) plays a vital role in alleviating\npsychological stress and providing emotional value through dialogue. While\nrecent studies have largely focused on data augmentation and synthetic corpus\nconstruction, they often overlook the deeper cognitive reasoning processes that\nunderpin effective emotional support. To address this gap, we propose\nCARE, a novel framework that strengthens reasoning in ESC without\nrelying on large-scale synthetic data. CARE leverages the original ESC training\nset to guide models in generating logically coherent and supportive responses,\nthereby explicitly enhancing cognitive reasoning. Building on this foundation,\nwe further employ reinforcement learning to refine and reinforce the reasoning\nprocess. Experimental results demonstrate that CARE significantly improves both\nthe logical soundness and supportive quality of responses, advancing the\ndevelopment of empathetic, cognitively robust, and human-like emotional support\nsystems.",
            "upvotes": 3,
            "discussionId": "68e5e55d975ac4c405ef2139",
            "projectPage": "https://github.com/aliyun/qwen-dianjin",
            "ai_summary": "CARE is a framework that enhances cognitive reasoning in emotional support conversations through reinforcement learning, improving response quality and empathy without relying on large-scale synthetic data.",
            "ai_keywords": [
                "CARE",
                "reinforcement learning",
                "cognitive reasoning",
                "emotional support conversations",
                "logical soundness",
                "supportive quality",
                "empathetic",
                "cognitively robust",
                "human-like"
            ],
            "organization": {
                "_id": "6800da699e8a5cadfd0474de",
                "name": "DianJin",
                "fullname": "Qwen DianJin",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/642656cbad1e3b0e6e91b752/DT7C9Hti0j2lx0ybd0N9c.png"
            }
        },
        "publishedAt": "2025-09-29T23:19:50.000Z",
        "title": "CARE: Cognitive-reasoning Augmented Reinforcement for Emotional Support\n  Conversation",
        "summary": "Emotional Support Conversation (ESC) plays a vital role in alleviating\npsychological stress and providing emotional value through dialogue. While\nrecent studies have largely focused on data augmentation and synthetic corpus\nconstruction, they often overlook the deeper cognitive reasoning processes that\nunderpin effective emotional support. To address this gap, we propose\nCARE, a novel framework that strengthens reasoning in ESC without\nrelying on large-scale synthetic data. CARE leverages the original ESC training\nset to guide models in generating logically coherent and supportive responses,\nthereby explicitly enhancing cognitive reasoning. Building on this foundation,\nwe further employ reinforcement learning to refine and reinforce the reasoning\nprocess. Experimental results demonstrate that CARE significantly improves both\nthe logical soundness and supportive quality of responses, advancing the\ndevelopment of empathetic, cognitively robust, and human-like emotional support\nsystems.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05122.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "642656cbad1e3b0e6e91b752",
            "avatarUrl": "/avatars/3bf0ee15fd528e09b2b889f5cce3cbd0.svg",
            "fullname": "Jie Zhu",
            "name": "amazingj",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "6800da699e8a5cadfd0474de",
            "name": "DianJin",
            "fullname": "Qwen DianJin",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/642656cbad1e3b0e6e91b752/DT7C9Hti0j2lx0ybd0N9c.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.06107",
            "authors": [
                {
                    "_id": "68e61bc3975ac4c405ef21c3",
                    "user": {
                        "_id": "60394599033b61166496163b",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614366097007-noauth.jpeg",
                        "isPro": false,
                        "fullname": "Gagan Bhatia",
                        "user": "gagan3012",
                        "type": "user"
                    },
                    "name": "Gagan Bhatia",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T11:49:03.207Z",
                    "hidden": false
                },
                {
                    "_id": "68e61bc3975ac4c405ef21c4",
                    "name": "Somayajulu G Sripada",
                    "hidden": false
                },
                {
                    "_id": "68e61bc3975ac4c405ef21c5",
                    "name": "Kevin Allan",
                    "hidden": false
                },
                {
                    "_id": "68e61bc3975ac4c405ef21c6",
                    "name": "Jacobo Azcona",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T16:40:31.000Z",
            "submittedOnDailyAt": "2025-10-08T06:40:57.946Z",
            "title": "Distributional Semantics Tracing: A Framework for Explaining\n  Hallucinations in Large Language Models",
            "submittedOnDailyBy": {
                "_id": "60394599033b61166496163b",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614366097007-noauth.jpeg",
                "isPro": false,
                "fullname": "Gagan Bhatia",
                "user": "gagan3012",
                "type": "user"
            },
            "summary": "Large Language Models (LLMs) are prone to hallucination, the generation of\nplausible yet factually incorrect statements. This work investigates the\nintrinsic, architectural origins of this failure mode through three primary\ncontributions.First, to enable the reliable tracing of internal semantic\nfailures, we propose Distributional Semantics Tracing (DST), a unified\nframework that integrates established interpretability techniques to produce a\ncausal map of a model's reasoning, treating meaning as a function of context\n(distributional semantics). Second, we pinpoint the model's layer at which a\nhallucination becomes inevitable, identifying a specific commitment\nlayer where a model's internal representations irreversibly diverge from\nfactuality. Third, we identify the underlying mechanism for these failures. We\nobserve a conflict between distinct computational pathways, which we interpret\nusing the lens of dual-process theory: a fast, heuristic associative\npathway (akin to System 1) and a slow, deliberate contextual pathway\n(akin to System 2), leading to predictable failure modes such as\nReasoning Shortcut Hijacks. Our framework's ability to quantify the\ncoherence of the contextual pathway reveals a strong negative correlation\n(rho = -0.863) with hallucination rates, implying that these failures are\npredictable consequences of internal semantic weakness. The result is a\nmechanistic account of how, when, and why hallucinations occur within the\nTransformer architecture.",
            "upvotes": 2,
            "discussionId": "68e61bc4975ac4c405ef21c7",
            "ai_summary": "A framework called Distributional Semantics Tracing identifies the layers and pathways in Transformers where hallucinations occur, revealing a correlation between internal semantic coherence and hallucination rates.",
            "ai_keywords": [
                "Distributional Semantics Tracing",
                "commitment layer",
                "associative pathway",
                "contextual pathway",
                "dual-process theory",
                "Reasoning Shortcut Hijacks",
                "Transformer architecture"
            ]
        },
        "publishedAt": "2025-10-07T12:40:31.000Z",
        "title": "Distributional Semantics Tracing: A Framework for Explaining\n  Hallucinations in Large Language Models",
        "summary": "Large Language Models (LLMs) are prone to hallucination, the generation of\nplausible yet factually incorrect statements. This work investigates the\nintrinsic, architectural origins of this failure mode through three primary\ncontributions.First, to enable the reliable tracing of internal semantic\nfailures, we propose Distributional Semantics Tracing (DST), a unified\nframework that integrates established interpretability techniques to produce a\ncausal map of a model's reasoning, treating meaning as a function of context\n(distributional semantics). Second, we pinpoint the model's layer at which a\nhallucination becomes inevitable, identifying a specific commitment\nlayer where a model's internal representations irreversibly diverge from\nfactuality. Third, we identify the underlying mechanism for these failures. We\nobserve a conflict between distinct computational pathways, which we interpret\nusing the lens of dual-process theory: a fast, heuristic associative\npathway (akin to System 1) and a slow, deliberate contextual pathway\n(akin to System 2), leading to predictable failure modes such as\nReasoning Shortcut Hijacks. Our framework's ability to quantify the\ncoherence of the contextual pathway reveals a strong negative correlation\n(rho = -0.863) with hallucination rates, implying that these failures are\npredictable consequences of internal semantic weakness. The result is a\nmechanistic account of how, when, and why hallucinations occur within the\nTransformer architecture.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06107.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60394599033b61166496163b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1614366097007-noauth.jpeg",
            "fullname": "Gagan Bhatia",
            "name": "gagan3012",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 28
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.06030",
            "authors": [
                {
                    "_id": "68e5bdf8975ac4c405ef203b",
                    "user": {
                        "_id": "5e75b7b93d77a72421292d01",
                        "avatarUrl": "/avatars/a832a73e8185175c452c0dc145cd2678.svg",
                        "isPro": false,
                        "fullname": "Rohit Goswami",
                        "user": "rgoswami",
                        "type": "user"
                    },
                    "name": "Rohit Goswami",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T05:49:59.985Z",
                    "hidden": false
                },
                {
                    "_id": "68e5bdf8975ac4c405ef203c",
                    "name": "Hannes Jónsson",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T15:27:39.000Z",
            "submittedOnDailyAt": "2025-10-08T14:17:15.234Z",
            "title": "Adaptive Pruning for Increased Robustness and Reduced Computational\n  Overhead in Gaussian Process Accelerated Saddle Point Searches",
            "submittedOnDailyBy": {
                "_id": "5e75b7b93d77a72421292d01",
                "avatarUrl": "/avatars/a832a73e8185175c452c0dc145cd2678.svg",
                "isPro": false,
                "fullname": "Rohit Goswami",
                "user": "rgoswami",
                "type": "user"
            },
            "summary": "Gaussian process (GP) regression provides a strategy for accelerating saddle\npoint searches on high-dimensional energy surfaces by reducing the number of\ntimes the energy and its derivatives with respect to atomic coordinates need to\nbe evaluated. The computational overhead in the hyperparameter optimization\ncan, however, be large and make the approach inefficient. Failures can also\noccur if the search ventures too far into regions that are not represented well\nenough by the GP model. Here, these challenges are resolved by using\ngeometry-aware optimal transport measures and an active pruning strategy using\na summation over Wasserstein-1 distances for each atom-type in farthest-point\nsampling, selecting a fixed-size subset of geometrically diverse configurations\nto avoid rapidly increasing cost of GP updates as more observations are made.\nStability is enhanced by permutation-invariant metric that provides a reliable\ntrust radius for early-stopping and a logarithmic barrier penalty for the\ngrowth of the signal variance. These physically motivated algorithmic changes\nprove their efficacy by reducing to less than a half the mean computational\ntime on a set of 238 challenging configurations from a previously published\ndata set of chemical reactions. With these improvements, the GP approach is\nestablished as, a robust and scalable algorithm for accelerating saddle point\nsearches when the evaluation of the energy and atomic forces requires\nsignificant computational effort.",
            "upvotes": 2,
            "discussionId": "68e5bdf9975ac4c405ef203d",
            "githubRepo": "https://github.com/theochemUI/otgpd_repro",
            "ai_summary": "Geometry-aware optimal transport and active pruning enhance Gaussian process regression for efficient saddle point searches on high-dimensional energy surfaces.",
            "ai_keywords": [
                "Gaussian process regression",
                "saddle point searches",
                "energy surfaces",
                "hyperparameter optimization",
                "geometry-aware optimal transport",
                "active pruning",
                "Wasserstein-1 distances",
                "farthest-point sampling",
                "permutation-invariant metric",
                "trust radius",
                "logarithmic barrier penalty",
                "signal variance"
            ],
            "githubStars": 0
        },
        "publishedAt": "2025-10-07T11:27:39.000Z",
        "title": "Adaptive Pruning for Increased Robustness and Reduced Computational\n  Overhead in Gaussian Process Accelerated Saddle Point Searches",
        "summary": "Gaussian process (GP) regression provides a strategy for accelerating saddle\npoint searches on high-dimensional energy surfaces by reducing the number of\ntimes the energy and its derivatives with respect to atomic coordinates need to\nbe evaluated. The computational overhead in the hyperparameter optimization\ncan, however, be large and make the approach inefficient. Failures can also\noccur if the search ventures too far into regions that are not represented well\nenough by the GP model. Here, these challenges are resolved by using\ngeometry-aware optimal transport measures and an active pruning strategy using\na summation over Wasserstein-1 distances for each atom-type in farthest-point\nsampling, selecting a fixed-size subset of geometrically diverse configurations\nto avoid rapidly increasing cost of GP updates as more observations are made.\nStability is enhanced by permutation-invariant metric that provides a reliable\ntrust radius for early-stopping and a logarithmic barrier penalty for the\ngrowth of the signal variance. These physically motivated algorithmic changes\nprove their efficacy by reducing to less than a half the mean computational\ntime on a set of 238 challenging configurations from a previously published\ndata set of chemical reactions. With these improvements, the GP approach is\nestablished as, a robust and scalable algorithm for accelerating saddle point\nsearches when the evaluation of the energy and atomic forces requires\nsignificant computational effort.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06030.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "5e75b7b93d77a72421292d01",
            "avatarUrl": "/avatars/a832a73e8185175c452c0dc145cd2678.svg",
            "fullname": "Rohit Goswami",
            "name": "rgoswami",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.05396",
            "authors": [
                {
                    "_id": "68e6ac940d37f65d7721a61f",
                    "name": "Nilesh Gupta",
                    "hidden": false
                },
                {
                    "_id": "68e6ac940d37f65d7721a620",
                    "name": "Chong You",
                    "hidden": false
                },
                {
                    "_id": "68e6ac940d37f65d7721a621",
                    "name": "Srinadh Bhojanapalli",
                    "hidden": false
                },
                {
                    "_id": "68e6ac940d37f65d7721a622",
                    "name": "Sanjiv Kumar",
                    "hidden": false
                },
                {
                    "_id": "68e6ac940d37f65d7721a623",
                    "name": "Inderjit Dhillon",
                    "hidden": false
                },
                {
                    "_id": "68e6ac940d37f65d7721a624",
                    "name": "Felix Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T21:41:58.000Z",
            "submittedOnDailyAt": "2025-10-08T16:58:47.917Z",
            "title": "Scalable In-context Ranking with Generative Models",
            "submittedOnDailyBy": {
                "_id": "6527151d5606f146974d60d8",
                "avatarUrl": "/avatars/00ac8ab005ceadae866dea5471f6aab9.svg",
                "isPro": false,
                "fullname": "Nilesh Gupta",
                "user": "quicktensor",
                "type": "user"
            },
            "summary": "In-context Ranking (ICR) is an emerging paradigm for Information Retrieval\n(IR), which leverages contextual understanding of LLMs by directly\nincorporating the task description, candidate documents, and the query into the\nmodel's input prompt and tasking the LLM to identify relevant document(s).\nWhile it is effective, efficiency is a significant challenge in this paradigm,\nespecially as the candidate list grows due to quadratic/super-linear scaling of\nattention operation with context length. To this end, this paper first\nidentifies inherent and exploitable structures in the attention of LLMs\nfinetuned for ICR: (1) inter-document block sparsity: attention is dense within\neach document block but sparse across different documents in the context; and\n(2) query-document block relevance: the attention scores from certain query\ntokens to a document block in middle layers strongly correlate with that\ndocument's actual relevance. Motivated by these observations, we introduce\nBlockRank (Blockwise In-context Ranking), a novel method that adapts the\nattention operation in an LLM by (a) architecturally enforcing the observed\ninter-document block sparsity, reducing attention complexity from quadratic to\nlinear without loss in performance, and (b) optimizing query-document block\nrelevance for true relevant documents during fine-tuning using an auxiliary\ncontrastive training objective, improving retrieval in attention. Experiments\non BEIR, MSMarco and NQ with Mistral-7B demonstrate that FLARE Mistral matches\nor outperforms existing SOTA listwise rankers and controlled fine-tuned\nbaseline while being significantly more efficient at inference (4.7x for 100\nMSMarco documents in context) and scaling gracefully to long-context\nshortlists, around 500 documents in-context (approximately 100K context length)\nwithin a second, presenting a scalable and effective solution for ICR.",
            "upvotes": 2,
            "discussionId": "68e6ac950d37f65d7721a625",
            "ai_summary": "BlockRank optimizes in-context ranking by enforcing inter-document block sparsity and enhancing query-document relevance, improving efficiency and scalability in large-scale information retrieval.",
            "ai_keywords": [
                "in-context ranking",
                "ICR",
                "LLMs",
                "attention operation",
                "inter-document block sparsity",
                "query-document block relevance",
                "BlockRank",
                "BEIR",
                "MSMarco",
                "NQ",
                "Mistral-7B",
                "FLARE Mistral",
                "listwise rankers",
                "contrastive training objective"
            ],
            "organization": {
                "_id": "5e6aca39878b8b2bf9806447",
                "name": "google",
                "fullname": "Google",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/WtA3YYitedOr9n02eHfJe.png"
            }
        },
        "publishedAt": "2025-10-06T17:41:58.000Z",
        "title": "Scalable In-context Ranking with Generative Models",
        "summary": "In-context Ranking (ICR) is an emerging paradigm for Information Retrieval\n(IR), which leverages contextual understanding of LLMs by directly\nincorporating the task description, candidate documents, and the query into the\nmodel's input prompt and tasking the LLM to identify relevant document(s).\nWhile it is effective, efficiency is a significant challenge in this paradigm,\nespecially as the candidate list grows due to quadratic/super-linear scaling of\nattention operation with context length. To this end, this paper first\nidentifies inherent and exploitable structures in the attention of LLMs\nfinetuned for ICR: (1) inter-document block sparsity: attention is dense within\neach document block but sparse across different documents in the context; and\n(2) query-document block relevance: the attention scores from certain query\ntokens to a document block in middle layers strongly correlate with that\ndocument's actual relevance. Motivated by these observations, we introduce\nBlockRank (Blockwise In-context Ranking), a novel method that adapts the\nattention operation in an LLM by (a) architecturally enforcing the observed\ninter-document block sparsity, reducing attention complexity from quadratic to\nlinear without loss in performance, and (b) optimizing query-document block\nrelevance for true relevant documents during fine-tuning using an auxiliary\ncontrastive training objective, improving retrieval in attention. Experiments\non BEIR, MSMarco and NQ with Mistral-7B demonstrate that FLARE Mistral matches\nor outperforms existing SOTA listwise rankers and controlled fine-tuned\nbaseline while being significantly more efficient at inference (4.7x for 100\nMSMarco documents in context) and scaling gracefully to long-context\nshortlists, around 500 documents in-context (approximately 100K context length)\nwithin a second, presenting a scalable and effective solution for ICR.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05396.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6527151d5606f146974d60d8",
            "avatarUrl": "/avatars/00ac8ab005ceadae866dea5471f6aab9.svg",
            "fullname": "Nilesh Gupta",
            "name": "quicktensor",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "5e6aca39878b8b2bf9806447",
            "name": "google",
            "fullname": "Google",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/WtA3YYitedOr9n02eHfJe.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.03978",
            "authors": [
                {
                    "_id": "68e5eb39975ac4c405ef215a",
                    "name": "Min Woo Sun",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef215b",
                    "name": "Alejandro Lozano",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef215c",
                    "name": "Javier Gamazo Tejero",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef215d",
                    "name": "Vishwesh Nath",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef215e",
                    "name": "Xiao Xiao Sun",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef215f",
                    "name": "James Burgess",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef2160",
                    "name": "Yuhui Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef2161",
                    "name": "Kun Yuan",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef2162",
                    "name": "Robert Tibshirani",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef2163",
                    "name": "Sean Huver",
                    "hidden": false
                },
                {
                    "_id": "68e5eb39975ac4c405ef2164",
                    "name": "Serena Yeung-Levy",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-04T23:38:18.000Z",
            "submittedOnDailyAt": "2025-10-08T03:12:01.211Z",
            "title": "No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language\n  Models",
            "submittedOnDailyBy": {
                "_id": "65ac61120844d9e0d67a9f89",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65ac61120844d9e0d67a9f89/wvXAMRs44oww2M57ZJGqT.jpeg",
                "isPro": false,
                "fullname": "Min Woo Sun",
                "user": "minwoosun",
                "type": "user"
            },
            "summary": "Embedding vision-language models (VLMs) are typically pretrained with short\ntext windows (<77 tokens), which forces the truncation of long-format captions.\nYet, the distribution of biomedical captions from large-scale open source\nliterature reveals that a huge portion of captions far exceed 77 tokens. To\nthis end, we investigate the impact of pretraining on long-format biomedical\ncaptions by extending the context length of text encoders in VLMs. We find that\nlonger context (thus, enabling additional supervision provided in long-format\ncaptions) correlates with better retrieval and classification performance.\nGiven this finding, we introduce BIOMEDICA-LongCAP, a dataset of 1M\nimage-caption pairs enriched with context-aware descriptions from full-text\narticles, providing longer and additional textual supervision. Using\nBIOMEDICA-LongCAP, we train BMC-LongCLIP, a long-context biomedical VLM with a\ntext encoder supporting windows of up to 512 tokens. Our model extends context\ncapacity by 6.6x, reducing token waste from 55% to just 2.2%. On long-caption\nretrieval benchmarks, BMC-LongCLIP achieves up to +30% absolute gains in\nRecall@1 and +2% average improvements in classification, while also converging\nfaster than short-context. Our results demonstrate that long-context modeling\nis a promising direction for advancing biomedical VLMs.",
            "upvotes": 2,
            "discussionId": "68e5eb39975ac4c405ef2165",
            "githubRepo": "https://github.com/minwoosun/open_clip_bmc",
            "ai_summary": "Extending the context length of text encoders in vision-language models improves performance on biomedical caption tasks by utilizing longer and more detailed descriptions.",
            "ai_keywords": [
                "embedding vision-language models",
                "VLMs",
                "text encoders",
                "biomedical captions",
                "context length",
                "token windows",
                "long-format captions",
                "BIOMEDICA-LongCAP",
                "BMC-LongCLIP",
                "long-context modeling",
                "Recall@1",
                "classification performance"
            ],
            "githubStars": 1
        },
        "publishedAt": "2025-10-04T19:38:18.000Z",
        "title": "No Tokens Wasted: Leveraging Long Context in Biomedical Vision-Language\n  Models",
        "summary": "Embedding vision-language models (VLMs) are typically pretrained with short\ntext windows (<77 tokens), which forces the truncation of long-format captions.\nYet, the distribution of biomedical captions from large-scale open source\nliterature reveals that a huge portion of captions far exceed 77 tokens. To\nthis end, we investigate the impact of pretraining on long-format biomedical\ncaptions by extending the context length of text encoders in VLMs. We find that\nlonger context (thus, enabling additional supervision provided in long-format\ncaptions) correlates with better retrieval and classification performance.\nGiven this finding, we introduce BIOMEDICA-LongCAP, a dataset of 1M\nimage-caption pairs enriched with context-aware descriptions from full-text\narticles, providing longer and additional textual supervision. Using\nBIOMEDICA-LongCAP, we train BMC-LongCLIP, a long-context biomedical VLM with a\ntext encoder supporting windows of up to 512 tokens. Our model extends context\ncapacity by 6.6x, reducing token waste from 55% to just 2.2%. On long-caption\nretrieval benchmarks, BMC-LongCLIP achieves up to +30% absolute gains in\nRecall@1 and +2% average improvements in classification, while also converging\nfaster than short-context. Our results demonstrate that long-context modeling\nis a promising direction for advancing biomedical VLMs.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.03978.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65ac61120844d9e0d67a9f89",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65ac61120844d9e0d67a9f89/wvXAMRs44oww2M57ZJGqT.jpeg",
            "fullname": "Min Woo Sun",
            "name": "minwoosun",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 21
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.02341",
            "authors": [
                {
                    "_id": "68e5c815975ac4c405ef20df",
                    "user": {
                        "_id": "647693afb9c742c51117e1fa",
                        "avatarUrl": "/avatars/6a7a3f0f47588b5c38881b289d042b7a.svg",
                        "isPro": false,
                        "fullname": "Yifan Wang",
                        "user": "AmberYifan",
                        "type": "user"
                    },
                    "name": "Yifan Wang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T05:49:24.565Z",
                    "hidden": false
                },
                {
                    "_id": "68e5c815975ac4c405ef20e0",
                    "name": "Bolian Li",
                    "hidden": false
                },
                {
                    "_id": "68e5c815975ac4c405ef20e1",
                    "name": "Junlin Wu",
                    "hidden": false
                },
                {
                    "_id": "68e5c815975ac4c405ef20e2",
                    "name": "Zhaoxuan Tan",
                    "hidden": false
                },
                {
                    "_id": "68e5c815975ac4c405ef20e3",
                    "name": "Zheli Liu",
                    "hidden": false
                },
                {
                    "_id": "68e5c815975ac4c405ef20e4",
                    "name": "Ruqi Zhang",
                    "hidden": false
                },
                {
                    "_id": "68e5c815975ac4c405ef20e5",
                    "name": "Ananth Grama",
                    "hidden": false
                },
                {
                    "_id": "68e5c815975ac4c405ef20e6",
                    "name": "Qingkai Zeng",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-27T03:06:27.000Z",
            "submittedOnDailyAt": "2025-10-08T00:43:22.431Z",
            "title": "DRIFT: Learning from Abundant User Dissatisfaction in Real-World\n  Preference Learning",
            "submittedOnDailyBy": {
                "_id": "647693afb9c742c51117e1fa",
                "avatarUrl": "/avatars/6a7a3f0f47588b5c38881b289d042b7a.svg",
                "isPro": false,
                "fullname": "Yifan Wang",
                "user": "AmberYifan",
                "type": "user"
            },
            "summary": "Real-world large language model deployments (e.g., conversational AI systems,\ncode generation assistants) naturally generate abundant implicit user\ndissatisfaction (DSAT) signals, as users iterate toward better answers through\nrefinements, corrections, and expressed preferences, while explicit\nsatisfaction (SAT) feedback is scarce. Existing preference learning approaches\nare poorly aligned with this data profile, as they rely on costly human\nannotations or assume plentiful positive responses. In this paper, we introduce\nDRIFT (Dissatisfaction-Refined Iterative\npreFerence Training), which anchors training on real-world\nDSAT signals and samples positives dynamically from the evolving policy.\nEmpirically, DRIFT models trained on real-world WildFeedback datasets\nand synthetic UltraFeedback datasets achieve up to +6.23\\% (7B) /\n+7.61\\% (14B) on WildBench Task Score and up to +8.95\\% (7B) / +12.29\\% (14B)\non AlpacaEval2 win rate over base models, outperforming strong baseline methods\nsuch as iterative DPO and SPIN. At larger scales, the improvements are\nparticularly pronounced: 14B models trained with DRIFT surpass GPT-4o-mini on\nWildBench. Further analysis shows that DRIFT also preserves exploratory\ncapacity, yielding more diverse high-reward solutions rather than collapsing to\nnarrow subsets. Theoretically, we demonstrate that this design preserves\npreference margins and avoids the gradient degeneration. These results show\nthat DRIFT is an effective and scalable recipe for real-world post-training\nthat leverages the most abundant and informative signal. The code and data are\navailable at https://github.com/cacayaya/DRIFT.git.",
            "upvotes": 2,
            "discussionId": "68e5c815975ac4c405ef20e7",
            "githubRepo": "https://github.com/cacayaya/DRIFT",
            "ai_summary": "DRIFT, a dissatisfaction-refined iterative preference training method, improves large language models using implicit user dissatisfaction signals, achieving better performance than existing methods on real-world datasets.",
            "ai_keywords": [
                "DRIFT",
                "Dissatisfaction-Refined Iterative Preference Training",
                "WildFeedback",
                "UltraFeedback",
                "WildBench Task Score",
                "AlpacaEval2 win rate",
                "iterative DPO",
                "SPIN",
                "gradient degeneration",
                "preference margins",
                "exploratory capacity"
            ],
            "githubStars": 0
        },
        "publishedAt": "2025-09-26T23:06:27.000Z",
        "title": "DRIFT: Learning from Abundant User Dissatisfaction in Real-World\n  Preference Learning",
        "summary": "Real-world large language model deployments (e.g., conversational AI systems,\ncode generation assistants) naturally generate abundant implicit user\ndissatisfaction (DSAT) signals, as users iterate toward better answers through\nrefinements, corrections, and expressed preferences, while explicit\nsatisfaction (SAT) feedback is scarce. Existing preference learning approaches\nare poorly aligned with this data profile, as they rely on costly human\nannotations or assume plentiful positive responses. In this paper, we introduce\nDRIFT (Dissatisfaction-Refined Iterative\npreFerence Training), which anchors training on real-world\nDSAT signals and samples positives dynamically from the evolving policy.\nEmpirically, DRIFT models trained on real-world WildFeedback datasets\nand synthetic UltraFeedback datasets achieve up to +6.23\\% (7B) /\n+7.61\\% (14B) on WildBench Task Score and up to +8.95\\% (7B) / +12.29\\% (14B)\non AlpacaEval2 win rate over base models, outperforming strong baseline methods\nsuch as iterative DPO and SPIN. At larger scales, the improvements are\nparticularly pronounced: 14B models trained with DRIFT surpass GPT-4o-mini on\nWildBench. Further analysis shows that DRIFT also preserves exploratory\ncapacity, yielding more diverse high-reward solutions rather than collapsing to\nnarrow subsets. Theoretically, we demonstrate that this design preserves\npreference margins and avoids the gradient degeneration. These results show\nthat DRIFT is an effective and scalable recipe for real-world post-training\nthat leverages the most abundant and informative signal. The code and data are\navailable at https://github.com/cacayaya/DRIFT.git.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.02341.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "647693afb9c742c51117e1fa",
            "avatarUrl": "/avatars/6a7a3f0f47588b5c38881b289d042b7a.svg",
            "fullname": "Yifan Wang",
            "name": "AmberYifan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2509.21499",
            "authors": [
                {
                    "_id": "68dee350df49fb0df1e03acb",
                    "name": "Abdul Waheed",
                    "hidden": false
                },
                {
                    "_id": "68dee350df49fb0df1e03acc",
                    "user": {
                        "_id": "65e13a4b06c9c86f2515afdf",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65e13a4b06c9c86f2515afdf/-ozW4YbRrzsBInoQU-4pP.jpeg",
                        "isPro": false,
                        "fullname": "Zhen Wu",
                        "user": "swzwan",
                        "type": "user"
                    },
                    "name": "Zhen Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T13:49:48.950Z",
                    "hidden": false
                },
                {
                    "_id": "68dee350df49fb0df1e03acd",
                    "name": "Carolyn Rosé",
                    "hidden": false
                },
                {
                    "_id": "68dee350df49fb0df1e03ace",
                    "name": "Daphne Ippolito",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-09-25T19:57:36.000Z",
            "submittedOnDailyAt": "2025-10-08T12:53:45.789Z",
            "title": "On Code-Induced Reasoning in LLMs",
            "submittedOnDailyBy": {
                "_id": "65e13a4b06c9c86f2515afdf",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65e13a4b06c9c86f2515afdf/-ozW4YbRrzsBInoQU-4pP.jpeg",
                "isPro": false,
                "fullname": "Zhen Wu",
                "user": "swzwan",
                "type": "user"
            },
            "summary": "Code data has been shown to enhance the reasoning capabilities of large\nlanguage models (LLMs), but it remains unclear which aspects of code are most\nresponsible. We investigate this question with a systematic, data-centric\nframework. We construct parallel instruction datasets in ten programming\nlanguages and apply controlled perturbations that selectively disrupt\nstructural or semantic properties of code. We then finetune LLMs from five\nmodel families and eight scales on each variant and evaluate their performance\non natural language, math, and code tasks. Across 3,331 experiments, our\nresults show that LLMs are more vulnerable to structural perturbations than\nsemantic ones, particularly on math and code tasks. Appropriate abstractions\nlike pseudocode and flowcharts can be as effective as code, while encoding the\nsame information with fewer tokens without adhering to original syntax can\noften retain or even improve performance. Remarkably, even corrupted code with\nmisleading signals remains competitive when surface-level regularities persist.\nFinally, syntactic styles also shape task-specific gains with Python favoring\nnatural language reasoning and lower-level languages such as Java and Rust\nfavoring math. Through our systematic framework, we aim to provide insight into\nhow different properties of code influence reasoning and inform the design of\ntraining data for enhancing LLM reasoning capabilities.",
            "upvotes": 2,
            "discussionId": "68dee351df49fb0df1e03acf",
            "ai_summary": "Systematic investigation reveals that large language models are more sensitive to structural than semantic code perturbations, with implications for training data design.",
            "ai_keywords": [
                "large language models",
                "LLMs",
                "instruction datasets",
                "programming languages",
                "controlled perturbations",
                "structural perturbations",
                "semantic perturbations",
                "pseudocode",
                "flowcharts",
                "token encoding",
                "syntactic styles",
                "natural language reasoning",
                "math reasoning"
            ],
            "organization": {
                "_id": "64a952283c201fd38df887e0",
                "name": "CarnegieMellonCS",
                "fullname": "Carnegie Mellon University Computer Science",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63c32ecc8cc87cf0c065be72/SEtHxt-4616aXDZOpEtDF.jpeg"
            }
        },
        "publishedAt": "2025-09-25T15:57:36.000Z",
        "title": "On Code-Induced Reasoning in LLMs",
        "summary": "Code data has been shown to enhance the reasoning capabilities of large\nlanguage models (LLMs), but it remains unclear which aspects of code are most\nresponsible. We investigate this question with a systematic, data-centric\nframework. We construct parallel instruction datasets in ten programming\nlanguages and apply controlled perturbations that selectively disrupt\nstructural or semantic properties of code. We then finetune LLMs from five\nmodel families and eight scales on each variant and evaluate their performance\non natural language, math, and code tasks. Across 3,331 experiments, our\nresults show that LLMs are more vulnerable to structural perturbations than\nsemantic ones, particularly on math and code tasks. Appropriate abstractions\nlike pseudocode and flowcharts can be as effective as code, while encoding the\nsame information with fewer tokens without adhering to original syntax can\noften retain or even improve performance. Remarkably, even corrupted code with\nmisleading signals remains competitive when surface-level regularities persist.\nFinally, syntactic styles also shape task-specific gains with Python favoring\nnatural language reasoning and lower-level languages such as Java and Rust\nfavoring math. Through our systematic framework, we aim to provide insight into\nhow different properties of code influence reasoning and inform the design of\ntraining data for enhancing LLM reasoning capabilities.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2509.21499.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "65e13a4b06c9c86f2515afdf",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/65e13a4b06c9c86f2515afdf/-ozW4YbRrzsBInoQU-4pP.jpeg",
            "fullname": "Zhen Wu",
            "name": "swzwan",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "organization": {
            "_id": "64a952283c201fd38df887e0",
            "name": "CarnegieMellonCS",
            "fullname": "Carnegie Mellon University Computer Science",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/63c32ecc8cc87cf0c065be72/SEtHxt-4616aXDZOpEtDF.jpeg"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.06596",
            "authors": [
                {
                    "_id": "68e7073f7ae125f9582e6873",
                    "name": "Ayush Zenith",
                    "hidden": false
                },
                {
                    "_id": "68e7073f7ae125f9582e6874",
                    "name": "Arnold Zumbrun",
                    "hidden": false
                },
                {
                    "_id": "68e7073f7ae125f9582e6875",
                    "name": "Neel Raut",
                    "hidden": false
                },
                {
                    "_id": "68e7073f7ae125f9582e6876",
                    "name": "Jing Lin",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-08T03:01:26.000Z",
            "submittedOnDailyAt": "2025-10-08T23:27:10.962Z",
            "title": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset\n  Evaluation",
            "submittedOnDailyBy": {
                "_id": "641a78a24577db917f6fe90a",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/641a78a24577db917f6fe90a/SDFCNsBD7UP3b_Ce0jSEW.jpeg",
                "isPro": false,
                "fullname": "Ayush Zenith",
                "user": "ayushzenith",
                "type": "user"
            },
            "summary": "The performance of machine learning models depends heavily on training data.\nThe scarcity of large-scale, well-annotated datasets poses significant\nchallenges in creating robust models. To address this, synthetic data generated\nthrough simulations and generative models has emerged as a promising solution,\nenhancing dataset diversity and improving the performance, reliability, and\nresilience of models. However, evaluating the quality of this generated data\nrequires an effective metric. This paper introduces the Synthetic Dataset\nQuality Metric (SDQM) to assess data quality for object detection tasks without\nrequiring model training to converge. This metric enables more efficient\ngeneration and selection of synthetic datasets, addressing a key challenge in\nresource-constrained object detection tasks. In our experiments, SDQM\ndemonstrated a strong correlation with the mean Average Precision (mAP) scores\nof YOLOv11, a leading object detection model, while previous metrics only\nexhibited moderate or weak correlations. Additionally, it provides actionable\ninsights for improving dataset quality, minimizing the need for costly\niterative training. This scalable and efficient metric sets a new standard for\nevaluating synthetic data. The code for SDQM is available at\nhttps://github.com/ayushzenith/SDQM",
            "upvotes": 1,
            "discussionId": "68e7073f7ae125f9582e6877",
            "githubRepo": "https://github.com/ayushzenith/SDQM",
            "ai_summary": "A new metric, SDQM, evaluates synthetic data quality for object detection tasks without requiring model convergence, improving dataset selection and quality.",
            "ai_keywords": [
                "synthetic data",
                "generative models",
                "object detection",
                "Synthetic Dataset Quality Metric",
                "mean Average Precision",
                "YOLOv11"
            ],
            "githubStars": 2
        },
        "publishedAt": "2025-10-07T23:01:26.000Z",
        "title": "SDQM: Synthetic Data Quality Metric for Object Detection Dataset\n  Evaluation",
        "summary": "The performance of machine learning models depends heavily on training data.\nThe scarcity of large-scale, well-annotated datasets poses significant\nchallenges in creating robust models. To address this, synthetic data generated\nthrough simulations and generative models has emerged as a promising solution,\nenhancing dataset diversity and improving the performance, reliability, and\nresilience of models. However, evaluating the quality of this generated data\nrequires an effective metric. This paper introduces the Synthetic Dataset\nQuality Metric (SDQM) to assess data quality for object detection tasks without\nrequiring model training to converge. This metric enables more efficient\ngeneration and selection of synthetic datasets, addressing a key challenge in\nresource-constrained object detection tasks. In our experiments, SDQM\ndemonstrated a strong correlation with the mean Average Precision (mAP) scores\nof YOLOv11, a leading object detection model, while previous metrics only\nexhibited moderate or weak correlations. Additionally, it provides actionable\ninsights for improving dataset quality, minimizing the need for costly\niterative training. This scalable and efficient metric sets a new standard for\nevaluating synthetic data. The code for SDQM is available at\nhttps://github.com/ayushzenith/SDQM",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06596.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "641a78a24577db917f6fe90a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/641a78a24577db917f6fe90a/SDFCNsBD7UP3b_Ce0jSEW.jpeg",
            "fullname": "Ayush Zenith",
            "name": "ayushzenith",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06528",
            "authors": [
                {
                    "_id": "68e701c57ae125f9582e6845",
                    "name": "Mingyang Yao",
                    "hidden": false
                },
                {
                    "_id": "68e701c57ae125f9582e6846",
                    "name": "Ke Chen",
                    "hidden": false
                },
                {
                    "_id": "68e701c57ae125f9582e6847",
                    "name": "Shlomo Dubnov",
                    "hidden": false
                },
                {
                    "_id": "68e701c57ae125f9582e6848",
                    "name": "Taylor Berg-Kirkpatrick",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-08T00:02:56.000Z",
            "submittedOnDailyAt": "2025-10-08T23:11:39.713Z",
            "title": "BACHI: Boundary-Aware Symbolic Chord Recognition Through Masked\n  Iterative Decoding on Pop and Classical Music",
            "submittedOnDailyBy": {
                "_id": "68250b55e6b679e8115d4f6c",
                "avatarUrl": "/avatars/d79ecb10d13ab90ba508d0f0cf13cd10.svg",
                "isPro": false,
                "fullname": "Mingyang Yao",
                "user": "Itsuki-music",
                "type": "user"
            },
            "summary": "Automatic chord recognition (ACR) via deep learning models has gradually\nachieved promising recognition accuracy, yet two key challenges remain. First,\nprior work has primarily focused on audio-domain ACR, while symbolic music\n(e.g., score) ACR has received limited attention due to data scarcity. Second,\nexisting methods still overlook strategies that are aligned with human music\nanalytical practices. To address these challenges, we make two contributions:\n(1) we introduce POP909-CL, an enhanced version of POP909 dataset with\ntempo-aligned content and human-corrected labels of chords, beats, keys, and\ntime signatures; and (2) We propose BACHI, a symbolic chord recognition model\nthat decomposes the task into different decision steps, namely boundary\ndetection and iterative ranking of chord root, quality, and bass (inversion).\nThis mechanism mirrors the human ear-training practices. Experiments\ndemonstrate that BACHI achieves state-of-the-art chord recognition performance\non both classical and pop music benchmarks, with ablation studies validating\nthe effectiveness of each module.",
            "upvotes": 1,
            "discussionId": "68e701c67ae125f9582e6849",
            "ai_summary": "BACHI, a symbolic chord recognition model, achieves state-of-the-art performance by decomposing the task into boundary detection and iterative ranking, using an enhanced POP909-CL dataset.",
            "ai_keywords": [
                "automatic chord recognition",
                "deep learning models",
                "symbolic music",
                "POP909-CL dataset",
                "BACHI model",
                "boundary detection",
                "iterative ranking",
                "chord root",
                "chord quality",
                "bass inversion",
                "human ear-training practices"
            ],
            "organization": {
                "_id": "627fedf80d2c1c0ba3dde2a3",
                "name": "ucsd",
                "fullname": "UCSD"
            }
        },
        "publishedAt": "2025-10-07T20:02:56.000Z",
        "title": "BACHI: Boundary-Aware Symbolic Chord Recognition Through Masked\n  Iterative Decoding on Pop and Classical Music",
        "summary": "Automatic chord recognition (ACR) via deep learning models has gradually\nachieved promising recognition accuracy, yet two key challenges remain. First,\nprior work has primarily focused on audio-domain ACR, while symbolic music\n(e.g., score) ACR has received limited attention due to data scarcity. Second,\nexisting methods still overlook strategies that are aligned with human music\nanalytical practices. To address these challenges, we make two contributions:\n(1) we introduce POP909-CL, an enhanced version of POP909 dataset with\ntempo-aligned content and human-corrected labels of chords, beats, keys, and\ntime signatures; and (2) We propose BACHI, a symbolic chord recognition model\nthat decomposes the task into different decision steps, namely boundary\ndetection and iterative ranking of chord root, quality, and bass (inversion).\nThis mechanism mirrors the human ear-training practices. Experiments\ndemonstrate that BACHI achieves state-of-the-art chord recognition performance\non both classical and pop music benchmarks, with ablation studies validating\nthe effectiveness of each module.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06528.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "68250b55e6b679e8115d4f6c",
            "avatarUrl": "/avatars/d79ecb10d13ab90ba508d0f0cf13cd10.svg",
            "fullname": "Mingyang Yao",
            "name": "Itsuki-music",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 1
        },
        "organization": {
            "_id": "627fedf80d2c1c0ba3dde2a3",
            "name": "ucsd",
            "fullname": "UCSD"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06213",
            "authors": [
                {
                    "_id": "68e644c3975ac4c405ef224d",
                    "name": "Albert Catalan-Tatjer",
                    "hidden": false
                },
                {
                    "_id": "68e644c3975ac4c405ef224e",
                    "name": "Niccolò Ajroldi",
                    "hidden": false
                },
                {
                    "_id": "68e644c3975ac4c405ef224f",
                    "name": "Jonas Geiping",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T17:59:07.000Z",
            "submittedOnDailyAt": "2025-10-08T09:34:11.949Z",
            "title": "Training Dynamics Impact Post-Training Quantization Robustness",
            "submittedOnDailyBy": {
                "_id": "63d86dbf3130cadcaf8bdd11",
                "avatarUrl": "/avatars/29d79a0c6dcec01111ef192fecd0fa7a.svg",
                "isPro": false,
                "fullname": "Jonas Geiping",
                "user": "JonasGeiping",
                "type": "user"
            },
            "summary": "While post-training quantization is widely adopted for efficient deployment\nof large language models, the mechanisms underlying quantization robustness\nremain unclear. We conduct a comprehensive analysis of quantization degradation\nacross open-source language model training trajectories up to 32B parameters\nand 15T training tokens to accurately assess the relationship between training\ndynamics and quantization performance. Our key finding is that quantization\nerrors in large-scale training runs are driven by a complex interplay between\nlearning rate and other training hyperparameters. Specifically, once learning\nrates decay, validation loss and quantization error diverge, largely\nindependent of training data scale. To investigate interventions on the\ntraining dynamics and identify specific configurations that can modulate\nquantization robustness favorably, we train our own models in controlled\nexperiments up to 100B tokens. Our results challenge the assumption that\nincreasing dataset scale inherently compromises quantization effectiveness,\ndemonstrating instead that strategic training hyperparameter interventions can\nimprove quantization quality at scale.",
            "upvotes": 1,
            "discussionId": "68e644c3975ac4c405ef2250",
            "ai_summary": "Quantization robustness in large language models is influenced by learning rate and other hyperparameters, not dataset scale, as demonstrated through controlled training experiments.",
            "ai_keywords": [
                "post-training quantization",
                "large language models",
                "quantization degradation",
                "training trajectories",
                "quantization performance",
                "learning rate",
                "training hyperparameters",
                "validation loss",
                "quantization error",
                "dataset scale",
                "training dynamics",
                "quantization robustness",
                "strategic training hyperparameter interventions"
            ]
        },
        "publishedAt": "2025-10-07T13:59:07.000Z",
        "title": "Training Dynamics Impact Post-Training Quantization Robustness",
        "summary": "While post-training quantization is widely adopted for efficient deployment\nof large language models, the mechanisms underlying quantization robustness\nremain unclear. We conduct a comprehensive analysis of quantization degradation\nacross open-source language model training trajectories up to 32B parameters\nand 15T training tokens to accurately assess the relationship between training\ndynamics and quantization performance. Our key finding is that quantization\nerrors in large-scale training runs are driven by a complex interplay between\nlearning rate and other training hyperparameters. Specifically, once learning\nrates decay, validation loss and quantization error diverge, largely\nindependent of training data scale. To investigate interventions on the\ntraining dynamics and identify specific configurations that can modulate\nquantization robustness favorably, we train our own models in controlled\nexperiments up to 100B tokens. Our results challenge the assumption that\nincreasing dataset scale inherently compromises quantization effectiveness,\ndemonstrating instead that strategic training hyperparameter interventions can\nimprove quantization quality at scale.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06213.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63d86dbf3130cadcaf8bdd11",
            "avatarUrl": "/avatars/29d79a0c6dcec01111ef192fecd0fa7a.svg",
            "fullname": "Jonas Geiping",
            "name": "JonasGeiping",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 33
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06139",
            "authors": [
                {
                    "_id": "68e5c2b6975ac4c405ef20a8",
                    "name": "Zanyi Wang",
                    "hidden": false
                },
                {
                    "_id": "68e5c2b6975ac4c405ef20a9",
                    "name": "Dengyang Jiang",
                    "hidden": false
                },
                {
                    "_id": "68e5c2b6975ac4c405ef20aa",
                    "name": "Liuzhuozheng Li",
                    "hidden": false
                },
                {
                    "_id": "68e5c2b6975ac4c405ef20ab",
                    "name": "Sizhe Dang",
                    "hidden": false
                },
                {
                    "_id": "68e5c2b6975ac4c405ef20ac",
                    "name": "Chengzu Li",
                    "hidden": false
                },
                {
                    "_id": "68e5c2b6975ac4c405ef20ad",
                    "name": "Harry Yang",
                    "hidden": false
                },
                {
                    "_id": "68e5c2b6975ac4c405ef20ae",
                    "name": "Guang Dai",
                    "hidden": false
                },
                {
                    "_id": "68e5c2b6975ac4c405ef20af",
                    "name": "Mengmeng Wang",
                    "hidden": false
                },
                {
                    "_id": "68e5c2b6975ac4c405ef20b0",
                    "name": "Jingdong Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T17:14:10.000Z",
            "submittedOnDailyAt": "2025-10-08T00:17:52.028Z",
            "title": "Deforming Videos to Masks: Flow Matching for Referring Video\n  Segmentation",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Referring Video Object Segmentation (RVOS) requires segmenting specific\nobjects in a video guided by a natural language description. The core challenge\nof RVOS is to anchor abstract linguistic concepts onto a specific set of pixels\nand continuously segment them through the complex dynamics of a video. Faced\nwith this difficulty, prior work has often decomposed the task into a pragmatic\n`locate-then-segment' pipeline. However, this cascaded design creates an\ninformation bottleneck by simplifying semantics into coarse geometric prompts\n(e.g, point), and struggles to maintain temporal consistency as the segmenting\nprocess is often decoupled from the initial language grounding. To overcome\nthese fundamental limitations, we propose FlowRVS, a novel framework that\nreconceptualizes RVOS as a conditional continuous flow problem. This allows us\nto harness the inherent strengths of pretrained T2V models, fine-grained pixel\ncontrol, text-video semantic alignment, and temporal coherence. Instead of\nconventional generating from noise to mask or directly predicting mask, we\nreformulate the task by learning a direct, language-guided deformation from a\nvideo's holistic representation to its target mask. Our one-stage, generative\napproach achieves new state-of-the-art results across all major RVOS\nbenchmarks. Specifically, achieving a J&F of 51.1 in\nMeViS (+1.6 over prior SOTA) and 73.3 in the zero shot Ref-DAVIS17 (+2.7),\ndemonstrating the significant potential of modeling video understanding tasks\nas continuous deformation processes.",
            "upvotes": 1,
            "discussionId": "68e5c2b7975ac4c405ef20b1",
            "ai_summary": "FlowRVS addresses the challenges of Referring Video Object Segmentation by reformulating the task as a continuous flow problem, leveraging pretrained T2V models and achieving state-of-the-art results.",
            "ai_keywords": [
                "Referring Video Object Segmentation",
                "RVOS",
                "natural language description",
                "pixel control",
                "text-video semantic alignment",
                "temporal coherence",
                "FlowRVS",
                "T2V models",
                "continuous flow problem",
                "generative approach",
                "$\\mathcal{J}\\&\\mathcal{F}$",
                "MeViS",
                "Ref-DAVIS17"
            ]
        },
        "publishedAt": "2025-10-07T13:14:10.000Z",
        "title": "Deforming Videos to Masks: Flow Matching for Referring Video\n  Segmentation",
        "summary": "Referring Video Object Segmentation (RVOS) requires segmenting specific\nobjects in a video guided by a natural language description. The core challenge\nof RVOS is to anchor abstract linguistic concepts onto a specific set of pixels\nand continuously segment them through the complex dynamics of a video. Faced\nwith this difficulty, prior work has often decomposed the task into a pragmatic\n`locate-then-segment' pipeline. However, this cascaded design creates an\ninformation bottleneck by simplifying semantics into coarse geometric prompts\n(e.g, point), and struggles to maintain temporal consistency as the segmenting\nprocess is often decoupled from the initial language grounding. To overcome\nthese fundamental limitations, we propose FlowRVS, a novel framework that\nreconceptualizes RVOS as a conditional continuous flow problem. This allows us\nto harness the inherent strengths of pretrained T2V models, fine-grained pixel\ncontrol, text-video semantic alignment, and temporal coherence. Instead of\nconventional generating from noise to mask or directly predicting mask, we\nreformulate the task by learning a direct, language-guided deformation from a\nvideo's holistic representation to its target mask. Our one-stage, generative\napproach achieves new state-of-the-art results across all major RVOS\nbenchmarks. Specifically, achieving a J&F of 51.1 in\nMeViS (+1.6 over prior SOTA) and 73.3 in the zero shot Ref-DAVIS17 (+2.7),\ndemonstrating the significant potential of modeling video understanding tasks\nas continuous deformation processes.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06139.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 120
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06071",
            "authors": [
                {
                    "_id": "68e64331975ac4c405ef2247",
                    "user": {
                        "_id": "67ec4013d674ac4ba71dd264",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67ec4013d674ac4ba71dd264/eY5KFSwHfiRY7MwS0P2PY.jpeg",
                        "isPro": true,
                        "fullname": "João Palmeiro",
                        "user": "joaompalmeiro",
                        "type": "user"
                    },
                    "name": "João Palmeiro",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T11:48:46.449Z",
                    "hidden": false
                },
                {
                    "_id": "68e64331975ac4c405ef2248",
                    "name": "Diogo Duarte",
                    "hidden": false
                },
                {
                    "_id": "68e64331975ac4c405ef2249",
                    "name": "Rita Costa",
                    "hidden": false
                },
                {
                    "_id": "68e64331975ac4c405ef224a",
                    "name": "Pedro Bizarro",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T15:59:19.000Z",
            "submittedOnDailyAt": "2025-10-08T10:29:35.559Z",
            "title": "Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI\n  Models for Scatterplot-Related Tasks",
            "submittedOnDailyBy": {
                "_id": "67ec4013d674ac4ba71dd264",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67ec4013d674ac4ba71dd264/eY5KFSwHfiRY7MwS0P2PY.jpeg",
                "isPro": true,
                "fullname": "João Palmeiro",
                "user": "joaompalmeiro",
                "type": "user"
            },
            "summary": "AI models are increasingly used for data analysis and visualization, yet\nbenchmarks rarely address scatterplot-specific tasks, limiting insight into\nperformance. To address this gap for one of the most common chart types, we\nintroduce a synthetic, annotated dataset of over 18,000 scatterplots from six\ndata generators and 17 chart designs, and a benchmark based on it. We evaluate\nproprietary models from OpenAI and Google using N-shot prompting on five\ndistinct tasks derived from annotations of cluster bounding boxes, their center\ncoordinates, and outlier coordinates. OpenAI models and Gemini 2.5 Flash,\nespecially when prompted with examples, are viable options for counting\nclusters and, in Flash's case, outliers (90%+ Accuracy). However, the results\nfor localization-related tasks are unsatisfactory: Precision and Recall are\nnear or below 50%, except for Flash in outlier identification (65.01%).\nFurthermore, the impact of chart design on performance appears to be a\nsecondary factor, but it is advisable to avoid scatterplots with wide aspect\nratios (16:9 and 21:9) or those colored randomly. Supplementary materials are\navailable at https://github.com/feedzai/biy-paper.",
            "upvotes": 1,
            "discussionId": "68e64331975ac4c405ef224b",
            "githubRepo": "https://github.com/feedzai/biy-paper",
            "ai_summary": "A benchmark for scatterplot-specific tasks using synthetic datasets evaluates AI models' performance in counting clusters and identifying outliers, with mixed results for localization tasks.",
            "ai_keywords": [
                "N-shot prompting",
                "cluster bounding boxes",
                "center coordinates",
                "outlier coordinates",
                "localization-related tasks",
                "Precision",
                "Recall",
                "aspect ratios"
            ],
            "githubStars": 4
        },
        "publishedAt": "2025-10-07T11:59:19.000Z",
        "title": "Benchmark It Yourself (BIY): Preparing a Dataset and Benchmarking AI\n  Models for Scatterplot-Related Tasks",
        "summary": "AI models are increasingly used for data analysis and visualization, yet\nbenchmarks rarely address scatterplot-specific tasks, limiting insight into\nperformance. To address this gap for one of the most common chart types, we\nintroduce a synthetic, annotated dataset of over 18,000 scatterplots from six\ndata generators and 17 chart designs, and a benchmark based on it. We evaluate\nproprietary models from OpenAI and Google using N-shot prompting on five\ndistinct tasks derived from annotations of cluster bounding boxes, their center\ncoordinates, and outlier coordinates. OpenAI models and Gemini 2.5 Flash,\nespecially when prompted with examples, are viable options for counting\nclusters and, in Flash's case, outliers (90%+ Accuracy). However, the results\nfor localization-related tasks are unsatisfactory: Precision and Recall are\nnear or below 50%, except for Flash in outlier identification (65.01%).\nFurthermore, the impact of chart design on performance appears to be a\nsecondary factor, but it is advisable to avoid scatterplots with wide aspect\nratios (16:9 and 21:9) or those colored randomly. Supplementary materials are\navailable at https://github.com/feedzai/biy-paper.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06071.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "67ec4013d674ac4ba71dd264",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67ec4013d674ac4ba71dd264/eY5KFSwHfiRY7MwS0P2PY.jpeg",
            "fullname": "João Palmeiro",
            "name": "joaompalmeiro",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 8
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.06056",
            "authors": [
                {
                    "_id": "68e675e6975ac4c405ef2311",
                    "name": "Gang Liu",
                    "hidden": false
                },
                {
                    "_id": "68e675e6975ac4c405ef2312",
                    "name": "Yihan Zhu",
                    "hidden": false
                },
                {
                    "_id": "68e675e6975ac4c405ef2313",
                    "name": "Jie Chen",
                    "hidden": false
                },
                {
                    "_id": "68e675e6975ac4c405ef2314",
                    "name": "Meng Jiang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T15:49:51.000Z",
            "submittedOnDailyAt": "2025-10-08T13:03:16.173Z",
            "title": "Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep\n  Research",
            "submittedOnDailyBy": {
                "_id": "63bf1afd4a2beec65565ee90",
                "avatarUrl": "/avatars/134ac63b443e1360be7c91f84f9d5ec7.svg",
                "isPro": false,
                "fullname": "Gang Liu",
                "user": "liuganghuggingface",
                "type": "user"
            },
            "summary": "Large language models hold promise as scientific assistants, yet existing\nagents either rely solely on algorithm evolution or on deep research in\nisolation, both of which face critical limitations. Pure algorithm evolution,\nas in AlphaEvolve, depends only on the internal knowledge of LLMs and quickly\nplateaus in complex domains, while pure deep research proposes ideas without\nvalidation, resulting in unrealistic or unimplementable solutions. We present\nDeepEvolve, an agent that integrates deep research with algorithm evolution,\nuniting external knowledge retrieval, cross-file code editing, and systematic\ndebugging under a feedback-driven iterative loop. Each iteration not only\nproposes new hypotheses but also refines, implements, and tests them, avoiding\nboth shallow improvements and unproductive over-refinements. Across nine\nbenchmarks in chemistry, mathematics, biology, materials, and patents,\nDeepEvolve consistently improves the initial algorithm, producing executable\nnew algorithms with sustained gains. By bridging the gap between unguided\nevolution and research without grounding, DeepEvolve provides a reliable\nframework for advancing scientific algorithm discovery. Our code is available\nat https://github.com/liugangcode/deepevolve.",
            "upvotes": 1,
            "discussionId": "68e675e7975ac4c405ef2315",
            "githubRepo": "https://github.com/liugangcode/deepevolve",
            "ai_summary": "DeepEvolve integrates deep research with algorithm evolution to propose, refine, implement, and test new hypotheses, improving initial algorithms across various scientific domains.",
            "ai_keywords": [
                "large language models",
                "algorithm evolution",
                "deep research",
                "external knowledge retrieval",
                "cross-file code editing",
                "systematic debugging",
                "feedback-driven iterative loop",
                "executable new algorithms",
                "scientific algorithm discovery"
            ],
            "githubStars": 24
        },
        "publishedAt": "2025-10-07T11:49:51.000Z",
        "title": "Scientific Algorithm Discovery by Augmenting AlphaEvolve with Deep\n  Research",
        "summary": "Large language models hold promise as scientific assistants, yet existing\nagents either rely solely on algorithm evolution or on deep research in\nisolation, both of which face critical limitations. Pure algorithm evolution,\nas in AlphaEvolve, depends only on the internal knowledge of LLMs and quickly\nplateaus in complex domains, while pure deep research proposes ideas without\nvalidation, resulting in unrealistic or unimplementable solutions. We present\nDeepEvolve, an agent that integrates deep research with algorithm evolution,\nuniting external knowledge retrieval, cross-file code editing, and systematic\ndebugging under a feedback-driven iterative loop. Each iteration not only\nproposes new hypotheses but also refines, implements, and tests them, avoiding\nboth shallow improvements and unproductive over-refinements. Across nine\nbenchmarks in chemistry, mathematics, biology, materials, and patents,\nDeepEvolve consistently improves the initial algorithm, producing executable\nnew algorithms with sustained gains. By bridging the gap between unguided\nevolution and research without grounding, DeepEvolve provides a reliable\nframework for advancing scientific algorithm discovery. Our code is available\nat https://github.com/liugangcode/deepevolve.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06056.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "63bf1afd4a2beec65565ee90",
            "avatarUrl": "/avatars/134ac63b443e1360be7c91f84f9d5ec7.svg",
            "fullname": "Gang Liu",
            "name": "liuganghuggingface",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 3
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05681",
            "authors": [
                {
                    "_id": "68e64504975ac4c405ef2252",
                    "user": {
                        "_id": "67041a46d1fb54bd91a478fd",
                        "avatarUrl": "/avatars/6414c7c501857948a36a55036b0e1f8b.svg",
                        "isPro": false,
                        "fullname": "Suhyeok Jang",
                        "user": "glory-hyeok",
                        "type": "user"
                    },
                    "name": "Suhyeok Jang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T11:48:44.093Z",
                    "hidden": false
                },
                {
                    "_id": "68e64504975ac4c405ef2253",
                    "name": "Dongyoung Kim",
                    "hidden": false
                },
                {
                    "_id": "68e64504975ac4c405ef2254",
                    "name": "Changyeon Kim",
                    "hidden": false
                },
                {
                    "_id": "68e64504975ac4c405ef2255",
                    "name": "Youngsuk Kim",
                    "hidden": false
                },
                {
                    "_id": "68e64504975ac4c405ef2256",
                    "name": "Jinwoo Shin",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T08:38:08.000Z",
            "submittedOnDailyAt": "2025-10-08T11:24:42.516Z",
            "title": "Verifier-free Test-Time Sampling for Vision Language Action Models",
            "submittedOnDailyBy": {
                "_id": "67041a46d1fb54bd91a478fd",
                "avatarUrl": "/avatars/6414c7c501857948a36a55036b0e1f8b.svg",
                "isPro": false,
                "fullname": "Suhyeok Jang",
                "user": "glory-hyeok",
                "type": "user"
            },
            "summary": "Vision-Language-Action models (VLAs) have demonstrated remarkable performance\nin robot control. However, they remain fundamentally limited in tasks that\nrequire high precision due to their single-inference paradigm. While test-time\nscaling approaches using external verifiers have shown promise, they require\nadditional training and fail to generalize to unseen conditions. We propose\nMasking Distribution Guided Selection (MG-Select), a novel test-time scaling\nframework for VLAs that leverages the model's internal properties without\nrequiring additional training or external modules. Our approach utilizes KL\ndivergence from a reference action token distribution as a confidence metric\nfor selecting the optimal action from multiple candidates. We introduce a\nreference distribution generated by the same VLA but with randomly masked\nstates and language conditions as inputs, ensuring maximum uncertainty while\nremaining aligned with the target task distribution. Additionally, we propose a\njoint training strategy that enables the model to learn both conditional and\nunconditional distributions by applying dropout to state and language\nconditions, thereby further improving the quality of the reference\ndistribution. Our experiments demonstrate that MG-Select achieves significant\nperformance improvements, including a 28%/35% improvement in real-world\nin-distribution/out-of-distribution tasks, along with a 168% relative gain on\nRoboCasa pick-and-place tasks trained with 30 demonstrations.",
            "upvotes": 1,
            "discussionId": "68e64504975ac4c405ef2257",
            "ai_summary": "MG-Select, a novel test-time scaling framework for Vision-Language-Action models, improves performance by using KL divergence from a reference distribution generated with masked inputs, achieving significant gains in both in-distribution and out-of-distribution tasks.",
            "ai_keywords": [
                "Vision-Language-Action models",
                "test-time scaling",
                "KL divergence",
                "reference action token distribution",
                "masked states",
                "language conditions",
                "dropout",
                "RoboCasa pick-and-place tasks"
            ],
            "organization": {
                "_id": "6475760c33192631bad2bb38",
                "name": "kaist-ai",
                "fullname": "KAIST AI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6469949654873f0043b09c22/aaZFiyXe1qR-Dmy_xq67m.png"
            }
        },
        "publishedAt": "2025-10-07T04:38:08.000Z",
        "title": "Verifier-free Test-Time Sampling for Vision Language Action Models",
        "summary": "Vision-Language-Action models (VLAs) have demonstrated remarkable performance\nin robot control. However, they remain fundamentally limited in tasks that\nrequire high precision due to their single-inference paradigm. While test-time\nscaling approaches using external verifiers have shown promise, they require\nadditional training and fail to generalize to unseen conditions. We propose\nMasking Distribution Guided Selection (MG-Select), a novel test-time scaling\nframework for VLAs that leverages the model's internal properties without\nrequiring additional training or external modules. Our approach utilizes KL\ndivergence from a reference action token distribution as a confidence metric\nfor selecting the optimal action from multiple candidates. We introduce a\nreference distribution generated by the same VLA but with randomly masked\nstates and language conditions as inputs, ensuring maximum uncertainty while\nremaining aligned with the target task distribution. Additionally, we propose a\njoint training strategy that enables the model to learn both conditional and\nunconditional distributions by applying dropout to state and language\nconditions, thereby further improving the quality of the reference\ndistribution. Our experiments demonstrate that MG-Select achieves significant\nperformance improvements, including a 28%/35% improvement in real-world\nin-distribution/out-of-distribution tasks, along with a 168% relative gain on\nRoboCasa pick-and-place tasks trained with 30 demonstrations.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05681.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "67041a46d1fb54bd91a478fd",
            "avatarUrl": "/avatars/6414c7c501857948a36a55036b0e1f8b.svg",
            "fullname": "Suhyeok Jang",
            "name": "glory-hyeok",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "6475760c33192631bad2bb38",
            "name": "kaist-ai",
            "fullname": "KAIST AI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/6469949654873f0043b09c22/aaZFiyXe1qR-Dmy_xq67m.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04087",
            "authors": [
                {
                    "_id": "68e4715be4e093a7044e4cce",
                    "user": {
                        "_id": "6642dafed48363a46ddb69ed",
                        "avatarUrl": "/avatars/111fb26ea38fb2e6f8470f7ed513d48d.svg",
                        "isPro": false,
                        "fullname": "hyung gyu rho",
                        "user": "sirano1004",
                        "type": "user"
                    },
                    "name": "Hyung Gyu Rho",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-07T12:27:19.479Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-05T08:23:08.000Z",
            "submittedOnDailyAt": "2025-10-08T00:39:48.168Z",
            "title": "A Contextual Quality Reward Model for Reliable and Efficient Best-of-N\n  Sampling",
            "submittedOnDailyBy": {
                "_id": "6642dafed48363a46ddb69ed",
                "avatarUrl": "/avatars/111fb26ea38fb2e6f8470f7ed513d48d.svg",
                "isPro": false,
                "fullname": "hyung gyu rho",
                "user": "sirano1004",
                "type": "user"
            },
            "summary": "Modern preference alignment techniques, such as Best-of-N (BoN) sampling,\nrely on reward models trained with pairwise comparison data. While effective at\nlearning relative preferences, this paradigm fails to capture a signal of\nresponse acceptability, leaving systems vulnerable to selecting the least bad\nof many unacceptable options. This is particularly problematic for hard\nprompts, where the risk of such false acceptances increases with the number of\nsamples. In this paper, we address this critical reliability gap by introducing\na new data collection and modeling framework. By augmenting preference data\nwith an outside option, inspired by discrete choice models, we train a reward\nmodel that can distinguish not just what is better, but what is\ngood enough. We leverage this capability to create an adaptive\ninference strategy, best of mini-N in-loop, which partitions the generation\nbudget into sequential loops with a calibrated, early-exit condition. Our\nexperiments show that when tuned as an alignment guardrail, it reduces\nreliability failures by 70\\%, and when tuned as an inference accelerator, it\nimproves average inference speed by over 22\\% in IMDB-sentiment setting. We\nthus provide a principled and flexible framework for practitioners to\nexplicitly manage the trade-off between reliability and computational\nefficiency.",
            "upvotes": 1,
            "discussionId": "68e4715be4e093a7044e4ccf",
            "ai_summary": "A new framework using an outside option in preference data collection and modeling improves reliability and efficiency in preference alignment techniques.",
            "ai_keywords": [
                "Best-of-N (BoN) sampling",
                "reward models",
                "pairwise comparison data",
                "discrete choice models",
                "adaptive inference strategy",
                "best of mini-N in-loop",
                "reliability failures",
                "inference speed",
                "IMDB-sentiment setting"
            ]
        },
        "publishedAt": "2025-10-05T04:23:08.000Z",
        "title": "A Contextual Quality Reward Model for Reliable and Efficient Best-of-N\n  Sampling",
        "summary": "Modern preference alignment techniques, such as Best-of-N (BoN) sampling,\nrely on reward models trained with pairwise comparison data. While effective at\nlearning relative preferences, this paradigm fails to capture a signal of\nresponse acceptability, leaving systems vulnerable to selecting the least bad\nof many unacceptable options. This is particularly problematic for hard\nprompts, where the risk of such false acceptances increases with the number of\nsamples. In this paper, we address this critical reliability gap by introducing\na new data collection and modeling framework. By augmenting preference data\nwith an outside option, inspired by discrete choice models, we train a reward\nmodel that can distinguish not just what is better, but what is\ngood enough. We leverage this capability to create an adaptive\ninference strategy, best of mini-N in-loop, which partitions the generation\nbudget into sequential loops with a calibrated, early-exit condition. Our\nexperiments show that when tuned as an alignment guardrail, it reduces\nreliability failures by 70\\%, and when tuned as an inference accelerator, it\nimproves average inference speed by over 22\\% in IMDB-sentiment setting. We\nthus provide a principled and flexible framework for practitioners to\nexplicitly manage the trade-off between reliability and computational\nefficiency.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04087.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6642dafed48363a46ddb69ed",
            "avatarUrl": "/avatars/111fb26ea38fb2e6f8470f7ed513d48d.svg",
            "fullname": "hyung gyu rho",
            "name": "sirano1004",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.01353",
            "authors": [
                {
                    "_id": "68e6f1237ae125f9582e6835",
                    "name": "Darshan Deshpande",
                    "hidden": false
                },
                {
                    "_id": "68e6f1237ae125f9582e6836",
                    "name": "Varun Gangal",
                    "hidden": false
                },
                {
                    "_id": "68e6f1237ae125f9582e6837",
                    "name": "Hersh Mehta",
                    "hidden": false
                },
                {
                    "_id": "68e6f1237ae125f9582e6838",
                    "name": "Anand Kannappan",
                    "hidden": false
                },
                {
                    "_id": "68e6f1237ae125f9582e6839",
                    "name": "Rebecca Qian",
                    "hidden": false
                },
                {
                    "_id": "68e6f1237ae125f9582e683a",
                    "name": "Peng Wang",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/60390e04770949ef34f12d9b/tsfkXu-WUg_qqV5d3ycKe.png",
                "https://cdn-uploads.huggingface.co/production/uploads/60390e04770949ef34f12d9b/7buY-LMc-rdykl9saTuI2.png"
            ],
            "publishedAt": "2025-10-01T18:34:03.000Z",
            "submittedOnDailyAt": "2025-10-08T21:56:33.918Z",
            "title": "MEMTRACK: Evaluating Long-Term Memory and State Tracking in\n  Multi-Platform Dynamic Agent Environments",
            "submittedOnDailyBy": {
                "_id": "60390e04770949ef34f12d9b",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1632225571380-60390e04770949ef34f12d9b.jpeg",
                "isPro": false,
                "fullname": "Darshan Deshpande",
                "user": "DarshanDeshpande",
                "type": "user"
            },
            "summary": "Recent works on context and memory benchmarking have primarily focused on\nconversational instances but the need for evaluating memory in dynamic\nenterprise environments is crucial for its effective application. We introduce\nMEMTRACK, a benchmark designed to evaluate long-term memory and state tracking\nin multi-platform agent environments. MEMTRACK models realistic organizational\nworkflows by integrating asynchronous events across multiple communication and\nproductivity platforms such as Slack, Linear and Git. Each benchmark instance\nprovides a chronologically platform-interleaved timeline, with noisy,\nconflicting, cross-referring information as well as potential\ncodebase/file-system comprehension and exploration. Consequently, our benchmark\ntests memory capabilities such as acquistion, selection and conflict\nresolution. We curate the MEMTRACK dataset through both manual expert driven\ndesign and scalable agent based synthesis, generating ecologically valid\nscenarios grounded in real world software development processes. We introduce\npertinent metrics for Correctness, Efficiency, and Redundancy that capture the\neffectiveness of memory mechanisms beyond simple QA performance. Experiments\nacross SoTA LLMs and memory backends reveal challenges in utilizing memory\nacross long horizons, handling cross-platform dependencies, and resolving\ncontradictions. Notably, the best performing GPT-5 model only achieves a 60\\%\nCorrectness score on MEMTRACK. This work provides an extensible framework for\nadvancing evaluation research for memory-augmented agents, beyond existing\nfocus on conversational setups, and sets the stage for multi-agent,\nmulti-platform memory benchmarking in complex organizational settings",
            "upvotes": 1,
            "discussionId": "68e6f1247ae125f9582e683b",
            "ai_summary": "MEMTRACK is a benchmark for evaluating long-term memory and state tracking in multi-platform agent environments, focusing on dynamic enterprise settings and providing metrics for correctness, efficiency, and redundancy.",
            "ai_keywords": [
                "MEMTRACK",
                "long-term memory",
                "state tracking",
                "multi-platform agent environments",
                "asynchronous events",
                "Slack",
                "Linear",
                "Git",
                "chronological timeline",
                "noisy information",
                "conflicting information",
                "cross-referring information",
                "codebase comprehension",
                "file-system exploration",
                "memory acquisition",
                "memory selection",
                "conflict resolution",
                "MEMTRACK dataset",
                "Correctness",
                "Efficiency",
                "Redundancy",
                "SoTA LLMs",
                "memory backends",
                "GPT-5",
                "multi-agent",
                "multi-platform memory benchmarking"
            ],
            "organization": {
                "_id": "64c98cca7fe12ecd0a9f4a3d",
                "name": "PatronusAI",
                "fullname": "Patronus AI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/noauth/jOAWAvmqOod2rYsgdxF0w.png"
            }
        },
        "publishedAt": "2025-10-01T14:34:03.000Z",
        "title": "MEMTRACK: Evaluating Long-Term Memory and State Tracking in\n  Multi-Platform Dynamic Agent Environments",
        "summary": "Recent works on context and memory benchmarking have primarily focused on\nconversational instances but the need for evaluating memory in dynamic\nenterprise environments is crucial for its effective application. We introduce\nMEMTRACK, a benchmark designed to evaluate long-term memory and state tracking\nin multi-platform agent environments. MEMTRACK models realistic organizational\nworkflows by integrating asynchronous events across multiple communication and\nproductivity platforms such as Slack, Linear and Git. Each benchmark instance\nprovides a chronologically platform-interleaved timeline, with noisy,\nconflicting, cross-referring information as well as potential\ncodebase/file-system comprehension and exploration. Consequently, our benchmark\ntests memory capabilities such as acquistion, selection and conflict\nresolution. We curate the MEMTRACK dataset through both manual expert driven\ndesign and scalable agent based synthesis, generating ecologically valid\nscenarios grounded in real world software development processes. We introduce\npertinent metrics for Correctness, Efficiency, and Redundancy that capture the\neffectiveness of memory mechanisms beyond simple QA performance. Experiments\nacross SoTA LLMs and memory backends reveal challenges in utilizing memory\nacross long horizons, handling cross-platform dependencies, and resolving\ncontradictions. Notably, the best performing GPT-5 model only achieves a 60\\%\nCorrectness score on MEMTRACK. This work provides an extensible framework for\nadvancing evaluation research for memory-augmented agents, beyond existing\nfocus on conversational setups, and sets the stage for multi-agent,\nmulti-platform memory benchmarking in complex organizational settings",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/60390e04770949ef34f12d9b/tsfkXu-WUg_qqV5d3ycKe.png",
            "https://cdn-uploads.huggingface.co/production/uploads/60390e04770949ef34f12d9b/7buY-LMc-rdykl9saTuI2.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.01353.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "60390e04770949ef34f12d9b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1632225571380-60390e04770949ef34f12d9b.jpeg",
            "fullname": "Darshan Deshpande",
            "name": "DarshanDeshpande",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 4
        },
        "organization": {
            "_id": "64c98cca7fe12ecd0a9f4a3d",
            "name": "PatronusAI",
            "fullname": "Patronus AI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/noauth/jOAWAvmqOod2rYsgdxF0w.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06199",
            "authors": [
                {
                    "_id": "68e702757ae125f9582e684b",
                    "name": "Chengyang Zhao",
                    "hidden": false
                },
                {
                    "_id": "68e702757ae125f9582e684c",
                    "name": "Uksang Yoo",
                    "hidden": false
                },
                {
                    "_id": "68e702757ae125f9582e684d",
                    "name": "Arkadeep Narayan Chaudhury",
                    "hidden": false
                },
                {
                    "_id": "68e702757ae125f9582e684e",
                    "name": "Giljoo Nam",
                    "hidden": false
                },
                {
                    "_id": "68e702757ae125f9582e684f",
                    "name": "Jonathan Francis",
                    "hidden": false
                },
                {
                    "_id": "68e702757ae125f9582e6850",
                    "name": "Jeffrey Ichnowski",
                    "hidden": false
                },
                {
                    "_id": "68e702757ae125f9582e6851",
                    "name": "Jean Oh",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T17:53:56.000Z",
            "submittedOnDailyAt": "2025-10-08T23:11:11.235Z",
            "title": "DYMO-Hair: Generalizable Volumetric Dynamics Modeling for Robot Hair\n  Manipulation",
            "submittedOnDailyBy": {
                "_id": "679165b9c7f527ef3619504e",
                "avatarUrl": "/avatars/f3e6ce5fc3d05c8632d8b208f55c2987.svg",
                "isPro": false,
                "fullname": "Chengyang Zhao",
                "user": "chengyzhao",
                "type": "user"
            },
            "summary": "Hair care is an essential daily activity, yet it remains inaccessible to\nindividuals with limited mobility and challenging for autonomous robot systems\ndue to the fine-grained physical structure and complex dynamics of hair. In\nthis work, we present DYMO-Hair, a model-based robot hair care system. We\nintroduce a novel dynamics learning paradigm that is suited for volumetric\nquantities such as hair, relying on an action-conditioned latent state editing\nmechanism, coupled with a compact 3D latent space of diverse hairstyles to\nimprove generalizability. This latent space is pre-trained at scale using a\nnovel hair physics simulator, enabling generalization across previously unseen\nhairstyles. Using the dynamics model with a Model Predictive Path Integral\n(MPPI) planner, DYMO-Hair is able to perform visual goal-conditioned hair\nstyling. Experiments in simulation demonstrate that DYMO-Hair's dynamics model\noutperforms baselines on capturing local deformation for diverse, unseen\nhairstyles. DYMO-Hair further outperforms baselines in closed-loop hair styling\ntasks on unseen hairstyles, with an average of 22% lower final geometric error\nand 42% higher success rate than the state-of-the-art system. Real-world\nexperiments exhibit zero-shot transferability of our system to wigs, achieving\nconsistent success on challenging unseen hairstyles where the state-of-the-art\nsystem fails. Together, these results introduce a foundation for model-based\nrobot hair care, advancing toward more generalizable, flexible, and accessible\nrobot hair styling in unconstrained physical environments. More details are\navailable on our project page: https://chengyzhao.github.io/DYMOHair-web/.",
            "upvotes": 0,
            "discussionId": "68e702767ae125f9582e6852",
            "ai_summary": "DYMO-Hair, a model-based robot hair care system, uses a novel dynamics learning paradigm and a 3D latent space to perform visual goal-conditioned hair styling with high accuracy and generalizability.",
            "ai_keywords": [
                "dynamics learning paradigm",
                "action-conditioned latent state editing",
                "3D latent space",
                "hair physics simulator",
                "Model Predictive Path Integral (MPPI) planner",
                "visual goal-conditioned hair styling",
                "local deformation",
                "closed-loop hair styling tasks",
                "zero-shot transferability"
            ]
        },
        "publishedAt": "2025-10-07T13:53:56.000Z",
        "title": "DYMO-Hair: Generalizable Volumetric Dynamics Modeling for Robot Hair\n  Manipulation",
        "summary": "Hair care is an essential daily activity, yet it remains inaccessible to\nindividuals with limited mobility and challenging for autonomous robot systems\ndue to the fine-grained physical structure and complex dynamics of hair. In\nthis work, we present DYMO-Hair, a model-based robot hair care system. We\nintroduce a novel dynamics learning paradigm that is suited for volumetric\nquantities such as hair, relying on an action-conditioned latent state editing\nmechanism, coupled with a compact 3D latent space of diverse hairstyles to\nimprove generalizability. This latent space is pre-trained at scale using a\nnovel hair physics simulator, enabling generalization across previously unseen\nhairstyles. Using the dynamics model with a Model Predictive Path Integral\n(MPPI) planner, DYMO-Hair is able to perform visual goal-conditioned hair\nstyling. Experiments in simulation demonstrate that DYMO-Hair's dynamics model\noutperforms baselines on capturing local deformation for diverse, unseen\nhairstyles. DYMO-Hair further outperforms baselines in closed-loop hair styling\ntasks on unseen hairstyles, with an average of 22% lower final geometric error\nand 42% higher success rate than the state-of-the-art system. Real-world\nexperiments exhibit zero-shot transferability of our system to wigs, achieving\nconsistent success on challenging unseen hairstyles where the state-of-the-art\nsystem fails. Together, these results introduce a foundation for model-based\nrobot hair care, advancing toward more generalizable, flexible, and accessible\nrobot hair styling in unconstrained physical environments. More details are\navailable on our project page: https://chengyzhao.github.io/DYMOHair-web/.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06199.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "679165b9c7f527ef3619504e",
            "avatarUrl": "/avatars/f3e6ce5fc3d05c8632d8b208f55c2987.svg",
            "fullname": "Chengyang Zhao",
            "name": "chengyzhao",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.06101",
            "authors": [
                {
                    "_id": "68e66698975ac4c405ef2294",
                    "name": "Muyu He",
                    "hidden": false
                },
                {
                    "_id": "68e66698975ac4c405ef2295",
                    "name": "Muhammad Ali Shafique",
                    "hidden": false
                },
                {
                    "_id": "68e66698975ac4c405ef2296",
                    "name": "Anand Kumar",
                    "hidden": false
                },
                {
                    "_id": "68e66698975ac4c405ef2297",
                    "name": "Tsach Mackey",
                    "hidden": false
                },
                {
                    "_id": "68e66698975ac4c405ef2298",
                    "name": "Nazneen Rajani",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/62424000cce0bae7eb45487b/lVazNme5xE7UFQzjIBSNL.png"
            ],
            "publishedAt": "2025-10-07T16:32:09.000Z",
            "submittedOnDailyAt": "2025-10-08T12:27:27.114Z",
            "title": "The Valley of Code Reasoning: Scaling Knowledge Distillation of Large\n  Language Models",
            "submittedOnDailyBy": {
                "_id": "62424000cce0bae7eb45487b",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1648508910554-noauth.jpeg",
                "isPro": false,
                "fullname": "Nazneen Rajani",
                "user": "nazneen",
                "type": "user"
            },
            "summary": "Distilling the thinking traces of a Large Language Model (LLM) with reasoning\ncapabilities into a smaller model has been proven effective. Yet, there is a\nscarcity of work done on how model performances scale with the quantity of\ndistillation data. In this work, we study the scaling trend of distilling\ncompetitive coding skills on two small non-reasoning LLMs. We validate the\nhypothesis that there is a valley of code reasoning: downstream\nperformance on competitive coding first drops as data quantity increases, then\nit steadily increases in a sharper-than-log-linear fashion. Having identified\nthe trend, we further fine-tune the models at two different distillation stages\non the same data to ground conclusions on their respective learning phases. We\nlearn that across stages in the low and medium-low data regimes, small models\nbenefit significantly from easier coding questions than from harder ones. We\nalso find that, surprisingly, the correctness of outputs in training data makes\nno difference to distillation outcomes. Our work represents a step forward in\nunderstanding the training dynamics of code reasoning distillation outside\nintuition",
            "upvotes": 0,
            "discussionId": "68e66699975ac4c405ef2299",
            "ai_summary": "Research on distilling coding skills from large language models to smaller ones reveals a \"valley of code reasoning\" where performance initially decreases with more data before improving sharply, and that small models benefit more from easier questions during distillation.",
            "ai_keywords": [
                "Large Language Model (LLM)",
                "distillation",
                "coding skills",
                "valley of code reasoning",
                "learning phases",
                "data regimes",
                "coding questions"
            ],
            "organization": {
                "_id": "656819ad88bfbc261a3e6341",
                "name": "collinear-ai",
                "fullname": "Collinear AI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62424000cce0bae7eb45487b/lP5HJtUZRnuiUXaqFdJoB.png"
            }
        },
        "publishedAt": "2025-10-07T12:32:09.000Z",
        "title": "The Valley of Code Reasoning: Scaling Knowledge Distillation of Large\n  Language Models",
        "summary": "Distilling the thinking traces of a Large Language Model (LLM) with reasoning\ncapabilities into a smaller model has been proven effective. Yet, there is a\nscarcity of work done on how model performances scale with the quantity of\ndistillation data. In this work, we study the scaling trend of distilling\ncompetitive coding skills on two small non-reasoning LLMs. We validate the\nhypothesis that there is a valley of code reasoning: downstream\nperformance on competitive coding first drops as data quantity increases, then\nit steadily increases in a sharper-than-log-linear fashion. Having identified\nthe trend, we further fine-tune the models at two different distillation stages\non the same data to ground conclusions on their respective learning phases. We\nlearn that across stages in the low and medium-low data regimes, small models\nbenefit significantly from easier coding questions than from harder ones. We\nalso find that, surprisingly, the correctness of outputs in training data makes\nno difference to distillation outcomes. Our work represents a step forward in\nunderstanding the training dynamics of code reasoning distillation outside\nintuition",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/62424000cce0bae7eb45487b/lVazNme5xE7UFQzjIBSNL.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.06101.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "62424000cce0bae7eb45487b",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/1648508910554-noauth.jpeg",
            "fullname": "Nazneen Rajani",
            "name": "nazneen",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 292
        },
        "organization": {
            "_id": "656819ad88bfbc261a3e6341",
            "name": "collinear-ai",
            "fullname": "Collinear AI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62424000cce0bae7eb45487b/lP5HJtUZRnuiUXaqFdJoB.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2510.05934",
            "authors": [
                {
                    "_id": "68e61d31975ac4c405ef21c9",
                    "user": {
                        "_id": "67c912c26ec61b19b174dde3",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67c912c26ec61b19b174dde3/C6NYw3PivMvysKm8GL4_L.jpeg",
                        "isPro": false,
                        "fullname": "Huang-Cheng Chou",
                        "user": "huangchengchou",
                        "type": "user"
                    },
                    "name": "Huang-Cheng Chou",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T11:49:00.843Z",
                    "hidden": false
                },
                {
                    "_id": "68e61d31975ac4c405ef21ca",
                    "name": "Chi-Chun Lee",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-07T13:45:09.000Z",
            "submittedOnDailyAt": "2025-10-08T06:44:54.703Z",
            "title": "Revisiting Modeling and Evaluation Approaches in Speech Emotion\n  Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions",
            "submittedOnDailyBy": {
                "_id": "67c912c26ec61b19b174dde3",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67c912c26ec61b19b174dde3/C6NYw3PivMvysKm8GL4_L.jpeg",
                "isPro": false,
                "fullname": "Huang-Cheng Chou",
                "user": "huangchengchou",
                "type": "user"
            },
            "summary": "Over the past two decades, speech emotion recognition (SER) has received\ngrowing attention. To train SER systems, researchers collect emotional speech\ndatabases annotated by crowdsourced or in-house raters who select emotions from\npredefined categories. However, disagreements among raters are common.\nConventional methods treat these disagreements as noise, aggregating labels\ninto a single consensus target. While this simplifies SER as a single-label\ntask, it ignores the inherent subjectivity of human emotion perception. This\ndissertation challenges such assumptions and asks: (1) Should minority\nemotional ratings be discarded? (2) Should SER systems learn from only a few\nindividuals' perceptions? (3) Should SER systems predict only one emotion per\nsample?\n  Psychological studies show that emotion perception is subjective and\nambiguous, with overlapping emotional boundaries. We propose new modeling and\nevaluation perspectives: (1) Retain all emotional ratings and represent them\nwith soft-label distributions. Models trained on individual annotator ratings\nand jointly optimized with standard SER systems improve performance on\nconsensus-labeled tests. (2) Redefine SER evaluation by including all emotional\ndata and allowing co-occurring emotions (e.g., sad and angry). We propose an\n``all-inclusive rule'' that aggregates all ratings to maximize diversity in\nlabel representation. Experiments on four English emotion databases show\nsuperior performance over majority and plurality labeling. (3) Construct a\npenalization matrix to discourage unlikely emotion combinations during\ntraining. Integrating it into loss functions further improves performance.\nOverall, embracing minority ratings, multiple annotators, and multi-emotion\npredictions yields more robust and human-aligned SER systems.",
            "upvotes": 0,
            "discussionId": "68e61d31975ac4c405ef21cb",
            "ai_summary": "Embracing minority ratings, multiple annotators, and multi-emotion predictions in speech emotion recognition improves system robustness and alignment with human perception.",
            "ai_keywords": [
                "speech emotion recognition",
                "emotional speech databases",
                "soft-label distributions",
                "co-occurring emotions",
                "all-inclusive rule",
                "penalization matrix",
                "loss functions"
            ],
            "organization": {
                "_id": "67d0292d877a3eab2aa6e8d1",
                "name": "NTHUcc",
                "fullname": "National Tsing Hua University",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d028721e238c9d95132d64/hQ3LRdm2w3gQu7XhHH2ER.png"
            }
        },
        "publishedAt": "2025-10-07T09:45:09.000Z",
        "title": "Revisiting Modeling and Evaluation Approaches in Speech Emotion\n  Recognition: Considering Subjectivity of Annotators and Ambiguity of Emotions",
        "summary": "Over the past two decades, speech emotion recognition (SER) has received\ngrowing attention. To train SER systems, researchers collect emotional speech\ndatabases annotated by crowdsourced or in-house raters who select emotions from\npredefined categories. However, disagreements among raters are common.\nConventional methods treat these disagreements as noise, aggregating labels\ninto a single consensus target. While this simplifies SER as a single-label\ntask, it ignores the inherent subjectivity of human emotion perception. This\ndissertation challenges such assumptions and asks: (1) Should minority\nemotional ratings be discarded? (2) Should SER systems learn from only a few\nindividuals' perceptions? (3) Should SER systems predict only one emotion per\nsample?\n  Psychological studies show that emotion perception is subjective and\nambiguous, with overlapping emotional boundaries. We propose new modeling and\nevaluation perspectives: (1) Retain all emotional ratings and represent them\nwith soft-label distributions. Models trained on individual annotator ratings\nand jointly optimized with standard SER systems improve performance on\nconsensus-labeled tests. (2) Redefine SER evaluation by including all emotional\ndata and allowing co-occurring emotions (e.g., sad and angry). We propose an\n``all-inclusive rule'' that aggregates all ratings to maximize diversity in\nlabel representation. Experiments on four English emotion databases show\nsuperior performance over majority and plurality labeling. (3) Construct a\npenalization matrix to discourage unlikely emotion combinations during\ntraining. Integrating it into loss functions further improves performance.\nOverall, embracing minority ratings, multiple annotators, and multi-emotion\npredictions yields more robust and human-aligned SER systems.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.05934.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "67c912c26ec61b19b174dde3",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/67c912c26ec61b19b174dde3/C6NYw3PivMvysKm8GL4_L.jpeg",
            "fullname": "Huang-Cheng Chou",
            "name": "huangchengchou",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 2
        },
        "organization": {
            "_id": "67d0292d877a3eab2aa6e8d1",
            "name": "NTHUcc",
            "fullname": "National Tsing Hua University",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d028721e238c9d95132d64/hQ3LRdm2w3gQu7XhHH2ER.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2510.04514",
            "authors": [
                {
                    "_id": "68e51f2a7e1f41b92bf8e9d7",
                    "user": {
                        "_id": "663c57534edaac49a8afe286",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/663c57534edaac49a8afe286/fUB5uphwK-lqZE6EN2Z8F.jpeg",
                        "isPro": false,
                        "fullname": "Rachneet Kaur",
                        "user": "rachneetkaur",
                        "type": "user"
                    },
                    "name": "Rachneet Kaur",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2025-10-08T08:01:32.102Z",
                    "hidden": false
                },
                {
                    "_id": "68e51f2a7e1f41b92bf8e9d8",
                    "name": "Nishan Srishankar",
                    "hidden": false
                },
                {
                    "_id": "68e51f2a7e1f41b92bf8e9d9",
                    "name": "Zhen Zeng",
                    "hidden": false
                },
                {
                    "_id": "68e51f2a7e1f41b92bf8e9da",
                    "name": "Sumitra Ganesh",
                    "hidden": false
                },
                {
                    "_id": "68e51f2a7e1f41b92bf8e9db",
                    "name": "Manuela Veloso",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-10-06T06:05:36.000Z",
            "submittedOnDailyAt": "2025-10-08T15:07:40.098Z",
            "title": "ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in\n  Complex Chart Question Answering",
            "submittedOnDailyBy": {
                "_id": "663c57534edaac49a8afe286",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/663c57534edaac49a8afe286/fUB5uphwK-lqZE6EN2Z8F.jpeg",
                "isPro": false,
                "fullname": "Rachneet Kaur",
                "user": "rachneetkaur",
                "type": "user"
            },
            "summary": "Recent multimodal LLMs have shown promise in chart-based visual question\nanswering, but their performance declines sharply on unannotated charts, those\nrequiring precise visual interpretation rather than relying on textual\nshortcuts. To address this, we introduce ChartAgent, a novel agentic framework\nthat explicitly performs visual reasoning directly within the chart's spatial\ndomain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively\ndecomposes queries into visual subtasks and actively manipulates and interacts\nwith chart images through specialized actions such as drawing annotations,\ncropping regions (e.g., segmenting pie slices, isolating bars), and localizing\naxes, using a library of chart-specific vision tools to fulfill each subtask.\nThis iterative reasoning process closely mirrors human cognitive strategies for\nchart comprehension. ChartAgent achieves state-of-the-art accuracy on the\nChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%\nabsolute gain overall and 17.31% on unannotated, numerically intensive queries.\nFurthermore, our analyses show that ChartAgent is (a) effective across diverse\nchart types, (b) achieve the highest scores across varying visual and reasoning\ncomplexity levels, and (c) serves as a plug-and-play framework that boosts\nperformance across diverse underlying LLMs. Our work is among the first to\ndemonstrate visually grounded reasoning for chart understanding using\ntool-augmented multimodal agents.",
            "upvotes": 0,
            "discussionId": "68e51f2b7e1f41b92bf8e9dc",
            "ai_summary": "ChartAgent, a novel agentic framework, performs visual reasoning directly within charts, achieving state-of-the-art accuracy on ChartBench and ChartX benchmarks by iteratively decomposing queries and using specialized visual actions.",
            "ai_keywords": [
                "multimodal LLMs",
                "visual question answering",
                "unannotated charts",
                "ChartAgent",
                "agentic framework",
                "visual reasoning",
                "spatial domain",
                "chain-of-thought reasoning",
                "visual subtasks",
                "drawing annotations",
                "cropping regions",
                "segmenting pie slices",
                "isolating bars",
                "localizing axes",
                "chart-specific vision tools",
                "ChartBench",
                "ChartX",
                "diverse chart types",
                "visual complexity",
                "reasoning complexity",
                "plug-and-play framework"
            ]
        },
        "publishedAt": "2025-10-06T02:05:36.000Z",
        "title": "ChartAgent: A Multimodal Agent for Visually Grounded Reasoning in\n  Complex Chart Question Answering",
        "summary": "Recent multimodal LLMs have shown promise in chart-based visual question\nanswering, but their performance declines sharply on unannotated charts, those\nrequiring precise visual interpretation rather than relying on textual\nshortcuts. To address this, we introduce ChartAgent, a novel agentic framework\nthat explicitly performs visual reasoning directly within the chart's spatial\ndomain. Unlike textual chain-of-thought reasoning, ChartAgent iteratively\ndecomposes queries into visual subtasks and actively manipulates and interacts\nwith chart images through specialized actions such as drawing annotations,\ncropping regions (e.g., segmenting pie slices, isolating bars), and localizing\naxes, using a library of chart-specific vision tools to fulfill each subtask.\nThis iterative reasoning process closely mirrors human cognitive strategies for\nchart comprehension. ChartAgent achieves state-of-the-art accuracy on the\nChartBench and ChartX benchmarks, surpassing prior methods by up to 16.07%\nabsolute gain overall and 17.31% on unannotated, numerically intensive queries.\nFurthermore, our analyses show that ChartAgent is (a) effective across diverse\nchart types, (b) achieve the highest scores across varying visual and reasoning\ncomplexity levels, and (c) serves as a plug-and-play framework that boosts\nperformance across diverse underlying LLMs. Our work is among the first to\ndemonstrate visually grounded reasoning for chart understanding using\ntool-augmented multimodal agents.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2510.04514.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "663c57534edaac49a8afe286",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/663c57534edaac49a8afe286/fUB5uphwK-lqZE6EN2Z8F.jpeg",
            "fullname": "Rachneet Kaur",
            "name": "rachneetkaur",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 8
        },
        "isAuthorParticipating": true
    }
]