[
    {
        "paper": {
            "id": "2512.24615",
            "authors": [
                {
                    "_id": "69564d96832867f2535257af",
                    "user": {
                        "_id": "622b00a776c20fee5d14501b",
                        "avatarUrl": "/avatars/e00496dda1e309548e7b5b437839bb65.svg",
                        "isPro": false,
                        "fullname": "Eason shi",
                        "user": "Easonshi",
                        "type": "user"
                    },
                    "name": "Yuchen Shi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-04T20:09:50.111Z",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b0",
                    "user": {
                        "_id": "66e258bdc70c02b46dfed6e3",
                        "avatarUrl": "/avatars/ccc2d604616c018f45a268a610472cac.svg",
                        "isPro": false,
                        "fullname": "Yuzheng Cai",
                        "user": "Ucreate",
                        "type": "user"
                    },
                    "name": "Yuzheng Cai",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:50.884Z",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b1",
                    "name": "Siqi Cai",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b2",
                    "name": "Zihan Xu",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b3",
                    "user": {
                        "_id": "64154bfa385a75d7790f80e8",
                        "avatarUrl": "/avatars/9e22f54b5eb7c4ebedad99a9a92c4b6a.svg",
                        "isPro": false,
                        "fullname": "Lichao Chen",
                        "user": "nth233",
                        "type": "user"
                    },
                    "name": "Lichao Chen",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:46.825Z",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b4",
                    "user": {
                        "_id": "6390525c00fb8ec4a424e0ff",
                        "avatarUrl": "/avatars/4302571e2ef4a9875491221aa630a329.svg",
                        "isPro": false,
                        "fullname": "Yulei Qin",
                        "user": "yolay",
                        "type": "user"
                    },
                    "name": "Yulei Qin",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-04T20:09:48.064Z",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b5",
                    "name": "Zhijian Zhou",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b6",
                    "name": "Xiang Fei",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b7",
                    "user": {
                        "_id": "6604e43869c47cd78fdebd08",
                        "avatarUrl": "/avatars/4c11f5e1aeae3c5eb213f6ec6d5bfe72.svg",
                        "isPro": false,
                        "fullname": "Qiu",
                        "user": "ChaofanDFG",
                        "type": "user"
                    },
                    "name": "Chaofan Qiu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:48.910Z",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b8",
                    "user": {
                        "_id": "637af0a7bdf7309aa6da1c36",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/637af0a7bdf7309aa6da1c36/NHZ-09otVCfbpXVxm8f-e.png",
                        "isPro": false,
                        "fullname": "Xiaoyu Tan",
                        "user": "WIlliam1900",
                        "type": "user"
                    },
                    "name": "Xiaoyu Tan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:52.763Z",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257b9",
                    "name": "Gang Li",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257ba",
                    "name": "Zongyi Li",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257bb",
                    "name": "Haojia Lin",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257bc",
                    "name": "Guocan Cai",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257bd",
                    "name": "Yong Mao",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257be",
                    "name": "Yunsheng Wu",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257bf",
                    "name": "Ke Li",
                    "hidden": false
                },
                {
                    "_id": "69564d96832867f2535257c0",
                    "user": {
                        "_id": "647401e50da364bd0d002f2a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/no-auth/vPuPn7EV092mLBOM2YZXd.png",
                        "isPro": false,
                        "fullname": "XING SUN",
                        "user": "tedsun",
                        "type": "user"
                    },
                    "name": "Xing Sun",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-02T15:38:39.390Z",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-31T04:17:36.000Z",
            "submittedOnDailyAt": "2026-01-05T00:21:56.456Z",
            "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization",
            "submittedOnDailyBy": {
                "_id": "63280915eeee4dd858083092",
                "avatarUrl": "/avatars/78347af4af42527d53e88d9969c5c934.svg",
                "isPro": false,
                "fullname": "Ke Li",
                "user": "tristanli",
                "type": "user"
            },
            "summary": "Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose Youtu-Agent, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a Workflow mode for standard tasks and a Meta-Agent mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an Agent Practice module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an Agent RL module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\\%) and GAIA (72.8\\%) using open-weight models. Our automated generation pipeline achieves over 81\\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\\% and +5.4\\% respectively. Moreover, our Agent RL training achieves 40\\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\\% and 21\\% on Maths and general/multi-hop QA benchmarks.",
            "upvotes": 86,
            "discussionId": "69564d96832867f2535257c1",
            "projectPage": "https://tencentcloudadp.github.io/youtu-agent/",
            "githubRepo": "https://github.com/TencentCloudADP/youtu-agent",
            "githubRepoAddedBy": "user",
            "githubStars": 4095,
            "organization": {
                "_id": "66543b6e420092799d2f625c",
                "name": "tencent",
                "fullname": "Tencent",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/Lp3m-XLpjQGwBItlvn69q.png"
            }
        },
        "publishedAt": "2025-12-30T23:17:36.000Z",
        "title": "Youtu-Agent: Scaling Agent Productivity with Automated Generation and Hybrid Policy Optimization",
        "summary": "Existing Large Language Model (LLM) agent frameworks face two significant challenges: high configuration costs and static capabilities. Building a high-quality agent often requires extensive manual effort in tool integration and prompt engineering, while deployed agents struggle to adapt to dynamic environments without expensive fine-tuning. To address these issues, we propose Youtu-Agent, a modular framework designed for the automated generation and continuous evolution of LLM agents. Youtu-Agent features a structured configuration system that decouples execution environments, toolkits, and context management, enabling flexible reuse and automated synthesis. We introduce two generation paradigms: a Workflow mode for standard tasks and a Meta-Agent mode for complex, non-standard requirements, capable of automatically generating tool code, prompts, and configurations. Furthermore, Youtu-Agent establishes a hybrid policy optimization system: (1) an Agent Practice module that enables agents to accumulate experience and improve performance through in-context optimization without parameter updates; and (2) an Agent RL module that integrates with distributed training frameworks to enable scalable and stable reinforcement learning of any Youtu-Agents in an end-to-end, large-scale manner. Experiments demonstrate that Youtu-Agent achieves state-of-the-art performance on WebWalkerQA (71.47\\%) and GAIA (72.8\\%) using open-weight models. Our automated generation pipeline achieves over 81\\% tool synthesis success rate, while the Practice module improves performance on AIME 2024/2025 by +2.7\\% and +5.4\\% respectively. Moreover, our Agent RL training achieves 40\\% speedup with steady performance improvement on 7B LLMs, enhancing coding/reasoning and searching capabilities respectively up to 35\\% and 21\\% on Maths and general/multi-hop QA benchmarks.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.24615.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "63280915eeee4dd858083092",
            "avatarUrl": "/avatars/78347af4af42527d53e88d9969c5c934.svg",
            "fullname": "Ke Li",
            "name": "tristanli",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "66543b6e420092799d2f625c",
            "name": "tencent",
            "fullname": "Tencent",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/5dd96eb166059660ed1ee413/Lp3m-XLpjQGwBItlvn69q.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2601.00393",
            "authors": [
                {
                    "_id": "695b2297832867f253525d68",
                    "user": {
                        "_id": "66dd71d0140f04eb180d7c2a",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66dd71d0140f04eb180d7c2a/7Qm0Ap0gCjKdumXrbgq_p.png",
                        "isPro": false,
                        "fullname": "Yuxue Yang",
                        "user": "Yuppie1204",
                        "type": "user"
                    },
                    "name": "Yuxue Yang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:23.295Z",
                    "hidden": false
                },
                {
                    "_id": "695b2297832867f253525d69",
                    "user": {
                        "_id": "649ecf9827145c4463240177",
                        "avatarUrl": "/avatars/27696cf31790a3d58d8be2e0c983800e.svg",
                        "isPro": false,
                        "fullname": "Lue Fan",
                        "user": "Abyssaledge",
                        "type": "user"
                    },
                    "name": "Lue Fan",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T13:49:26.330Z",
                    "hidden": false
                },
                {
                    "_id": "695b2297832867f253525d6a",
                    "user": {
                        "_id": "644cc2c36dfd5f8240d76a52",
                        "avatarUrl": "/avatars/dcd9279af1c6d8535e48dc6e3e6511cd.svg",
                        "isPro": false,
                        "fullname": "Ziqi Shi",
                        "user": "renshengjihe",
                        "type": "user"
                    },
                    "name": "Ziqi Shi",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:21.077Z",
                    "hidden": false
                },
                {
                    "_id": "695b2297832867f253525d6b",
                    "name": "Junran Peng",
                    "hidden": false
                },
                {
                    "_id": "695b2297832867f253525d6c",
                    "name": "Feng Wang",
                    "hidden": false
                },
                {
                    "_id": "695b2297832867f253525d6d",
                    "name": "Zhaoxiang Zhang",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/66dd71d0140f04eb180d7c2a/zVr0WeywcHVevhzmqwIaj.mp4"
            ],
            "publishedAt": "2026-01-01T17:07:30.000Z",
            "submittedOnDailyAt": "2026-01-05T02:49:46.994Z",
            "title": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos",
            "submittedOnDailyBy": {
                "_id": "66dd71d0140f04eb180d7c2a",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66dd71d0140f04eb180d7c2a/7Qm0Ap0gCjKdumXrbgq_p.png",
                "isPro": false,
                "fullname": "Yuxue Yang",
                "user": "Yuppie1204",
                "type": "user"
            },
            "summary": "In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io",
            "upvotes": 84,
            "discussionId": "695b2297832867f253525d6e",
            "projectPage": "https://neoverse-4d.github.io/",
            "githubRepo": "https://github.com/IamCreateAI/NeoVerse",
            "githubRepoAddedBy": "user",
            "ai_summary": "NeoVerse is a scalable 4D world model that enables pose-free reconstruction and novel-trajectory video generation from monocular videos with state-of-the-art performance.",
            "ai_keywords": [
                "4D world model",
                "4D reconstruction",
                "novel-trajectory video generation",
                "monocular videos",
                "pose-free",
                "feed-forward",
                "degradation pattern simulation"
            ],
            "githubStars": 124
        },
        "publishedAt": "2026-01-01T12:07:30.000Z",
        "title": "NeoVerse: Enhancing 4D World Model with in-the-wild Monocular Videos",
        "summary": "In this paper, we propose NeoVerse, a versatile 4D world model that is capable of 4D reconstruction, novel-trajectory video generation, and rich downstream applications. We first identify a common limitation of scalability in current 4D world modeling methods, caused either by expensive and specialized multi-view 4D data or by cumbersome training pre-processing. In contrast, our NeoVerse is built upon a core philosophy that makes the full pipeline scalable to diverse in-the-wild monocular videos. Specifically, NeoVerse features pose-free feed-forward 4D reconstruction, online monocular degradation pattern simulation, and other well-aligned techniques. These designs empower NeoVerse with versatility and generalization to various domains. Meanwhile, NeoVerse achieves state-of-the-art performance in standard reconstruction and generation benchmarks. Our project page is available at https://neoverse-4d.github.io",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/66dd71d0140f04eb180d7c2a/zVr0WeywcHVevhzmqwIaj.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.00393.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "66dd71d0140f04eb180d7c2a",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/66dd71d0140f04eb180d7c2a/7Qm0Ap0gCjKdumXrbgq_p.png",
            "fullname": "Yuxue Yang",
            "name": "Yuppie1204",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 7
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2601.00664",
            "authors": [
                {
                    "_id": "695b237a832867f253525d70",
                    "user": {
                        "_id": "66b57c77778c98d29446c8ec",
                        "avatarUrl": "/avatars/c176bb7c072f3093f6a0786c87d384d8.svg",
                        "isPro": false,
                        "fullname": "Taekyung Ki",
                        "user": "taekyungki",
                        "type": "user"
                    },
                    "name": "Taekyung Ki",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:19.100Z",
                    "hidden": false
                },
                {
                    "_id": "695b237a832867f253525d71",
                    "name": "Sangwon Jang",
                    "hidden": false
                },
                {
                    "_id": "695b237a832867f253525d72",
                    "name": "Jaehyeong Jo",
                    "hidden": false
                },
                {
                    "_id": "695b237a832867f253525d73",
                    "user": {
                        "_id": "652066649004117947e46ed6",
                        "avatarUrl": "/avatars/972c97df6f26d2c3d6ce71ec579984bb.svg",
                        "isPro": false,
                        "fullname": "Jaehong Yoon",
                        "user": "jaehong31",
                        "type": "user"
                    },
                    "name": "Jaehong Yoon",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:17.228Z",
                    "hidden": false
                },
                {
                    "_id": "695b237a832867f253525d74",
                    "name": "Sung Ju Hwang",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/OjpAmq7fuwGa-ZxL3KbSY.mp4"
            ],
            "publishedAt": "2026-01-02T11:58:48.000Z",
            "submittedOnDailyAt": "2026-01-05T00:05:44.498Z",
            "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.",
            "upvotes": 44,
            "discussionId": "695b237a832867f253525d75",
            "projectPage": "https://taekyungki.github.io/AvatarForcing/",
            "githubRepo": "https://github.com/TaekyungKi/AvatarForcing",
            "githubRepoAddedBy": "user",
            "ai_summary": "Avatar Forcing framework enables real-time interactive head avatar generation with low latency and expressive motion through diffusion forcing and label-free preference optimization.",
            "ai_keywords": [
                "diffusion forcing",
                "real-time interaction",
                "multimodal inputs",
                "audio",
                "motion",
                "causal constraints",
                "synthetic losing samples",
                "direct preference optimization",
                "interactive head avatar generation"
            ],
            "githubStars": 65
        },
        "publishedAt": "2026-01-02T06:58:48.000Z",
        "title": "Avatar Forcing: Real-Time Interactive Head Avatar Generation for Natural Conversation",
        "summary": "Talking head generation creates lifelike avatars from static portraits for virtual communication and content creation. However, current models do not yet convey the feeling of truly interactive communication, often generating one-way responses that lack emotional engagement. We identify two key challenges toward truly interactive avatars: generating motion in real-time under causal constraints and learning expressive, vibrant reactions without additional labeled data. To address these challenges, we propose Avatar Forcing, a new framework for interactive head avatar generation that models real-time user-avatar interactions through diffusion forcing. This design allows the avatar to process real-time multimodal inputs, including the user's audio and motion, with low latency for instant reactions to both verbal and non-verbal cues such as speech, nods, and laughter. Furthermore, we introduce a direct preference optimization method that leverages synthetic losing samples constructed by dropping user conditions, enabling label-free learning of expressive interaction. Experimental results demonstrate that our framework enables real-time interaction with low latency (approximately 500ms), achieving 6.8X speedup compared to the baseline, and produces reactive and expressive avatar motion, which is preferred over 80% against the baseline.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/OjpAmq7fuwGa-ZxL3KbSY.mp4"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.00664.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 199
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2512.24330",
            "authors": [
                {
                    "_id": "69560bcd832867f2535256fc",
                    "name": "Yong Xien Chng",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f2535256fd",
                    "name": "Tao Hu",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f2535256fe",
                    "name": "Wenwen Tong",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f2535256ff",
                    "name": "Xueheng Li",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525700",
                    "name": "Jiandong Chen",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525701",
                    "name": "Haojia Yu",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525702",
                    "name": "Jiefan Lu",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525703",
                    "name": "Hewei Guo",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525704",
                    "name": "Hanming Deng",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525705",
                    "name": "Chengjun Xie",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525706",
                    "name": "Gao Huang",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525707",
                    "name": "Dahua Lin",
                    "hidden": false
                },
                {
                    "_id": "69560bcd832867f253525708",
                    "name": "Lewei Lu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-30T16:31:45.000Z",
            "submittedOnDailyAt": "2026-01-05T00:14:32.572Z",
            "title": "SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning",
            "submittedOnDailyBy": {
                "_id": "647d4f1236e109abce409c3b",
                "avatarUrl": "/avatars/d166f5f8be666e96b522a0a0effd21c4.svg",
                "isPro": false,
                "fullname": "Wenwen Tong",
                "user": "tongww",
                "type": "user"
            },
            "summary": "While Vision-Language Models (VLMs) can solve complex tasks through agentic reasoning, their capabilities remain largely constrained to text-oriented chain-of-thought or isolated tool invocation. They fail to exhibit the human-like proficiency required to seamlessly interleave dynamic tool manipulation with continuous reasoning, particularly in knowledge-intensive and visually complex scenarios that demand coordinated external tools such as search and image cropping. In this work, we introduce SenseNova-MARS, a novel Multimodal Agentic Reasoning and Search framework that empowers VLMs with interleaved visual reasoning and tool-use capabilities via reinforcement learning (RL). Specifically, SenseNova-MARS dynamically integrates the image search, text search, and image crop tools to tackle fine-grained and knowledge-intensive visual understanding challenges. In the RL stage, we propose the Batch-Normalized Group Sequence Policy Optimization (BN-GSPO) algorithm to improve the training stability and advance the model's ability to invoke tools and reason effectively. To comprehensively evaluate the agentic VLMs on complex visual tasks, we introduce the HR-MMSearch benchmark, the first search-oriented benchmark composed of high-resolution images with knowledge-intensive and search-driven questions. Experiments demonstrate that SenseNova-MARS achieves state-of-the-art performance on open-source search and fine-grained image understanding benchmarks. Specifically, on search-oriented benchmarks, SenseNova-MARS-8B scores 67.84 on MMSearch and 41.64 on HR-MMSearch, surpassing proprietary models such as Gemini-3-Flash and GPT-5. SenseNova-MARS represents a promising step toward agentic VLMs by providing effective and robust tool-use capabilities. To facilitate further research in this field, we will release all code, models, and datasets.",
            "upvotes": 30,
            "discussionId": "69560bcd832867f253525709",
            "githubRepo": "https://github.com/OpenSenseNova/SenseNova-MARS",
            "githubRepoAddedBy": "user",
            "githubStars": 24,
            "organization": {
                "_id": "64f0405f8a4cf3e5e6b38f9c",
                "name": "sensenova",
                "fullname": "SenseNova",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/652d06833b5997ed71ce5c46/k66xcOMf4NVbMSFulUjHY.png"
            }
        },
        "publishedAt": "2025-12-30T11:31:45.000Z",
        "title": "SenseNova-MARS: Empowering Multimodal Agentic Reasoning and Search via Reinforcement Learning",
        "summary": "While Vision-Language Models (VLMs) can solve complex tasks through agentic reasoning, their capabilities remain largely constrained to text-oriented chain-of-thought or isolated tool invocation. They fail to exhibit the human-like proficiency required to seamlessly interleave dynamic tool manipulation with continuous reasoning, particularly in knowledge-intensive and visually complex scenarios that demand coordinated external tools such as search and image cropping. In this work, we introduce SenseNova-MARS, a novel Multimodal Agentic Reasoning and Search framework that empowers VLMs with interleaved visual reasoning and tool-use capabilities via reinforcement learning (RL). Specifically, SenseNova-MARS dynamically integrates the image search, text search, and image crop tools to tackle fine-grained and knowledge-intensive visual understanding challenges. In the RL stage, we propose the Batch-Normalized Group Sequence Policy Optimization (BN-GSPO) algorithm to improve the training stability and advance the model's ability to invoke tools and reason effectively. To comprehensively evaluate the agentic VLMs on complex visual tasks, we introduce the HR-MMSearch benchmark, the first search-oriented benchmark composed of high-resolution images with knowledge-intensive and search-driven questions. Experiments demonstrate that SenseNova-MARS achieves state-of-the-art performance on open-source search and fine-grained image understanding benchmarks. Specifically, on search-oriented benchmarks, SenseNova-MARS-8B scores 67.84 on MMSearch and 41.64 on HR-MMSearch, surpassing proprietary models such as Gemini-3-Flash and GPT-5. SenseNova-MARS represents a promising step toward agentic VLMs by providing effective and robust tool-use capabilities. To facilitate further research in this field, we will release all code, models, and datasets.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.24330.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "647d4f1236e109abce409c3b",
            "avatarUrl": "/avatars/d166f5f8be666e96b522a0a0effd21c4.svg",
            "fullname": "Wenwen Tong",
            "name": "tongww",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "64f0405f8a4cf3e5e6b38f9c",
            "name": "sensenova",
            "fullname": "SenseNova",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/652d06833b5997ed71ce5c46/k66xcOMf4NVbMSFulUjHY.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2512.24271",
            "authors": [
                {
                    "_id": "695b1d02832867f253525d50",
                    "name": "Zhe Huang",
                    "hidden": false
                },
                {
                    "_id": "695b1d02832867f253525d51",
                    "name": "Hao Wen",
                    "hidden": false
                },
                {
                    "_id": "695b1d02832867f253525d52",
                    "user": {
                        "_id": "6583a8bdaa85c512dac3be51",
                        "avatarUrl": "/avatars/5ece6d142e85b58ea5f59b9af251ee02.svg",
                        "isPro": false,
                        "fullname": "aiming hao",
                        "user": "HamHugging",
                        "type": "user"
                    },
                    "name": "Aiming Hao",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:32.637Z",
                    "hidden": false
                },
                {
                    "_id": "695b1d02832867f253525d53",
                    "name": "Bingze Song",
                    "hidden": false
                },
                {
                    "_id": "695b1d02832867f253525d54",
                    "name": "Meiqi Wu",
                    "hidden": false
                },
                {
                    "_id": "695b1d02832867f253525d55",
                    "name": "Jiahong Wu",
                    "hidden": false
                },
                {
                    "_id": "695b1d02832867f253525d56",
                    "name": "Xiangxiang Chu",
                    "hidden": false
                },
                {
                    "_id": "695b1d02832867f253525d57",
                    "name": "Sheng Lu",
                    "hidden": false
                },
                {
                    "_id": "695b1d02832867f253525d58",
                    "name": "Haoqian Wang",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-30T14:53:33.000Z",
            "submittedOnDailyAt": "2026-01-05T01:14:54.357Z",
            "title": "Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation",
            "submittedOnDailyBy": {
                "_id": "66d255e3947594430c723ff6",
                "avatarUrl": "/avatars/c56e4792332a01bf34085a75ee64916e.svg",
                "isPro": false,
                "fullname": "xiaochonglinghu",
                "user": "xiaochonglinghu",
                "type": "user"
            },
            "summary": "Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy common sense. This limitation, stemming from the intrinsic data imbalance between text and video, is challenging to address due to the substantial cost of collecting and annotating counterfactual data. To address this, we introduce DualityForge, a novel counterfactual data synthesis framework that employs controllable, diffusion-based video editing to transform real-world videos into counterfactual scenarios. By embedding structured contextual information into the video editing and QA generation processes, the framework automatically produces high-quality QA pairs together with original-edited video pairs for contrastive training. Based on this, we build DualityVidQA, a large-scale video dataset designed to reduce MLLM hallucinations. In addition, to fully exploit the contrastive nature of our paired data, we propose Duality-Normalized Advantage Training (DNA-Train), a two-stage SFT-RL training regime where the RL phase applies pair-wise ell_1 advantage normalization, thereby enabling a more stable and efficient policy optimization. Experiments on DualityVidQA-Test demonstrate that our method substantially reduces model hallucinations on counterfactual videos, yielding a relative improvement of 24.0% over the Qwen2.5-VL-7B baseline. Moreover, our approach achieves significant gains across both hallucination and general-purpose benchmarks, indicating strong generalization capability. We will open-source our dataset and code.",
            "upvotes": 25,
            "discussionId": "695b1d02832867f253525d59",
            "projectPage": "https://amap-ml.github.io/Taming-Hallucinations/",
            "githubRepo": "https://github.com/AMAP-ML/Taming-Hallucinations",
            "githubRepoAddedBy": "user",
            "githubStars": 29,
            "organization": {
                "_id": "67d11771890254196d3174e5",
                "name": "GD-ML",
                "fullname": "AMAP-ML",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"
            }
        },
        "publishedAt": "2025-12-30T09:53:33.000Z",
        "title": "Taming Hallucinations: Boosting MLLMs' Video Understanding via Counterfactual Video Generation",
        "summary": "Multimodal Large Language Models (MLLMs) have made remarkable progress in video understanding. However, they suffer from a critical vulnerability: an over-reliance on language priors, which can lead to visual ungrounded hallucinations, especially when processing counterfactual videos that defy common sense. This limitation, stemming from the intrinsic data imbalance between text and video, is challenging to address due to the substantial cost of collecting and annotating counterfactual data. To address this, we introduce DualityForge, a novel counterfactual data synthesis framework that employs controllable, diffusion-based video editing to transform real-world videos into counterfactual scenarios. By embedding structured contextual information into the video editing and QA generation processes, the framework automatically produces high-quality QA pairs together with original-edited video pairs for contrastive training. Based on this, we build DualityVidQA, a large-scale video dataset designed to reduce MLLM hallucinations. In addition, to fully exploit the contrastive nature of our paired data, we propose Duality-Normalized Advantage Training (DNA-Train), a two-stage SFT-RL training regime where the RL phase applies pair-wise ell_1 advantage normalization, thereby enabling a more stable and efficient policy optimization. Experiments on DualityVidQA-Test demonstrate that our method substantially reduces model hallucinations on counterfactual videos, yielding a relative improvement of 24.0% over the Qwen2.5-VL-7B baseline. Moreover, our approach achieves significant gains across both hallucination and general-purpose benchmarks, indicating strong generalization capability. We will open-source our dataset and code.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.24271.png",
        "numComments": 4,
        "submittedBy": {
            "_id": "66d255e3947594430c723ff6",
            "avatarUrl": "/avatars/c56e4792332a01bf34085a75ee64916e.svg",
            "fullname": "xiaochonglinghu",
            "name": "xiaochonglinghu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 4
        },
        "organization": {
            "_id": "67d11771890254196d3174e5",
            "name": "GD-ML",
            "fullname": "AMAP-ML",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2601.00796",
            "authors": [
                {
                    "_id": "695b646f832867f253525e0d",
                    "name": "Jiewen Chan",
                    "hidden": false
                },
                {
                    "_id": "695b646f832867f253525e0e",
                    "name": "Zhenjun Zhao",
                    "hidden": false
                },
                {
                    "_id": "695b646f832867f253525e0f",
                    "name": "Yu-Lun Liu",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6459d5da3b6fafd9664807ab/enxEXrkIl4E0MXNfFVAK4.qt"
            ],
            "publishedAt": "2026-01-02T18:59:55.000Z",
            "submittedOnDailyAt": "2026-01-05T04:47:40.380Z",
            "title": "AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction",
            "submittedOnDailyBy": {
                "_id": "6459d5da3b6fafd9664807ab",
                "avatarUrl": "/avatars/57430d1bbde3a2fe5586e5fbcafb0e74.svg",
                "isPro": false,
                "fullname": "Yu-Lun Liu",
                "user": "yulunliu",
                "type": "user"
            },
            "summary": "Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/",
            "upvotes": 22,
            "discussionId": "695b646f832867f253525e10",
            "projectPage": "https://jiewenchan.github.io/AdaGaR/"
        },
        "publishedAt": "2026-01-02T13:59:55.000Z",
        "title": "AdaGaR: Adaptive Gabor Representation for Dynamic Scene Reconstruction",
        "summary": "Reconstructing dynamic 3D scenes from monocular videos requires simultaneously capturing high-frequency appearance details and temporally continuous motion. Existing methods using single Gaussian primitives are limited by their low-pass filtering nature, while standard Gabor functions introduce energy instability. Moreover, lack of temporal continuity constraints often leads to motion artifacts during interpolation. We propose AdaGaR, a unified framework addressing both frequency adaptivity and temporal continuity in explicit dynamic scene modeling. We introduce Adaptive Gabor Representation, extending Gaussians through learnable frequency weights and adaptive energy compensation to balance detail capture and stability. For temporal continuity, we employ Cubic Hermite Splines with Temporal Curvature Regularization to ensure smooth motion evolution. An Adaptive Initialization mechanism combining depth estimation, point tracking, and foreground masks establishes stable point cloud distributions in early training. Experiments on Tap-Vid DAVIS demonstrate state-of-the-art performance (PSNR 35.49, SSIM 0.9433, LPIPS 0.0723) and strong generalization across frame interpolation, depth consistency, video editing, and stereo view synthesis. Project page: https://jiewenchan.github.io/AdaGaR/",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6459d5da3b6fafd9664807ab/enxEXrkIl4E0MXNfFVAK4.qt"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.00796.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6459d5da3b6fafd9664807ab",
            "avatarUrl": "/avatars/57430d1bbde3a2fe5586e5fbcafb0e74.svg",
            "fullname": "Yu-Lun Liu",
            "name": "yulunliu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 7
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2601.00417",
            "authors": [
                {
                    "_id": "695b2238832867f253525d62",
                    "user": {
                        "_id": "647bf082aba7062fe5c51ca9",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/647bf082aba7062fe5c51ca9/VvKAhQC_LxBcBuy3XROSX.jpeg",
                        "isPro": false,
                        "fullname": "Yifan Zhang",
                        "user": "yifAI",
                        "type": "user"
                    },
                    "name": "Yifan Zhang",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T13:49:28.701Z",
                    "hidden": false
                },
                {
                    "_id": "695b2238832867f253525d63",
                    "user": {
                        "_id": "653d276681f52ceb4d12bd85",
                        "avatarUrl": "/avatars/56601a25e5f883a8f6dc15f6fd9dcc57.svg",
                        "isPro": false,
                        "fullname": "Yifeng Liu",
                        "user": "Lewis-Lau",
                        "type": "user"
                    },
                    "name": "Yifeng Liu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:25.264Z",
                    "hidden": false
                },
                {
                    "_id": "695b2238832867f253525d64",
                    "name": "Mengdi Wang",
                    "hidden": false
                },
                {
                    "_id": "695b2238832867f253525d65",
                    "name": "Quanquan Gu",
                    "hidden": false
                }
            ],
            "mediaUrls": [
                "https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/BQO8lEQ-MwHpWvjNsJo6d.png"
            ],
            "publishedAt": "2026-01-01T18:11:38.000Z",
            "submittedOnDailyAt": "2026-01-05T00:00:42.191Z",
            "title": "Deep Delta Learning",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector k(X) and a gating scalar (X). We provide a spectral analysis of this operator, demonstrating that the gate (X) enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.",
            "upvotes": 22,
            "discussionId": "695b2238832867f253525d66",
            "projectPage": "https://yifanzhang-pro.github.io/deep-delta-learning",
            "githubRepo": "https://github.com/yifanzhang-pro/deep-delta-learning",
            "githubRepoAddedBy": "user",
            "ai_summary": "Deep Delta Learning introduces a novel residual connection mechanism that uses a learnable geometric transformation to generalize identity shortcuts, enabling more flexible feature modeling while maintaining stable training properties.",
            "ai_keywords": [
                "deep residual networks",
                "identity shortcut connection",
                "vanishing gradient problem",
                "residual connection",
                "Delta Operator",
                "rank-1 perturbation",
                "reflection direction vector",
                "gating scalar",
                "spectral analysis",
                "geometric reflection",
                "synchronous rank-1 injection",
                "layer-wise transition operator",
                "non-monotonic dynamics",
                "gated residual architectures"
            ],
            "githubStars": 234,
            "organization": {
                "_id": "659e8e0b336c5a4647897ca4",
                "name": "math-ai",
                "fullname": "math-ai",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/647bf082aba7062fe5c51ca9/UT7gQJZxvgq1eoG8j1Fg2.jpeg"
            }
        },
        "publishedAt": "2026-01-01T13:11:38.000Z",
        "title": "Deep Delta Learning",
        "summary": "The efficacy of deep residual networks is fundamentally predicated on the identity shortcut connection. While this mechanism effectively mitigates the vanishing gradient problem, it imposes a strictly additive inductive bias on feature transformations, thereby limiting the network's capacity to model complex state transitions. In this paper, we introduce Deep Delta Learning (DDL), a novel architecture that generalizes the standard residual connection by modulating the identity shortcut with a learnable, data-dependent geometric transformation. This transformation, termed the Delta Operator, constitutes a rank-1 perturbation of the identity matrix, parameterized by a reflection direction vector k(X) and a gating scalar (X). We provide a spectral analysis of this operator, demonstrating that the gate (X) enables dynamic interpolation between identity mapping, orthogonal projection, and geometric reflection. Furthermore, we restructure the residual update as a synchronous rank-1 injection, where the gate acts as a dynamic step size governing both the erasure of old information and the writing of new features. This unification empowers the network to explicitly control the spectrum of its layer-wise transition operator, enabling the modeling of complex, non-monotonic dynamics while preserving the stable training characteristics of gated residual architectures.",
        "mediaUrls": [
            "https://cdn-uploads.huggingface.co/production/uploads/6039478ab3ecf716b1a5fd4d/BQO8lEQ-MwHpWvjNsJo6d.png"
        ],
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.00417.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 199
        },
        "organization": {
            "_id": "659e8e0b336c5a4647897ca4",
            "name": "math-ai",
            "fullname": "math-ai",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/647bf082aba7062fe5c51ca9/UT7gQJZxvgq1eoG8j1Fg2.jpeg"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2512.24695",
            "authors": [
                {
                    "_id": "695b4caa832867f253525dcd",
                    "user": {
                        "_id": "65cccd5134a5d74cbaa9446c",
                        "avatarUrl": "/avatars/5255b734628992106598eae4f2c5848f.svg",
                        "isPro": false,
                        "fullname": "Ali Behrouz",
                        "user": "AliBehrouz",
                        "type": "user"
                    },
                    "name": "Ali Behrouz",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:10.014Z",
                    "hidden": false
                },
                {
                    "_id": "695b4caa832867f253525dce",
                    "name": "Meisam Razaviyayn",
                    "hidden": false
                },
                {
                    "_id": "695b4caa832867f253525dcf",
                    "name": "Peilin Zhong",
                    "hidden": false
                },
                {
                    "_id": "695b4caa832867f253525dd0",
                    "name": "Vahab Mirrokni",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-31T07:59:43.000Z",
            "submittedOnDailyAt": "2026-01-05T03:02:31.820Z",
            "title": "Nested Learning: The Illusion of Deep Learning Architectures",
            "submittedOnDailyBy": {
                "_id": "65cccd5134a5d74cbaa9446c",
                "avatarUrl": "/avatars/5255b734628992106598eae4f2c5848f.svg",
                "isPro": false,
                "fullname": "Ali Behrouz",
                "user": "AliBehrouz",
                "type": "user"
            },
            "summary": "Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients' information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL's insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.",
            "upvotes": 21,
            "discussionId": "695b4cab832867f253525dd1"
        },
        "publishedAt": "2025-12-31T02:59:43.000Z",
        "title": "Nested Learning: The Illusion of Deep Learning Architectures",
        "summary": "Despite the recent progresses, particularly in developing Language Models, there are fundamental challenges and unanswered questions about how such models can continually learn/memorize, self-improve, and find effective solutions. In this paper, we present a new learning paradigm, called Nested Learning (NL), that coherently represents a machine learning model with a set of nested, multi-level, and/or parallel optimization problems, each of which with its own context flow. Through the lenses of NL, existing deep learning methods learns from data through compressing their own context flow, and in-context learning naturally emerges in large models. NL suggests a philosophy to design more expressive learning algorithms with more levels, resulting in higher-order in-context learning and potentially unlocking effective continual learning capabilities. We advocate for NL by presenting three core contributions: (1) Expressive Optimizers: We show that known gradient-based optimizers, such as Adam, SGD with Momentum, etc., are in fact associative memory modules that aim to compress the gradients' information (by gradient descent). Building on this insight, we present other more expressive optimizers with deep memory and/or more powerful learning rules; (2) Self-Modifying Learning Module: Taking advantage of NL's insights on learning algorithms, we present a sequence model that learns how to modify itself by learning its own update algorithm; and (3) Continuum Memory System: We present a new formulation for memory system that generalizes the traditional viewpoint of long/short-term memory. Combining our self-modifying sequence model with the continuum memory system, we present a continual learning module, called Hope, showing promising results in language modeling, knowledge incorporation, and few-shot generalization tasks, continual learning, and long-context reasoning tasks.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.24695.png",
        "numComments": 5,
        "submittedBy": {
            "_id": "65cccd5134a5d74cbaa9446c",
            "avatarUrl": "/avatars/5255b734628992106598eae4f2c5848f.svg",
            "fullname": "Ali Behrouz",
            "name": "AliBehrouz",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 4
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2601.00747",
            "authors": [
                {
                    "_id": "695bd6ef6aa73bc11f09130c",
                    "name": "Max Ruiz Luyten",
                    "hidden": false
                },
                {
                    "_id": "695bd6ef6aa73bc11f09130d",
                    "name": "Mihaela van der Schaar",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-02T17:10:31.000Z",
            "submittedOnDailyAt": "2026-01-05T12:56:27.215Z",
            "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
            "submittedOnDailyBy": {
                "_id": "64b666ceb59ced6b452ffb09",
                "avatarUrl": "/avatars/3114cc44273944a6923c33f94aa93ea7.svg",
                "isPro": false,
                "fullname": "Max Ruiz Luyten",
                "user": "maxruizluyten",
                "type": "user"
            },
            "summary": "State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.",
            "upvotes": 10,
            "discussionId": "695bd6ef6aa73bc11f09130e",
            "ai_summary": "Large language model training methods that optimize for correctness can cause reasoning path diversity collapse, but a new variational framework provides principled solutions to maintain both accuracy and creativity.",
            "ai_keywords": [
                "large language models",
                "bootstrapped reasoning loops",
                "chains of thought",
                "reasoning paths",
                "semantic entropy",
                "Distributional Creative Reasoning",
                "variational objective",
                "gradient flow",
                "probability measures",
                "solution traces",
                "STaR",
                "GRPO",
                "DPO",
                "entropy bonuses"
            ],
            "organization": {
                "_id": "65f9e02087d1c912d985eebf",
                "name": "CambUni",
                "fullname": "University of Cambridge",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/noauth/gdCou-0KoYsLPYqPrz6xn.png"
            }
        },
        "publishedAt": "2026-01-02T12:10:31.000Z",
        "title": "The Reasoning-Creativity Trade-off: Toward Creativity-Driven Problem Solving",
        "summary": "State-of-the-art large language model (LLM) pipelines rely on bootstrapped reasoning loops: sampling diverse chains of thought and reinforcing the highest-scoring ones, mainly optimizing correctness. We analyze how this design choice is sensitive to the collapse of the model's distribution over reasoning paths, slashing semantic entropy and undermining creative problem-solving. To analyze this failure, we introduce Distributional Creative Reasoning (DCR), a unified variational objective that casts training as gradient flow through probability measures on solution traces. STaR, GRPO, and DPO, as well as entropy bonuses, and other methods, all constitute special cases of the same loss. The framework delivers three core results: (i) the diversity decay theorem, describing how correctness-based objectives lead to distinct modes of diversity decay for STaR, GRPO, and DPO; (ii) designs that ensure convergence to a stable and diverse policy, effectively preventing collapse; and (iii) simple, actionable recipes to achieve this in practice. DCR thus offers the first principled recipe for LLMs that remain both correct and creative.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.00747.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "64b666ceb59ced6b452ffb09",
            "avatarUrl": "/avatars/3114cc44273944a6923c33f94aa93ea7.svg",
            "fullname": "Max Ruiz Luyten",
            "name": "maxruizluyten",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "organization": {
            "_id": "65f9e02087d1c912d985eebf",
            "name": "CambUni",
            "fullname": "University of Cambridge",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/noauth/gdCou-0KoYsLPYqPrz6xn.png"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2512.22955",
            "authors": [
                {
                    "_id": "695b3555832867f253525d92",
                    "user": {
                        "_id": "6445e7b1b272430bdbf64e80",
                        "avatarUrl": "/avatars/d3e59a3b488f8539966c944bb16f7b90.svg",
                        "isPro": false,
                        "fullname": "Haoyuan WU",
                        "user": "hywu",
                        "type": "user"
                    },
                    "name": "Haoyuan Wu",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:15.168Z",
                    "hidden": false
                },
                {
                    "_id": "695b3555832867f253525d93",
                    "name": "Hai Wang",
                    "hidden": false
                },
                {
                    "_id": "695b3555832867f253525d94",
                    "name": "Jiajia Wu",
                    "hidden": false
                },
                {
                    "_id": "695b3555832867f253525d95",
                    "name": "Jinxiang Ou",
                    "hidden": false
                },
                {
                    "_id": "695b3555832867f253525d96",
                    "name": "Keyao Wang",
                    "hidden": false
                },
                {
                    "_id": "695b3555832867f253525d97",
                    "name": "Weile Chen",
                    "hidden": false
                },
                {
                    "_id": "695b3555832867f253525d98",
                    "name": "Zihao Zheng",
                    "hidden": false
                },
                {
                    "_id": "695b3555832867f253525d99",
                    "name": "Bei Yu",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-28T14:53:24.000Z",
            "submittedOnDailyAt": "2026-01-05T06:31:03.112Z",
            "title": "Diversity or Precision? A Deep Dive into Next Token Prediction",
            "submittedOnDailyBy": {
                "_id": "6445e7b1b272430bdbf64e80",
                "avatarUrl": "/avatars/d3e59a3b488f8539966c944bb16f7b90.svg",
                "isPro": false,
                "fullname": "Haoyuan WU",
                "user": "hywu",
                "type": "user"
            },
            "summary": "Recent advancements have shown that reinforcement learning (RL) can substantially improve the reasoning abilities of large language models (LLMs). The effectiveness of such RL training, however, depends critically on the exploration space defined by the pre-trained model's token-output distribution. In this paper, we revisit the standard cross-entropy loss, interpreting it as a specific instance of policy gradient optimization applied within a single-step episode. To systematically study how the pre-trained distribution shapes the exploration potential for subsequent RL, we propose a generalized pre-training objective that adapts on-policy RL principles to supervised learning. By framing next-token prediction as a stochastic decision process, we introduce a reward-shaping strategy that explicitly balances diversity and precision. Our method employs a positive reward scaling factor to control probability concentration on ground-truth tokens and a rank-aware mechanism that treats high-ranking and low-ranking negative tokens asymmetrically. This allows us to reshape the pre-trained token-output distribution and investigate how to provide a more favorable exploration space for RL, ultimately enhancing end-to-end reasoning performance. Contrary to the intuition that higher distribution entropy facilitates effective exploration, we find that imposing a precision-oriented prior yields a superior exploration space for RL.",
            "upvotes": 4,
            "discussionId": "695b3556832867f253525d9a",
            "organization": {
                "_id": "6645f953c39288df638dbdd5",
                "name": "Tencent-Hunyuan",
                "fullname": "Tencent Hunyuan",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62d22496c58f969c152bcefd/woKSjt2wXvBNKussyYPsa.png"
            }
        },
        "publishedAt": "2025-12-28T09:53:24.000Z",
        "title": "Diversity or Precision? A Deep Dive into Next Token Prediction",
        "summary": "Recent advancements have shown that reinforcement learning (RL) can substantially improve the reasoning abilities of large language models (LLMs). The effectiveness of such RL training, however, depends critically on the exploration space defined by the pre-trained model's token-output distribution. In this paper, we revisit the standard cross-entropy loss, interpreting it as a specific instance of policy gradient optimization applied within a single-step episode. To systematically study how the pre-trained distribution shapes the exploration potential for subsequent RL, we propose a generalized pre-training objective that adapts on-policy RL principles to supervised learning. By framing next-token prediction as a stochastic decision process, we introduce a reward-shaping strategy that explicitly balances diversity and precision. Our method employs a positive reward scaling factor to control probability concentration on ground-truth tokens and a rank-aware mechanism that treats high-ranking and low-ranking negative tokens asymmetrically. This allows us to reshape the pre-trained token-output distribution and investigate how to provide a more favorable exploration space for RL, ultimately enhancing end-to-end reasoning performance. Contrary to the intuition that higher distribution entropy facilitates effective exploration, we find that imposing a precision-oriented prior yields a superior exploration space for RL.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.22955.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6445e7b1b272430bdbf64e80",
            "avatarUrl": "/avatars/d3e59a3b488f8539966c944bb16f7b90.svg",
            "fullname": "Haoyuan WU",
            "name": "hywu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 23
        },
        "organization": {
            "_id": "6645f953c39288df638dbdd5",
            "name": "Tencent-Hunyuan",
            "fullname": "Tencent Hunyuan",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/62d22496c58f969c152bcefd/woKSjt2wXvBNKussyYPsa.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2601.00671",
            "authors": [
                {
                    "_id": "695b23dc832867f253525d77",
                    "name": "Tianyu Zhao",
                    "hidden": false
                },
                {
                    "_id": "695b23dc832867f253525d78",
                    "name": "Llion Jones",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-02T12:37:53.000Z",
            "submittedOnDailyAt": "2026-01-05T00:07:23.841Z",
            "title": "Fast-weight Product Key Memory",
            "submittedOnDailyBy": {
                "_id": "6039478ab3ecf716b1a5fd4d",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
                "isPro": true,
                "fullname": "taesiri",
                "user": "taesiri",
                "type": "user"
            },
            "summary": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.",
            "upvotes": 1,
            "discussionId": "695b23dc832867f253525d79",
            "ai_summary": "FwPKM introduces a dynamic, fast-weight episodic memory mechanism for sequence modeling that balances storage capacity and efficiency, achieving strong performance on long-context tasks like Needle in a Haystack evaluations.",
            "ai_keywords": [
                "Softmax attention",
                "Product Key Memory (PKM)",
                "Fast-weight Product Key Memory (FwPKM)",
                "fast-weight",
                "local chunk-level gradient descent",
                "episodic memory",
                "Needle in a Haystack evaluations",
                "perplexity"
            ],
            "organization": {
                "_id": "65dfe46e4de6f5d5664ef3af",
                "name": "SakanaAI",
                "fullname": "Sakana AI",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/644b983f0fbe4830f192c4f5/7bSM-11NGnrhHd15hN4W_.jpeg"
            }
        },
        "publishedAt": "2026-01-02T07:37:53.000Z",
        "title": "Fast-weight Product Key Memory",
        "summary": "Sequence modeling layers in modern language models typically face a trade-off between storage capacity and computational efficiency. While Softmax attention offers unbounded storage at prohibitive quadratic costs, linear variants provide efficiency but suffer from limited, fixed-size storage. We propose Fast-weight Product Key Memory (FwPKM), a novel architecture that resolves this tension by transforming the sparse Product Key Memory (PKM) from a static module into a dynamic, \"fast-weight\" episodic memory. Unlike PKM, FwPKM updates its parameters dynamically at both training and inference time via local chunk-level gradient descent, allowing the model to rapidly memorize and retrieve new key-value pairs from input sequences. Experiments reveal that FwPKM functions as an effective episodic memory that complements the semantic memory of standard modules, yielding significant perplexity reductions on long-context datasets. Notably, in Needle in a Haystack evaluations, FwPKM generalizes to 128K-token contexts despite being trained on only 4K-token sequences.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.00671.png",
        "numComments": 2,
        "submittedBy": {
            "_id": "6039478ab3ecf716b1a5fd4d",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6039478ab3ecf716b1a5fd4d/_Thy4E7taiSYBLKxEKJbT.jpeg",
            "fullname": "taesiri",
            "name": "taesiri",
            "type": "user",
            "isPro": true,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 199
        },
        "organization": {
            "_id": "65dfe46e4de6f5d5664ef3af",
            "name": "SakanaAI",
            "fullname": "Sakana AI",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/644b983f0fbe4830f192c4f5/7bSM-11NGnrhHd15hN4W_.jpeg"
        },
        "isAuthorParticipating": false
    },
    {
        "paper": {
            "id": "2601.00575",
            "authors": [
                {
                    "_id": "695b64ed832867f253525e16",
                    "name": "Ishir Garg",
                    "hidden": false
                },
                {
                    "_id": "695b64ed832867f253525e17",
                    "name": "Neel Kolhe",
                    "hidden": false
                },
                {
                    "_id": "695b64ed832867f253525e18",
                    "user": {
                        "_id": "6275a465597c70eb8949fce5",
                        "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
                        "isPro": false,
                        "fullname": "Xuandong Zhao",
                        "user": "Xuandong",
                        "type": "user"
                    },
                    "name": "Xuandong Zhao",
                    "status": "admin_assigned",
                    "statusLastChangedAt": "2026-01-05T16:03:21.868Z",
                    "hidden": false
                },
                {
                    "_id": "695b64ed832867f253525e19",
                    "name": "Dawn Song",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-02T05:26:27.000Z",
            "submittedOnDailyAt": "2026-01-05T04:47:39.325Z",
            "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
            "submittedOnDailyBy": {
                "_id": "6275a465597c70eb8949fce5",
                "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
                "isPro": false,
                "fullname": "Xuandong Zhao",
                "user": "Xuandong",
                "type": "user"
            },
            "summary": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/",
            "upvotes": 1,
            "discussionId": "695b64ee832867f253525e1a",
            "projectPage": "https://ishirgarg.github.io/infosynth_web/",
            "githubRepo": "https://github.com/ishirgarg/infosynth",
            "githubRepoAddedBy": "user",
            "ai_summary": "InfoSynth is a framework that automatically generates novel and diverse reasoning benchmarks for large language models using information-theoretic principles and genetic algorithms.",
            "ai_keywords": [
                "large language models",
                "reasoning benchmarks",
                "information-theoretic principles",
                "KL-divergence",
                "entropy",
                "genetic algorithms",
                "code generation",
                "test cases",
                "benchmark evaluation"
            ],
            "githubStars": 0,
            "organization": {
                "_id": "61f20a9ce108f2cba2dc0730",
                "name": "Berkeley",
                "fullname": "UC Berkeley",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/0FjsTg2txEZZ4dEgmMnQL.png"
            }
        },
        "publishedAt": "2026-01-02T00:26:27.000Z",
        "title": "InfoSynth: Information-Guided Benchmark Synthesis for LLMs",
        "summary": "Large language models (LLMs) have demonstrated significant advancements in reasoning and code generation. However, efficiently creating new benchmarks to evaluate these capabilities remains a challenge. Traditional benchmark creation relies on manual human effort, a process that is both expensive and time-consuming. Furthermore, existing benchmarks often contaminate LLM training data, necessitating novel and diverse benchmarks to accurately assess their genuine capabilities. This work introduces InfoSynth, a novel framework for automatically generating and evaluating reasoning benchmarks guided by information-theoretic principles. We propose metrics based on KL-divergence and entropy to quantify benchmark novelty and diversity without relying on costly model evaluations. Building on this framework, we develop an end-to-end pipeline that synthesizes robust Python coding problems from seed datasets using genetic algorithms and iterative code feedback. Our method generates accurate test cases and solutions to new problems 97% of the time, and the synthesized benchmarks consistently exhibit higher novelty and diversity compared to their seed datasets. Moreover, our algorithm provides a method for controlling the novelty/diversity and difficulty of generated problems. InfoSynth offers a scalable, self-verifying pipeline for constructing high-quality, novel and diverse benchmarks for LLMs. Project Page: https://ishirgarg.github.io/infosynth_web/",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.00575.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "6275a465597c70eb8949fce5",
            "avatarUrl": "https://cdn-avatars.huggingface.co/v1/production/uploads/6275a465597c70eb8949fce5/ph4UogqMurMB0hSXZC38w.png",
            "fullname": "Xuandong Zhao",
            "name": "Xuandong",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 6
        },
        "organization": {
            "_id": "61f20a9ce108f2cba2dc0730",
            "name": "Berkeley",
            "fullname": "UC Berkeley",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/61ac8f8a00d01045fca0ad2f/0FjsTg2txEZZ4dEgmMnQL.png"
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2601.00204",
            "authors": [
                {
                    "_id": "695b4545832867f253525dc5",
                    "user": {
                        "_id": "65813fbeabafd960c84fdf2f",
                        "avatarUrl": "/avatars/d8f9cb56a2e44c3ca4472099437e0b50.svg",
                        "isPro": false,
                        "fullname": "Xiaokun Sun",
                        "user": "XiaokunSun",
                        "type": "user"
                    },
                    "name": "Xiaokun Sun",
                    "status": "claimed_verified",
                    "statusLastChangedAt": "2026-01-05T08:27:11.914Z",
                    "hidden": false
                },
                {
                    "_id": "695b4545832867f253525dc6",
                    "name": "Zeyu Cai",
                    "hidden": false
                },
                {
                    "_id": "695b4545832867f253525dc7",
                    "name": "Hao Tang",
                    "hidden": false
                },
                {
                    "_id": "695b4545832867f253525dc8",
                    "name": "Ying Tai",
                    "hidden": false
                },
                {
                    "_id": "695b4545832867f253525dc9",
                    "name": "Jian Yang",
                    "hidden": false
                },
                {
                    "_id": "695b4545832867f253525dca",
                    "name": "Zhenyu Zhang",
                    "hidden": false
                }
            ],
            "publishedAt": "2026-01-01T04:42:59.000Z",
            "submittedOnDailyAt": "2026-01-05T02:32:57.773Z",
            "title": "MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing",
            "submittedOnDailyBy": {
                "_id": "65813fbeabafd960c84fdf2f",
                "avatarUrl": "/avatars/d8f9cb56a2e44c3ca4472099437e0b50.svg",
                "isPro": false,
                "fullname": "Xiaokun Sun",
                "user": "XiaokunSun",
                "type": "user"
            },
            "summary": "3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.",
            "upvotes": 1,
            "discussionId": "695b4545832867f253525dcb",
            "projectPage": "https://xiaokunsun.github.io/MorphAny3D.github.io",
            "githubRepo": "https://github.com/XiaokunSun/MorphAny3D",
            "githubRepoAddedBy": "user",
            "githubStars": 19
        },
        "publishedAt": "2025-12-31T23:42:59.000Z",
        "title": "MorphAny3D: Unleashing the Power of Structured Latent in 3D Morphing",
        "summary": "3D morphing remains challenging due to the difficulty of generating semantically consistent and temporally smooth deformations, especially across categories. We present MorphAny3D, a training-free framework that leverages Structured Latent (SLAT) representations for high-quality 3D morphing. Our key insight is that intelligently blending source and target SLAT features within the attention mechanisms of 3D generators naturally produces plausible morphing sequences. To this end, we introduce Morphing Cross-Attention (MCA), which fuses source and target information for structural coherence, and Temporal-Fused Self-Attention (TFSA), which enhances temporal consistency by incorporating features from preceding frames. An orientation correction strategy further mitigates the pose ambiguity within the morphing steps. Extensive experiments show that our method generates state-of-the-art morphing sequences, even for challenging cross-category cases. MorphAny3D further supports advanced applications such as decoupled morphing and 3D style transfer, and can be generalized to other SLAT-based generative models. Project page: https://xiaokunsun.github.io/MorphAny3D.github.io/.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2601.00204.png",
        "numComments": 3,
        "submittedBy": {
            "_id": "65813fbeabafd960c84fdf2f",
            "avatarUrl": "/avatars/d8f9cb56a2e44c3ca4472099437e0b50.svg",
            "fullname": "Xiaokun Sun",
            "name": "XiaokunSun",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false
        },
        "isAuthorParticipating": true
    },
    {
        "paper": {
            "id": "2512.24146",
            "authors": [
                {
                    "_id": "695c6b646aa73bc11f0913af",
                    "name": "Chubin Chen",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b0",
                    "name": "Sujie Hu",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b1",
                    "name": "Jiashu Zhu",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b2",
                    "name": "Meiqi Wu",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b3",
                    "name": "Jintao Chen",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b4",
                    "name": "Yanxun Li",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b5",
                    "name": "Nisha Huang",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b6",
                    "name": "Chengyu Fang",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b7",
                    "name": "Jiahong Wu",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b8",
                    "name": "Xiangxiang Chu",
                    "hidden": false
                },
                {
                    "_id": "695c6b646aa73bc11f0913b9",
                    "name": "Xiu Li",
                    "hidden": false
                }
            ],
            "publishedAt": "2025-12-30T11:17:52.000Z",
            "submittedOnDailyAt": "2026-01-05T23:27:44.115Z",
            "title": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning",
            "submittedOnDailyBy": {
                "_id": "66d255e3947594430c723ff6",
                "avatarUrl": "/avatars/c56e4792332a01bf34085a75ee64916e.svg",
                "isPro": false,
                "fullname": "xiaochonglinghu",
                "user": "xiaochonglinghu",
                "type": "user"
            },
            "summary": "Recent studies have demonstrated significant progress in aligning text-to-image diffusion models with human preference via Reinforcement Learning from Human Feedback. However, while existing methods achieve high scores on automated reward metrics, they often lead to Preference Mode Collapse (PMC)-a specific form of reward hacking where models converge on narrow, high-scoring outputs (e.g., images with monolithic styles or pervasive overexposure), severely degrading generative diversity. In this work, we introduce and quantify this phenomenon, proposing DivGenBench, a novel benchmark designed to measure the extent of PMC. We posit that this collapse is driven by over-optimization along the reward model's inherent biases. Building on this analysis, we propose Directional Decoupling Alignment (D^2-Align), a novel framework that mitigates PMC by directionally correcting the reward signal. Specifically, our method first learns a directional correction within the reward model's embedding space while keeping the model frozen. This correction is then applied to the reward signal during the optimization process, preventing the model from collapsing into specific modes and thereby maintaining diversity. Our comprehensive evaluation, combining qualitative analysis with quantitative metrics for both quality and diversity, reveals that D^2-Align achieves superior alignment with human preference.",
            "upvotes": 1,
            "discussionId": "695c6b646aa73bc11f0913ba",
            "ai_summary": "Researchers identify and address Preference Mode Collapse in text-to-image diffusion models through a novel framework that maintains generative diversity while improving human preference alignment.",
            "ai_keywords": [
                "text-to-image diffusion models",
                "Reinforcement Learning from Human Feedback",
                "Preference Mode Collapse",
                "reward hacking",
                "DivGenBench",
                "Directional Decoupling Alignment",
                "D$^2$-Align",
                "reward model",
                "embedding space",
                "reward signal",
                "optimization process"
            ],
            "organization": {
                "_id": "67d11771890254196d3174e5",
                "name": "GD-ML",
                "fullname": "AMAP-ML",
                "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"
            }
        },
        "publishedAt": "2025-12-30T06:17:52.000Z",
        "title": "Taming Preference Mode Collapse via Directional Decoupling Alignment in Diffusion Reinforcement Learning",
        "summary": "Recent studies have demonstrated significant progress in aligning text-to-image diffusion models with human preference via Reinforcement Learning from Human Feedback. However, while existing methods achieve high scores on automated reward metrics, they often lead to Preference Mode Collapse (PMC)-a specific form of reward hacking where models converge on narrow, high-scoring outputs (e.g., images with monolithic styles or pervasive overexposure), severely degrading generative diversity. In this work, we introduce and quantify this phenomenon, proposing DivGenBench, a novel benchmark designed to measure the extent of PMC. We posit that this collapse is driven by over-optimization along the reward model's inherent biases. Building on this analysis, we propose Directional Decoupling Alignment (D^2-Align), a novel framework that mitigates PMC by directionally correcting the reward signal. Specifically, our method first learns a directional correction within the reward model's embedding space while keeping the model frozen. This correction is then applied to the reward signal during the optimization process, preventing the model from collapsing into specific modes and thereby maintaining diversity. Our comprehensive evaluation, combining qualitative analysis with quantitative metrics for both quality and diversity, reveals that D^2-Align achieves superior alignment with human preference.",
        "thumbnail": "https://cdn-thumbnails.huggingface.co/social-thumbnails/papers/2512.24146.png",
        "numComments": 1,
        "submittedBy": {
            "_id": "66d255e3947594430c723ff6",
            "avatarUrl": "/avatars/c56e4792332a01bf34085a75ee64916e.svg",
            "fullname": "xiaochonglinghu",
            "name": "xiaochonglinghu",
            "type": "user",
            "isPro": false,
            "isHf": false,
            "isHfAdmin": false,
            "isMod": false,
            "followerCount": 4
        },
        "organization": {
            "_id": "67d11771890254196d3174e5",
            "name": "GD-ML",
            "fullname": "AMAP-ML",
            "avatar": "https://cdn-uploads.huggingface.co/production/uploads/67d116c47be76de1a40873ca/s5ukAx9E36ZZIKvbpBRi4.png"
        },
        "isAuthorParticipating": false
    }
]