[
    {
        "名称": "2025 [2501.13200] SRMT: Shared Memory for Multi-agent Lifelong Pathfinding.pdf",
        "作者": "Alsu Sagirova, Yuri Kuratov, Mikhail Burtsev",
        "摘要": "摘要：多智能体强化学习（MARL）在解决各种环境中的合作和竞争性多智能体问题方面取得了显著进展。MARL的主要挑战之一是需要明确预测智能体的行为以实现合作。为解决这一问题，我们提出了共享递归记忆转换器（SRMT），通过汇集和全局广播个体工作记忆，将记忆转换器扩展到多智能体设置中，使智能体能够隐式交换信息并协调其行动。我们在玩具瓶颈导航任务中评估了SRMT在部分可观察的多智能体路径规划问题中的表现，该任务要求智能体通过一个狭窄的走廊，并在POGEMA基准任务集上进行了测试。在瓶颈任务中，SRMT在稀疏奖励下持续优于各种强化学习基线，并且在训练期间能有效地推广到更长的走廊上。在包括迷宫、随机和MovingAI的POGEMA地图上，SRMT在最近的MARL、混合和基于规划的算法中具有竞争力。这些结果表明，将共享递归记忆整合到基于转换器的架构中可以增强去中心化多智能体系统中的协调能力。用于训练和评估的源代码可在GitHub上获得：此https URL。",
        "地址": "https://arxiv.org/pdf/2501.13200.pdf"
    },
    {
        "名称": "2025 [2501.13629] Sigma: Differential Rescaling of Query, Key and Value for Efficient Language Models.pdf",
        "作者": "Zhenghao Lin, Zihao Tang, Xiao Liu, Yeyun Gong, Yi Cheng, Qi Chen, Hang Li, Ying Xin, Ziyue Yang, Kailai Yang, Yu Yan, Xiao Liang, Shuai Lu, Yiming Huang, Zheheng Luo, Lei Qu, Xuan Feng, Yaoxiang Wang, Yuqing Xia, Feiyang Chen, Yuting Jiang, Yasen Hu, Hao Ni, Binyang Li, Guoshuai Zhao, Jui-Hao Chiang, Zhongxin Guo, Chen Lin, Kun Kuang, Wenjie Li, Yelong Shen, Jian Jiao, Peng Cheng, Mao Yang",
        "摘要": "摘要: 我们介绍了Sigma，这是一种高效的大型语言模型，专门为系统领域设计，并通过一种新颖的架构——DiffQKV注意力机制赋能。DiffQKV注意力机制通过差异化优化注意力机制中的Query (Q)、Key (K)和Value (V)组件，根据它们对模型性能和效率指标的不同影响，显著提高了Sigma的推理效率。具体而言，我们（1）进行广泛的实验，展示模型对K和V组件压缩的不同敏感性，进而开发出差异压缩的KV组件，（2）提出增强Q头维度，以扩展Q头维度，从而在对推理速度影响最小的情况下提高模型的表示能力。严格的理论和实证分析表明，DiffQKV注意力机制显著提高了效率，在长上下文场景中相比传统的分组查询注意力机制（GQA）提高了多达33.36%的推理速度。我们在从各种来源精心收集的19.5B系统领域数据和1万亿合成和重写数据上预训练了Sigma，总共处理了6万亿tokens。在通用领域，Sigma实现了与其他最先进模型相当的性能。在系统领域，我们引入了第一个综合基准AIMicius，Sigma在所有任务中表现出色，相比GPT-4有高达52.5%的绝对性能提升。\n\n论文链接: https://arxiv.org/pdf/2501.13629.pdf",
        "地址": "https://arxiv.org/pdf/2501.13629.pdf"
    },
    {
        "名称": "2025 [2501.13918] Improving Video Generation with Human Feedback.pdf",
        "作者": "Jie Liu, Gongye Liu, Jiajun Liang, Ziyang Yuan, Xiaokun Liu, Mingwu Zheng, Xiele Wu, Qiulin Wang, Wenyu Qin, Menghan Xia, Xintao Wang, Xiaohong Liu, Fei Yang, Pengfei Wan, Di Zhang, Kun Gai, Yujiu Yang, Wanli Ouyang",
        "摘要": "摘要：视频生成技术通过修正流技术取得了显著进展，但仍存在运动不流畅和视频与提示不对齐等问题。在这项工作中，我们开发了一个系统管道，利用人类反馈来缓解这些问题并改进视频生成模型。具体而言，我们首先构建了一个大型人类偏好数据集，重点关注现代视频生成模型，包含跨多个维度的成对注释。随后，我们引入了一个多维度的视频奖励模型VideoReward，研究了注释和各种设计选择对其奖励效果的影响。从统一的强化学习角度出发，旨在通过KL正则化最大化奖励，我们通过扩展扩散模型中的那些方法，针对基于流的模型引入了三种对齐算法。其中包括两个训练阶段策略：流的直接偏好优化（Flow-DPO）和流的奖励加权回归（Flow-RWR），以及一个推理阶段技术Flow-NRG，该技术将奖励指导直接应用于噪声视频。实验结果表明，VideoReward显著优于现有的奖励模型，而Flow-DPO相比于Flow-RWR和标准的监督微调方法表现更优。此外，Flow-NRG允许用户在推理期间为多个目标分配自定义权重，以满足个性化视频质量需求。项目页面：这个https URL。",
        "地址": "https://arxiv.org/pdf/2501.13918.pdf"
    },
    {
        "名称": "2025 [2501.13919] Temporal Preference Optimization for Long-Form Video Understanding.pdf",
        "作者": "Rui Li, Xiaohan Wang, Yuhui Zhang, Zeyu Wang, Serena Yeung-Levy",
        "摘要": "摘要：尽管视频大规模多模态模型（video-LMMs）取得了显著进展，但在长视频中实现有效的时间性定位仍然是现有模型面临的挑战。为了解决这一局限性，我们提出了一种新颖的后训练框架——时间偏好优化（TPO），其设计目的是通过偏好学习来增强视频大规模多模态模型的时间性定位能力。TPO采用自训练方法，通过利用两个粒度的精心策划的偏好数据集，使模型能够区分时间定位良好和不准确的时间响应：局部时间定位，专注于特定视频片段；和全面时间定位，捕捉整个视频序列中的扩展时间依赖性。通过在这些偏好数据集上进行优化，TPO显著增强了时间理解能力，同时减少了对人工标注数据的依赖。在三个长视频理解基准（LongVideoBench、MLVU和Video-MME）上的大量实验表明，TPO在两个最先进的视频大规模多模态模型中的有效性。值得注意的是，LLaVA-Video-TPO在Video-MME基准上确立了作为领先的7B模型的地位，强调了TPO作为一种可扩展且高效的长视频理解时间推理的解决方案的潜力。项目页面：this https URL。",
        "地址": "https://arxiv.org/pdf/2501.13919.pdf"
    },
    {
        "名称": "2025 [2501.13926] Can We Generate Images with CoT? Let's Verify and Reinforce Image Generation Step by Step.pdf",
        "作者": "Ziyu Guo, Renrui Zhang, Chengzhuo Tong, Zhizheng Zhao, Peng Gao, Hongsheng Li, Pheng-Ann Heng",
        "摘要": "摘要：尽管链式思维（Chain-of-Thought, CoT）推理在大型模型中已被广泛探索以解决复杂的理解任务，但这些策略是否可以应用于验证和强化图像生成场景仍然是一个未解的问题。在本文中，我们首次对CoT推理在增强自回归图像生成中的潜力进行了全面调查。我们重点研究了三个技术：扩展测试时间计算进行验证，通过直接偏好优化（DPO）对齐模型偏好，以及将这些技术结合以产生互补效果。我们的结果表明，这些方法可以有效地适应并组合，以显著提高图像生成性能。此外，鉴于奖励模型在我们研究中的关键作用，我们提出了专门用于自回归图像生成的潜在评估奖励模型（PARM）和PARM++。PARM通过潜在评估方法自适应地评估每一步生成，融合了现有奖励模型的优点，而PARM++进一步引入反思机制以自我纠正生成的不满意图像。利用我们研究的推理策略，我们增强了基准模型Show-o，使其在GenEval基准测试中获得了显著的+24%改进，超过了Stable Diffusion 3的+15%。我们希望我们的研究为将CoT推理与自回归图像生成的结合提供独特见解并开辟新路径。代码和模型在此https URL发布。",
        "地址": "https://arxiv.org/pdf/2501.13926.pdf"
    },
    {
        "名称": "2025 [2501.13826] Video-MMMU: Evaluating Knowledge Acquisition from Multi-Discipline Professional Videos.pdf",
        "作者": "Kairui Hu, Penghao Wu, Fanyi Pu, Wang Xiao, Yuanhan Zhang, Xiang Yue, Bo Li, Ziwei Liu",
        "摘要": "摘要：人类通过三个认知阶段来获取知识：感知信息、理解知识及适应知识以解决新问题。视频作为这一学习过程的有效媒介，有助于顺利通过这些认知阶段。然而，现有的视频基准无法系统地评估大型多模态模型（LMMs）的知识获取能力。为解决这一问题，我们提出了视频-MMMU，这是一个多模态、多学科的基准，旨在评估LMMs从视频中获取和利用知识的能力。视频-MMMU由300个专家级视频和900个人工标注的问题组成，覆盖六个学科，通过与阶段对齐的问题和答案对来评估知识获取：感知、理解和适应。提出的知识增益量度{\\\\Delta}knowledge量化了视频观看后的性能改善。对LMMs的评估显示，随着认知需求的增加，其性能急剧下降，并强调了人与模型在知识获取方面存在的显著差距，突出了需要改进LMMs从视频中学习和适应能力的方法。\n\n翻译成中文的摘要：人类通过感知信息、理解知识和适应知识来解决新问题三个认知阶段来获取知识。视频是这一学习过程的有效媒介，有助于顺利完成这些认知阶段。然而，现有的视频基准无法系统地评估大型多模态模型（LMMs）的知识获取能力。为解决这一问题，我们引入了视频-MMMU，这是一个多模态、多学科的基准，旨在评估LMMs从视频中获取和利用知识的能力。视频-MMMU包含由300个专家级视频和900个人工注释的问题，涵盖六个学科，通过与阶段对齐的问答对来评估知识获取：感知、理解和适应。提出的知识增益度量{\\\\Delta}knowledge量化了视频观看后的性能提升。对LMMs的评估表明，随着认知需求的增加，其性能急剧下降，强调了人与模型在知识获取方面存在的显著差距，突显了需要提高LMMs从视频中学习和适应能力的方法。",
        "地址": "https://arxiv.org/pdf/2501.13826.pdf"
    },
    {
        "名称": "2025 [2501.13920] IMAGINE-E: Image Generation Intelligence Evaluation of State-of-the-art Text-to-Image Models.pdf",
        "作者": "Jiayi Lei, Renrui Zhang, Xiangfei Hu, Weifeng Lin, Zhen Li, Wenjian Sun, Ruoyi Du, Le Zhuo, Zhongyu Li, Xinyue Li, Shitian Zhao, Ziyu Guo, Yiting Lu, Peng Gao, Hongsheng Li",
        "摘要": "摘要：随着扩散模型的快速发展，文本生成图像（T2I）模型取得了显著进展，展示了在遵循提示和图像生成方面的出色能力。近期推出的模型如FLUX.1和Ideogram2.0，以及其他如Dall-E3和Stable Diffusion 3，在各类复杂任务中表现优异，引发了人们对T2I模型是否正迈向通用适用性的疑问。除了传统的图像生成，这些模型在可控生成、图像编辑、视频、音频、3D和运动生成以及诸如语义分割和深度估计等计算机视觉任务方面表现出色。然而，目前的评估框架不足以全面评估这些模型在不断扩展的领域中的表现。为了全面评估这些模型，我们开发了IMAGINE-E并测试了六个主要模型：FLUX.1, Ideogram2.0, Midjourney, Dall-E3, Stable Diffusion 3和Jimeng。我们的评估分为五个关键领域：结构化输出生成、真实感和物理一致性、特定领域生成、挑战性场景生成和多风格创作任务。这一全面评估突出了每个模型的优缺点，特别是FLUX.1和Ideogram2.0在结构化和特定领域任务中的出色表现，强调了T2I模型作为基础AI工具的应用和潜力的不断扩展。这项研究为T2I模型当前状态和未来发展方向提供了宝贵的见解。评估脚本将在此https URL发布。",
        "地址": "https://arxiv.org/pdf/2501.13920.pdf"
    },
    {
        "名称": "2025 [2501.10018] DiffuEraser: A Diffusion Model for Video Inpainting.pdf",
        "作者": "Xiaowen Li, Haolan Xue, Peiran Ren, Liefeng Bo",
        "摘要": "摘要： 近期的视频修复算法结合了基于光流的像素传播和基于变压器的生成，以利用光流从邻近帧恢复纹理和物体，同时通过视觉变压器完成遮罩区域。然而，这些方法在处理大遮罩时往往会遇到模糊和时间不一致的问题，突显了对具有增强生成能力的模型的需求。近年来，扩散模型因其出色的性能在图像和视频生成中崭露头角。在本文中，我们介绍了一种基于稳定扩散的视频修复模型DiffuEraser，旨在填充遮罩区域以获得更高细节和更连贯的结构。我们结合了先验信息以提供初始化和弱条件，这有助于减轻噪声伪影并抑制幻觉。此外，为了在长序列推理过程中提高时间一致性，我们扩展了先验模型和DiffuEraser的时间感受野，并通过利用视频扩散模型的时间平滑特性进一步增强了一致性。实验结果表明，我们提出的方法在内容完整性和时间一致性方面优于最新技术，同时保持了可接受的效率。",
        "地址": "https://arxiv.org/pdf/2501.10018.pdf"
    },
    {
        "名称": "2025 [2501.10799] Step-KTO: Optimizing Mathematical Reasoning through Stepwise Binary Feedback.pdf",
        "作者": "Yen-Ting Lin, Di Jin, Tengyu Xu, Tianhao Wu, Sainbayar Sukhbaatar, Chen Zhu, Yun He, Yun-Nung Chen, Jason Weston, Yuandong Tian, Arash Rahnama, Sinong Wang, Hao Ma, Han Fang",
        "摘要": "摘要：大型语言模型（LLMs）在数学推理方面最近表现出显著的成功。尽管链式思维提示和自一致性采样等方法取得了进展，但这些进展通常侧重于最终的正确性，而没有确保底层推理过程的连贯性和可靠性。本文引入了Step-KTO，一个结合过程级别和结果级别二元反馈的训练框架，以引导LLMs走向更可信的推理轨迹。通过为中间推理步骤和最终答案提供二元评估，Step-KTO 鼓励模型遵循逻辑进展，而不是依赖表面的捷径。我们在具有挑战性的数学基准测试上的实验表明，Step-KTO 显著提高了最终答案的准确性和中间推理步骤的质量。例如，在MATH-500数据集上，Step-KTO相较于强大的基线方法在Pass@1准确率上取得了显著的改进。这些结果突显了将逐步过程反馈整合到LLM训练中的前景，为更具解释性和可靠性的推理能力铺平了道路。",
        "地址": "https://arxiv.org/pdf/2501.10799.pdf"
    },
    {
        "名称": "2025 [2501.13554] One-Prompt-One-Story: Free-Lunch Consistent Text-to-Image Generation Using a Single Prompt.pdf",
        "作者": "Tao Liu, Kai Wang, Senmao Li, Joost van de Weijer, Fahad Shahbaz Khan, Shiqi Yang, Yaxing Wang, Jian Yang, Ming-Ming Cheng",
        "摘要": "摘要：文本到图像生成模型可以根据输入提示生成高质量图像。然而，它们在支持故事情节中保持身份一致生成的要求方面存在困难。现有的解决方法通常需要在大型数据集上进行广泛训练或对原始模型架构进行额外修改。这限制了它们在不同领域和各种扩散模型配置中的适用性。在本文中，我们首先观察到语言模型具有一种我们称为上下文一致性的固有能力，能够通过单个提示在上下文中理解身份。受到这种固有上下文一致性的启发，我们提出了一种新的无需训练的一致文本到图像生成方法，称为“一提示一故事”（1Prompt1Story）。我们的1Prompt1Story方法将所有提示结合为一个输入以进行文本到图像扩散模型的操作，初步保留角色身份。然后，我们使用两种新技术：奇异值重加权和身份保留交叉注意来优化生成过程，确保每帧与输入描述更好地对齐。在我们的实验中，我们通过定量指标和定性评估将我们的方法与各种现有的一致文本到图像生成方法进行比较，以证明其有效性。代码可在此https URL获得。\n\n翻译完成。",
        "地址": "https://arxiv.org/pdf/2501.13554.pdf"
    },
    {
        "名称": "2025 [2501.13824] Hallucinations Can Improve Large Language Models in Drug Discovery.pdf",
        "作者": "Shuzhou Yuan, Michael Färber",
        "摘要": "摘要: 对大语言模型（LLMs）出现幻觉的担忧已被研究人员提出，但在药物发现等需要创造力的领域中，它们的潜力值得探索。本文提出了幻觉可以改善LLMs在药物发现中的表现的假设。为了验证这一假设，我们使用LLMs来用自然语言描述分子的SMILES字符串，然后将这些描述作为提示的一部分以解决药物发现中的特定任务。在对七个LLMs和五个分类任务的评估中，我们的发现证实了这一假设：LLMs在包含幻觉的文本下可以取得更好的表现。值得注意的是，Llama-3.1-8B在无幻觉的基线下实现了18.35%的ROC-AUC增益。此外，由GPT-4o生成的幻觉在不同模型中提供了最一致的改进。此外，我们进行了实证分析和案例研究，以调查影响性能的关键因素及其潜在原因。我们的研究揭示了幻觉在LLMs中的潜在用途，并为今后利用LLMs进行药物发现的研究提供了新的视角。",
        "地址": "https://arxiv.org/pdf/2501.13824.pdf"
    },
    {
        "名称": "2025 [2501.13452] EchoVideo: Identity-Preserving Human Video Generation by Multimodal Feature Fusion.pdf",
        "作者": "Jiangchuan Wei, Shiyue Yan, Wenfeng Lin, Boyuan Liu, Renjie Chen, Mingyu Guo",
        "摘要": "摘要: 视频生成的最新进展显著影响了各种下游应用，特别是在身份保持视频生成（IPT2V）方面。然而，现有方法由于依赖于低级面部图像信息，导致了“复制粘贴”伪影和低相似度问题。这种依赖会导致面部外观僵硬，并且伪影反映了无关的细节。为了应对这些挑战，我们提出了EchoVideo，采用了两个关键策略：（1）身份图像-文本融合模块（IITF），该模块集成了来自文本的高级语义特征，能够捕捉干净的面部身份表示，同时消除遮挡、姿势和光照变化，以避免伪影引入；（2）两阶段训练策略，在第二阶段采用随机方法随机使用浅层面部信息。目标是在利用浅层特征提供的保真度增强同时减少对它们的过度依赖。这一策略鼓励模型在训练期间利用高级特征，最终促进对面部身份的更鲁棒表示。EchoVideo有效地保留了面部身份并保持了全身的完整性。大量实验证明，该方法在生成高质量、可控性和真实感视频方面取得了卓越的结果。",
        "地址": "https://arxiv.org/pdf/2501.13452.pdf"
    },
    {
        "名称": "2025 [2501.13075] Evolution and The Knightian Blindspot of Machine Learning.pdf",
        "作者": "Joel Lehman, Elliot Meyerson, Tarek El-Gaaly, Kenneth O. Stanley, Tarin Ziyaee",
        "摘要": "摘要：本文认为，机器学习（ML）在很大程度上忽视了通用智能的一个重要方面：在开放世界中对质上未知未来的鲁棒性。这种鲁棒性与经济学中的奈特不确定性（KU）有关，即无法量化的不确定性，这在ML的关键形式中被排除在考虑范围之外。本文旨在识别这一盲点，论证其重要性，并催化解决它的研究，我们认为这是创建真正鲁棒的开放世界AI所必需的。为了帮助阐明这一盲点，我们将机器学习的一个领域——强化学习（RL）与生物进化的过程进行了对比。尽管RL在进行中的进展惊人，但在开放世界情境下仍然挣扎，经常在不可预见的情况下失败。例如，将仅在美国训练的自动驾驶汽车政策零样本转移到英国，目前看来是极其冒险的。与此形成鲜明对比的是，生物进化例行地产生在开放世界中茁壮成长的代理，有时甚至是在显著超出分布的情境中（例如，入侵物种；或人类，他们确实进行这种零样本国际驾驶）。有趣的是，进化在没有显式理论、形式或数学梯度的情况下就实现了这样的鲁棒性。我们探讨了RL典型形式的假设，显示它们如何限制RL与不断变化的复杂世界的未知未知的接触。此外，我们确定了进化过程如何培养对新颖和不可预测挑战的鲁棒性，并讨论了算法化地体现它们的潜在途径。结论是，ML引人注目的现存脆弱性可能源于其形式盲点，直接应对KU挑战可能带来显著收益。\n\n作者：Joel Lehman, Elliot Meyerson, Tarek El-Gaaly, Kenneth O. Stanley, Tarin Ziyaee\n\n链接：https://arxiv.org/pdf/2501.13075.pdf\n\n标题：2025 [2501.13075] Evolution and The Knightian Blindspot of Machine Learning",
        "地址": "https://arxiv.org/pdf/2501.13075.pdf"
    },
    {
        "名称": "2025 [2501.13124] Debate Helps Weak-to-Strong Generalization.pdf",
        "作者": "Hao Lang, Fei Huang, Yongbin Li",
        "摘要": "摘要：现有的对齐已经具备能力模型与期望行为的常用方法依赖于人类提供监督。然而，未来超人类模型的能力将超过人类。因此，人类只能对超人类模型进行弱监督。这种预期中人类评估的不足将削弱未来人工智能系统的安全性。可扩展监管和从弱到强的泛化是解决这一问题的两种互补方法。在本文中，我们尝试结合这两种方法的优势以进一步改善对齐。具体来说，我们研究了使用强大的预训练模型改进人类监督的方法，然后通过增强的弱人类监督对强模型进行监督。为了实现迭代的实验进展，我们考虑了一个类比：我们能否用一个强模型改善弱模型的监督，然后用它来监督强模型？我们通过使用强大模型的额外帮助，在真实标签上微调弱小的模型进行实证测试，然后在由弱模型生成的标签上微调强大模型。我们发现，辩论可以帮助弱模型从不可信的强模型中提取可信的信息，为训练弱模型提供样本上下文的杠杆。我们还表明，弱模型的集成有助于利用强模型辩论者生成的长篇论点，并获得更稳健的监管估计。在 OpenAI 从弱到强的 NLP 基准测试上进行的大量实验表明，结合后的方法导致了更好的对齐，这表明辩论有助于从弱到强的泛化。\n\n年份：2025\n\n作者：Hao Lang, Fei Huang, Yongbin Li\n\n评论：发表于AAAI2025的AI对齐特别轨道（口头报告）\n\n网址：https://arxiv.org/pdf/2501.13124.pdf\n\n标题：辩论有助于从弱到强的泛化",
        "地址": "https://arxiv.org/pdf/2501.13124.pdf"
    },
    {
        "名称": "2025 [2501.10979] Control LLM: Controlled Evolution for Intelligence Retention in LLM.pdf",
        "作者": "Haichao Wei, Yunxiang Ren, Zhoutong Fu, Aman Lunia, Yi-Lin Chen, Alice Leung, Ya Xu",
        "摘要": "摘要：大规模语言模型（LLMs）需要大量的计算资源，因此在不重头开始训练的情况下提升其能力是至关重要的。该领域的一个关键挑战是灾难性遗忘（CF），它会在持续预训练（CPT）和持续监督微调（CSFT）过程中阻碍性能。我们提出了Control LLM，这是一种新的方法，利用并行预训练和扩展的变压器块，通过插值策略对齐它们的隐藏状态。这种方法有效地在保持现有任务性能的同时，无缝整合了新的知识。大量实验展示了Control LLM在CPT和CSFT中的有效性。在Llama3.1-8B-Instruct上，它在数学推理（Math-Hard上提升了14.4%）和编码性能（MBPP-PLUS上提升了10%）方面取得了显著的改进。在Llama3.1-8B上，它增强了多语言能力（C-Eval上提升了10.6%，CMMLU上提升了6.8%，CMMLU-0shot-CoT上提升了30.2%）。它超越了现有方法，并在同一基础模型微调的开源模型中实现了SOTA，使用的数据和计算量显著减少。关键是，这些收益是在保留强大的原始能力的同时实现的，与开源的数学和编码模型相比，性能下降仅为不到4.3%，而不是超过35%。这种方法已经成功部署在LinkedIn的使用GenAI技术的求职者和广告单元产品中。为了支持进一步的研究，我们向社区发布了训练和评估代码（网址：https://arxiv.org/pdf/2501.10979.pdf）以及在公共数据集上训练的模型（网址：https://arxiv.org/pdf/2501.10979.pdf）。",
        "地址": "https://arxiv.org/pdf/2501.10979.pdf"
    },
    {
        "名称": "2025 [2501.10283] GSTAR: Gaussian Surface Tracking and Reconstruction.pdf",
        "作者": "Chengwei Zheng, Lixin Xue, Juan Zarate, Jie Song",
        "摘要": "摘要：3D 高斯分布技术能够高效地对静态场景进行照片级逼真渲染。近期的研究将这些方法扩展到支持曲面重建和追踪。然而，由于曲面出现、消失或分裂等复杂的拓扑变化，用 3D 高斯进行动态曲面追踪仍然具有挑战性。为了解决这些挑战，我们提出了 GSTAR，一种新的方法，能够实现照片级逼真渲染、精确的曲面重建以及对具有变化拓扑的常规动态场景进行可靠的 3D 追踪。在输入多视角捕捉的情况下，GSTAR 将高斯绑定到网格面上以表示动态对象。对于拓扑一致的曲面，GSTAR 保持网格拓扑结构并使用高斯追踪网格。在拓扑变化的区域，GSTAR 自适应地将高斯从网格上解绑，从而基于这些优化的高斯实现精确的配准和新曲面的生成。此外，我们提出一种基于曲面的场景流方法，为帧间追踪提供了稳健的初始化。实验表明，我们的方法能够有效地追踪和重建动态曲面，支持多种应用。我们的项目页面和代码发布可在此网址找到：https://arxiv.org/pdf/2501.10283.pdf。",
        "地址": "https://arxiv.org/pdf/2501.10283.pdf"
    }
]