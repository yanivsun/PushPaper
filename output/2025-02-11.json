[
    {
        "名称": "2025 [2502.06394] SynthDetoxM: Modern LLMs are Few-Shot Parallel Detoxification Data Annotators.pdf",
        "作者": "Daniil Moskovskiy, Nikita Sushko, Sergey Pletenev, Elena Tutubalina, Alexander Panchenko",
        "摘要": "摘要: 现有的多语言文本净化方法受到平行多语言数据集缺乏的限制。为了解决这一问题，本文介绍了一种生成多语言平行净化数据的流程。我们还发布了SynthDetoxM，这是一个手动收集和合成生成的多语言平行文本净化数据集，包含了德语、法语、西班牙语和俄语的16000对高质量净化句子。数据来源于不同的毒性评估数据集，并在少量示例设置下重新用九个现代开源大型语言模型（LLMs）改写。我们的实验表明，即使在数据有限的情况下，使用合成数据集训练的模型性能优于用人工注释的MultiParaDetox数据集训练的模型。训练于SynthDetoxM的数据集上的模型在少量示例设置下超越了所有评估的LLMs。为了推动多语言文本净化领域的进一步研究，我们公开了我们的数据集和代码。\n\n作者: Daniil Moskovskiy, Nikita Sushko, Sergey Pletenev, Elena Tutubalina, Alexander Panchenko\n\n备注: 已被NAACL 2025主会议接受\n\n链接: [https://arxiv.org/pdf/2502.06394.pdf](https://arxiv.org/pdf/2502.06394.pdf)\n\n标题: SynthDetoxM: 现代大型语言模型是少量示例平行净化数据注释器",
        "地址": "https://arxiv.org/pdf/2502.06394.pdf"
    },
    {
        "名称": "2025 [2502.06703] Can 1B LLM Surpass 405B LLM? Rethinking Compute-Optimal Test-Time Scaling.pdf",
        "作者": "Runze Liu, Junqi Gao, Jian Zhao, Kaiyan Zhang, Xiu Li, Biqing Qi, Wanli Ouyang, Bowen Zhou",
        "摘要": "论文摘要: 测试时扩展 (Test-Time Scaling, TTS) 是一种通过在推理阶段使用额外计算来提高大型语言模型 (LLMs) 性能的重要方法。然而，目前的研究尚未系统分析决策模型、过程奖励模型 (PRMs) 和问题难度如何影响 TTS。这种缺乏分析限制了对 TTS 方法的理解和实际应用。在本文中，我们关注两个核心问题：(1) 在不同的决策模型、PRMs 和问题难度级别上，扩展测试时计算的最佳方法是什么？(2) 额外计算在多大程度上可以提高 LLM 在复杂任务上的性能，以及较小的语言模型能否通过这种方法超越较大的模型？通过对 MATH-500 和具有挑战性的 AIME24 任务进行全面实验，我们有以下观察结果：(1) 计算最优的 TTS 策略高度依赖于决策模型、PRM 和问题难度的选择。(2) 使用我们的计算最优 TTS 策略，极小的决策模型可以超越较大的模型。例如，一个1B的LLM可以在MATH-500上胜过一个405B的LLM。此外，在 MATH-500和AIME24上，一个0.5B的LLM超过了GPT-4o，3B的LLM超越了405B的LLM，7B的LLM击败了o1和DeepSeek-R1，同时具有更高的推理效率。这些发现表明，为每个任务和模型的特定特性调整TTS策略的重要性，并表明TTS是一种有前途的方法，可以增强LLM的推理能力。",
        "地址": "https://arxiv.org/pdf/2502.06703.pdf"
    },
    {
        "名称": "2025 [2502.06781] Exploring the Limit of Outcome Reward for Learning Mathematical Reasoning.pdf",
        "作者": "Chengqi Lyu, Songyang Gao, Yuzhe Gu, Wenwei Zhang, Jianfei Gao, Kuikun Liu, Ziyi Wang, Shuaibin Li, Qian Zhao, Haian Huang, Weihan Cao, Jiangning Liu, Hongwei Liu, Junnan Liu, Songyang Zhang, Dahua Lin, Kai Chen",
        "摘要": "摘要：推理能力，特别是解决复杂数学问题的能力，是通用智能的关键组成部分。诸如OpenAI的o系列模型等专有公司的最新进展在推理任务上取得了显著进步。然而，这些技术的具体细节尚未完全公开，而已知采用的技术仅为强化学习（RL）和长链思维。本文提出了一种新的RL框架，称为OREAL，旨在通过基于结果奖励的强化学习来达到数学推理任务的性能极限，在这种情况下，仅可轻松获取二进制结果奖励。我们从理论上证明，使用从N个样本中挑选最优的（BoN）采样结果进行正向轨迹行为克隆，即可在二进制反馈环境中学习到KL正则化的最优策略。这种模型还意味着负样本的奖励应重新设计，以确保正负样本之间的梯度一致性。为缓解RL中长期存在的稀疏奖励问题，特别是因推理任务的长链思维部分正确性而加剧的稀疏奖励问题，我们进一步应用了令牌级奖励模型，对学习中的推理轨迹中的重要令牌进行采样。使用OREAL，7B模型首次通过RL在MATH-500上获得了与32B模型媲美的94.0的pass@1准确率。OREAL-32B还以95.0的pass@1准确率超越了之前通过蒸馏训练的32B模型。我们的研究还表明了初始策略模型和RL训练查询的重要性。代码、模型和数据将发布以促进未来的研究。",
        "地址": "https://arxiv.org/pdf/2502.06781.pdf"
    },
    {
        "名称": "2025 [2502.06060] Training Language Models for Social Deduction with Multi-Agent Reinforcement Learning.pdf",
        "作者": "Bidipta Sarkar, Warren Xia, C. Karen Liu, Dorsa Sadigh",
        "摘要": "摘要：在多智能体环境中使用自然语言交流是一种强大的工具，因为它使独立的代理能够在部分可观察的环境中共享信息，并允许与人类进行零样本协调。然而，大多数先前的工作要么依赖于大量的人类演示进行训练，要么缺乏生成自然且有用的交流策略的能力。在这项工作中，我们在没有任何人类演示的情况下训练语言模型，用自然语言对其环境进行有效讨论。我们将交流问题分解为聆听和说话。我们的关键思想是利用代理的目标来预测有关世界的有用信息，并将其作为引导交流的稠密奖励信号。具体而言，我们通过训练模型根据讨论预测环境信息来提高其聆听技能，同时通过多智能体强化学习在信息对其他代理的影响基础上奖励消息，从而提高模型的说话技能。为了研究复杂社会环境中交流的作用和必要性，我们研究了一个基于《Among Us》的具身社会推理游戏，在该游戏中需要回答的关键问题是敌对伪装者的身份。我们分析了由于我们的方法而产生的行为，例如指控嫌疑人和提供证据，发现它能够进行强有力的讨论，使获胜率相比标准强化学习提高了一倍。我们在此链接 https URL 发布了我们的代码和模型。",
        "地址": "https://arxiv.org/pdf/2502.06060.pdf"
    },
    {
        "名称": "2025 [2502.05664] CODESIM: Multi-Agent Code Generation and Problem Solving through Simulation-Driven Planning and Debugging.pdf",
        "作者": "Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez",
        "摘要": "摘要：大语言模型（LLMs）在代码生成和问题解决方面取得了显著进展。目前的方法采用基于外部工具的迭代调试器，利用编译器或其他工具的运行时反馈来改进通过各种方法生成的粗略程序。然而，这些方法的有效性在很大程度上依赖于初始代码生成的质量，后者仍然是一个开放的挑战。本文介绍了CodeSim，这是一种新颖的多代理代码生成框架，通过类人感知方法全面解决程序合成的各个阶段——规划、编码和调试。与人类通过视觉模拟验证其对任何算法的理解类似，CodeSim独特地通过逐步模拟输入/输出的方法来进行计划验证和内部调试。在七个具有挑战性的竞争性问题解决和程序合成基准测试中进行的广泛实验展示了CodeSim出色的代码生成能力。我们的框架实现了新的最先进结果（pass@1）：HumanEval 95.1%，MBPP 90.7%，APPS 22%，和CodeContests 29.1%。此外，我们的方法在与外部调试器级联时显示出更大的增强潜力。为了促进该领域的进一步研究和发展，我们已在此链接（此https URL）中开源了我们的框架。\n\n作者：Md. Ashraful Islam, Mohammed Eunus Ali, Md Rizwan Parvez\n\n注释：已被NAACL 2025 Findings接受",
        "地址": "https://arxiv.org/pdf/2502.05664.pdf"
    },
    {
        "名称": "2025 [2502.06049] LM2: Large Memory Models.pdf",
        "作者": "Jikun Kang, Wenqi Wu, Filippos Christianos, Alex J. Chan, Fraser Greenlee, George Thomas, Marvin Purtorab, Andy Toulis",
        "摘要": "摘要：本文介绍了一种名为大内存模型（Large Memory Model，简称LM2）的解码器专用Transformer架构，该架构通过辅助内存模块进行了增强，旨在解决标准Transformers在多步推理、关系论证以及合成分布在长上下文中的信息方面的局限性。所提出的LM2包含一个作为上下文表示存储库的内存模块，通过交叉注意力与输入标记交互，并通过门控机制进行更新。为了保留Transformer的通用功能，LM2在整合一个互补的内存路径的同时，保持了原始的信息流。基于BABILong基准的实验结果表明，LM2模型在任务平均上，比内存增强的RMT模型高出37.1%，比基础的Llama-3.2模型高出86.3%。LM2在多跳推理、数值推理和大上下文问答方面表现出色。在MMLU数据集上，它比预训练的普通模型提高了5.0%，显示出其内存模块不会降低在一般任务上的性能。此外，在我们的分析中，我们探讨了内存的可解释性、内存模块的有效性以及测试时的行为。我们的研究结果强调了显式内存在增强Transformer架构中的重要性。\n\n作者：Jikun Kang, Wenqi Wu, Filippos Christianos, Alex J. Chan, Fraser Greenlee, George Thomas, Marvin Purtorab, Andy Toulis\n\n链接：https://arxiv.org/pdf/2502.06049.pdf\n\n标题：2025 [2502.06049] LM2: Large Memory Models.pdf",
        "地址": "https://arxiv.org/pdf/2502.06049.pdf"
    },
    {
        "名称": "2025 [2502.05415] Show-o Turbo: Towards Accelerated Unified Multimodal Understanding and Generation.pdf",
        "作者": "Chenkai Xu, Xu Wang, Zhenyi Liao, Yishun Li, Tianqi Hou, Zhijie Deng",
        "摘要": "该学术论文的摘要为：\n随着对构建统一的多模态理解和生成模型的研究兴趣日益增加，Show-o 作为一个显著的代表在文本到图像和图像到文本生成方面展示了很大的潜力。Show-o 的推理涉及逐步对图像标记去噪和自回归地解码文本标记，因此不幸的是两者都存在低效率的问题。本文介绍了 Show-o Turbo 来弥补这一差距。我们首先基于文本标记的并行解码确定了 Show-o 中图像和文本生成的统一去噪视角。随后我们提出将一致性蒸馏（CD），一种用于缩短扩散模型去噪过程的合格方法，扩展到 Show-o 的多模态去噪轨迹中。我们引入了轨迹分割策略和课程学习程序来提高训练收敛性。实证结果表明，在文本到图像生成中，Show-o Turbo 在4个采样步骤中无需使用无分类器引导（CFG）即可显示出 0.625 的 GenEval 分数，超过了原始 Show-o 在使用 8 个步骤和 CFG 后的表现；在图像到文本生成中，Show-o Turbo 在不显著牺牲性能的情况下表现出1.5倍的加速。代码可在此 https URL 获得。",
        "地址": "https://arxiv.org/pdf/2502.05415.pdf"
    },
    {
        "名称": "2025 [2502.05609] Lossless Acceleration of Large Language Models with Hierarchical Drafting based on Temporal Locality in Speculative Decoding.pdf",
        "作者": "Sukmin Cho, Sangjin Choi, Taeho Hwang, Jeongyeon Seo, Soyeong Jeong, Huije Lee, Hoyun Song, Jong C. Park, Youngjin Kwon",
        "摘要": "摘要：加速大语言模型（LLMs）的推理对于实时交互至关重要，因为它们已被广泛应用于实际服务中。作为一种完全算法解决方案的猜测解码，通过草拟和验证标记进行推理速度的提升，从而在单次前向传递中生成多个标记，引起了关注。然而，目前的草拟策略通常需要大量的微调或在不同任务上的性能不一致。为了解决这些问题，我们提出了层次草拟（HD），一种新颖的无损草拟方法，该方法基于时间局部性将各种标记源组织到多个数据库中，形成分层框架。在草拟步骤中，HD依次访问多个数据库，从最高到最低的局部性获取草拟标记，确保在多种任务中实现一致的加速，并最小化草拟延迟。我们在使用7B和13B参数的大型语言模型的Spec-Bench实验中表明，HD优于现有的数据库草拟方法，在模型大小、任务和温度方面实现了稳健的推理加速。\n\n作者：Sukmin Cho, Sangjin Choi, Taeho Hwang, Jeongyeon Seo, Soyeong Jeong, Huije Lee, Hoyun Song, Jong C. Park, Youngjin Kwon\n\n评论：NAACL 2025的研究成果\n\n链接：https://arxiv.org/pdf/2502.05609.pdf\n\n标题：基于时间局部性在猜测解码中通过层次草拟实现大型语言模型的无损加速",
        "地址": "https://arxiv.org/pdf/2502.05609.pdf"
    },
    {
        "名称": "2025 [2502.06786] Matryoshka Quantization.pdf",
        "作者": "Pranav Nair, Puranjay Datta, Jeff Dean, Prateek Jain, Aditya Kusupati",
        "摘要": "摘要: 量化模型权重是降低大模型通信和推理成本的关键。然而，将模型量化，特别是量化到int4或int2等低精度时，需要在模型质量上进行权衡；尤其是int2，已知严重降低了模型质量。因此，实践中往往需要维护多个具有不同量化级别的模型，或者选择一个最能满足质量-延迟权衡的单一模型。另一方面，整型数据类型，如int8，本质上具有嵌套（Matryoshka）结构，其中较小比特宽度的整型数据类型，如int4或int2，嵌套在最重要的位中。本文提出了Matryoshka量化（MatQuant），一种新颖的多尺度量化技术，解决了需要多个量化模型的问题。它允许训练和维护一个模型，然后可以在不同精度水平上运行。此外，由于MatQuant提供的联合训练和蒸馏正则化，MatQuant提取的int2精度模型可以比标准int2量化（使用QAT或OmniQuant等技术）提升高达10%的精度。这在模型量化方面取得了显著进展，证明了在相同方案下，int2 FFN量化的Gemma-2 9B模型的精度高于int8 FFN量化的Gemma-2 2B模型。\n\n作者: Pranav Nair, Puranjay Datta, Jeff Dean, Prateek Jain, Aditya Kusupati\n\n链接: https://arxiv.org/pdf/2502.06786.pdf\n\n标题: 2025 [2502.06786] Matryoshka Quantization.pdf",
        "地址": "https://arxiv.org/pdf/2502.06786.pdf"
    },
    {
        "名称": "2025 [2502.06772] ReasonFlux: Hierarchical LLM Reasoning via Scaling Thought Templates.pdf",
        "作者": "Ling Yang, Zhaochen Yu, Bin Cui, Mengdi Wang",
        "摘要": "摘要：我们展示了通过扩展思维模板进行分层大型语言模型（LLM）推理可以有效优化推理搜索空间，并超越像OpenAI o1-preview和DeepSeek V3这样强大的LLM的数学推理能力。我们用8块GPU训练了我们的ReasonFlux-32B模型，带来了三项创新：(i) 一个结构化且通用的思维模板库，包含约500个高阶思维模板，能够推广到类似或相关的推理问题；(ii) 对一系列思维模板而不是长的思维链（CoTs）进行分层强化学习，优化基础LLM以计划出渐进处理复杂问题的最佳模板轨迹；(iii) 一个全新的推理扩展系统，通过在推理时自适应扩展思维模板实现分层LLM推理。通过包含顺序思维模板的模板轨迹，我们的ReasonFlux-32B显著地将数学推理能力提升到最先进水平。在MATH基准测试中，其达到了91.2%的准确率，超越了o1-preview 6.7%。在美国数学奥林匹克（AIME）基准测试中，ReasonFlux-32B平均解决了56.7%的问题，分别比o1-preview和DeepSeek-V3高出27%和45%。\n\n作者：杨玲，余钊辰，崔斌，王梦迪\n\n链接：https://arxiv.org/pdf/2502.06772.pdf\n\n标题：2025 [2502.06772] ReasonFlux: 通过扩展思维模板进行分层LLM推理",
        "地址": "https://arxiv.org/pdf/2502.06772.pdf"
    },
    {
        "名称": "2025 [2502.06788] EVEv2: Improved Baselines for Encoder-Free Vision-Language Models.pdf",
        "作者": "Haiwen Diao, Xiaotong Li, Yufeng Cui, Yueze Wang, Haoge Deng, Ting Pan, Wenxuan Wang, Huchuan Lu, Xinlong Wang",
        "摘要": "摘要：现有的无编码器视觉语言模型（VLMs）正迅速缩小与基于编码器的模型之间的性能差距，凸显了具有结构简单和高效部署的统一多模态系统的巨大潜力。我们系统性地分析了使用预训练视觉编码器、离散标记器和从零开始的简约视觉层的VLMs之间的性能差距，深入挖掘了无编码器VLMs的未充分研究的特性。我们开发了能与主流基于编码器的模型相媲美的无编码器VLMs的高效策略。经过深入研究，我们推出了EVEv2.0，一个新的、改进的无编码器VLMs系列。我们的研究表明：(i) 在统一模型中适当地解构和分层关联视觉和语言可以减少模态之间的干扰。(ii) 精心设计的训练策略使无编码器VLMs的优化更加有效。通过广泛的评估，我们的EVEv2.0展示了一种跨模态开发纯解码架构的全面研究，展现了卓越的数据效率和强大的视觉推理能力。源代码可以在此网址公开获取：this https URL。",
        "地址": "https://arxiv.org/pdf/2502.06788.pdf"
    },
    {
        "名称": "2025 [2502.03628] The Hidden Life of Tokens: Reducing Hallucination of Large Vision-Language Models via Visual Information Steering.pdf",
        "作者": "Zhuowei Li, Haizhou Shi, Yunhe Gao, Di Liu, Zhenting Wang, Yuxiao Chen, Ting Liu, Long Zhao, Hao Wang, Dimitris N. Metaxas",
        "摘要": "摘要: 大型视觉-语言模型 (LVLMs) 可以在文本和视觉输入上有效地进行推理，但它们往往生成语法上连贯但在视觉上无依据的内容。在本文中，我们通过检查生成过程中的标记logits排名，揭示了LVLMs处理信息的内在动力学，发现在生成过程中存在以下三种关键模式: (1) 逐步的视觉信息丧失——视觉上的依据标记在生成过程中逐渐变得不受欢迎；(2) 早期激活——语义上有意义的标记在较终层之前的层中达到峰值激活；(3) 隐藏的真实信息——即使视觉上有依据的标记最终未被决定，仍在推理时保持较高的排名。基于这些见解，我们提出了VISTA (利用标记-logit增强进行视觉信息引导)，一种无需训练的推理时干预框架，通过促进真实信息并减少幻觉。VISTA结合了两种互补方法：在激活空间中加强视觉信息和利用早期层激活来促进语义有意义的解码。与现有方法相比，VISTA不需要外部监督，适用于各种解码策略。广泛的实验表明，VISTA平均减少了约40%的评估开放式生成任务中的幻觉，并在四个基准测试中一致优于现有方法，在四种架构和三种解码策略下表现出色。",
        "地址": "https://arxiv.org/pdf/2502.03628.pdf"
    },
    {
        "名称": "2025 [2502.06782] Lumina-Video: Efficient and Flexible Video Generation with Multi-scale Next-DiT.pdf",
        "作者": "Dongyang Liu, Shicheng Li, Yutong Liu, Zhen Li, Kai Wang, Xinyue Li, Qi Qin, Yufei Liu, Yi Xin, Zhongyu Li, Bin Fu, Chenyang Si, Yuewen Cao, Conghui He, Ziwei Liu, Yu Qiao, Qibin Hou, Hongsheng Li, Peng Gao",
        "摘要": "摘要：最近的进展已将扩散变压器（DiTs）确立为生成建模中的主导框架。在此成功的基础上，Lumina-Next利用Next-DiT在生成逼真图像方面取得了卓越的性能。然而，其在视频生成方面的潜力仍未完全挖掘，对视频数据中固有的时空复杂性的建模面临显著挑战。为了解决这个问题，我们推出了Lumina-Video，一个利用Next-DiT优势并引入定制解决方案的视频合成功能框架。Lumina-Video引入多尺度Next-DiT架构，通过联合学习多个分片来增强效率和灵活性。通过将运动评分作为显式条件，Lumina-Video还能够直接控制生成视频的动态程度。结合逐步训练方案，逐渐提高分辨率和帧率，以及混合自然和合成数据的多源训练方案，Lumina-Video在高训练和推理效率下实现了显著的美学质量和运动平滑度。我们还提出了基于Next-DiT的视频到音频模型Lumina-V2A，为生成的视频创建同步声音。代码已在此HTTPS链接发布：https://arxiv.org/pdf/2502.06782.pdf。",
        "地址": "https://arxiv.org/pdf/2502.06782.pdf"
    },
    {
        "名称": "2025 [2502.06764] History-Guided Video Diffusion.pdf",
        "作者": "Kiwhan Song, Boyuan Chen, Max Simchowitz, Yilun Du, Russ Tedrake, Vincent Sitzmann",
        "摘要": "摘要：无分类器引导（CFG）是提高扩散模型中条件生成的关键技术，它能够在增强样本质量的同时实现更精确的控制。将这一技术扩展到视频扩散中是很自然的做法，视频扩散在生成视频时依赖于不同数量的上下文帧，而这些帧被统称为历史。然而，我们发现基于可变长度历史进行引导面临两个主要挑战：仅支持固定大小条件的架构和CFG风格的历史丢弃表现不佳的经验观察。为了解决这些问题，我们提出了扩散强制转换器（DFoT），这是一种视频扩散架构和理论上有依据的训练目标，它们共同支持对灵活数量的历史帧进行条件控制。然后我们引入了历史引导，这是一系列由DFoT独特实现的引导方法。我们展示了其最简单的形式——普通历史引导，已经显著提高了视频生成质量和时间一致性。一种更高级的方法，跨时间和频率的历史引导进一步增强了运动动态，实现了对分布外历史的组成泛化，并能稳定地生成超长视频。\n\n网站：this https URL",
        "地址": "https://arxiv.org/pdf/2502.06764.pdf"
    },
    {
        "名称": "2025 [2502.05957] MetaChain: A Fully-Automated and Zero-Code Framework for LLM Agents.pdf",
        "作者": "Jiabin Tang, Tianyu Fan, Chao Huang",
        "摘要": "摘要: 大型语言模型 (LLM) 智能体在任务自动化和智能决策方面展现出显著能力，促进了LangChain和AutoGen等智能体开发框架的广泛应用。然而，这些框架主要面向拥有丰富技术专长的开发者，考虑到全球只有0.03%的人口具备必要的编程技能，这是一个显著的限制。这种鲜明的可访问性差距提出了一个基本问题：我们能否让每个人，无论是否具备技术背景，仅通过自然语言来构建自己的LLM智能体？为了解决这一挑战，我们推出了MetaChain——一个全自动且高度自我开发的框架，能够通过自然语言让用户创建和部署LLM智能体。MetaChain作为一个自主智能体操作系统，包含四个关键组件：i) 智能体系统实用工具，ii) LLM驱动的可执行引擎，iii) 自我管理的文件系统，以及iv) 自我模拟的智能体定制模块。这个轻量级但功能强大的系统，无需编码要求或手动干预，即可高效、动态地创建和修改工具、智能体和工作流程。除支持无代码的智能体开发能力外，MetaChain还作为一个多用途的一般AI助手多智能体系统。GAIA基准测试的全面评估证明了MetaChain在通用多智能体任务中的有效性，超越了现有的最先进方法。此外，MetaChain在与检索增强生成 (RAG) 相关的能力方面表现出持续超越许多替代性LLM解决方案的优异表现。",
        "地址": "https://arxiv.org/pdf/2502.05957.pdf"
    },
    {
        "名称": "2025 [2502.06023] Dual Caption Preference Optimization for Diffusion Models.pdf",
        "作者": "Amir Saeidi, Yiran Luo, Agneet Chatterjee, Shamanthak Hegde, Bimsara Pathiraja, Yezhou Yang, Chitta Baral",
        "摘要": "摘要：最近，在大型语言模型（LLM）中开发的人类偏好优化方面的进展显示出改进文本到图像扩散模型的显著潜力。这些方法旨在学习偏好样本的分布，同时将其与不太受欢迎的样本区分开来。然而，现有的偏好数据集通常在这些分布之间表现出重叠，导致冲突分布。此外，我们发现输入提示包含与不太受欢迎图像无关的信息，限制了去噪网络在偏好优化方法中准确预测噪声的能力，这被称为无关提示问题。为了解决这些挑战，我们提出了双字幕偏好优化（DCPO），这是一种利用两个不同字幕来减轻无关提示的新方法。为了解决冲突分布，我们引入了Pick-Double Caption数据集，这是Pick-a-Pic v2的修改版本，为偏好图像和不太偏好图像提供单独的字幕。我们进一步提出了三种生成不同字幕的策略：字幕、扰动和混合方法。我们的实验表明，DCPO显著提高了图像质量和提示相关性，在多个指标上（包括Pickscore, HPSv2.1, GenEval, CLIPscore和ImageReward）优于Stable Diffusion (SD) 2.1, SFT_Chosen, Diffusion-DPO和MaPO，在SD 2.1作为骨干网的基础上进行微调。",
        "地址": "https://arxiv.org/pdf/2502.06023.pdf"
    },
    {
        "名称": "2025 [2502.05795] The Curse of Depth in Large Language Models.pdf",
        "作者": "Wenfang Sun, Xinyuan Song, Pengxiang Li, Lu Yin, Yefeng Zheng, Shiwei Liu",
        "摘要": "摘要：在本文中，我们介绍了“深度诅咒”这一概念，该概念突出了现代大型语言模型（LLMs）中最近观察到的现象，即近一半的层次效果不如预期。我们首先证实了这种现象在Llama、Mistral、DeepSeek和Qwen等最受欢迎的LLM系列中广泛存在。我们的理论和实证分析表明，LLMs深层无效的根本原因在于广泛使用的预先层归一化（Pre-LN）。虽然Pre-LN稳定了Transformer LLMs的训练，但其输出方差随着模型深度指数增长，导致深层Transformer块的导数趋于单位矩阵，因此在训练中几乎没有贡献。为了解决这一训练难题，我们提出了层归一化缩放（LayerNorm Scaling），通过以其深度的平方根反比缩放归一化层的输出方差。这一简单的修改缓解了较深Transformer层的输出方差爆炸，提高了它们的贡献。我们的实验结果（覆盖从130M到1B的模型尺寸）表明，与Pre-LN相比，LayerNorm Scaling显著提高了LLM预训练性能，而且这种改进无缝地体现在有监督微调中。所有这些提升都可归因于LayerNorm Scaling使较深的层在训练过程中更有效地发挥作用。",
        "地址": "https://arxiv.org/pdf/2502.05795.pdf"
    },
    {
        "名称": "2025 [2502.06155] Efficient-vDiT: Efficient Video Diffusion Transformers With Attention Tile.pdf",
        "作者": "Hangliang Ding, Dacheng Li, Runlong Su, Peiyuan Zhang, Zhijie Deng, Ion Stoica, Hao Zhang",
        "摘要": "摘要：尽管扩散变压器（DiT）有望合成高保真视频，但由于注意力计算的复杂性和大量采样步骤，使用3D全注意力的DiTs推理过程往往非常耗时。例如，流行的Open-Sora-Plan模型生成一个29帧的视频需要超过9分钟。本文从两个方面解决了这一低效问题：1) 根据视频数据中的冗余性，对3D全注意力进行剪枝。我们在视频数据的3D注意力图中发现了一种常见的瓷砖式重复模式，并提出了一种具有线性复杂度的新型稀疏3D注意力方法。2) 采用现有的多步骤一致性蒸馏，以缩短采样过程。我们将整个采样轨迹分成多个阶段，在每个阶段内部进行一致性蒸馏，以激活少步骤生成能力。我们进一步设计了一个三阶段训练流程，将低复杂度注意力和少步骤生成能力结合起来。值得注意的是，使用0.1%的预训练数据，我们将Open-Sora-Plan-1.2模型变得更高效，对于生成29和93帧的720p视频，速度提高了7.4倍到7.8倍，而在VBench上的性能损失微乎其微。此外，我们证明我们的方法适用于分布式推理，当在4个GPU上使用序列并行运行时，实现了额外3.91倍的速度提升。\n\n作者：丁行量，李大成，苏润龙，张沛源，邓志杰，Ion Stoica，张昊",
        "地址": "https://arxiv.org/pdf/2502.06155.pdf"
    },
    {
        "名称": "2025 [2502.04370] DreamDPO: Aligning Text-to-3D Generation with Human Preferences via Direct Preference Optimization.pdf",
        "作者": "Zhenglin Zhou, Xiaobo Xia, Fan Ma, Hehe Fan, Yi Yang, Tat-Seng Chua",
        "摘要": "摘要：文本到3D生成通过将文本描述自动转化为3D内容，在多个领域具有变革潜力。然而，现有的方法常常难以使生成的内容符合人类偏好，限制了其适用性和灵活性。为了解决这些限制，本文提出了一种基于优化的框架——DreamDPO，通过直接偏好优化，将人类偏好集成到3D生成过程中。实际操作上，DreamDPO首先构建成对示例，然后使用奖励或大型多模态模型比较其与人类偏好的对齐情况，最后通过偏好驱动的损失函数优化3D表示。通过利用成对比较来反映偏好，DreamDPO减少了对精确逐点质量评估的依赖，同时通过偏好引导的优化实现细粒度的可控性。实验表明，DreamDPO取得了有竞争力的结果，并且相比现有方法提供了更高质量和更具可控性的3D内容。代码和模型将开源。",
        "地址": "https://arxiv.org/pdf/2502.04370.pdf"
    },
    {
        "名称": "2025 [2502.06527] CustomVideoX: 3D Reference Attention Driven Dynamic Adaptation for Zero-Shot Customized Video Diffusion Transformers.pdf",
        "作者": "D. She, Mushui Liu, Jingxuan Pang, Jin Wang, Zhen Yang, Wanggui He, Guanghao Zhang, Yi Wang, Qihan Huang, Haobin Tang, Yunlong Yu, Siming Fu",
        "摘要": "摘要：定制化生成在图像合成方面已经取得了显著进展，但由于时序不一致和质量下降，个性化视频生成仍然具有挑战性。本文介绍了一种创新框架CustomVideoX，它利用视频扩散变压器从参考图像生成个性化视频。CustomVideoX通过仅训练LoRA参数来提取参考特征，充分利用预训练视频网络，确保了高效性和适应性。为了方便参考图像与视频内容的无缝互动，我们提出了3D参考注意力机制，使参考图像特征能够在空间和时间维度上直接且同时与所有视频帧进行互动。为减轻参考图像特征和文本引导在推理过程中对生成视频内容的过度影响，我们实施了时间感知参考注意偏差(TAB)策略，在不同时间步动态调整参考偏差。此外，我们引入了实体区域感知增强(ERAE)模块，通过调整注意力偏差将关键实体标记的高度激活区域与参考特征注入对齐。为了全面评估个性化视频生成，我们建立了一个包含50多个对象和100个提示的新基准VideoBench。实验结果表明，CustomVideoX在视频一致性和质量方面显著优于现有方法。\n\n来源链接：https://arxiv.org/pdf/2502.06527.pdf",
        "地址": "https://arxiv.org/pdf/2502.06527.pdf"
    },
    {
        "名称": "2025 [2502.05431] APE: Faster and Longer Context-Augmented Generation via Adaptive Parallel Encoding.pdf",
        "作者": "Xinyu Yang, Tianqi Chen, Beidi Chen",
        "摘要": "摘要：上下文增强生成（CAG）技术，包括RAG和ICL，需要高效地结合多个上下文来生成用户查询的响应。直接将这些上下文作为序列输入，会由于每次请求重新编码组合后的上下文而引入大量计算负担。为了解决这个问题，我们探索了并行编码的潜力，以独立地预先计算和缓存每个上下文的KV状态。这种方法使得在推理过程中能够直接加载缓存的状态，同时通过在上下文之间重复使用位置来容纳更多的上下文。然而，由于注意力分布不对齐，直接应用并行编码会导致性能显著下降。为了实现有效且高效的CAG，我们提出了自适应并行编码（APE），其通过共享前缀、注意力温度和缩放因子来使并行编码的分布与顺序编码对齐。在RAG和ICL任务上的结果表明，APE在使用相同输入时可以分别保留98%和93%的顺序编码性能，同时分别超过并行编码3.6%和7.9%。它也能扩展到多次CAG，有效并行编码数百个上下文。效率评估显示，APE通过减少128K长度上下文的28倍预填充时间，实现了端到端的4.5倍加速。\n\n作者：杨新宇，陈天奇，陈北弟\n评论：ICLR 2025\n链接： https://arxiv.org/pdf/2502.05431.pdf\n标题：2025 [2502.05431] APE: 更快更长的上下文增强生成通过自适应并行编码",
        "地址": "https://arxiv.org/pdf/2502.05431.pdf"
    },
    {
        "名称": "2025 [2502.06635] Steel-LLM:From Scratch to Open Source -- A Personal Journey in Building a Chinese-Centric LLM.pdf",
        "作者": "Qingshui Gu, Shu Li, Tianyu Zheng, Zhaoxiang Zhang",
        "摘要": "摘要：Steel-LLM 是一款中文为中心的语言模型，从零开始开发，目标是在计算资源有限的情况下创建一个高质量的开源模型。该项目于2024年3月启动，旨在基于大规模数据集训练一个拥有十亿参数的模型，优先考虑透明性并分享实际见解，以帮助社区中的其他人。训练过程主要集中在中文数据上，包含少量的英文数据，通过提供更详尽和实用的模型构建经历，弥补了现有开源大型语言模型中的不足。Steel-LLM 在CEVAL和CMMLU等基准测试中表现出竞争力，超越了大型机构的早期模型。本文汇总了项目的主要贡献，包括数据收集、模型设计、训练方法以及遇到的挑战，为希望开发自己的大型语言模型的研究人员和从业者提供了宝贵的资源。模型检查点和训练脚本可在此HTTPS链接中获取。\n\n链接：https://arxiv.org/pdf/2502.06635.pdf",
        "地址": "https://arxiv.org/pdf/2502.06635.pdf"
    },
    {
        "名称": "2025 [2502.06282] Jakiro: Boosting Speculative Decoding with Decoupled Multi-Head via MoE.pdf",
        "作者": "Haiduo Huang, Fuwei Yang, Zhenhua Liu, Yixing Xu, Jinze Li, Yang Liu, Xuanwu Yin, Dong Li, Pengju Ren, Emad Barsoum",
        "摘要": "摘要：推测解码（SD）通过使用一个较小的草稿模型提前预测多个标记，然后由较大的目标模型并行验证，从而加速大语言模型的推理。然而，由于草稿模型能力有限，通常需要基于树的采样来提高预测准确性，每一步生成多个候选项。我们指出了这种方法的一个关键限制：同一步骤的候选项来源于相同的表示，限制了多样性并降低了整体效果。为了解决这个问题，我们提出了Jakiro，利用专家混合（MoE），不同的专家生成多样化的预测，有效地解耦候选项之间的相关性。此外，我们引入了一种混合推理策略，将自动回归解码用于初始标记，并将并行解码用于后续阶段，并在特征中增强对比机制以提高准确性。我们的方法显著提高了预测准确性，实现了更高的推理加速。在不同模型上的广泛实验验证了我们方法的有效性和鲁棒性，确立了推测解码的新SOTA。我们的代码可以在此URL上获取。\n\n摘要翻译：推测解码（SD）通过使用一个较小的草稿模型预测多个标记，然后由更大的目标模型并行验证，以加速大模型的推理。然而，由于草稿模型能力有限，通常需要基于树的采样来提高预测准确性，每一步生成多个候选项。我们指出了这种方法的关键限制：同一步骤的候选项来自相同的表示，限制了多样性并降低了整体效果。为了解决这个问题，我们提出了Jakiro，利用专家混合（MoE），不同的专家生成多样化的预测，有效地解耦候选项之间的相关性。此外，我们引入了一种混合推理策略，将自动回归解码用于初始标记，并采用并行解码用于后续阶段，并在特征中增强对比机制以提高准确性。我们的方法显著提升了预测准确性和推理速度。在各种模型上的广泛实验验证了我们方法的效果和稳健性，确立了推测解码的新SOTA。我们的代码可以在此URL上获取。",
        "地址": "https://arxiv.org/pdf/2502.06282.pdf"
    },
    {
        "名称": "2025 [2502.06776] Towards Internet-Scale Training For Agents.pdf",
        "作者": "Brandon Trabucco, Gunnar Sigurdsson, Robinson Piramuthu, Ruslan Salakhutdinov",
        "摘要": "摘要：当前训练网络导航代理的主流方法是收集一组热门网站和手写任务的人工演示，但事实表明人类数据是一种低效的资源。我们开发了一条流水线，旨在实现无需繁琐人工标注的互联网规模训练。在第一阶段，LLM（大型语言模型）为15万个不同的网站生成任务。在第二阶段，LLM代理完成任务并生成轨迹。在最后阶段，LLM审查这些轨迹并判断其成功与否。语言模型在与人工标注者的竞争中表现出色，检测和过滤有害内容的准确率为97%，生成可行任务的成功率为89%，判断成功轨迹的准确率为82.6%。通过扩展这条流水线，基于Llama 3.1 70B的代理针对15万个网站解决了16.7%的任务。使用我们流水线生成的数据进行训练，与使用人工演示训练的效果相当。在来自Mind2Web和WebLINX的数据有限环境中，使用混合我们流水线数据和人工数据训练的代理，步骤准确度分别提高了最高达+89.5%和+122.1%。在使用这些基准的所有可用人工数据训练代理的情况下，代理无法推广到各种真实网站，而添加我们的数据后，推广能力在WebLINX上提高了+149.0%，在Mind2Web上提高了+156.3%。代码将发布在此URL。\n\n原文链接：https://arxiv.org/pdf/2502.06776.pdf  \n作者：Brandon Trabucco, Gunnar Sigurdsson, Robinson Piramuthu, Ruslan Salakhutdinov",
        "地址": "https://arxiv.org/pdf/2502.06776.pdf"
    },
    {
        "名称": "2024 [2411.18676] Embodied Red Teaming for Auditing Robotic Foundation Models.pdf",
        "作者": "Sathwik Karnik, Zhang-Wei Hong, Nishant Abhangi, Yen-Chen Lin, Tsun-Hsuan Wang, Christophe Dupuy, Rahul Gupta, Pulkit Agrawal",
        "摘要": "摘要：基于语言条件的机器人模型有可能使机器人能够根据自然语言指令执行广泛的任务。然而，由于单一任务的不同表述方式难以全部测试，评估其安全性和有效性仍然具有挑战性。当前的基准存在两个主要限制：它们依赖于有限的人类生成指令集，遗漏了许多具有挑战性的情况，并且仅关注任务性能，而不评估安全性，例如避免损坏。为了解决这些问题，我们引入了体现的红队测试（ERT），这是一种新的评估方法，用于生成多样且具有挑战性的指令来测试这些模型。ERT使用带有视觉语言模型（VLMs）的自动红队技术，创建具有上下文关联的困难指令。实验结果表明，最先进的基于语言条件的机器人模型在ERT生成的指令上失败或表现出不安全行为，突显了当前基准在评估现实世界性能和安全性方面的不足。代码和视频可在此链接获取。\n\n论文标题: 体现的红队测试用于审计机器人基础模型\n\n作者：Sathwik Karnik, Zhang-Wei Hong, Nishant Abhangi, Yen-Chen Lin, Tsun-Hsuan Wang, Christophe Dupuy, Rahul Gupta, Pulkit Agrawal\n\nurl：https://arxiv.org/pdf/2411.18676.pdf",
        "地址": "https://arxiv.org/pdf/2411.18676.pdf"
    }
]