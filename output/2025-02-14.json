[
    {
        "名称": "2025 [2502.08910] InfiniteHiP: Extending Language Model Context Up to 3 Million Tokens on a Single GPU.pdf",
        "作者": "Heejun Lee, Geon Park, Jaduk Suh, Sung Ju Hwang",
        "摘要": "该论文摘要如下所示：\n\n在现代大型语言模型（LLMs）中，处理非常长的上下文长度带来了显著的挑战，因为这会导致推理速度变慢和内存消耗增加。此外，大多数现有的预训练LLM无法在其原始训练序列长度之外进行泛化。为了实现高效且实用的长上下文利用，我们引入了InfiniteHiP，这是一种新颖且实用的LLM推理框架，通过动态消除无关的上下文标记，通过模块化层次化标记修剪算法来加速处理。我们的方法还通过根据LLMs内部的注意力模式选择性地应用各种RoPE调整方法，允许泛化到更长的序列。此外，我们在推理期间将键值缓存卸载到主存储器，显著减轻了GPU内存压力。因此，InfiniteHiP能够在单个48GB的L40s GPU上处理多达300万标记——是原来的3倍大——且没有任何永久的上下文信息丢失。我们的框架在处理100万标记上下文时，注意力解码实现了18.95倍的加速，而无需额外训练。我们在SGLang框架中实现了我们的方法，并通过广泛的评估展示了其有效性和实用性。\n\n论文作者：Heejun Lee, Geon Park, Jaduk Suh, Sung Ju Hwang\n\n该论文共有21页。详细信息可以通过访问链接https://arxiv.org/pdf/2502.08910.pdf查看。",
        "地址": "https://arxiv.org/pdf/2502.08910.pdf"
    },
    {
        "名称": "2025 [2502.08690] Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation.pdf",
        "作者": "Hoigi Seo, Wongi Jeong, Jae-sun Seo, Se Young Chun",
        "摘要": "摘要: 大规模文本编码器在文本到图像(T2I)扩散模型中展示了从文本提示生成高质量图像的出色性能。与依赖多次迭代步骤的去噪模块不同，文本编码器只需一次前向传递即可生成文本嵌入。然而，尽管其对总推理时间和浮点运算(FLOPs)的贡献最小，文本编码器的内存使用量却明显更高，最高可达去噪模块的八倍。为了解决这种低效率问题，我们提出了跳过和重用层(Skrr)这一简单但有效的剪枝策略，专为T2I扩散模型中的文本编码器设计。Skrr通过有选择性地跳过或重用某些Transformer块中的层，利用了其固有的冗余，以减少内存消耗而不影响性能。广泛的实验表明，即使在高稀疏度水平下，Skrr也能保持与原始模型相当的图像质量，优于现有的分块剪枝方法。此外，Skrr在多个评估指标（包括FID、CLIP、DreamSim和GenEval分数）上实现了在保持性能的同时，在内存效率方面的最先进水平。\n\n作者: 徐浩基, 王佶, 徐在宣, 千世英\n\n链接: https://arxiv.org/pdf/2502.08690.pdf\n\n标题: 2025 [2502.08690] Skrr: Skip and Re-use Text Encoder Layers for Memory Efficient Text-to-Image Generation",
        "地址": "https://arxiv.org/pdf/2502.08690.pdf"
    },
    {
        "名称": "2025 [2502.09604] SelfCite: Self-Supervised Alignment for Context Attribution in Large Language Models.pdf",
        "作者": "Yung-Sung Chuang, Benjamin Cohen-Wang, Shannon Zejiang Shen, Zhaofeng Wu, Hu Xu, Xi Victoria Lin, James Glass, Shang-Wen Li, Wen-tau Yih",
        "摘要": "摘要：\n我们介绍了SelfCite，这是一种新颖的自监督方法，旨在使大型语言模型（LLMs）生成高质量、细粒度的句子级引用，以支持其生成的响应中的声明。SelfCite不仅依赖于昂贵且费力的人工标注，还利用了通过上下文消融由LLM自身提供的奖励信号：如果引用是必要的，移除上下文中的引用文本应该会阻止生成相同的响应；如果引用是充分的，保留引用文本本身应当能够保持相同的响应。这个奖励信号可以指导推断时的最佳N取样策略，以显著提高引用质量，同时还可以用于偏好优化，直接微调模型以生成更好的引用。SelfCite的有效性通过在LongBench-Cite基准上的五项长形式问答任务中将引用F1提高到5.3点得以证明。",
        "地址": "https://arxiv.org/pdf/2502.09604.pdf"
    },
    {
        "名称": "2025 [2502.09619] Can this Model Also Recognize Dogs? Zero-Shot Model Search from Weights.pdf",
        "作者": "Jonathan Kahana, Or Nathan, Eliahu Horwitz, Yedid Hoshen",
        "摘要": "摘要：随着公开可用模型数量的增加，可能已经有适用于大多数用户任务的预训练在线模型。然而，当前的模型搜索方法比较初级，本质上是文档中的文本搜索，因此用户无法找到相关模型。本文介绍了ProbeLog，这是一种在没有访问模型元数据或训练数据的情况下检索能够识别目标概念（如“狗”）的分类模型的方法。与之前的探测方法不同，ProbeLog通过观察模型对一组固定输入（探针）的响应，为每个模型的每个输出维度（logit）计算描述符。我们的方法支持基于logit的检索（“找到更多类似的logit”）和零样本、基于文本的检索（“找到所有与狗对应的logit”）。由于基于探测的表示需要多次昂贵的前向传播通过模型，我们开发了一种基于协同过滤的方法，将编码库的成本降低了3倍。我们证明了ProbeLog在现实世界和细粒度搜索任务中都实现了高检索准确率，并且能够扩展到全尺寸库。\n\n作者：Jonathan Kahana, Or Nathan, Eliahu Horwitz, Yedid Hoshen\n\n链接：https://arxiv.org/pdf/2502.09619.pdf\n\n标题：这模型还可以识别狗吗？基于权重的零样本模型搜索",
        "地址": "https://arxiv.org/pdf/2502.09619.pdf"
    },
    {
        "名称": "2025 [2502.09056] An Open Recipe: Adapting Language-Specific LLMs to a Reasoning Model in One Day via Model Merging.pdf",
        "作者": "Kunat Pipatanakul, Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai",
        "摘要": "这篇论文研究了数据选择和模型合并的方法，旨在将高级推理功能（如DeepSeek R1的推理能力）整合到特定语言的大型语言模型（LLMs）中，特别是针对泰国语言模型。我们的目标是在保持目标语言能力的同时，增强特定语言LLMs的推理能力。DeepSeek R1在推理方面表现出色，但主要惠及英语和中文等高资源语言。然而，由于英语为中心的训练数据和模型优化的主导地位，低资源语言方面仍然未能得到充分服务，导致在这些语言上的性能受限，代码转换不可靠，对于低资源语言任务的效果也打折扣。同时，本地和区域的LLM计划试图通过开发语言特定的LLMs来改善本地语言的准确性。我们证明，仅使用公开可用的数据集和120美元的计算预算，就可以在不影响目标语言任务性能的情况下，将特定语言LLMs的推理能力提升到与DeepSeek R1相当的水平。\n\n来源: Kunat Pipatanakul, Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai\n评论: 共9页\n网址: https://arxiv.org/pdf/2502.09056.pdf\n标题: 2025 [2502.09056] 一个公开配方：通过模型合并在一天内将特定语言的LLMs适应于推理模型.pdf",
        "地址": "https://arxiv.org/pdf/2502.09056.pdf"
    },
    {
        "名称": "2025 [2502.09560] EmbodiedBench: Comprehensive Benchmarking Multi-modal Large Language Models for Vision-Driven Embodied Agents.pdf",
        "作者": "Rui Yang, Hanyang Chen, Junyu Zhang, Mark Zhao, Cheng Qian, Kangrui Wang, Qineng Wang, Teja Venkat Koripella, Marziyeh Movahedi, Manling Li, Heng Ji, Huan Zhang, Tong Zhang",
        "摘要": "摘要：利用多模态大型语言模型（Multi-modal Large Language Models, MLLMs）创建具身智能体为应对现实世界任务提供了一个有前景的途径。虽然语言中心的具身智能体受到了广泛关注，但由于缺乏全面的评估框架，基于MLLM的具身智能体仍然研究不足。为弥补这一差距，我们引入了EmbodiedBench，这是一个用于评估视觉驱动具身智能体的广泛基准。EmbodiedBench具有以下特点：（1）跨越四个环境的1,128个测试任务，任务范围从高层语义任务（例如家务）到涉及基本动作（例如导航和操作）的低层任务；（2）精心策划的六个子集，用于评估常识推理、复杂指令理解、空间意识、视觉感知和长期规划等智能体的基本能力。通过大量实验，我们在EmbodiedBench中评估了13个领先的专有和开源MLLMs。我们的研究结果表明：MLLMs在高层任务上表现出色，但在低层操作上表现不佳，最佳模型GPT-4o的平均得分仅为28.9%。EmbodiedBench提供了一个多方面的标准化评估平台，不仅揭示了现有的挑战，还为推进基于MLLM的具身智能体提供了宝贵的见解。我们的代码可在此https URL获得。\n\n",
        "地址": "https://arxiv.org/pdf/2502.09560.pdf"
    },
    {
        "名称": "2025 [2502.09620] Exploring the Potential of Encoder-free Architectures in 3D LMMs.pdf",
        "作者": "Yiwen Tang, Zoey Guo, Zhuhao Wang, Ray Zhang, Qizhi Chen, Junli Liu, Delin Qu, Zhigang Wang, Dong Wang, Xuelong Li, Bin Zhao",
        "摘要": "摘要：目前，无编码器架构在二维视觉领域中已经进行了初步探索，但在三维理解场景中是否可以有效应用仍是一个未解的问题。本文首次全面探讨了无编码器架构在克服基于编码器的三维大型多模态模型（LMMs）的挑战方面的潜力。这些挑战包括无法适应不同分辨率的点云以及编码器生成的点特征不满足大型语言模型（LLMs）的语义需求。我们确定了三维LMMs去除编码器并使LLM承担三维编码器角色的关键方面：1）在预训练阶段，我们提出了LLM嵌入的语义编码策略，探索了各种点云自监督损失的效果，并提出了混合语义损失以提取高级语义。2）在指令调优阶段，我们引入了分层几何聚合策略，将归纳偏差整合到LLM的早期层次中以关注点云的局部细节。最终我们提出了第一个无编码器的三维LMM，ENEL。我们的7B模型与当前最先进的ShapeLLM-13B相比，在分类、字幕生成和VQA任务上分别达到了55.0%、50.92%和42.7%的成绩。我们的结果表明，无编码器架构在替代三维理解领域中的基于编码器架构方面极具前景。代码已发布在此链接https URL。",
        "地址": "https://arxiv.org/pdf/2502.09620.pdf"
    },
    {
        "名称": "2025 [2502.09082] CoSER: Coordinating LLM-Based Persona Simulation of Established Roles.pdf",
        "作者": "Xintao Wang, Heng Wang, Yifei Zhang, Xinfeng Yuan, Rui Xu, Jen-tse Huang, Siyu Yuan, Haoran Guo, Jiangjie Chen, Wei Wang, Yanghua Xiao, Shuchang Zhou",
        "摘要": "摘要翻译为中文：\n\n摘要：角色扮演语言代理（RPLAs）作为大型语言模型（LLMs）的一项有前景的应用不断涌现。然而，由于缺乏真实的角色数据集以及使用此类数据的细致评估方法，模拟已建立的角色对RPLAs来说是一个具有挑战性的任务。本文介绍了CoSER，一个高质量数据集、开放模型以及面向有效模拟已建立角色的评估协议的集合。CoSER数据集涵盖了771本著名书籍中的17,966个角色。它提供了具有现实复杂性的真实对话，以及各种数据类型，如对话设置、角色经验和内心想法。借鉴表演方法，我们引入了给定情境表演来训练和评估角色扮演LLMs，其中LLMs依次在书籍场景中描绘多个角色。利用我们的数据集，我们开发了CoSER 8B和CoSER 70B，即基于LLaMA-3.1模型构建的先进开放角色扮演LLMs。广泛的实验表明，CoSER数据集在RPLA训练、评估和检索中的重要价值。此外，CoSER 70B在我们的评估和现有三项基准测试中表现出超越或匹配GPT-4o的最先进性能，即在InCharacter和LifeChoice基准测试中分别达到75.80%和93.47%的准确率。",
        "地址": "https://arxiv.org/pdf/2502.09082.pdf"
    },
    {
        "名称": "2025 [2502.06608] TripoSG: High-Fidelity 3D Shape Synthesis using Large-Scale Rectified Flow Models.pdf",
        "作者": "Yangguang Li, Zi-Xin Zou, Zexiang Liu, Dehu Wang, Yuan Liang, Zhipeng Yu, Xingchao Liu, Yuan-Chen Guo, Ding Liang, Wanli Ouyang, Yan-Pei Cao",
        "摘要": "摘要：最近在扩散技术方面的进步将图像和视频生成推向了前所未有的高质量水平，显著加速了生成式人工智能的部署和应用。然而，3D形状生成技术迄今为止仍然落后，受限于3D数据规模、3D数据处理的复杂性以及在3D领域中对先进技术探索的不足。目前的3D形状生成方法在输出质量、泛化能力和输入条件对齐方面面临重大挑战。我们提出了TripoSG，这是一种新的精简形状扩散范式，能够根据输入图像生成高保真度的3D网格。具体来说，我们提出了以下几点：1）大规模校正流变压器用于3D形状生成，通过对海量高质量数据的训练，达到最先进的保真度。2）混合监督训练策略，结合SDF、法线和eikonal损失用于3D VAE，达到高质量的3D重建性能。3）数据处理管道，生成了200万个高质量的3D样本，强调了在训练3D生成模型中数据质量和数量的重要规则。通过综合实验，我们验证了新框架中每个组成部分的有效性。这些部分的无缝集成使得TripoSG在3D形状生成方面达到了最先进的性能。生成的3D形状由于高分辨率能力而展现出更高的细节，并表现出对输入图像的卓越保真度。此外，TripoSG在从不同图像风格和内容生成3D模型方面展示了改进的多样性和强大的泛化能力。为了促进3D生成领域的进步和创新，我们将公开我们的模型。",
        "地址": "https://arxiv.org/pdf/2502.06608.pdf"
    },
    {
        "名称": "2025 [2502.08946] The Stochastic Parrot on LLM's Shoulder: A Summative Assessment of Physical Concept Understanding.pdf",
        "作者": "Mo Yu, Lemao Liu, Junjie Wu, Tsz Ting Chung, Shunchi Zhang, Jiangnan Li, Dit-Yan Yeung, Jie Zhou",
        "摘要": "摘要：我们系统地研究了一个广泛关注的问题：大型语言模型（LLMs）是否真的理解它们所说的内容？这与更熟悉的术语“随机鹦鹉”相关。为此，我们提出了一种总结性评估方法，基于精心设计的物理概念理解任务PhysiCo。我们的任务通过使用抽象描述物理现象的网格格式输入，减轻了记忆问题。网格表达了不同层次的理解，从核心现象、应用示例到对其他抽象模式的类比。对我们的任务进行的全面研究表明： (1) 最先进的LLMs，包括GPT-4o、o1和Gemini 2.0闪思，与人类相比落后约40%；(2) LLMs中存在随机鹦鹉现象，因为它们在我们的网格任务上表现不佳，但能够很好地在自然语言中描述和识别相同的概念；(3) 由于内在的困难，我们的任务对LLMs构成了挑战，而不是因为不熟悉的网格格式，因为在相同格式数据上的上下文学习和微调对它们的表现几乎没有提升。",
        "地址": "https://arxiv.org/pdf/2502.08946.pdf"
    },
    {
        "名称": "2025 [2502.09621] MME-CoT: Benchmarking Chain-of-Thought in Large Multimodal Models for Reasoning Quality, Robustness, and Efficiency.pdf",
        "作者": "Dongzhi Jiang, Renrui Zhang, Ziyu Guo, Yanwei Li, Yu Qi, Xinyan Chen, Liuhui Wang, Jianhan Jin, Claire Guo, Shen Yan, Bo Zhang, Chaoyou Fu, Peng Gao, Hongsheng Li",
        "摘要": "摘要：使用Chain-of-Thought (CoT)进行问题回答大大增强了大型语言模型(LLMs)的推理能力，然而其对大型多模态模型(LMMs)的影响仍缺乏系统的评估和深入的研究。在本文中，我们介绍了MME-CoT，一个专门评估LMMs CoT推理性能的基准，涵盖了数学、科学、OCR、逻辑、时空和一般场景六个领域。作为该领域的第一项综合研究，我们提出了一个全面的评估套件，包含三个新的指标，用于在细粒度水平上评估推理质量、鲁棒性和效率。利用精心整理的高质量数据和独特的评估策略，我们对最先进的LMMs进行了深入分析，揭示了几个关键见解：1）具有反思机制的模型表现出卓越的CoT质量，其中Kimi k1.5优于GPT-4o，并显示出最高质量的结果；2）CoT提示往往会降低LMM在感知密集型任务上的表现，表明潜在的有害过度思考行为；3）尽管CoT质量高，具有反思的LMM在正常响应和自我校正阶段表现出显著的低效率。我们希望MME-CoT能为推进LMMs中的多模态推理提供基础。项目页面：this https URL",
        "地址": "https://arxiv.org/pdf/2502.09621.pdf"
    },
    {
        "名称": "2025 [2502.09100] Logical Reasoning in Large Language Models: A Survey.pdf",
        "作者": "Hanmeng Liu, Zhizhang Fu, Mengru Ding, Ruoxi Ning, Chaoli Zhang, Xiaozhang Liu, Yue Zhang",
        "摘要": "摘要：随着OpenAI o3和DeepSeek-R1等先进推理模型的出现，大型语言模型（LLMs）展示了显著的推理能力。然而，它们执行严格逻辑推理的能力仍是一个未解决的问题。这篇综述综合了LLMs进行逻辑推理的最新进展，这是人工智能研究的一个关键领域。它概述了LLMs中逻辑推理的范围、理论基础以及用于评估推理能力的基准。我们分析了在不同推理范式（演绎、归纳、溯因和类比）中的现有能力，并评估了各种增强推理性能的策略，包括以数据为中心的调优、强化学习、解码策略和神经符号方法。综述最后提出了未来方向，强调需要进一步探索以加强AI系统中的逻辑推理能力。",
        "地址": "https://arxiv.org/pdf/2502.09100.pdf"
    },
    {
        "名称": "2025 [2502.09042] Typhoon T1: An Open Thai Reasoning Model.pdf",
        "作者": "Pittawat Taveekitworachai, Potsawee Manakul, Kasima Tharnpipitchai, Kunat Pipatanakul",
        "摘要": "摘要: 本文介绍了Typhoon T1，这是一个开发开放泰文推理模型的开放项目。推理模型是一种建立在大型语言模型（LLMs）基础上的新型生成模型。在得出最终答案之前，推理模型会生成一长串的思考链，这种方法被发现能提升复杂任务的性能。然而，关于开发这种模型的细节是有限的，特别是能够在资源稀缺语言中生成推理痕迹的推理模型。Typhoon T1通过使用开放数据集进行监督微调，而不是强化学习，展示了一种更具成本效益的开发推理模型的方法。本文分享了关于合成数据生成和训练的细节，以及我们的数据集和模型权重。此外，我们提供了在开发一种能够生成低资源语言（以泰语为例）推理痕迹，并能跨领域泛化的推理模型过程中的见解。我们希望这个开放项目能为该领域的进一步研究提供基础。",
        "地址": "https://arxiv.org/pdf/2502.09042.pdf"
    },
    {
        "名称": "2025 [2502.09601] CoT-Valve: Length-Compressible Chain-of-Thought Tuning.pdf",
        "作者": "Xinyin Ma, Guangnian Wan, Runpeng Yu, Gongfan Fang, Xinchao Wang",
        "摘要": "摘要:\n推理链显著增强了模型的推理能力，但由于推理链较长，推理成本也显著增加。观察到在简单任务中推理路径可以轻松压缩，但在困难任务中却难以压缩，我们探索了只使用一个模型弹性控制推理路径长度的可行性，从而基于任务难度动态减少推理模型的推理开销。我们提出了一种名为CoT-Valve的新的调优和推理策略，用于生成不同长度的推理链。为此，我们提出通过识别参数空间中的一个方向来有效控制生成CoT的长度。此外，我们表明这种特性对于压缩推理链具有重要意义。我们为相同问题构建了从长到短的链式数据集，并探索了两种改进策略：(1) 精确的可长度压缩的CoT调优方法，以及(2) 渐进的链长度压缩方法。我们的实验表明，CoT-Valve成功实现了推理链的可控性和可压缩性，并且性能优于基于提示的控制方法。我们将这种方法应用于QwQ-32B-Preview，将GSM8K上推理链的长度从741个标记减少到225个标记，性能仅略微下降（从95.07％降至94.92％），在AIME上的推理链长度从6827个标记减少到4629个标记，仅多出一个错误答案。\n\n翻译：\n推理链显著增强了模型的推理能力，但由于推理链较长，推理成本也显著增加。观察到在简单任务中推理路径可以轻松压缩，但在困难任务中却难以压缩，我们探索了只使用一个模型弹性控制推理路径长度的可行性，从而基于任务难度动态减少推理模型的推理开销。我们提出了一种名为CoT-Valve的新的调优和推理策略，用于生成不同长度的推理链。为此，我们提出通过识别参数空间中的一个方向来有效控制生成CoT的长度。此外，我们表明这种特性对于压缩推理链具有重要意义。我们为相同问题构建了从长到短的链式数据集，并探索了两种改进策略：(1) 精确的可长度压缩的CoT调优方法，以及(2) 渐进的链长度压缩方法。我们的实验表明，CoT-Valve成功实现了推理链的可控性和可压缩性，并且性能优于基于提示的控制方法。我们将这种方法应用于QwQ-32B-Preview，将GSM8K上推理链的长度从741个标记减少到225个标记，性能仅略微下降（从95.07％降至94.92％），在AIME上的推理链长度从6827个标记减少到4629个标记，仅多出一个错误答案。",
        "地址": "https://arxiv.org/pdf/2502.09601.pdf"
    },
    {
        "名称": "2025 [2502.09390] SQuARE: Sequential Question Answering Reasoning Engine for Enhanced Chain-of-Thought in Large Language Models.pdf",
        "作者": "Daniel Fleischer, Moshe Berchansky, Gad Markovits, Moshe Wasserblat",
        "摘要": "摘要：在快速发展的自然语言处理领域， 大型语言模型（LLMs）面临着越来越复杂的推理挑战。传统的方法如链式思维提示虽然显示出了一定的潜力，但往往未能充分利用模型的推理能力。本文介绍了一种新颖的提示技术SQuARE（Sequential Question Answering Reasoning Engine），其设计旨在通过自我质询范式改善推理能力。基于CoT（Chain-of-Thought）框架，SQuARE提示模型在处理主要问题之前生成和解决多个辅助问题，从而促进对主题各个方面的更全面探讨。我们使用Llama 3和GPT-4o模型在多个问答数据集上进行的广泛评估表明，SQuARE明显优于传统的CoT提示和现有的重述与回应方法。通过系统性地分解查询，SQuARE在推理任务中提升了LLM的能力。代码公开发布在此：https网址。",
        "地址": "https://arxiv.org/pdf/2502.09390.pdf"
    },
    {
        "名称": "2025 [2502.08468] mmE5: Improving Multimodal Multilingual Embeddings via High-quality Synthetic Data.pdf",
        "作者": "Haonan Chen, Liang Wang, Nan Yang, Yutao Zhu, Ziliang Zhao, Furu Wei, Zhicheng Dou",
        "摘要": "摘要：多模态嵌入模型因其能够将文本和图像等不同模态的数据映射到统一的表示空间而受到广泛关注。然而，有限的标注多模态数据通常会阻碍嵌入性能。近期的方法利用数据合成来解决这个问题，但合成数据的质量仍是一个关键瓶颈。在这项工作中，我们确定了高质量合成多模态数据的三个标准。首先，广泛的覆盖范围确保生成的数据涵盖多种任务和模态，使其适用于各种下游场景。其次，稳健的跨模态对齐使不同模态在语义上一致。第三，高保真度确保合成数据保持真实细节，以增强其可靠性。在这些原则的指导下，我们合成了以下数据集：(1)涵盖广泛的任务、模态组合和语言，(2)通过多模态大型语言模型的单次深度思考过程生成，(3)结合了具有准确和相关文本的真实世界图像，通过自评估和改进确保保真度。利用这些高质量的合成和标注数据集，我们训练了一个多模态多语言的E5模型 mmE5。大量实验证明，mmE5在MMEB基准上达到了最先进的性能，并且在XTD基准上表现出卓越的多语言性能。我们的代码、数据集和模型已在此 https URL 发布。",
        "地址": "https://arxiv.org/pdf/2502.08468.pdf"
    },
    {
        "名称": "2025 [2502.05979] VFX Creator: Animated Visual Effect Generation with Controllable Diffusion Transformer.pdf",
        "作者": "Xinyu Liu, Ailing Zeng, Wei Xue, Harry Yang, Wenhan Luo, Qifeng Liu, Yike Guo",
        "摘要": "摘要：影视制作中最令人兴奋的一部分是创造魔术和幻象，视觉效果（VFX）是令人难忘的电影体验背后的强大推动力。尽管最近在生成式人工智能方面的进展推动了通用图像和视频合成的发展，但可控VFX生成领域仍相对未被充分探索。在这项工作中，我们提出了一种新的动画VFX生成范式作为图像动画，通过用户友好的文本描述和静态参考图像生成动态效果。我们的工作有两个主要贡献：（i）Open-VFX，这是第一个涵盖15个不同效果类别的高质量VFX视频数据集，附有文本描述、用于空间控制的实例分割掩模和用于时间控制的起止时间戳。（ii）VFX Creator，一个基于视频扩散变压器的简单但有效的可控VFX生成框架。该模型结合了空间和时间可控的LoRA适配器，所需的训练视频极少。特别是，一个即插即用的掩模控制模块实现了实例级的空间操作，而在扩散过程中嵌入的令牌化的起止运动时间戳以及文本编码器允许对效果时间和速度进行精确的时间控制。在Open-VFX测试集上的大量实验表明，该系统在生成真实和动态效果方面的优越性，在空间和时间可控性方面达到了最先进的性能和泛化能力。此外，我们引入了一个专门的指标来评估时间控制的精确度。通过将传统VFX技术与生成方法结合，VFX Creator开启了高效和高质量视频效果生成的新可能，使高级VFX为更广泛的受众所用。",
        "地址": "https://arxiv.org/pdf/2502.05979.pdf"
    },
    {
        "名称": "2025 [2502.08680] Mathematical Reasoning in Large Language Models: Assessing Logical and Arithmetic Errors across Wide Numerical Ranges.pdf",
        "作者": "Safal Shrestha, Minwu Kim, Keith Ross",
        "摘要": "摘要：大型语言模型（LLMs）中的数学推理通常使用数值范围有限的基准进行评估，未能反映出在不同尺度下的实际问题解决能力。此外，大多数现有的评估方法仅将模型输出与真实答案进行比较，掩盖了对推理过程的洞察。为了解决这些限制，我们介绍了GSM-Ranges，这是一种源自GSM8K的数据集生成器，通过系统性地扰动数学问题中的数值来评估模型在不同数值尺度下的稳健性。此外，我们提出了一种新的评分方法，区分逻辑错误和非逻辑错误，提供了对推理过程的更精确评估，超越了计算准确性。我们对各种模型的实验揭示了一个重要的发现：随着数值复杂性的增加，逻辑错误率显著上升，高达14个百分点，这表明在处理非分布数值时推理能力普遍较弱。此外，尽管模型在独立算术任务上表现出较高的准确性，但在嵌入文字问题中的计算性能大幅下降。这些发现为评估LLMs的数学推理能力提供了全面的见解，并为未来改进语言模型的数值泛化能力指明了研究方向。",
        "地址": "https://arxiv.org/pdf/2502.08680.pdf"
    },
    {
        "名称": "2025 [2502.09614] DexTrack: Towards Generalizable Neural Tracking Control for Dexterous Manipulation from Human References.pdf",
        "作者": "Xueyi Liu, Jianibieke Adalibieke, Qianwei Han, Yuzhe Qin, Li Yi",
        "摘要": "摘要：我们解决了从人类参考中开发通用神经跟踪控制器用于灵巧操作的挑战。该控制器旨在管理灵巧机器人手，以便根据运动学的人与物体相互作用，操纵各种物体以实现多种目的。开发此类控制器的复杂性在于灵巧操作的复杂接触动态，以及对适应性、普遍性和鲁棒性的需求。目前的强化学习和轨迹优化方法往往由于依赖于特定任务的奖励或精确的系统模型而不足。我们提出了一种方法，策划了大规模成功的机器人跟踪演示，包括人类参考和机器人动作对，以训练神经控制器。利用数据飞轮，我们迭代地提高控制器的性能，以及成功跟踪演示的数量和质量。我们利用现有的跟踪演示，并仔细整合强化学习和模仿学习，以增强控制器在动态环境中的性能。同时，为了获得高质量的跟踪演示，我们通过在同伦优化方法中利用学习到的跟踪控制器，单独优化每个轨迹跟踪。同伦优化模仿思维链，有助于解决具有挑战性的轨迹跟踪问题，以增加演示的多样性。我们通过在模拟和真实世界中训练通用的神经控制器并进行评估展示了我们的成功。与领先的基线相比，我们的方法在成功率方面取得了超过10%的提升。项目网站的动画结果可在这个https URL上找到。",
        "地址": "https://arxiv.org/pdf/2502.09614.pdf"
    },
    {
        "名称": "2025 [2502.05761] 3CAD: A Large-Scale Real-World 3C Product Dataset for Unsupervised Anomaly.pdf",
        "作者": "Enquan Yang, Peng Xing, Hanyang Sun, Wenbo Guo, Yuanwei Ma, Zechao Li, Dan Zeng",
        "摘要": "摘要：工业异常检测因MVTec-AD和VisA等数据集取得了进展。然而，这些数据集在缺陷样本数量、缺陷类型和真实场景的可用性方面存在局限性。这些限制阻碍了研究人员进一步提升工业检测准确性的可能性。为此，我们提出了一个新的大规模异常检测数据集3CAD，该数据集来自真实的3C生产线。具体来说，3CAD包含八种不同类型的制造零件，共有27,039张标注了像素级异常的高分辨率图像。3CAD的关键特性是它涵盖了不同大小的异常区域、多种异常类型以及每张异常图像可能包含多个异常区域和多种异常类型。3CAD是第一个专门用于3C产品质量控制的异常检测数据集，供社区探索和发展。同时，我们引入了一种简单而有效的无监督异常检测框架：一种具有恢复指导的粗到细检测范式（CFRG）。为了检测小缺陷异常，所提出的CFRG利用了粗到细的检测范式。具体来说，我们使用异质蒸馏模型进行粗定位，然后通过分割模型进行精细定位。此外，为了更好地捕捉正常模式，我们引入了恢复特征作为指导。最后，我们报告了CFRG框架和流行异常检测方法在3CAD数据集上的结果，展示了其强大的竞争力，并提供了一个高度挑战性的基准，以促进异常检测领域的发展。数据和代码可用：https网址。",
        "地址": "https://arxiv.org/pdf/2502.05761.pdf"
    }
]