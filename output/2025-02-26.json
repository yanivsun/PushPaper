[
    {
        "名称": "2025 [2502.18411] OmniAlign-V: Towards Enhanced Alignment of MLLMs with Human Preference.pdf",
        "作者": "Xiangyu Zhao, Shengyuan Ding, Zicheng Zhang, Haian Huang, Maosong Cao, Weiyun Wang, Jiaqi Wang, Xinyu Fang, Wenhai Wang, Guangtao Zhai, Haodong Duan, Hua Yang, Kai Chen",
        "摘要": "摘要：近年来，开源多模态大语言模型（MLLMs）的进展主要集中在增强基础能力上，导致与人类偏好对齐方面存在显著差距。本文介绍了OmniAlign-V，这是一个包含20万个高质量训练样本的综合数据集，特征为多样的图像、复杂的问题和多种响应格式，旨在改善MLLMs与人类偏好的对齐度。我们还提出了MM-AlignBench，这是一个专门设计用于评估MLLMs与人类价值观对齐度的人类标注基准。实验结果表明，使用监督微调（SFT）或直接偏好优化（DPO）对MLLMs进行OmniAlign-V微调，可以显著增强与人类偏好的对齐度，同时在标准视觉问答（VQA）基准测试上的表现得到保持或提升，保持其基础能力。我们的数据集、基准、代码和检查点已在此https URL发布。\n\n作者：赵翔宇，丁圣渊，张子成，黄海安，曹茂松，王维韵，王嘉琪，方新宇，王文海，翟广涛，段浩东，杨华，陈锴",
        "地址": "https://arxiv.org/pdf/2502.18411.pdf"
    },
    {
        "名称": "2025 [2502.18137] SpargeAttn: Accurate Sparse Attention Accelerating Any Model Inference.pdf",
        "作者": "Jintao Zhang, Chendong Xiang, Haofeng Huang, Jia Wei, Haocheng Xi, Jun Zhu, Jianfei Chen",
        "摘要": "摘要：由于注意力机制的二次时间复杂度，对于大型模型来说，高效的注意力实现至关重要。幸运的是，注意力通常表现出稀疏性，即注意力图中的许多值接近于零，从而允许省略相应的计算。许多研究利用这种稀疏模式来加速注意力机制。然而，大多数现有工作集中于通过利用特定模型的某些稀疏模式来优化注意力机制。普遍适用于各种模型并能保证加速和端到端性能的通用稀疏注意力仍然难以实现。在本文中，我们提出了SpargeAttn，这是一种适用于任何模型的通用稀疏量化注意力机制。我们的方法使用了两阶段的在线过滤器：在第一阶段，我们快速且准确地预测注意力图，从而可以跳过注意力机制中的一些矩阵乘法。在第二阶段，我们设计了一个不产生额外开销的在线softmax感知过滤器，进一步跳过了一些矩阵乘法。实验表明，我们的方法显著加速了各种模型的运行，包括语言、图像和视频生成，而不会牺牲端到端的性能指标。代码可在此网址获取：https://arxiv.org/pdf/2502.18137.pdf。\n\n作者：张金涛，项晨东，黄昊峰，魏佳，席昊成，朱军，陈剑飞",
        "地址": "https://arxiv.org/pdf/2502.18137.pdf"
    },
    {
        "名称": "2025 [2502.18449] SWE-RL: Advancing LLM Reasoning via Reinforcement Learning on Open Software Evolution.pdf",
        "作者": "Yuxiang Wei, Olivier Duchenne, Jade Copet, Quentin Carbonneaux, Lingming Zhang, Daniel Fried, Gabriel Synnaeve, Rishabh Singh, Sida I. Wang",
        "摘要": "摘要：最近发布的DeepSeek-R1展示了强化学习（RL）在增强大型语言模型（LLM）的一般推理能力方面的巨大潜力。虽然DeepSeek-R1及其后续工作的重点主要是将RL应用于竞赛编程和数学问题，该论文介绍了SWE-RL，这是第一个在实际软件工程中扩展基于RL的LLM推理的方法。SWE-RL利用了一种轻量级的基于规则的奖励机制（例如，ground-truth与LLM生成解答之间的相似度评分），使LLM能够通过学习大量的开源软件演化数据（包括软件生命周期中的代码快照、代码更改以及问题和拉取请求等事件记录）自主恢复开发人员的推理过程和解决方案。我们的推理模型Llama3-SWE-RL-70B基于Llama 3训练，在经过人工验证的真实GitHub问题集SWE-bench Verified上实现了41.0%的解决率。据我们所知，这是目前中型（<100B）LLM所报告的最佳表现，甚至可与领先的专有LLM如GPT-4o相媲美。令人惊讶的是，尽管仅在软件演化数据上进行RL，Llama3-SWE-RL甚至还具备了通用推理技能。例如，它在五个领域外任务（函数编码、库使用、代码推理、数学和一般语言理解）上也显示了改进，而监督微调基线则平均表现下降。总体而言，SWE-RL为通过大量软件工程数据上的强化学习改进LLM的推理能力开辟了新方向。",
        "地址": "https://arxiv.org/pdf/2502.18449.pdf"
    },
    {
        "名称": "2025 [2502.17363] KV-Edit: Training-Free Image Editing for Precise Background Preservation.pdf",
        "作者": "Tianrui Zhu, Shiyi Zhang, Jiawei Shao, Yansong Tang",
        "摘要": "摘要：背景一致性仍然是图像编辑任务中的一个重大挑战。尽管已有大量发展，现有的工作在保持与原始图像的相似性和生成与目标一致的内容之间仍面临折衷。本文提出了KV-Edit，这是一种使用DiTs中的KV缓存来保持背景一致性的无训练方法，其中保留而不是重新生成背景标记，消除了复杂机制或昂贵训练的需求，最终在用户提供的区域内生成与背景无缝集成的新内容。我们进一步探讨了编辑过程中KV缓存的内存消耗，并使用无反转方法将空间复杂度优化为O(1)。我们的方法兼容任何基于DiT的生成模型，无需额外训练。实验表明，KV-Edit在背景和图像质量方面显著优于现有方法，甚至超越了基于训练的方法。项目网页可访问网址为此https URL。",
        "地址": "https://arxiv.org/pdf/2502.17363.pdf"
    },
    {
        "名称": "2025 [2502.18364] ART: Anonymous Region Transformer for Variable Multi-Layer Transparent Image Generation.pdf",
        "作者": "Yifan Pu, Yiming Zhao, Zhicong Tang, Ruihong Yin, Haoxing Ye, Yuhui Yuan, Dong Chen, Jianmin Bao, Sirui Zhang, Yanbin Wang, Lin Liang, Lijuan Wang, Ji Li, Xiu Li, Zhouhui Lian, Gao Huang, Baining Guo",
        "摘要": "摘要：多层图像生成是一个基础任务，使用户能够隔离、选择和编辑特定图像层，从而彻底改变与生成模型的交互。在本文中，我们介绍了匿名区域转换器（ART），它基于全局文本提示和匿名区域布局，促进了可变多层透明图像的直接生成。受图式理论的启发，匿名区域布局允许生成模型自主确定哪些视觉令牌应与哪些文本令牌对齐，这与先前主导的语义布局生成任务形成对比。此外，逐层区域裁剪机制仅选择属于每个匿名区域的视觉令牌，显著减少了注意力计算成本，并能够高效地生成具有多个不同层（例如，50+层）的图像。与全注意力方法相比，我们的方法速度快超过12倍，且层冲突更少。此外，我们提出了一种高质量多层透明图像自编码器，支持变量多层图像透明度的直接联合编码和解码。通过实现精确控制和可扩展的层生成，ART为互动内容创作建立了新范式。",
        "地址": "https://arxiv.org/pdf/2502.18364.pdf"
    },
    {
        "名称": "2025 [2502.17262] Unveiling Downstream Performance Scaling of LLMs: A Clustering-Based Perspective.pdf",
        "作者": "Chengyin Xu, Kaiyuan Chen, Xiao Li, Ke Shen, Chenggang Li",
        "摘要": "摘要：计算的快速进步极大地增加了训练大型语言模型（LLMs）的规模和成本。在模型训练之前准确预测下游任务性能对于高效的资源分配至关重要，但由于两个主要限制因素，这仍然具有挑战性：(1) 下游性能指标只有在经过大量训练后才变得有意义的“涌现现象”，限制了使用较小模型进行预测的能力；(2) 任务难度分布不均和缺乏一致的扩展规律，导致指标的显著变异性。现有的性能预测方法准确性和可靠性有限，从而阻碍了对LLM潜在能力的评估。为了应对这些挑战，我们提出了一个基于难度聚类（COD）的下游性能预测框架。COD首先通过基于难度特征对任务进行聚类，构建一个可预测的支持子集，策略性地排除了非涌现和不可扩展的聚类。所选子集的评分作为对全评价集下游性能的有效中间预测指标。在理论支持下，我们推导出一个映射函数，将性能指标从可预测子集转换到全评价集，从而确保了对LLM下游性能的准确外推。所提出的方法已经应用于预测一个70B LLM的性能扩展，为训练资源分配提供了可操作的见解，并有助于监控训练过程。值得注意的是，COD通过利用多个小模型集成，在八个重要的LLM评估基准上实现了1.36%的绝对平均偏差，展现了显著的预测准确性。\n\n作者：徐诚银，陈开元，李潇，沈可，李成钢\n\n注释：21页，6张图\n\n网址： https://arxiv.org/pdf/2502.17262.pdf\n\n标题：2025 [2502.17262] 揭示LLMs下游性能扩展：基于聚类的视角",
        "地址": "https://arxiv.org/pdf/2502.17262.pdf"
    },
    {
        "名称": "2025 [2502.15499] Scale-Distribution Decoupling: Enabling Stable and Effective Training of Large Language Models.pdf",
        "作者": "Ya Wang, Zhijian Zhuo, Yutao Zeng, Xun Zhou, Jian Yang, Xiaoqing Li",
        "摘要": "摘要：训练稳定性是大型语言模型（LLMs）预训练中的一个持续挑战，特别是对Post-Norm Transformers等架构，它们容易发生梯度爆炸和消失。在本文中，我们提出了尺度分布解耦（Scale-Distribution Decoupling, SDD），这是一种通过显式解耦全连接层中权重矩阵的尺度和分布来稳定训练的新方法。SDD应用了一种归一化机制来调节激活，并使用一个可学习的缩放向量来保持良好条件的梯度，从而有效防止梯度爆炸和消失。这种分离通过确保梯度传播的稳定性，提高了深层网络的优化效率。实验结果表明，我们的方法在各种LLM架构中稳定了训练，并在不同的归一化配置中优于现有技术。此外，该方法轻量且与现有框架兼容，使其成为稳定LLM训练的实用解决方案。代码可在此链接获取：https://arxiv.org/pdf/2502.15499.pdf。",
        "地址": "https://arxiv.org/pdf/2502.15499.pdf"
    },
    {
        "名称": "2025 [2502.16069] Curie: Toward Rigorous and Automated Scientific Experimentation with AI Agents.pdf",
        "作者": "Patrick Tser Jern Kon, Jiachen Liu, Qiuyi Ding, Yiming Qiu, Zhenning Yang, Yibo Huang, Jayanth Srinivasa, Myungjin Lee, Mosharaf Chowdhury, Ang Chen",
        "摘要": "摘要：科学实验是人类进步的基石，它要求在可靠性、方法控制和可解释性上保持严格，以产生有意义的结果。尽管大型语言模型（LLMs）在自动化科学过程的不同方面越来越有能力，但自动化严格的实验仍然是一个重大挑战。为了解决这一问题，我们提出了Curie，这是一种AI代理框架，旨在通过三个关键组件将严格性嵌入实验过程中：增强可靠性的内代理严格模块、维护方法控制的外代理严格模块以及提高可解释性的实验知识模块。为了评估Curie，我们设计了一项新颖的实验基准，由四个计算机科学领域的46个问题组成，这些问题来源于有影响力的研究论文和广泛采用的开源项目。与最强的基线相比，我们在正确回答实验问题上取得了3.4倍的改进。Curie的源码已在此链接开源发布。\n\n翻译：科帕特里克·策尔·杰恩·昆、刘嘉晨、丁秋仪、邱义明、杨振宁、黄乂波、杰杨·斯里尼瓦斯、李明进、乔杜里·莫沙拉夫、陈昂",
        "地址": "https://arxiv.org/pdf/2502.16069.pdf"
    },
    {
        "名称": "2025 [2502.18461] K-LoRA: Unlocking Training-Free Fusion of Any Subject and Style LoRAs.pdf",
        "作者": "Ziheng Ouyang, Zhen Li, Qibin Hou",
        "摘要": "摘要：最近的研究探索了结合不同的LoRA来共同生成学习到的风格和内容。然而，现有的方法要么无法同时有效地保留原始主题和风格，要么需要额外的训练。本文认为LoRA的内在特性能够有效地指导扩散模型在融合学习到的主题和风格时进行选择。在此基础上，我们提出了K-LoRA，一种简单而有效的无训练LoRA融合方法。在每个注意力层中，K-LoRA比较每个要融合的LoRA中的Top-K元素，确定选择哪个LoRA以实现最佳融合。这种选择机制确保在融合过程中保留了主题和风格的最具代表性的特征，有效地平衡了它们的贡献。实验结果表明，该方法有效地整合了原始LoRA所学习到的主题和风格信息，在定性和定量结果方面优于现有的基于训练的最先进方法。\n\n翻译：[摘要]最近的研究探索了结合不同LoRA来共同生成学习的风格和内容。然而，现有方法要么无法有效同时保留原始主题和风格，要么需要额外的训练。本文认为LoRA的内在特性能够有效指导扩散模型融合学习到的主题和风格。基于这一见解，我们提出了K-LoRA，这是一个简单但有效的无训练LoRA融合方法。在每个注意层，K-LoRA比较每个要融合的LoRA中的Top-K元素，决定选择哪个LoRA进行最优融合。这一选择机制确保在融合过程中保留主题与风格的最大代表性特征，有效平衡它们的贡献。实验结果表明，所提方法有效整合了原始LoRA学习的主题与风格信息，在定性、定量结果方面均 outperform state-of-the-art training-based approaches.",
        "地址": "https://arxiv.org/pdf/2502.18461.pdf"
    },
    {
        "名称": "2025 [2502.18356] WebGames: Challenging General-Purpose Web-Browsing AI Agents.pdf",
        "作者": "George Thomas, Alex J. Chan, Jikun Kang, Wenqi Wu, Filippos Christianos, Fraser Greenlee, Andy Toulis, Marvin Purtorab",
        "摘要": "摘要：\n我们介绍了WebGames，这是一个综合基准套件，专为通过50多个互动挑战来评估通用网页浏览AI代理而设计。这些挑战被特别设计为对人类来说简单，但系统地测试了当前AI系统在基本浏览器交互、高级输入处理、认知任务、工作流自动化和互动娱乐方面的局限性。我们的框架通过一个隔离的测试环境消除了外部依赖，确保了可重复的评估和可验证的标准答案。我们评估了包括GPT-4o、Claude Computer-Use、Gemini-1.5-Pro和Qwen2-VL在内的领先视觉-语言模型，并将它们的表现与人类进行了对比。结果显示，最佳AI系统仅实现了43.1%的成功率，而人类的表现为95.7%，这突显了当前AI系统在处理人类直观的常见网页交互模式方面的根本性局限性。该基准套件在此公开网址提供，具有轻量级、客户端实现，便于快速评估周期。通过其模块化架构和标准化挑战规范，WebGames为衡量更强大的网页浏览代理的发展进步提供了坚实基础。\n\n摘要翻译：\n我们提出了WebGames，这是一个全面的基准测试套件，旨在通过一系列50多个互动挑战来评估通用网页浏览AI代理。这些挑战专门设计为对人类来说很简单，同时系统地测试当前AI系统在基本浏览器交互、先进输入处理、认知任务、工作流自动化和互动娱乐方面的局限性。我们的框架通过一个封闭的测试环境消除了外部依赖，确保评估的可重复性，并提供可验证的标准答案。我们评估了包括GPT-4o、Claude Computer-Use、Gemini-1.5-Pro和Qwen2-VL在内的领先视觉-语言模型，并与人类的表现进行了对比。结果显示，最佳AI系统的成功率仅为43.1%，而人类的表现为95.7%，这突显了当前AI系统在处理人类直观的常见网页交互模式方面的根本局限性。这个基准测试套件在此公开网址提供，具有轻量级和客户端实现，便于快速评估循环。通过其模块化架构和标准化挑战规范，WebGames为衡量更强大的网页浏览代理的开发进展提供了坚实的基础。",
        "地址": "https://arxiv.org/pdf/2502.18356.pdf"
    },
    {
        "名称": "2025 [2502.17425] Introducing Visual Perception Token into Multimodal Large Language Model.pdf",
        "作者": "Runpeng Yu, Xinyin Ma, Xinchao Wang",
        "摘要": "摘要：为了利用视觉信息，多模态大型语言模型（MLLM）依赖其视觉编码器的感知过程。视觉感知的完整性和准确性显著影响空间推理、细粒度理解及其他任务的精度。然而，MLLM仍然缺乏自主控制其视觉感知过程的能力，例如，有选择地审查图像的特定区域或关注与特定对象类别相关的信息。在这项工作中，我们提出了视觉感知令牌的概念，旨在为MLLM提供一种控制其视觉感知过程的机制。我们设计了两种视觉感知令牌，称为区域选择令牌和视觉重新编码令牌。MLLM自主生成这些令牌，就像生成文本一样，并使用它们触发额外的视觉感知动作。区域选择令牌明确识别图像中需要进一步感知的特定区域，而视觉重新编码令牌则使用其隐藏状态作为控制信号来引导额外的视觉感知过程。大量实验证明了这些令牌在处理空间推理、改进细粒度理解及其他任务中的优势。平均而言，引入视觉感知令牌使一个2B模型的性能提高了23.6%，其得分从0.572提高到0.708，甚至超过了7B参数模型13.4%（从0.624）。\n\n链接：https://arxiv.org/pdf/2502.17425.pdf",
        "地址": "https://arxiv.org/pdf/2502.17425.pdf"
    },
    {
        "名称": "2025 [2502.16825] Finding the Sweet Spot: Preference Data Construction for Scaling Preference Optimization.pdf",
        "作者": "Yao Xiao, Hai Ye, Linyao Chen, Hwee Tou Ng, Lidong Bing, Xiaoli Li, Roy Ka-wei Lee",
        "摘要": "摘要：迭代数据生成和模型再训练广泛用于调整大规模语言模型（LLMs）。该过程通常涉及一个策略模型生成策略响应和一个奖励模型引导训练数据的选择。直接偏好优化（DPO）通过构建选择和拒绝响应的偏好对进一步增强了这个过程。在这项工作中，我们旨在通过重复随机抽样来增加策略样本的数量，以提高对齐性能。传统做法选择奖励最高的样本作为选择，奖励最低的样本作为拒绝用于DPO。然而，我们的实验表明，随着样本规模的增加，这一策略会导致性能下降。为了解决这个问题，我们通过样本奖励的基础正态分布视角研究偏好数据构建。我们将奖励空间分为七个代表点，并系统地探索所有21（$C_7^2$）对组合。通过AlpacaEval 2对四个模型的评估，我们发现选择在奖励位置$\\mu - 2\\sigma$而非最低奖励作为拒绝响应，才能实现最佳性能。最终，我们引入了一种可扩展的偏好数据构建策略，随着样本规模的增加，能够持续增强模型性能。\n\n翻译：",
        "地址": "https://arxiv.org/pdf/2502.16825.pdf"
    },
    {
        "名称": "2025 [2502.17535] The Lottery LLM Hypothesis, Rethinking What Abilities Should LLM Compression Preserve?.pdf",
        "作者": "Zhenheng Tang, Xiang Liu, Qian Wang, Peijie Dong, Bingsheng He, Xiaowen Chu, Bo Li",
        "摘要": "摘要翻译为中文如下：\n\n摘要：为了减小大语言模型（LLMs）的计算和存储成本，模型压缩和KV缓存压缩引起了研究者们的广泛关注。然而，目前的方法主要侧重于通过困惑度或是常识问答和基本算术推理任务的简单准确性来保持压缩后LLMs的性能。在本文中，我们简要回顾了最近在与检索增强生成、多步推理、外部工具和计算表达能力相关的LLMs方面的进展，这些进展大大提升了LLM的性能。随后，我们提出了一个彩票LLM假设，表明对于给定的LLM和任务，在多步推理和外部工具的帮助下，存在一个较小的彩票LLM能够产生与原始LLM相同的性能。基于对当前LLMs进展的回顾，我们讨论并总结了彩票LLM和KV缓存压缩必须具备的重要能力，这些能力在现有方法中被忽视了。\n\n作者：曾恒、刘翔、王强、董培杰、何炳胜、楚晓文、李波\n\nURL：https://arxiv.org/pdf/2502.17535.pdf\n\n标题：2025 [2502.17535] 彩票LLM假设：重新思考LLM压缩应保留哪些能力？",
        "地址": "https://arxiv.org/pdf/2502.17535.pdf"
    },
    {
        "名称": "2025 [2502.16794] AAD-LLM: Neural Attention-Driven Auditory Scene Understanding.pdf",
        "作者": "Xilin Jiang, Sukru Samet Dindar, Vishal Choudhari, Stephan Bickel, Ashesh Mehta, Guy M McKhann, Adeen Flinker, Daniel Friedman, Nima Mesgarani",
        "摘要": "摘要：现有的听觉基础模型，包括听觉大语言模型（LLMs），对所有声源输入一视同仁，而不考虑听者的感知。然而，人类的听觉感知本质上是选择性的：听者在复杂的听觉场景中会集中注意力于特定的讲话者，同时忽略其他人。现有模型并未结合这种选择性，限制了其生成与感知一致反应的能力。为了解决这个问题，我们提出了意图知晓的听觉场景理解（II-ASU），并展示了一个原型系统——听觉注意驱动的LLM（AAD-LLM），它集成了脑电信号以推断听者的注意力。AAD-LLM通过结合颅内脑电图（iEEG）记录，来解码听者关注的讲话者，并据此优化生成的反应。该模型首先从神经活动中预测听者所关注的讲话者，然后以此推断出的注意状态为条件生成反应。我们在多讲话者场景中评估了AAD-LLM的效果，包括讲话者描述、语音转录和提取、以及问答，结果显示无论是客观还是主观评分，都更好地与听者意图对齐。通过迈出意图感知听觉AI的第一步，这项工作探索了一种新的范式，其中听者感知指导机器聆听，为未来以听者为中心的听觉系统铺平了道路。演示和代码已开放：https://arxiv.org/pdf/2502.16794.pdf",
        "地址": "https://arxiv.org/pdf/2502.16794.pdf"
    },
    {
        "名称": "2025 [2502.14855] Prompt-to-Leaderboard.pdf",
        "作者": "Evan Frick, Connor Chen, Joseph Tennyson, Tianle Li, Wei-Lin Chiang, Anastasios N. Angelopoulos, Ion Stoica",
        "摘要": "摘要：大型语言模型（LLM）的评估通常依赖于诸如准确性或人类偏好等汇总指标，在用户和提示之间取平均值。这种平均掩盖了模型性能中的用户和提示特异性变化。为了解决这一问题，我们提出了Prompt-to-Leaderboard（P2L）方法，该方法生成特定于提示的排行榜。核心思想是训练一个LLM，以自然语言提示作为输入，输出一组Bradley-Terry系数向量，然后用其预测人类偏好投票。最终生成的基于提示的排行榜允许进行无监督的任务特定评估、查询路由优化、个性化以及模型优缺点的自动评估。Chatbot Arena的数据表明，P2L比平均排行榜更好地捕捉了语言模型性能的细微差别。此外，我们的研究结果表明，P2L生成提示特定评估的能力呈现出类似于LLM自身的幂律缩放。在2025年1月，根据此方法训练的路由器在Chatbot Arena排行榜上获得了第一名。我们的代码可在以下的GitHub链接获取：this https URL。",
        "地址": "https://arxiv.org/pdf/2502.14855.pdf"
    },
    {
        "名称": "2025 [2502.17422] MLLMs Know Where to Look: Training-free Perception of Small Visual Details with Multimodal LLMs.pdf",
        "作者": "Jiarui Zhang, Mahyar Khayatkhoei, Prateek Chhikara, Filip Ilievski",
        "摘要": "摘要：多模态大型语言模型（MLLMs）近年来在视觉识别任务中取得了迅速进展。鉴于其潜在的广泛应用，了解其视觉感知的局限性变得尤为重要。在这项工作中，我们研究MLLMs在回答关于图像的问题时，是否能够像识别大视觉细节一样有效地识别小视觉细节。我们观察到，其性能对问题中视觉主体的大小非常敏感。通过干预研究，我们进一步证明这种效应实际上存在因果关系。接下来，我们研究了MLLMs在回答视觉问题时的注意模式，发现即使在提供错误答案时，它们也始终知道看哪里。基于这些发现，我们提出了一种不需要训练的视觉干预方法，利用任何MLLMs内部的注意力和梯度图来增强其对小视觉细节的感知。我们在两种广泛使用的MLLMs和七个视觉问答基准上评估了我们提出的方法，结果表明这种方法显著提高了MLLMs的准确性，而不需要任何训练。我们的结果阐明了MLLMs在涉及小细节的视觉识别任务中应用的风险，并表明利用模型内部状态进行视觉干预是一种有前途的方向来减轻这种风险。\n\n翻译为中文：多模态大型语言模型（MLLMs）近年来在视觉识别任务中取得了迅速进展。由于其潜在的广泛应用，了解其视觉感知的局限性变得尤为重要。在本研究中，我们探讨了当回答有关图像的问题时，MLLMs是否能够像识别大尺寸视觉主体一样有效地识别小尺寸视觉主体。我们观察到，其性能对视觉主体的大小非常敏感，并通过干预研究进一步证明这种效应具有因果关系。接下来，我们研究了MLLMs在回答视觉问题时的注意力模式，发现即使在回答错误时，它们也始终知道该看哪里。基于这些发现，我们提出了无需训练的视觉干预方法，利用任何MLLMs内部的注意力和梯度图来增强其对小视觉细节的感知。我们在两个广泛使用的MLLMs和七个视觉问答基准上评估了我们提出的方法，结果显示这种方法显著提高了MLLMs的准确性，而无需进行任何训练。我们的研究结果揭示了在涉及小细节的视觉识别任务中应用MLLMs的风险，并表明利用模型内部状态进行视觉干预是减轻这种风险的一个有前途的方向。",
        "地址": "https://arxiv.org/pdf/2502.17422.pdf"
    },
    {
        "名称": "2025 [2502.17814] An Overview of Large Language Models for Statisticians.pdf",
        "作者": "Wenlong Ji, Weizhe Yuan, Emily Getzen, Kyunghyun Cho, Michael I. Jordan, Song Mei, Jason E Weston, Weijie J. Su, Jing Xu, Linjun Zhang",
        "摘要": "摘要：大型语言模型（LLMs）在人工智能（AI）领域中已成为变革性的工具，展示了在文本生成、推理和决策等多种任务中的显著能力。虽然其成功主要归因于计算能力和深度学习架构的进步，但在不确定性量化、决策、因果推断和分布偏移等领域的新兴问题需要更深入地与统计学领域进行互动。本文探讨了统计学家在LLMs的发展中可以做出重要贡献的潜在领域，特别是那些旨在为人类用户带来可信度和透明度的领域。因此，我们关注不确定性量化、可解释性、公平性、隐私、水印和模型适应性等问题。我们还考虑了LLMs在统计分析中的可能角色。通过连接AI和统计学，我们旨在促进更深层次的合作，推进LLMs的理论基础和实际应用，最终塑造其在应对复杂社会挑战中的作用。\n\n原文链接：https://arxiv.org/pdf/2502.17814.pdf",
        "地址": "https://arxiv.org/pdf/2502.17814.pdf"
    },
    {
        "名称": "2025 [2502.15612] LaTIM: Measuring Latent Token-to-Token Interactions in Mamba Models.pdf",
        "作者": "Hugo Pitorro, Marcos Treviso",
        "摘要": "摘要：状态空间模型（SSMs），如Mamba，已经成为长上下文序列建模中一种有效的替代方案。然而，尽管其应用日益广泛，SSMs缺乏用于理解和改进基于注意力的架构所必需的可解释性工具。尽管最近的研究提供了对Mamba内部机制的见解，但它们并没有明确分解每个标记的贡献，使得难以理解Mamba如何在各层选择性地处理序列。在这项工作中，我们为Mamba-1和Mamba-2引入了一种新的标记级分解方法LaTIM，从而实现细粒度的可解释性。我们在机器翻译、复制和基于检索的生成等多种任务上广泛评估了我们的方法，证明了其在揭示Mamba标记间交互模式方面的有效性。",
        "地址": "https://arxiv.org/pdf/2502.15612.pdf"
    },
    {
        "名称": "2025 [2502.17092] Shakti-VLMs: Scalable Vision-Language Models for Enterprise AI.pdf",
        "作者": "Syed Abdul Gaffar Shakhadri, Kruthika KR, Kartik Basavaraj Angadi",
        "摘要": "摘要：\n我们介绍了Shakti VLM，这是一系列具有1B和4B参数的视觉-语言模型，旨在应对多模态学习中的数据效率挑战。尽管最近的VLM通过大量训练数据取得了强劲的性能，但Shakti模型利用架构创新，在使用较少数据的情况下实现了具有竞争力的结果。主要进展包括用于注意力稳定的QK-归一化、混合归一化技术和增强的位置信息编码。三阶段训练策略进一步优化了学习效率。评估显示，Shakti-VLM-1B和Shakti-VLM-4B在文档理解、视觉推理、OCR提取和通用多模态推理方面表现优秀。我们的结果表明，通过模型设计和训练策略，可以在无需大量数据的情况下实现高性能，使得Shakti成为企业级多模态任务的高效解决方案。",
        "地址": "https://arxiv.org/pdf/2502.17092.pdf"
    },
    {
        "名称": "2025 [2502.17910] Scaling LLM Pre-training with Vocabulary Curriculum.pdf",
        "作者": "Fangyuan Yu",
        "摘要": "摘 要：现代语言模型依赖于在预训练之前固定的静态词汇表，这与人类语言学习中观察到的自适应词汇习得形成对比。为了弥合这一差距，我们引入了词汇课程学习，这种方法通过相对词汇表大小的对数线性扩展功能来提高预训练效率。我们的方法在熵引导的词汇扩展和模型优化之间进行交替，使模型能够学习跨不同标记粒度的可迁移表征。这种方法自然产生了一种最佳计算分配模式：较长的标记捕捉可预测的内容，而较短的标记则关注更复杂、难以预测的上下文。在小规模GPT模型上的实验表明，动态分词的缩放效率得到提高，进一步证明了其有效性。为了支持进一步的研究，我们发布了代码，并计划将实验扩展到更大的模型和不同的领域。",
        "地址": "https://arxiv.org/pdf/2502.17910.pdf"
    },
    {
        "名称": "2025 [2502.18302] LDGen: Enhancing Text-to-Image Synthesis via Large Language Model-Driven Language Representation.pdf",
        "作者": "Pengzhi Li, Pengfei Yu, Zide Liu, Wei He, Xuhao Pan, Xudong Rao, Tao Wei, Wei Chen",
        "摘要": "摘要：在本文中，我们介绍了LDGen，这是一种将大型语言模型（LLMs）整合到现有的文本到图像扩散模型中，同时将计算需求降到最低的新方法。传统的文本编码器，如CLIP和T5，在多语言处理方面存在局限性，阻碍了不同语言的图像生成。我们通过利用LLMs的先进能力来解决这些挑战。我们的方法采用了一种语言表示策略，应用了分层标题优化和人类指令技术，以提取精确的语义信息。随后，我们引入了一个轻量级适配器和一个跨模态精炼器，以促进LLMs和图像特征之间的高效特征对齐和交互。LDGen减少了训练时间，并实现了零样本多语言图像生成。实验结果表明，我们的方法在提示符合性和图像美学质量方面均优于基线模型，同时无缝支持多种语言。项目页面：this https URL。",
        "地址": "https://arxiv.org/pdf/2502.18302.pdf"
    },
    {
        "名称": "2025 [2502.18316] WiCkeD: A Simple Method to Make Multiple Choice Benchmarks More Challenging.pdf",
        "作者": "Ahmed Elhady, Eneko Agirre, Mikel Artetxe",
        "摘要": "摘要：我们介绍了一种称为WiCkeD的简单方法，通过随机用“以上都不是”替换一个选项来增加现有多项选择基准测试的复杂性，这种方法常用于教育测试。我们展示了WiCkeD可以自动应用于任何现有的基准测试，使其更具挑战性。我们将WiCkeD应用于6个流行的基准测试，并用它来评估18个公开权重的大型语言模型。相对于原始数据集版本，模型的性能平均下降了12.1个点。当在3个MMLU数据集上使用链式思维时，WiCkeD变体的性能下降与直接使用大型语言模型时观察到的下降类似，表明WiCkeD对于具有增强推理能力的模型也是具有挑战性的。WiCkeD还揭示了一些模型对额外推理需求更为敏感，提供了相对于原始基准测试的额外信息。我们在这个网址发布了我们的代码和数据：\n\n作者：Ahmed Elhady, Eneko Agirre, Mikel Artetxe\n\n链接：https://arxiv.org/pdf/2502.18316.pdf",
        "地址": "https://arxiv.org/pdf/2502.18316.pdf"
    }
]