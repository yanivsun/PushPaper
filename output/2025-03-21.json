[
    {
        "名称": "2025 [2503.13358] One-Step Residual Shifting Diffusion for Image Super-Resolution via Distillation.pdf",
        "作者": "Daniil Selikhanovych, David Li, Aleksei Leonov, Nikita Gushchin, Sergei Kushneriuk, Alexander Filippov, Evgeny Burnaev, Iaroslav Koshelev, Alexander Korotin",
        "摘要": "摘要:扩散模型用于超分辨率（SR）可以生成高质量的视觉效果，但需要昂贵的计算成本。尽管已经开发了几种加速基于扩散的SR模型的方法，但一些方法（如SinSR）未能产生逼真的感知细节，而其他一些方法（如OSEDiff）可能会幻觉出不存在的结构。为了克服这些问题，我们提出了RSD，这是一种针对顶级基于扩散的SR模型ResShift的新蒸馏方法。我们的方法基于训练学生网络生成图像，以使得在这些图像上训练的新假ResShift模型与教师模型一致。RSD实现了单步恢复，并在很大程度上超越了教师模型。我们证明了我们的蒸馏方法可以超过其他基于蒸馏的ResShift方法——SinSR，使其与最新的基于扩散的SR蒸馏方法相提并论。与基于预训练文本到图像模型的SR方法相比，RSD在感知质量上具有竞争力，提供了与退化输入图像更好对齐的图像，且需要更少的参数和GPU内存。我们在各种现实世界和合成数据集上提供了实验结果，包括RealSR、RealSet65、DRealSR、ImageNet和DIV2K。",
        "地址": "https://arxiv.org/pdf/2503.13358.pdf"
    },
    {
        "名称": "2025 [2503.16419] Stop Overthinking: A Survey on Efficient Reasoning for Large Language Models.pdf",
        "作者": "Yang Sui, Yu-Neng Chuang, Guanchu Wang, Jiamu Zhang, Tianyi Zhang, Jiayi Yuan, Hongyi Liu, Andrew Wen, Shaochen (Henry)Zhong, Hanjie Chen, Xia Hu",
        "摘要": "摘要: 大型语言模型（LLMs）在复杂任务中展示了显著的能力。最近，在大推理模型（LRMs）如OpenAI o1和DeepSeek-R1的研究进展中，通过利用有监督微调（SFT）和强化学习（RL）技术，加强了链式推理（CoT），进一步提升了在数学和编程等系统-2推理领域中的表现。然而，尽管较长的CoT推理序列提升了表现，但它们也因为冗长和冗余的输出（称为“过度思考现象”）而引入了显著的计算开销。本文首次提供了一个有结构的综述，系统地调查和探索了实现LLMs高效推理的当前进展。总体上，我们依靠LLMs的内在机制，将现有工作分类为几个关键方向：（1）基于模型的高效推理，考虑将完整长度推理模型优化为更简洁的推理模型或直接训练高效的推理模型；（2）基于推理输出的高效推理，旨在动态减少推理步骤和推理长度；（3）基于输入提示的高效推理，致力于根据输入提示的属性如难度或长度控制来增强推理效率。此外，我们介绍了用于训练推理模型的高效数据，探索了小型语言模型的推理能力，并讨论了评估方法和基准测试。",
        "地址": "https://arxiv.org/pdf/2503.16419.pdf"
    },
    {
        "名称": "2025 [2503.16416] Survey on Evaluation of LLM-based Agents.pdf",
        "作者": "Asaf Yehudai, Lilach Eden, Alan Li, Guy Uziel, Yilun Zhao, Roy Bar-Haim, Arman Cohan, Michal Shmueli-Scheuer",
        "摘要": "摘要：基于大型语言模型（LLM）的智能体的出现代表了人工智能领域的范式转变，使得自主系统能够在与动态环境交互的过程中进行规划、推理、使用工具和保持记忆。本文首次全面调查了这些日益强大的智能体的评估方法。我们系统地分析了在四个重要维度上的评估基准和框架：(1) 基础智能体能力，包括规划、工具使用、自我反思和记忆；(2) 针对网络、软件工程、科学和对话智能体的特定应用基准；(3) 通用智能体的评估基准；(4) 用于评估智能体的框架。我们的分析揭示了新兴趋势，包括向更现实、更具挑战性的评估转变，同时不断更新基准。我们还确定了未来研究必须解决的重要 gaps，特别是在评估成本效益、安全性和鲁棒性，以及开发精细和可扩展的评估方法方面。该调查绘制了智能体评估领域快速演变的图景，揭示了该领域的新兴趋势，确定了当前的局限性，并提出了未来研究的方向。\n\n翻译：\n基于大型语言模型（LLM）的智能体的出现代表了人工智能领域的范式转变，使得自主系统能够在与动态环境交互的过程中进行规划、推理、使用工具和保持记忆。本文首次全面调查了这些日益强大的智能体的评估方法。我们系统地分析了在四个重要维度上的评估基准和框架：(1) 基础智能体能力，包括规划、工具使用、自我反思和记忆；(2) 针对网络、软件工程、科学和对话智能体的特定应用基准；(3) 通用智能体的评估基准；(4) 用于评估智能体的框架。我们的分析揭示了新兴趋势，包括向更现实、更具挑战性的评估转变，同时不断更新基准。我们还确定了未来研究必须解决的重要 gaps，特别是在评估成本效益、安全性和鲁棒性，以及开发精细和可扩展的评估方法方面。该调查绘制了智能体评估领域快速演变的图景，揭示了该领域的新兴趋势，确定了当前的局限性，并提出了未来研究的方向。",
        "地址": "https://arxiv.org/pdf/2503.16416.pdf"
    },
    {
        "名称": "2025 [2503.16302] Unleashing Vecset Diffusion Model for Fast Shape Generation.pdf",
        "作者": "Zeqiang Lai, Yunfei Zhao, Zibo Zhao, Haolin Liu, Fuyun Wang, Huiwen Shi, Xianghui Yang, Qinxiang Lin, Jinwei Huang, Yuhong Liu, Jie Jiang, Chunchao Guo, Xiangyu Yue",
        "摘要": "摘要: 通过开发所谓的“原生”3D扩散，特别是通过Vecset扩散模型（VDM），3D形状生成得到了极大的发展。尽管最近的进展在生成高分辨率3D形状方面显示出令人鼓舞的成果，但VDM在高速生成方面仍然存在困难。这不仅是因为加速扩散采样存在挑战，还因为VDM中的VAE解码也是前期工作中未充分探讨的领域。为了应对这些挑战，我们提出了FlashVDM，这是一个加速VDM中VAE和DiT的系统框架。对于DiT，FlashVDM通过我们新引入的渐进流蒸馏（Progressive Flow Distillation）稳定一致性蒸馏，从而实现了灵活的扩散采样，推理步骤少至5步且质量可比。对于VAE，我们引入了一个配备有自适应KV选择、分层体积解码和高效网络设计的高速vecset解码器。通过利用vecset的局部性和体积中形状表面的稀疏性，我们的解码器大幅降低了计算复杂度，最小化了解码开销。我们将FlashVDM应用于Hunyuan3D-2，获得了Hunyuan3D-2 Turbo。通过系统评估，我们展示了我们的模型显著优于现有的快速3D生成方法，在重建和生成的推理时间上分别减少了超过45倍和32倍的同时，达到了与最先进方法相当的性能。代码和模型可在此https URL获取。\n\n作者: Zeqiang Lai, Yunfei Zhao, Zibo Zhao, Haolin Liu, Fuyun Wang, Huiwen Shi, Xianghui Yang, Qinxiang Lin, Jinwei Huang, Yuhong Liu, Jie Jiang, Chunchao Guo, Xiangyu Yue",
        "地址": "https://arxiv.org/pdf/2503.16302.pdf"
    },
    {
        "名称": "2025 [2503.16397] Scale-wise Distillation of Diffusion Models.pdf",
        "作者": "Nikita Starodubcev, Denis Kuznedelev, Artem Babenko, Dmitry Baranchuk",
        "摘要": "摘要：我们提出了SwD，一种用于扩散模型（DMs）的尺度蒸馏框架，它有效地利用了基于扩散的少步生成器的下一个尺度预测理念。更具体地说，SwD受到最近将扩散过程与隐式频谱自回归相关的见解的启发。我们假设DMs可以在较低的数据分辨率下启动生成，并在每个去噪步骤逐步放大样本，而不会影响性能，同时显著降低计算成本。SwD自然地将这一理念整合到现有的基于分布匹配的扩散蒸馏方法中。此外，我们通过引入一种新的补丁损失来丰富分布匹配方法家族，以增强与目标分布的细粒度相似性。当应用于最先进的文本到图像扩散模型时，SwD达到了两次全分辨率步骤的推理时间，并且在人为偏好研究和自动化指标中，均显著优于相同计算预算下的对手。",
        "地址": "https://arxiv.org/pdf/2503.16397.pdf"
    },
    {
        "名称": "2025 [2503.14487] DiffMoE: Dynamic Token Selection for Scalable Diffusion Transformers.pdf",
        "作者": "Minglei Shi, Ziyang Yuan, Haotian Yang, Xintao Wang, Mingwu Zheng, Xin Tao, Wenliang Zhao, Wenzhao Zheng, Jie Zhou, Jiwen Lu, Pengfei Wan, Di Zhang, Kun Gai",
        "摘要": "摘要：扩散模型在各种图像生成任务中表现出显著成功，但其性能通常受到在不同条件和噪声水平下对输入进行统一处理的限制。为了解决这一限制，我们提出了一种新方法，利用扩散过程的内在异质性。我们的方法，DiffMoE，引入了批级全球令牌池，使专家在训练期间能够访问全球令牌分布，促进专业化专家行为。为了释放扩散过程的全部潜力，DiffMoE包含一个容量预测器，该预测器根据噪声水平和样本复杂性动态分配计算资源。通过综合评估，DiffMoE在ImageNet基准上实现了扩散模型中的最先进性能，显著超越了具有3倍激活参数的密集架构和现有的MoE方法，而保持了1倍激活参数。我们的方法不仅在类条件生成方面表现出色，还扩展到更具挑战性的任务，例如文本到图像生成，展示了其在不同扩散模型应用中的广泛适用性。项目页面：此 https URL\n\n翻译：\n扩散模型在各种图像生成任务中表现出显著成功，但其性能通常受到对于在不同条件和噪声水平下输入的统一处理的限制。为了解决这一限制，我们提出了一种新方法，该方法利用扩散过程的内在异质性。我们的方法 DiffMoE 引入一个批次级的全球令牌池，使专家能够在训练期间访问全球令牌分布，从而促进专家行为的专业化。为了释放扩散过程的全部潜力，DiffMoE 融入了一个容量预测器，可以根据噪声水平和样本复杂性动态分配计算资源。通过全面评估，DiffMoE 在图像生成标准数据集 ImageNet 上达到了最新的技术水平，显著超过了具有3倍激活参数的密集架构和现有的 MoE 方法，同时保持了1倍激活参数。我们的方法不仅在类条件生成方面表现出色，还扩展到更具挑战性的任务，例如文本到图像生成，展示了其在不同扩散模型应用中的广泛适用性。项目页面：此 https URL",
        "地址": "https://arxiv.org/pdf/2503.14487.pdf"
    },
    {
        "名称": "2025 [2503.16365] JARVIS-VLA: Post-Training Large-Scale Vision Language Models to Play Visual Games with Keyboards and Mouse.pdf",
        "作者": "Muyao Li, Zihao Wang, Kaichen He, Xiaojian Ma, Yitao Liang",
        "摘要": "摘要: 近年来，在开放世界环境中基于动作的决策越来越受到关注。预训练于大规模网络数据集上的视觉语言动作 (VLA) 模型在决策任务中显示出了很大的潜力。然而，以往的研究主要集中于动作后训练，常常忽略了对基础模型本身的改进。针对这一问题，我们提出了一种新方法，即通过视觉和语言引导在自监督模式下优化视觉语言模型 (VLMs) 的“后训练动作算法”。这一改进增强了模型在世界知识、视觉识别和空间定位方面的能力。在上述后训练范式下，我们获得了第一个在Minecraft中能够依照人类指令完成超过1000种不同原子任务（包括制作、熔炼、烹饪、采矿和战斗）的VLA模型。我们的实验表明，相对于最佳代理基线，非轨迹任务的后训练带来了40%的显著提升。此外，我们的方法在Minecraft中超越了传统的模仿学习策略，实现了最先进的性能。我们已开源了代码、模型和数据集，以促进进一步的研究。项目页面可以在这个https URL中找到。\n\n作者: Muyao Li, Zihao Wang, Kaichen He, Xiaojian Ma, Yitao Liang\n\n评论: 22页，5幅图\n\n网址: https://arxiv.org/pdf/2503.16365.pdf\n\n标题: JARVIS-VLA: 后训练大规模视觉语言模型以使用键盘和鼠标玩视觉游戏",
        "地址": "https://arxiv.org/pdf/2503.16365.pdf"
    },
    {
        "名称": "2025 [2503.15558] Cosmos-Reason1: From Physical Common Sense To Embodied Reasoning.pdf",
        "作者": "NVIDIA: Alisson Azzolini, Hannah Brandon, Prithvijit Chattopadhyay, Huayu Chen, Jinju Chu, Yin Cui, Jenna Diamond, Yifan Ding, Francesco Ferroni, Rama Govindaraju, Jinwei Gu, Siddharth Gururani, Imad El Hanafi, Zekun Hao, Jacob Huffman, Jingyi Jin, Brendan Johnson, Rizwan Khan, George Kurian, Elena Lantz, Nayeon Lee, Zhaoshuo Li, Xuan Li, Tsung-Yi Lin, Yen-Chen Lin, Ming-Yu Liu, Andrew Mathau, Yun Ni, Lindsey Pavao, Wei Ping, David W. Romero, Misha Smelyanskiy, Shuran Song, Lyne Tchapmi, Andrew Z. Wang, Boxin Wang, Haoxiang Wang, Fangyin Wei, Jiashu Xu, Yao Xu, Xiaodong Yang, Zhuolin Yang, Xiaohui Zeng, Zhe Zhang",
        "摘要": "摘要：物理人工智能系统需要在物理世界中感知、理解并执行复杂的动作。在本文中，我们介绍了Cosmos-Reason1模型，这些模型可以理解物理世界并通过长链思维过程以自然语言生成适当的具身决策（例如，下一步行动）。我们首先定义了物理人工智能推理的关键能力，重点关注物理常识和具身推理。为了表示物理常识，我们使用了一个分层本体，它捕捉了关于空间、时间和物理学的基本知识。对于具身推理，我们依赖一个可以跨不同物理体现进行概括的二维本体。基于这些能力，我们开发了两个多模态大型语言模型，Cosmos-Reason1-8B和Cosmos-Reason1-56B。我们整理了数据并在四个阶段对我们的模型进行训练：视觉预训练，一般监督微调（SFT），物理人工智能SFT和作为后训练的物理人工智能强化学习（RL）。为了评估我们的模型，我们根据我们的本体构建了物理常识和具身推理的综合基准。评估结果表明，物理人工智能SFT和强化学习带来了显著的改进。为了促进物理人工智能的发展，我们将在NVIDIA开放模型许可下公开我们的代码和预训练模型。",
        "地址": "https://arxiv.org/pdf/2503.15558.pdf"
    },
    {
        "名称": "2025 [2503.16257] Plug-and-Play 1.x-Bit KV Cache Quantization for Video Large Language Models.pdf",
        "作者": "Keda Tao, Haoxuan You, Yang Sui, Can Qin, Huan Wang",
        "摘要": "摘要: 视频大语言模型（VideoLLMs）已经展示了处理更长视频输入并进行复杂推理和分析的能力。然而，由于视频帧中的数千个视觉标记，键值（KV）缓存会显著增加内存需求，成为推理速度和内存使用的瓶颈。KV缓存量化是解决这个问题的广泛使用的方法。在本文中，我们发现将VideoLLMs的KV进行2位量化几乎不会损害模型性能，而对于更低位的KV缓存量化的极限还没有被研究过。为了弥补这一空白，我们提出了VidKV，这是一种即插即用的KV缓存量化方法，可以将KV缓存压缩到低于2位。具体来说，(1)对于键，我们在通道维度上提出了混合精度量化策略，对异常通道进行2位量化，对正常通道结合FFT进行1位量化；(2)对于值，我们实现了1.58位量化，同时选择性地过滤语义显著的视觉标记，以有针对性地保留，以更好地在精度和模型性能之间权衡。重要的是，我们的研究结果表明，VideoLLMs的值缓存应该按通道方式进行量化，而不是此前LLMs的KV缓存量化工作提出的按标记方式进行量化。实证方面，我们使用LLaVA-OV-7B和Qwen2.5-VL-7B在六个基准上进行了大量实验，结果表明VidKV能有效地将KV缓存压缩到1.5位和1.58位精度，与FP16版本相比，几乎没有性能下降。",
        "地址": "https://arxiv.org/pdf/2503.16257.pdf"
    },
    {
        "名称": "2025 [2503.16212] MathFusion: Enhancing Mathematic Problem-solving of LLM through Instruction Fusion.pdf",
        "作者": "Qizhi Pei, Lijun Wu, Zhuoshi Pan, Yu Li, Honglin Lin, Chenlin Ming, Xin Gao, Conghui He, Rui Yan",
        "摘要": "摘要: 大型语言模型（LLMs）在数学推理方面取得了令人瞩目的进展。尽管数据增强有望提升数学问题解决能力，但当前的方法主要局限于实例级修改，如改写或生成句法变体，这些方法未能捕捉和利用数学知识中固有的关系结构。受到人类学习过程中系统性接触相互关联概念的方式的启发，我们引入了MathFusion，这是一种通过跨问题指令合成来增强数学推理的新框架。MathFusion通过三种融合策略实现这一目标：(1) 顺序融合，通过链式相关问题来建立解题依赖；(2) 并行融合，结合类似问题以强化概念理解；(3) 条件融合，创建基于上下文的选择性问题以增强推理灵活性。通过应用这些策略，我们生成了一个新数据集MathFusionQA，并在其上对模型（DeepSeekMath-7B，Mistral-7B，Llama3-8B）进行微调。实验结果表明，MathFusion在保持高数据效率的同时，实现了数学推理的显著提升，在各类基准上性能提高了18.0个百分点，同时只需额外45K条合成指令，较传统的单指令方法有显著改进。我们的数据集、模型和代码均在此https URL公开。",
        "地址": "https://arxiv.org/pdf/2503.16212.pdf"
    },
    {
        "名称": "2025 [2503.13657] Why Do Multi-Agent LLM Systems Fail?.pdf",
        "作者": "Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, Kannan Ramchandran, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica",
        "摘要": "摘要：尽管对多智能体系统（MAS）的热情日益高涨，其中多个大规模语言模型（LLM）智能体协作完成任务，但在流行基准测试中的性能提升与单智能体框架相比仍然很小。这一差距突显了分析阻碍MAS有效性的挑战的必要性。本文展示了关于MAS挑战的首个全面研究。我们通过六位专家标注者对超过150个任务中的五个流行MAS框架进行分析，识别出14种独特的故障模式，并提出适用于各种MAS框架的全面分类法。此分类法通过每个研究中的三名专家标注者的一致意见迭代生成，达到0.88的Cohen's Kappa评分。这些细化的故障模式分为三个类别：（i）规格和系统设计故障，（ii）智能体之间的不一致，（iii）任务验证和终止。为了支持可扩展评估，我们将MASFT与LLM-as-a-Judge集成。我们还探讨了通过提出两项干预措施（改进智能体角色规范和增强编排策略）是否可以轻松预防发现的故障。我们的研究结果表明，发现的故障需要更复杂的解决方案，为未来研究明确了路线图。我们开放了数据集和LLM标注器的源代码。\n\n作者：Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, Kannan Ramchandran, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica\n\n链接：https://arxiv.org/pdf/2503.13657.pdf\n\n标题：2025 [2503.13657] 为什么多智能体LLM系统会失败？",
        "地址": "https://arxiv.org/pdf/2503.13657.pdf"
    },
    {
        "名称": "2025 [2503.16418] InfiniteYou: Flexible Photo Recrafting While Preserving Your Identity.pdf",
        "作者": "Liming Jiang, Qing Yan, Yumin Jia, Zichuan Liu, Hao Kang, Xin Lu",
        "摘要": "摘要：实现灵活且高保真度的身份保留图像生成仍然具有挑战性，特别是对于像FLUX这样的先进扩散变换器（Diffusion Transformers，DiTs）。我们引入了InfiniteYou（InfU），这是最早利用DiTs进行该任务的鲁棒框架之一。InfU解决了现有方法的重大问题，例如身份相似性不足、文本-图像对齐差、生成质量和美学低劣。InfU的核心组件是InfuseNet，它通过残差连接向DiT基础模型注入身份特征，在增强身份相似性的同时保持生成能力。多阶段训练策略，包括预训练和使用合成的单人多样本（synthetic single-person-multiple-sample，SPMS）数据进行监督微调（supervised fine-tuning，SFT），进一步改善了文本-图像对齐，提升了图像质量，并缓解了面部复制粘贴问题。大量实验证明，InfU达到了最先进的性能，超越了现有基准。此外，InfU的即插即用设计确保了与各种现有方法的兼容性，为更广泛的社区提供了有价值的贡献。",
        "地址": "https://arxiv.org/pdf/2503.16418.pdf"
    },
    {
        "名称": "2025 [2503.15299] Inside-Out: Hidden Factual Knowledge in LLMs.pdf",
        "作者": "Zorik Gekhman, Eyal Ben David, Hadas Orgad, Eran Ofek, Yonatan Belinkov, Idan Szpector, Jonathan Herzig, Roi Reichart",
        "摘要": "摘要: 本文提出了一种评估大型语言模型（LLMs）在其参数中是否比在其输出中表达更多事实知识的框架。虽然有少量研究暗示了这种可能性，但没有一项明确地定义或展示了这一现象。我们首先提出了一个知识的正式定义，通过给定问题的正确-错误答案对中正确答案的排名高低来量化它。这产生了外部和内部知识，这取决于用于评分单个答案候选项的信息：模型的可观察的标记级概率或其中间计算。当内部知识超过外部知识时，隐藏知识就出现了。然后我们进行了一项案例研究，在一个闭卷问答设置中将该框架应用于三个流行的开源权重LLMs。我们的结果表明：(1) LLMs的内部始终编码比外部表达更多的事实知识，平均差距为40%。(2) 令人惊讶的是，有些知识隐藏得如此之深，以至于一个模型内部可以完全知道答案，但即使在大规模重复采样1000次答案的情况下也未能生成答案。这揭示了LLMs在生成能力上的基本限制，这(3) 对通过闭卷问答中重复答案采样来扩展测试时计算量提出了实际约束：显著的性能改进仍不可达，因为一些答案实际上从未被采样到，但如果被采样到，我们将保证它们排名第一。\n\n论文链接：https://arxiv.org/pdf/2503.15299.pdf\n作者：Zorik Gekhman, Eyal Ben David, Hadas Orgad, Eran Ofek, Yonatan Belinkov, Idan Szpector, Jonathan Herzig, Roi Reichart\n标题：2025 [2503.15299] Inside-Out: Hidden Factual Knowledge in LLMs.pdf",
        "地址": "https://arxiv.org/pdf/2503.15299.pdf"
    },
    {
        "名称": "2025 [2503.16413] M3: 3D-Spatial MultiModal Memory.pdf",
        "作者": "Xueyan Zou, Yuchen Song, Ri-Zhao Qiu, Xuanbin Peng, Jianglong Ye, Sifei Liu, Xiaolong Wang",
        "摘要": "摘要：我们介绍了3D空间多模态记忆（M3），这是一种多模态记忆系统，旨在通过视频源保留中等大小静态场景的视觉感知信息。通过结合3D高斯散点技术与基础模型，M3构建了能够在不同粒度上渲染特征表示的多模态记忆，涵盖了广泛的知识。在研究中，我们发现之前特征散点工作中的两个关键挑战：(1) 在存储每个高斯基元的高维特征时的计算限制，以及 (2) 蒸馏特征和基础模型特征之间的错位或信息丢失。为了解决这些挑战，我们提出了M3，包含主要场景组件和高斯记忆注意的关键组件，从而实现高效的训练和推理。为了验证M3，我们进行了全面的定量评估，包括特征相似性和下游任务的评估，以及定性可视化，以突出高斯记忆注意的像素痕迹。我们的方法涵盖了各种基础模型，包括视觉-语言模型（VLMs）、感知模型和大型多模态和语言模型（LMMs/LLMs）。此外，为了展示其在现实世界中的应用性，我们在四足机器人上部署了M3的特征场景。值得注意的是，我们宣称M3是第一个解决了3D特征蒸馏核心压缩挑战的工作。",
        "地址": "https://arxiv.org/pdf/2503.16413.pdf"
    },
    {
        "名称": "2025 [2503.16356] CaKE: Circuit-aware Editing Enables Generalizable Knowledge Learners.pdf",
        "作者": "Yunzhi Yao, Jizhan Fang, Jia-Chen Gu, Ningyu Zhang, Shumin Deng, Huajun Chen, Nanyun Peng",
        "摘要": "摘要：知识编辑（Knowledge Editing，KE）使得在大型语言模型（LLMs）中修改过时或错误信息成为可能。尽管现有的KE方法可以更新孤立的事实，但它们难以将这些更新推广到依赖已修改知识的多跳推理任务。通过对推理电路（LLMs用于基于知识推理的神经路径）的分析，我们观察到当前层局部的KE方法，例如MEMIT和WISE，仅编辑单层或少数几层模型，难以有效地将更新信息整合到这些推理路径中。为了解决这一局限性，我们提出了CaKE（Circuit-aware Knowledge Editing），一种能够更有效地将更新知识整合到LLMs中的新方法。CaKE利用经过我们基于推理电路分析策略精心策划的数据，强制模型使用修改后的知识，促使模型为新整合的知识发展出适当的推理电路。实验结果表明，CaKE能够在相关推理任务中更准确和一致地使用更新知识，使得在MQuAKE数据集上的多跳推理准确性比现有KE方法平均提高20%。我们在https URL上发布了代码和数据。",
        "地址": "https://arxiv.org/pdf/2503.16356.pdf"
    },
    {
        "名称": "2025 [2503.16422] 1000+ FPS 4D Gaussian Splatting for Dynamic Scene Rendering.pdf",
        "作者": "Yuheng Yuan, Qiuhong Shen, Xingyi Yang, Xinchao Wang",
        "摘要": "摘要: 4D Gaussian Splatting (4DGS) 作为一种重建动态场景的方法，最近获得了相当大的关注。尽管其画质优越，但4DGS通常需要大量的存储空间，并且渲染速度也较慢。在这项工作中，我们深入探讨了这些问题，并确定了时间冗余的两个主要来源。(Q1) \\textbf{短生命周期的高斯函数}: 4DGS使用了大量短时间跨度的高斯函数来表示场景动态，导致高斯函数数量过多。(Q2) \\textbf{无效高斯函数}: 在渲染时，每帧只有少量高斯函数起作用。尽管如此，所有高斯函数在光栅化过程中都被处理，导致了计算的冗余。为了解决这些冗余问题，我们提出了\\textbf{4DGS-1K}，它在现代GPU上运行速度超过1000 FPS。针对Q1，我们引入了时空变化评分，这是一种新的修剪标准，能够有效去除短生命周期高斯函数，同时鼓励4DGS使用更长时间跨度的高斯函数来捕捉场景动态。针对Q2，我们为连续帧的活跃高斯函数存储了一个掩码，显著减少了渲染中的冗余计算。与原始4DGS相比，我们的方法在复杂动态场景中实现了$41\\\\times$的存储减少和$9\\\\times$的光栅化速度提升，同时保持了相当的视觉质量。请访问我们的项目页面（此HTTPS URL）以了解更多信息。",
        "地址": "https://arxiv.org/pdf/2503.16422.pdf"
    },
    {
        "名称": "2025 [2503.16420] SynCity: Training-Free Generation of 3D Worlds.pdf",
        "作者": "Paul Engstler, Aleksandar Shtedritski, Iro Laina, Christian Rupprecht, Andrea Vedaldi",
        "摘要": "摘要翻译如下：\n\n我们解决了从文本描述生成三维世界的挑战。我们提出了SynCity，这是一种无需训练和优化的方法，它利用预训练的三维生成模型的几何精度和二维图像生成器的艺术多样性来创建大型高质量的三维空间。尽管大多数三维生成模型是以对象为中心的，无法生成大规模的世界，但我们展示了如何将三维和二维生成器结合起来生成不断扩展的场景。通过基于瓦片的方法，我们可以对场景的布局和外观进行细粒度控制。世界是一块一块地生成，每个新瓦片在其世界上下文中生成，然后与场景融合。SynCity生成的场景引人入胜且身临其境，细节丰富，具有多样性。",
        "地址": "https://arxiv.org/pdf/2503.16420.pdf"
    },
    {
        "名称": "2025 [2503.16322] Ultra-Resolution Adaptation with Ease.pdf",
        "作者": "Ruonan Yu, Songhua Liu, Zhenxiong Tan, Xinchao Wang",
        "摘要": "摘要：近年来，文本生成图像的扩散模型取得了显著进展。然而，高分辨率图像生成模型的训练仍然具有挑战性，特别是当训练数据和计算资源有限时。在本文中，我们从数据和参数效率两个关键角度探讨这一实际问题，并提出了一套称为URAE的超分辨率适配关键指南。对于数据效率，我们从理论和实证上证明了一些教师模型生成的合成数据能够显著促进训练的收敛。在参数效率方面，我们发现，当合成数据不可用时，调整权重矩阵的次要组件比广泛使用的低秩适配器表现更好，在保持效率的同时提供显著的性能提升。此外，对于利用指导蒸馏的模型，例如FLUX，我们展示在适配过程中禁用无分类器指导（即将指导缩放设置为1）对于满意的性能至关重要。广泛的实验验证了URAE在仅有3000个样本和2000次迭代的情况下获得了与最先进的闭源模型如FLUX1.1 [Pro] Ultra相当的2K生成性能，同时为4K分辨率生成设定了新基准。代码可以在此处获取。\n\n翻译：近年来，文本生成图像的扩散模型取得了显著进展。然而，高分辨率图像生成模型的训练仍然具有挑战性，特别是当训练数据和计算资源有限时。在本文中，我们从数据和参数效率两个关键角度探讨这一实际问题，并提出了一套称为URAE的超分辨率适配关键指南。对于数据效率，我们从理论和实证上证明了一些教师模型生成的合成数据能够显著促进训练的收敛。在参数效率方面，我们发现，当合成数据不可用时，调整权重矩阵的次要组件比广泛使用的低秩适配器表现更好，在保持效率的同时提供显著的性能提升。此外，对于利用指导蒸馏的模型，例如FLUX，我们展示在适配过程中禁用无分类器指导（即将指导缩放设置为1）对于满意的性能至关重要。广泛的实验验证了URAE在仅有3000个样本和2000次迭代的情况下获得了与最先进的闭源模型如FLUX1.1 [Pro] Ultra相当的2K生成性能，同时为4K分辨率生成设定了新基准。代码可以在此处获取。",
        "地址": "https://arxiv.org/pdf/2503.16322.pdf"
    },
    {
        "名称": "2025 [2503.16057] Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts.pdf",
        "作者": "Yike Yuan, Ziyu Wang, Zihao Huang, Defa Zhu, Xun Zhou, Jingyi Yu, Qiyang Min",
        "摘要": "摘要：扩散模型已成为视觉生成领域的主流框架。在此成功的基础上，集成专家混合（Mixture of Experts，MoE）方法已显示出在提高模型可扩展性和性能方面的潜力。本文介绍了Race-DiT，一种用于扩散变换器的具有灵活路由策略Expert Race的新型MoE模型。通过允许令牌与专家一起竞争并选择最佳候选，模型可以动态地分配关键令牌给专家。此外，我们提出了每层正则化以应对浅层学习中的挑战，并提出了路由器相似性损失以防止模式崩溃，确保更好的专家利用。在ImageNet上的大量实验验证了我们方法的有效性，展示了显著的性能提升以及良好的扩展性。\n\n作者：Yike Yuan, Ziyu Wang, Zihao Huang, Defa Zhu, Xun Zhou, Jingyi Yu, Qiyang Min \n\nURL链接：[https://arxiv.org/pdf/2503.16057.pdf](https://arxiv.org/pdf/2503.16057.pdf)\n\n标题：2025 [2503.16057] Expert Race: A Flexible Routing Strategy for Scaling Diffusion Transformer with Mixture of Experts",
        "地址": "https://arxiv.org/pdf/2503.16057.pdf"
    },
    {
        "名称": "2025 [2503.16428] XAttention: Block Sparse Attention with Antidiagonal Scoring.pdf",
        "作者": "Ruyi Xu, Guangxuan Xiao, Haofeng Huang, Junxian Guo, Song Han",
        "摘要": "摘要：长上下文Transformer模型（LCTM）对现实世界的应用至关重要，但其因注意力机制的平方复杂性而导致计算成本过高。块稀疏注意力通过将计算集中在关键区域缓解了这一问题，但现有方法由于块重要性测量代价高昂，在精度和效率之间难以平衡。在本文中，我们介绍了XAttention，这是一种即插即用的框架，通过使用稀疏注意力显著加速Transformer模型的长上下文推理。XAttention的关键创新点在于注意力矩阵中反对角线（即从左下到右上）的值之和提供了块重要性的强大代理。这使得能够精确识别和修剪非必要块，从而实现高稀疏性和显著加速的推理。在包括RULER和LongBench语言基准测试、VideoMME视频理解和VBench视频生成等要求苛刻的长上下文基准测试中的全面评估中，XAttention在实现与全注意力相当的精度的同时，提供了显著的计算增益。我们展示了注意力计算速度最高可加速13.5倍。这些结果强调了XAttention解锁块稀疏注意力的实际潜力，为LCTM在实际应用中的可扩展和高效部署铺平了道路。代码可以在此链接获取: https://arxiv.org/pdf/2503.16428.pdf。",
        "地址": "https://arxiv.org/pdf/2503.16428.pdf"
    },
    {
        "名称": "2025 [2503.16425] Tokenize Image as a Set.pdf",
        "作者": "Zigang Geng, Mengde Xu, Han Hu, Shuyang Gu",
        "摘要": "摘要：本文提出了一种通过基于集合的标记化和分布建模进行图像生成的全新范式。与将图像序列化为具有统一压缩率的固定位置潜在代码的常规方法不同，我们引入了一种无序标记集表示，以根据区域语义复杂性动态分配编码容量。此TokenSet增强了全局上下文聚合，并提高了对局部扰动的鲁棒性。为了解决离散集建模的关键挑战，我们设计了一种双重变换机制，可以双射地将集合转换为具有总和约束的固定长度整数序列。此外，我们提出了Fixed-Sum Discrete Diffusion——第一个同时处理离散值、固定序列长度和总和不变性的框架，从而实现有效的集合分布建模。实验表明，我们的方法在语义感知表示和生成质量方面具有优势。我们的创新，涵盖了新的表示和建模策略，推动了视觉生成超越传统的顺序标记范式。我们的代码和模型在此HTTPS URL上公开可用。\n\n作者：Zigang Geng, Mengde Xu, Han Hu, Shuyang Gu\n\nURL：https://arxiv.org/pdf/2503.16425.pdf\n\n标题：2025 [2503.16425] 将图像标记化为集合.pdf",
        "地址": "https://arxiv.org/pdf/2503.16425.pdf"
    },
    {
        "名称": "2025 [2503.16421] MagicMotion: Controllable Video Generation with Dense-to-Sparse Trajectory Guidance.pdf",
        "作者": "Quanhao Li, Zhen Xing, Rui Wang, Hui Zhang, Qi Dai, Zuxuan Wu",
        "摘要": "摘要：近期视频生成领域的进展显著提高了视觉质量和时间一致性。在此基础上，可控轨迹的视频生成技术应运而生，使得通过明确定义的空间路径对物体运动进行精确控制成为可能。然而，现有方法在复杂物体运动和多物体运动控制方面存在困难，导致轨迹遵循不精确、物体一致性差以及视觉质量受损。此外，这些方法仅支持单一格式的轨迹控制，限制了其在不同场景中的适用性。此外，目前没有专门为轨迹可控视频生成量身定制的公开数据集或基准，阻碍了稳健训练和系统评估。为了应对这些挑战，我们提出了MagicMotion，这是一种新颖的图像到视频生成框架，通过从密到稀三个级别的条件来实现轨迹控制：掩码、边界框和稀疏框。给定输入图像和轨迹，MagicMotion可以无缝地沿定义的轨迹动画化对象，同时保持对象一致性和视觉质量。此外，我们还提出了MagicData，一个大规模轨迹控制的视频数据集，并配有自动化的注释和筛选流程。我们还引入了MagicBench，这是一个全面的基准，评估不同数量对象的视觉质量和轨迹控制精度。大量实验表明，MagicMotion在各种指标上均优于以往的方法。我们的项目页面可通过此链接公开访问。\n\n链接：https://arxiv.org/pdf/2503.16421.pdf",
        "地址": "https://arxiv.org/pdf/2503.16421.pdf"
    },
    {
        "名称": "2025 [2503.16252] Fin-R1: A Large Language Model for Financial Reasoning through Reinforcement Learning.pdf",
        "作者": "Zhaowei Liu, Xin Guo, Fangqi Lou, Lingfeng Zeng, Jinyi Niu, Zixuan Wang, Jiajie Xu, Weige Cai, Ziwei Yang, Xueqian Zhao, Chao Li, Sheng Xu, Dezhi Chen, Yun Chen, Zuo Bai, Liwen Zhang",
        "摘要": "摘要翻译如下：\n\n摘要：大型语言模型在各个领域迅速发展。然而，它们在处理复杂金融任务方面的能力仍需深入探索。在本文中，我们介绍了一种专为金融领域设计的推理大型语言模型 Fin-R1。Fin-R1 基于 DeepSeek-R1，通过双阶段架构构建，利用一个经过提炼和处理的金融推理数据集。通过监督微调（SFT）和强化学习（RL）训练，Fin-R1 在一系列金融推理任务中表现出接近 DeepSeek-R1 的性能，参数规模为 70 亿。它在我们评估的 FinQA 和 ConvFinQA 任务中达到了最先进水平（SOTA），在其他任务中也超越了更大的模型。Fin-R1 展示了强大的推理和决策能力，能够为金融领域中遇到的各种问题提供解决方案。我们的代码可在此 https URL 获取。",
        "地址": "https://arxiv.org/pdf/2503.16252.pdf"
    },
    {
        "名称": "2025 [2503.16219] Reinforcement Learning for Reasoning in Small LLMs: What Works and What Doesn't.pdf",
        "作者": "Quy-Anh Dang, Chris Ngo",
        "摘要": "摘要: 增强大型语言模型（LLMs）的推理能力通常依赖于大量计算资源和广泛的数据集，这限制了资源受限环境的可访问性。我们的研究探讨了强化学习（RL）在提高小型LLMs推理能力方面的潜力，重点研究一个拥有15亿参数的模型——DeepSeek-R1-Distill-Qwen-1.5B，在严格的限制条件下：在4个NVIDIA A40 GPU（每个48GB VRAM）的环境中，24小时内进行训练。通过调整群体相对策略优化（GRPO）算法并策划一个紧凑的高质量数学推理数据集，我们进行了三个实验以探索模型行为和性能。我们的结果展示了快速的推理提升——例如，AMC23准确率从63%上升到80%，AIME24达到46.7%，超越了o1-preview——仅使用7000个样本和42美元的训练成本，相比之下基线模型需要数千美元。然而，随着训练时间的延长，优化不稳定性和长度约束等挑战也随之出现。这些发现突显了基于RL的微调对于小型LLMs的有效性，提供了一种成本效益高的替代大型化方法。我们将我们的代码和数据集作为开源资源发布，提供了对权衡的见解，并为资源受限环境中的可扩展、有推理能力的LLMs奠定了基础。所有资源均可在此网址获取。",
        "地址": "https://arxiv.org/pdf/2503.16219.pdf"
    },
    {
        "名称": "2025 [2503.16055] SALT: Singular Value Adaptation with Low-Rank Transformation.pdf",
        "作者": "Abdelrahman Elsayed, Sarim Hashmi, Mohammed Elseiagy, Hu Wang, Mohammad Yaqub, Ibrahim Almakky",
        "摘要": "摘要: 医学图像分割的复杂性要求模型设计要能够捕捉详细的、领域特定的特征。大型基础模型具有相当的灵活性，但微调这些模型的代价仍然是一个显著的障碍。参数高效微调（PEFT）方法，如低秩适应（LoRA），通过低秩矩阵有效更新模型权重，但如果选择的秩不足以捕捉领域特定的细微差别，则可能会出现欠拟合。相反，基于满秩奇异值分解（SVD）的方法通过修改所有奇异值提供全面更新，然而这些方法通常缺乏灵活性并且在不同数据集上的表现不一致。我们提出了一种方法SALT（奇异值适应与低秩转换），该方法利用可训练的缩放和移位参数有选择地适应最具影响力的奇异值，同时对其余子空间进行低秩更新。这种混合方法利用了LoRA和SVD的优势，能够在不增加模型大小或深度的情况下实现有效的适应。我们在5个具有挑战性的医学数据集上进行了评估，样本数从20到1000不等，SALT在Dice系数上比最先进的PEFT方法（LoRA和SVD）高出2%到5%，且仅有3.9%的可训练参数，展示了即使在低资源环境下也具备强大的适应能力。SALT的代码可在以下链接获得：https://arxiv.org/pdf/2503.16055.pdf\n\n作者: Abdelrahman Elsayed, Sarim Hashmi, Mohammed Elseiagy, Hu Wang, Mohammad Yaqub, Ibrahim Almakky",
        "地址": "https://arxiv.org/pdf/2503.16055.pdf"
    },
    {
        "名称": "2025 [2503.15242] BigO(Bench) -- Can LLMs Generate Code with Controlled Time and Space Complexity?.pdf",
        "作者": "Pierre Chambon, Baptiste Roziere, Benoit Sagot, Gabriel Synnaeve",
        "摘要": "摘要：我们介绍了BigO(Bench)，一个新颖的编码基准，用于评估生成语言模型在理解和生成具有特定时间和空间复杂性的代码方面的能力。这个基准测试解决了当前评估中通常忽略模型理解和生成受计算复杂性约束的代码的能力的空白。BigO(Bench)包括工具，可以根据分析测量推断任何Python函数的算法复杂性，包括人类或LLM生成的解决方案。BigO(Bench)还包括一组3,105个编码问题和1,190,250个从编码竞赛中带有推断（合成）时间和空间复杂性标签的解决方案，以及相应的大输入规模的运行时和内存占用值。我们展示了在此基准测试中评估多个最先进的语言模型的结果，强调了它们在处理复杂性需求方面的优势和劣势。特别是，token-space推理模型在代码生成方面无与伦比，但在复杂性理解方面却不尽如人意，暗示它们可能无法很好地推广到训练时未给出奖励的任务。\n\n作者：Pierre Chambon, Baptiste Roziere, Benoit Sagot, Gabriel Synnaeve\n\n网址：https://arxiv.org/pdf/2503.15242.pdf\n\n标题：2025 [2503.15242] BigO(Bench) -- LLM能否生成具有受控时间和空间复杂性的代码？",
        "地址": "https://arxiv.org/pdf/2503.15242.pdf"
    },
    {
        "名称": "2025 [2503.10625] LHM: Large Animatable Human Reconstruction Model from a Single Image in Seconds.pdf",
        "作者": "Lingteng Qiu, Xiaodong Gu, Peihao Li, Qi Zuo, Weichao Shen, Junfei Zhang, Kejie Qiu, Weihao Yuan, Guanying Chen, Zilong Dong, Liefeng Bo",
        "摘要": "摘要：从单张图像进行可动画的3D人体重建由于在解耦几何、外观和变形方面的模糊性，是一个具有挑战性的问题。近期3D人体重建的进展主要集中在静态人体建模，且依赖于合成的3D扫描进行训练，这限制了它们的泛化能力。相比之下，基于优化的视频方法虽然在真实感上表现更好，但需要受控的捕捉条件和计算密集的优化过程。受到大规模静态重建模型高效性的启发，我们提出了LHM（大规模可动画人体重建模型），通过一次前馈传递推理出由3D高斯点表示的高保真虚拟人物。我们的模型利用了多模态变压器架构，有效地将人体位置特征和图像特征通过注意机制进行编码，从而详细保留了衣物的几何和纹理。为了进一步提升面部身份保留和细节恢复，我们提出了一种头部特征金字塔编码方案，以聚合头部区域的多尺度特征。大量实验证明确我们的方法在无需后期处理的情况下，在几秒内生成逼真的可动画人物，在重建精度和泛化能力上均超越现有方法。",
        "地址": "https://arxiv.org/pdf/2503.10625.pdf"
    },
    {
        "名称": "2025 [2503.16375] NuiScene: Exploring Efficient Generation of Unbounded Outdoor Scenes.pdf",
        "作者": "Han-Hung Lee, Qinghong Han, Angel X. Chang",
        "摘要": "摘要：在本文中，我们探索了生成广阔的户外场景的任务，场景范围从城堡到高层建筑。与之前工作主要关注的室内场景生成不同，户外场景生成提出了独特的挑战，包括场景高度的巨大变化以及需要一种能够快速生成大型景观的方法。为了解决这个问题，我们提出了一种高效的方法，将场景块编码为统一的矢量集，提供比先前方法中使用的空间结构潜变量更好的压缩和性能。此外，我们训练了一个显式扩展模型用于无边界生成，与先前基于重采样的图像修补方案相比，该模型改善了连贯性，同时由于消除了额外的扩散步骤而加快了生成速度。为了促进这一任务的完成，我们整理了NuiScene43，这是一个小但高质量的场景集，经过预处理以进行联合训练。值得注意的是，当在风格各异的场景上进行训练时，我们的模型能够在同一场景中融合不同的环境，例如乡村房屋和城市摩天大楼，凸显了我们的整理过程在联合训练中利用异质场景的潜力。",
        "地址": "https://arxiv.org/pdf/2503.16375.pdf"
    },
    {
        "名称": "2025 [2503.15567] Towards Unified Latent Space for 3D Molecular Latent Diffusion Modeling.pdf",
        "作者": "Yanchen Luo, Zhiyuan Liu, Yi Zhao, Sihang Li, Kenji Kawaguchi, Tat-Seng Chua, Xiang Wang",
        "摘要": "摘要：3D分子生成在药物发现和材料科学中至关重要，要求模型处理包括原子类型、化学键和3D坐标在内的复杂多模态。一个关键挑战是结合这些不同形状的模态，同时保持3D坐标的SE(3)等变性。为了实现这一目标，现有方法通常为不变和等变模态保持独立的潜在空间，从而降低了训练和采样效率。在这项工作中，我们提出了统一的变分自编码器（UAE-3D），用于3D分子的潜在扩散建模。该多模态VAE将3D分子压缩到统一潜在空间中的潜在序列，同时保持接近零的重构误差。这个统一的潜在空间排除了在执行潜在扩散建模时处理多模态和等变的复杂性。我们通过采用Diffusion Transformer证明了这一点，这是一个不具有分子归纳偏差的通用扩散模型，用于潜在生成。在GEOM-Drugs和QM9数据集上进行的大量实验表明，我们的方法在初始和条件3D分子生成方面显著建立了新的基准，达到了领先的效率和质量。\n\n作者：罗彦辰，刘志远，赵毅，李思航，川口健二，蔡达成，王翔\n\nURL：https://arxiv.org/pdf/2503.15567.pdf\n\n标题：Towards Unified Latent Space for 3D Molecular Latent Diffusion Modeling",
        "地址": "https://arxiv.org/pdf/2503.15567.pdf"
    },
    {
        "名称": "2025 [2503.13356] Agents Play Thousands of 3D Video Games.pdf",
        "作者": "Zhongwen Xu, Xianliang Wang, Siyi Li, Tao Yu, Liang Wang, Qiang Fu, Wei Yang",
        "摘要": "摘要：我们提出了PORTAL，一种全新的框架，用于开发能够通过语言引导策略生成来玩成千上万个3D视频游戏的人工智能代理。通过将决策问题转化为语言建模任务，我们的方法利用大型语言模型（LLMs）生成以领域特定语言（DSL）表示的行为树。这种方法消除了与传统强化学习方法相关的计算负担，同时保留了策略深度和快速适应性。我们的框架引入了一种混合策略结构，将基于规则的节点与神经网络组件相结合，从而实现高层次的战略推理和精确的低层控制。一个结合定量游戏指标和视觉-语言模型分析的双反馈机制，促进了在战术和战略层面的迭代策略改进。生成的策略可即时部署、人类可解释，并能够在不同的游戏环境中进行泛化。实验结果证明了PORTAL在成千上万个第一人称射击（FPS）游戏中的有效性，展现了与传统方法相比在开发效率、策略泛化和行为多样性方面的显著改进。PORTAL在游戏AI开发方面取得了重大进展，为创建能够在成千上万个商业视频游戏中操作的复杂代理提供了一个实用的解决方案。3D视频游戏的实验结果可通过此https网址查看。\n\n作者：许忠文、王显良、李思怡、于涛、王亮、付强、杨伟\n\n链接：https://arxiv.org/pdf/2503.13356.pdf\n\n标题：2025 [2503.13356] 代理玩成千上万个3D视频游戏.pdf",
        "地址": "https://arxiv.org/pdf/2503.13356.pdf"
    },
    {
        "名称": "2025 [2503.16278] Uni-3DAR: Unified 3D Generation and Understanding via Autoregression on Compressed Spatial Tokens.pdf",
        "作者": "Shuqi Lu, Haowei Lin, Lin Yao, Zhifeng Gao, Xiaohong Ji, Weinan E, Linfeng Zhang, Guolin Ke",
        "摘要": "摘要：最近在大型语言模型及其多模态扩展方面的进展展示了通过自回归下一词预测统一生成和理解的有效性。然而，尽管在科学领域AI中3D结构生成和理解（3D GU）任务具有关键作用，这些任务在很大程度上是独立发展的，并且自回归方法仍然鲜有探索。为弥合这一差距，我们引入了Uni-3DAR，一个通过自回归预测无缝整合3D GU任务的统一框架。Uni-3DAR的核心是采用一种新颖的分层标记法，利用八叉树压缩3D空间，利用3D结构的固有稀疏性，然后应用额外的标记法来捕获精细的结构细节，包括原子类型和微观3D结构的精确空间坐标。我们进一步提出了两种优化以提高效率和效果。第一种是两级子树压缩策略，将八叉树标记序列减少多达8倍。第二种是动态变化标记位置的掩蔽下一词预测机制，显著提升了模型性能。通过结合这些策略，Uni-3DAR成功地在单一自回归框架中统一了各种3D GU任务。跨多个微观3D GU任务（包括分子、蛋白质、聚合物和晶体）的广泛实验验证了其有效性和多功能性。值得注意的是，Uni-3DAR大大超越了以前的最先进扩散模型，取得了高达256%的相对改进，同时推理速度提升了多达21.8倍。代码公开可用，网址为此https URL。",
        "地址": "https://arxiv.org/pdf/2503.16278.pdf"
    },
    {
        "名称": "2025 [2503.16188] CLS-RL: Image Classification with Rule-Based Reinforcement Learning.pdf",
        "作者": "Ming Li, Shitian Zhao, Jike Zhong, Yuxiang Lai, Kaipeng Zhang",
        "摘要": "摘要：分类是机器学习中的核心任务。最近的研究表明，尽管多模态大语言模型（MLLM）起初在图像分类方面表现不佳，但通过足够的数据进行微调可以显著提升其性能，使其与最新的分类模型相媲美。然而，获取大规模标注数据的成本昂贵。在本文中，我们探索了少样本MLLM分类微调。我们发现，少样本微调（SFT）会导致严重的过拟合问题，甚至可能使性能低于零样本方法。为了解决这一挑战，受基于规则的强化学习最近成功的启发，我们提出了CLS-RL，它使用可验证的信号作为奖励来微调MLLM。我们发现CLS-RL在大多数数据集上表现优于SFT，在基础到新颖和少样本学习设置中具有更高的平均准确度。此外，我们观察到CLS-RL存在一个“免费午餐”现象；即使在特定数据集上微调模型，其在其他不同数据集上的表现也可能比零样本模型有显著改善，即使这些数据集在分布和类名上有所不同。这表明基于强化学习的方法能够有效地教会模型分类的基础知识。最后，受推理时间思维过程最近研究的启发，我们在视觉分类的背景下重新审视微调期间的“思维过程”，质疑此类任务是否需要在微调期间进行广泛的思考过程，并提出这可能实际上有损性能。在此基础上，我们介绍了No-Thinking-CLS-RL方法，通过设置一个等式准确度奖励来最小化训练期间的思维过程。我们的研究表明，No-Thinking-CLS-RL方法的微调时间更少，但其域内性能和泛化能力优于CLS-RL。\n\n(原文链接：https://arxiv.org/pdf/2503.16188.pdf)",
        "地址": "https://arxiv.org/pdf/2503.16188.pdf"
    },
    {
        "名称": "2025 [2503.15851] Zero-1-to-A: Zero-Shot One Image to Animatable Head Avatars Using Video Diffusion.pdf",
        "作者": "Zhou Zhenglin, Ma Fan, Fan Hehe, Chua Tat-Seng",
        "摘要": "摘要：动画头部头像的生成通常需要大量数据进行训练。为了减少数据需求，一个自然的解决方案是利用现有的无数据静态头像生成方法，例如带有得分蒸馏采样（SDS）的预训练扩散模型，这些方法会将生成的头像与扩散模型的伪真实输出对齐。然而，直接从视频扩散中提取4D头像常常会因为生成视频中的空间和时间不一致性而导致结果过于平滑。为了解决这个问题，我们提出了Zero-1-to-A，这是一种稳健的方法，使用视频扩散模型合成一个空间和时间一致性的数据集，用于4D头像重建。具体来说，Zero-1-to-A以迭代方式构建视频数据集，并以渐进的方式优化动画头像，确保头像质量在学习过程中平稳一致地提高。这种渐进学习涉及两个阶段：（1）空间一致性学习，在前视到侧视过程中固定表情进行学习；（2）时间一致性学习，在从放松到夸张的表情过程中固定视角进行学习，以简单到复杂的方式生成4D头像。大量实验证明，与现有的基于扩散的方法相比，Zero-1-to-A在逼真度、动画质量和渲染速度方面都有所提高，为逼真的头像创建提供了一个解决方案。代码已公开发布，网址为：this https URL。",
        "地址": "https://arxiv.org/pdf/2503.15851.pdf"
    },
    {
        "名称": "2025 [2503.14237] Make Your Training Flexible: Towards Deployment-Efficient Video Models.pdf",
        "作者": "Chenting Wang, Kunchang Li, Tianxiang Jiang, Xiangyu Zeng, Yi Wang, Limin Wang",
        "摘要": "摘要：流行的视频训练方法主要在从预定的时空网格中采样的固定数量的标记上运行，由于固有的视频冗余，导致了次优的精度计算权衡。它们还缺乏对下游任务中可变计算预算的适应性，阻碍了最具竞争力的模型在现实场景中的应用。因此，我们提出了一个新的测试设置，即标记优化，用于跨预算最大化输入信息，通过从更适宜采样的视频中选择标记来优化大小有限的输入标记集。为此，我们提出了一种新的增强工具，称为Flux。通过使采样网格灵活并利用标记选择，它可以轻松应用于大多数流行的视频训练框架，几乎无需额外成本即可提高模型的鲁棒性。我们将Flux整合到大规模视频预训练中，所产生的FluxViT在标准成本下在广泛任务中建立了新的最先进成果。值得注意的是，仅用1/4的标记，利用标记优化就能匹敌之前最先进模型的性能，节省了近90%的成本。所有模型和数据均可在此https URL获取。",
        "地址": "https://arxiv.org/pdf/2503.14237.pdf"
    },
    {
        "名称": "2025 [2503.16429] Sonata: Self-Supervised Learning of Reliable Point Representations.pdf",
        "作者": "Xiaoyang Wu, Daniel DeTone, Duncan Frost, Tianwei Shen, Chris Xie, Nan Yang, Jakob Engel, Richard Newcombe, Hengshuang Zhao, Julian Straub",
        "摘要": "摘要：在这篇文章中，我们探讨了是否可以通过简单的线性探测，在使用有限数据和最小计算的情况下获得可靠的自监督点云模型，从而适用于多种3D任务。我们发现，现有的3D自监督学习方法在通过线性探测评估表示质量时表现不佳。我们假设这是由于我们称之为“几何捷径”的现象，它导致表示退化为低级空间特征。这一挑战对3D特有，源于点云数据的稀疏性。我们通过两种关键策略解决这个问题：模糊空间信息和增强对输入特征的依赖，最终通过自我蒸馏生成了一个由14万个点组成的Sonata点云集。Sonata简单直观，但其学习到的表示强大且可靠：零样本可视化展示了语义分组，同时通过最近邻关系表现出强大的空间推理能力。Sonata展示了卓越的参数和数据效率，在ScanNet上的线性探测准确率提高了三倍（从21.8%提高到72.5%），在仅用1%数据的情况下性能几乎翻倍，超过了之前的方法。完全微调进一步推进了3D室内和室外感知任务的最新技术水平（SOTA）。\n\n翻译：摘要：本文探讨了是否能通过简单的线性探测获得可靠的自监督点云模型，即使在数据有限和计算最小化的情况下，依然可以适用于多种3D任务。我们发现，现有的3D自监督学习方法在通过线性探测评估表示质量时表现不佳。我们推测这是由于“几何捷径”现象，导致表示退化为低级空间特征。这一挑战对3D特有，因为点云数据的稀疏性。我们通过两种关键策略解决这一问题：模糊空间信息和增强对输入特征的依赖，最终通过自我蒸馏生成了一个有14万个点云的Sonata。Sonata简单直观，但其学习到的表示强大且可靠：零样本可视化展示了语义分组，并通过最近邻关系表现出强大的空间推理能力。Sonata展示了卓越的参数和数据效率，在ScanNet上的线性探测准确率提高了三倍（从21.8%提高到72.5%），在仅用1%数据的情况下性能几乎翻倍，超过了之前的方法。完全微调进一步推进了3D室内和室外感知任务的最新技术水平。",
        "地址": "https://arxiv.org/pdf/2503.16429.pdf"
    },
    {
        "名称": "2025 [2503.16031] Deceptive Humor: A Synthetic Multilingual Benchmark Dataset for Bridging Fabricated Claims with Humorous Content.pdf",
        "作者": "Sai Kartheek Reddy Kasu, Shankar Biradar, Sunil Saumya",
        "摘要": "摘要：本文介绍了Deceptive Humor Dataset (DHD)，这是一个用于研究源自虚假声明和错误信息的幽默内容的新颖资源。在信息泛滥的时代，理解幽默与欺骗的交织至关重要。DHD包含由虚假叙述生成的幽默评论，利用ChatGPT-4o模型融合了虚构声明和操控信息。每个实例都标有讽刺水平，范围从1的微妙讽刺到3的高级讽刺，并被分类为五个不同的幽默类别：黑色幽默、反讽、社会评论、文字游戏和荒诞。该数据集涵盖多种语言，包括英文、泰卢固语、印地语、卡纳达语、泰米尔语及其混合变体（Te-En、Hi-En、Ka-En、Ta-En），使其成为一个多语言基准。通过引入DHD，我们为分析欺骗性上下文中的幽默建立了结构化基础，开辟了一个新的研究方向，探索幽默如何与误信息互动并影响其感知和传播。我们为该数据集建立了强有力的基线，为未来的研究提供了基准，并推动欺骗性幽默检测模型的发展。",
        "地址": "https://arxiv.org/pdf/2503.16031.pdf"
    },
    {
        "名称": "2025 [2503.15451] MotionStreamer: Streaming Motion Generation via Diffusion-based Autoregressive Model in Causal Latent Space.pdf",
        "作者": "Lixing Xiao, Shunlin Lu, Huaijin Pi, Ke Fan, Liang Pan, Yueer Zhou, Ziyong Feng, Xiaowei Zhou, Sida Peng, Jingbo Wang",
        "摘要": "摘要：本文研究了与文本条件相关的流媒体动作生成这一难题，这需要我们根据可变长度的历史动作和输入文本预测下一步的人体姿态。现有方法在实现流媒体动作生成方面存在困难，例如，扩散模型受到预定义动作长度的限制，而基于GPT的方法由于离散化的非因果标记化问题会出现响应延迟和误差累积问题。为了解决这些问题，我们提出了MotionStreamer，这是一种新颖的框架，将连续的因果潜在空间引入到概率自回归模型中。连续的潜在变量减轻了离散化造成的信息丢失，并有效减少了长期自回归生成过程中的误差累积。此外，通过在当前和历史动作潜在变量之间建立时间因果依赖关系，我们的模型充分利用了可用的信息，实现了精确的在线动作解码。实验表明，我们的方法优于现有方法，同时还提供了更多的应用，包括多轮生成、长期生成和动态动作组合。\n\n项目页面：https://arxiv.org/pdf/2503.15451.pdf",
        "地址": "https://arxiv.org/pdf/2503.15451.pdf"
    },
    {
        "名称": "2025 [2503.12689] MagicID: Hybrid Preference Optimization for ID-Consistent and Dynamic-Preserved Video Customization.pdf",
        "作者": "Hengjia Li, Lifan Jiang, Xi Xiao, Tianyang Wang, Hongwei Yi, Boxi Wu, Deng Cai",
        "摘要": "摘要：视频身份定制旨在根据用户的参考图像生成高保真度的视频，这些视频在保持一致身份的同时展示出显著的动态。然而，现有的方法面临两个关键挑战：视频长度延长时身份退化以及训练过程中动态减少，主要原因在于它们依赖于静态图像的传统自重建训练。为了解决这些问题，我们引入了$\\\\textbf{MagicID}$，这是一个新颖的框架，旨在直接促进生成符合用户偏好的身份一致且动态丰富的视频。具体来说，我们提出构建具有明确身份和动态奖励的成对偏好视频数据以进行偏好学习，而不是坚持传统的自重建训练。为了解决定制偏好数据的限制，我们引入了一种混合采样策略。该方法首先利用来自参考图像的静态视频优先保持身份，然后通过基于Frontier的采样方法提高生成视频的动态运动质量。通过利用这些混合偏好对，我们优化模型以符合定制偏好的成对奖励差异。大量实验证明MagicID成功实现了身份一致性和自然动态，在各种指标上都超越了现有方法。",
        "地址": "https://arxiv.org/pdf/2503.12689.pdf"
    },
    {
        "名称": "2025 [2503.09949] UVE: Are MLLMs Unified Evaluators for AI-Generated Videos?.pdf",
        "作者": "Yuanxin Liu, Rui Zhu, Shuhuai Ren, Jiacong Wang, Haoyuan Guo, Xu Sun, Lu Jiang",
        "摘要": "摘要：随着视频生成模型（VGMs）的快速发展，开发可靠且全面的自动化指标来评估人工智能生成的视频（AIGVs）变得至关重要。现有的方法要么使用为其他任务优化的现成模型，要么依赖人工评估数据来训练专门的评估器。这些方法受限于特定的评估方面，难以应对对更细粒度和更全面评估的日益增长的需求。为了解决这个问题，本研究探讨了利用多模态大语言模型（MLLMs）作为统一的AIGV评估器的可行性，利用其强大的视觉感知和语言理解能力。为了评估自动化指标在统一AIGV评估中的表现，我们引入了一个名为UVE-Bench的基准。UVE-Bench收集了由最先进的VGMs生成的视频，并提供了15个评估方面的成对人工偏好注释。使用UVE-Bench，我们广泛评估了16个MLLMs。我们的实证结果表明，尽管先进的MLLMs（例如Qwen2VL-72B和InternVL2.5-78B）仍然落后于人工评估者，但它们在统一AIGV评估中展示了令人鼓舞的能力，显著超过了现有的专门评估方法。此外，我们对影响MLLM驱动评估器表现的关键设计选择进行了深入分析，为未来的AIGV评估研究提供了有价值的见解。代码已在此提供。\n\n链接：[https://arxiv.org/pdf/2503.09949.pdf](https://arxiv.org/pdf/2503.09949.pdf)",
        "地址": "https://arxiv.org/pdf/2503.09949.pdf"
    },
    {
        "名称": "2025 [2503.16194] Improving Autoregressive Image Generation through Coarse-to-Fine Token Prediction.pdf",
        "作者": "Ziyao Guo, Kaipeng Zhang, Michael Qizhe Shieh",
        "摘要": "摘要（中文翻译）：自回归模型通过采用源自语言建模的序列预测技术，在图像生成中表现出显著成功。然而，将这些方法应用于图像时，需要通过VQ-VAE等矢量量化方法离散化连续的像素数据。为缓解存在于VQ-VAE中的量化误差，最近的工作倾向于使用更大的代码簿。然而，这将相应地扩大词汇量，增加自回归建模任务的复杂性。本文旨在找到一种方法，在享受大代码簿带来好处的同时，不增加自回归建模的难度。通过实证研究，我们发现具有相似代码字表示的标记对最终生成的图像产生的效果相似，揭示出大代码簿中存在显著的冗余性。基于这一洞察，我们提出了从粗到细的标记预测（CTF），通过为相似标记分配相同的粗标签来实现。我们的框架包括两个阶段：（1）一个自回归模型，按顺序预测序列中每个标记的粗标签；（2）一个辅助模型，通过条件粗标签同时预测所有标记的细粒度标签。对ImageNet的实验表明我们的方法具有卓越的性能，与基线相比在Inception Score上平均提高59分。值得注意的是，尽管增加了一个推理步骤，我们的方法仍然实现了更快的采样速度。",
        "地址": "https://arxiv.org/pdf/2503.16194.pdf"
    },
    {
        "名称": "2025 [2503.15855] VideoRFSplat: Direct Scene-Level Text-to-3D Gaussian Splatting Generation with Flexible Pose and Multi-View Joint Modeling.pdf",
        "作者": "Hyojun Go, Byeongjun Park, Hyelin Nam, Byung-Hoon Kim, Hyungjin Chung, Changick Kim",
        "摘要": "摘要：我们提出了VideoRFSplat，一个利用视频生成模型直接生成真实3D高斯点云（3DGS）的从文本到3D模型的方法，适用于无边界的真实场景。为了生成多样化的相机姿态和无边界的真实场景空间范围，同时确保对任意文本提示的泛化，之前的方法对2D生成模型进行微调，以便联合建模相机姿态和多视角图像。然而，由于模态差距，这些方法在将2D生成模型扩展到联合建模时会遇到不稳定性，因而需要额外的模型来稳定训练和推理。在这项工作中，我们提出了一种在微调视频生成模型时联合建模多视角图像和相机姿态的架构和采样策略。我们的核心理念是双流架构，通过通信块将专用的姿态生成模型附加到预训练的视频生成模型上，通过独立的流生成多视角图像和相机姿态。这一设计减少了姿态和图像模态之间的干扰。此外，我们还提出了一种异步采样策略，该策略比多视角图像更快地去噪相机姿态，使得快速去噪的姿态能够调节多视角生成，减少相互模糊性并增强跨模态一致性。经过在多个大规模真实世界数据集（RealEstate10K、MVImgNet、DL3DV-10K、ACID）上的训练，VideoRFSplat无需依赖评分蒸馏采样的后期优化，表现优于现有的依赖后期优化的文本到3D直接生成方法，取得了更优异的结果。\n\n作者：高宥俊，朴炳俊，南慧琳，金秉勋，钟亨镇，金昌锡\n\n评论：项目页面：这个 HTTPS URL\n\n网址：https://arxiv.org/pdf/2503.15855.pdf\n\n标题：2025 [2503.15855] VideoRFSplat：具有灵活姿态和多视角联合建模的直观场景级文本到3D高斯点云生成",
        "地址": "https://arxiv.org/pdf/2503.15855.pdf"
    },
    {
        "名称": "2025 [2503.13834] See-Saw Modality Balance: See Gradient, and Sew Impaired Vision-Language Balance to Mitigate Dominant Modality Bias.pdf",
        "作者": "JuneHyoung Kwon, MiHyeon Kim, Eunju Lee, Juhwan Choi, YoungBin Kim",
        "摘要": "摘要:视觉-语言（VL）模型在各种任务中表现出强大的性能。然而，这些模型往往依赖于特定的模态进行预测，导致“主导模态偏差”。这种偏差显著影响性能，特别是当一种模态受损时。在这项研究中，我们分析了在主导模态偏差下的模型行为，并从理论上证明了未对齐的梯度或梯度幅度的差异会阻碍损失的平衡收敛。基于这些发现，我们提出了一个新的框架BalGrad来减轻主导模态偏差。我们的方法包括跨模态梯度重权重，根据每种模态的贡献调整KL散度的梯度，以及跨任务梯度投影，以非冲突的方式对齐任务方向。在UPMC Food-101、Hateful Memes和MM-IMDb数据集上的实验证实，BalGrad能有效缓解预测时对特定模态的过度依赖。",
        "地址": "https://arxiv.org/pdf/2503.13834.pdf"
    },
    {
        "名称": "2025 [2503.07906] Painting with Words: Elevating Detailed Image Captioning with Benchmark and Alignment Learning.pdf",
        "作者": "Qinghao Ye, Xianhan Zeng, Fu Li, Chunyuan Li, Haoqi Fan",
        "摘要": "摘要：图像描述一直是视觉理解中的重要任务，近期在视觉语言模型（VLMs）方面的进展大大提升了生成详细图像描述的能力。然而，由于过时的评价指标和粗糙的注释，对于详细图像描述的评估仍然研究不足。本文中，我们介绍了DeCapBench及用于详细描述任务的新指标DCScore。DCScore通过将响应分解为称为原始信息单元的最小自足单位并分别评估它们，来评估幻觉和细粒度的全面性。我们的评估显示，DCScore比其他基于规则或模型的指标更符合人类判断。同时，DeCapBench在描述任务的VLM领域结果上显示出高度的相关性，超越了现有的视觉语言模型基准。此外，我们提出了一种基于我们高级指标的自动细粒度反馈收集方法FeedQuill，用于偏好优化，显示出在自动生成的偏好数据上的强大泛化能力。在多个VLM上的广泛实验表明，我们的方法不仅显著减少了幻觉，还增强了各种基准测试中的表现，在细节描述表现上优于GPT-4o。\n\n翻译：图像描述长期以来是视觉理解中的一项重要任务，最近在视觉语言模型（VLMs）方面的进展显著提高了生成详细图像描述的能力。然而，由于过时的评价指标和粗糙的注释，详细图像描述评估仍未得到充分研究。本文介绍了DeCapBench以及专为详细描述任务设计的新指标DCScore。DCScore通过将回复分解为最小自足单位（原始信息单元）并单独评估它们，来评估幻觉和细粒度全面性。我们的评估表明，DCScore比其他基于规则或模型的指标更符合人类判断。同时，DeCapBench在描述任务的VLM领域结果上显示出高相关性，超越了现有的视觉语言模型基准。此外，我们提出了一种基于改进指标的自动细粒度反馈收集方法FeedQuill，用于偏好优化，展示了在自动生成偏好数据上的强大泛化能力。在多个VLM上的大量实验表明，我们的方法不仅显著减少了幻觉，还提升了各种基准测试上的表现，在细节描述表现上优于GPT-4o。",
        "地址": "https://arxiv.org/pdf/2503.07906.pdf"
    },
    {
        "名称": "2025 [2503.16091] AIMI: Leveraging Future Knowledge and Personalization in Sparse Event Forecasting for Treatment Adherence.pdf",
        "作者": "Abdullah Mamun, Diane J. Cook, Hassan Ghasemzadeh",
        "摘要": "摘要：对于慢性病患者来说，遵循处方治疗对于避免高昂或不良健康结果至关重要。对于某些患者群体，强化生活方式干预对于提高药物依从性至关重要。准确预测治疗依从性能为开发按需干预工具开启途径，从而实现及时和个性化的支持。随着智能手机和可穿戴设备的日益普及，开发和部署智能活动监测系统变得比以往任何时候都更容易。然而，基于可穿戴传感器的有效治疗依从性预测系统仍未广泛可用。我们通过提出机智智能依从性预测和干预系统（AIMI）来填补这一空白。AIMI 是一个知识引导的依从性预测系统，利用智能手机传感器和以往的药物历史来估计遗忘服药的可能性。我们对27名患者（这些患者每天服药以管理心血管疾病）进行了用户研究。我们设计并开发了基于 CNN 和 LSTM 的预测模型，使用各种输入特征组合，发现 LSTM 模型可以以0.932的准确率和0.936的 F-1 分数预测药物依从性。此外，通过一系列涉及卷积神经网络和循环神经网络架构的消融研究，我们表明利用未来已知知识和个性化训练可以提高药物依从性预测的准确性。代码可在此网址获取：this https URL。",
        "地址": "https://arxiv.org/pdf/2503.16091.pdf"
    },
    {
        "名称": "2025 [2503.14201] Why Personalizing Deep Learning-Based Code Completion Tools Matters.pdf",
        "作者": "Alessandro Giagnorio, Alberto Martin-Lopez, Gabriele Bavota",
        "摘要": "摘要: 基于深度学习（DL）的代码补全工具通过高级代码生成技术彻底改变了软件开发。这些工具利用从众多代码库中获取的大量代码进行训练的模型，以捕捉一般的编码模式。然而，针对特定组织或开发人员调整这些模型以提高其在这些特定主体上的性能的影响仍未得到探索。在这项工作中，我们通过提供坚实的实证证据来回答这一问题。更具体地说，我们研究了来自两个组织（Apache和Spring）的136名开发人员、两种模型架构（T5和Code Llama）以及三种模型大小（60M、750M和7B可训练参数）。T5模型（60M、750M）在超过2000个开源项目上进行了预训练和微调，排除了主体组织的数据，并与在组织和开发人员特定数据集上微调的版本进行了比较。对于Code Llama模型（7B），我们比较了在线公开的已经预训练的模型与通过参数高效微调在组织和开发人员特定数据集上微调的相同模型的性能。我们的结果显示，通过组织特定和开发人员特定的额外微调，预测能力得到了提升，其中组织特定的微调表现尤为出色。这一发现对两个主题组织（即Apache和Spring）以及完全不同规模的模型（从60M到7B可训练参数）具有普遍性。最后，我们展示了在组织特定数据集上微调的DL模型达到了与直接使用预训练代码模型相同的完成性能，而后者的规模要大$\\sim$10倍，从而在部署和推理成本方面实现了节约（例如，需要更小的GPU）。\n\n翻译成中文后详细信息如下：\n年份: 2025\n摘要: 基于深度学习（DL）的代码补全工具通过高级代码生成技术彻底改变了软件开发。这些工具利用从众多代码库中获取的大量代码进行训练的模型，以捕捉一般的编码模式。然而，针对特定组织或开发人员调整这些模型以提高其在这些特定主体上的性能的影响仍未得到探索。在这项工作中，我们通过提供坚实的实证证据来回答这一问题。更具体地说，我们研究了来自两个组织（Apache和Spring）的136名开发人员、两种模型架构（T5和Code Llama）以及三种模型大小（60M、750M和7B可训练参数）。T5模型（60M、750M）在超过2000个开源项目上进行了预训练和微调，排除了主体组织的数据，并与在组织和开发人员特定数据集上微调的版本进行了比较。对于Code Llama模型（7B），我们比较了公开的已预训练模型与通过参数高效微调在组织和开发人员特定数据集上微调的相同模型的性能。结果表明，无论是组织特定还是开发人员特定的额外微调，均能提高预测能力，尤其是组织特定的微调表现尤为出色。这一发现对所研究的两个组织（即Apache和Spring）以及完全不同规模的模型（从60M到7B可训练参数）均具有普遍性。最后，我们展示了在组织特定数据集上微调的深度学习模型在代码完成性能方面达到了与现成的预训练模型相当的水平，而其规模要小约10倍，从而在部署和推理成本方面实现了显著节约（例如，需要更小的GPU）。\n作者: Alessandro Giagnorio, Alberto Martin-Lopez, Gabriele Bavota\n评论: 已被ACM TOSEM接受发表\n网址: https://arxiv.org/pdf/2503.14201.pdf\n标题: 2025 [2503.14201] 为什么个性化深度学习基础的代码补全工具很重要.pdf",
        "地址": "https://arxiv.org/pdf/2503.14201.pdf"
    },
    {
        "名称": "2025 [2503.11509] TikZero: Zero-Shot Text-Guided Graphics Program Synthesis.pdf",
        "作者": "Jonas Belouadi, Eddy Ilg, Margret Keuper, Hideki Tanaka, Masao Utiyama, Raj Dabre, Steffen Eger, Simone Paolo Ponzetto",
        "摘要": "摘要：随着生成式AI的兴起，从文本标题生成图形变得愈发吸引人。然而，实现高几何精度和可编辑性需要使用类似TikZ的语言将图形表示为图形程序，而对齐的训练数据（即带有标题的图形程序）仍然稀缺。同时，大量未对齐的图形程序和帶有标题的光栅图像更易获取。我们通过提出TikZero来调和这些不同的数据源，TikZero使用图像表示作为中介桥梁将图形程序生成与文本理解解耦。它实现了对图形程序和带标题图像的独立训练，并在推理过程中允许零样本文本引导的图形程序生成。我们证明了我们的方法显著优于那些只能处理带标题对齐图形程序的基线。此外，当利用带标题对齐图形程序作为辅助训练信号时，TikZero的表现与更大的模型相媲美或超越，包括像GPT-4o这样的商业系统。我们的代码、数据集和选定的模型是公开可用的。",
        "地址": "https://arxiv.org/pdf/2503.11509.pdf"
    },
    {
        "名称": "2025 [2503.15672] GASP: Unifying Geometric and Semantic Self-Supervised Pre-training for Autonomous Driving.pdf",
        "作者": "William Ljungbergh, Adam Lilja, Adam Tonderski. Arvid Laveno Ling, Carl Lindström, Willem Verbeke, Junsheng Fu, Christoffer Petersson, Lars Hammarstrand, Michael Felsberg",
        "摘要": "摘要：基于下一个标记预测的自监督预训练使大型语言模型能够捕捉文本的基础结构，并在大规模应用时在大量任务上取得了前所未有的性能。同样，自动驾驶生成了大量的时空数据，这暗示了利用规模来学习环境及其随时间演变的几何和语义结构的可能性。在这个方向上，我们提出了一种几何和语义自监督预训练方法GASP，该方法通过在时空中任意查询的未来点进行预测，学习一种统一的表示：（1）一般占用率，捕捉3D场景的演变结构；（2）自车占用率，建模自车通过环境的路径；（3）从视觉基础模型提取的高层次特征。通过对几何与语义的4D占用场进行建模，而不是原始传感器测量，模型学习到了环境及其随时间演变的结构化、可泛化的表示。我们在多个自动驾驶基准测试上验证了GASP，展示了在语义占用率预测、在线地图构建和自车轨迹预测上的显著改进。我们的结果表明，连续4D几何和语义占用预测为自动驾驶提供了一种可扩展且有效的预训练范式。有关代码和更多可视化信息，请参见链接。",
        "地址": "https://arxiv.org/pdf/2503.15672.pdf"
    },
    {
        "名称": "2025 [2503.13891] Where do Large Vision-Language Models Look at when Answering Questions?.pdf",
        "作者": "Xiaoying Xing, Chia-Wen Kuo, Li Fuxin, Yulei Niu, Fan Chen, Ming Li, Ying Wu, Longyin Wen, Sijie Zhu",
        "摘要": "摘要: 大型视觉语言模型（LVLMs）在视觉语言理解和推理任务中表现出很有前景。然而，它们的视觉理解行为仍然缺乏深入研究。一个基本问题是：LVLMs在多大程度上依赖视觉输入，哪些图像区域对其响应起作用？由于其复杂的视觉架构（例如多个编码器和多分辨率）以及可变长度输出，解释LVLMs的自由生成并非易事。本文扩展了现有的热图可视化方法（例如iGOS++），以支持LVLMs的开放式视觉问答。我们提出了一种方法，选择反映生成答案与输入图像相关性的视觉相关标记。此外，我们对需要视觉信息的基准上最先进的LVLM进行了全面分析。我们的研究发现提供了对LVLM行为的若干见解，包括焦点区域与答案正确性之间的关系、不同架构在视觉注意力上的差异以及LLM规模对视觉理解的影响。代码和数据可在此链接获得：https URL。\n\n作者: Xiaoying Xing, Chia-Wen Kuo, Li Fuxin, Yulei Niu, Fan Chen, Ming Li, Ying Wu, Longyin Wen, Sijie Zhu",
        "地址": "https://arxiv.org/pdf/2503.13891.pdf"
    }
]