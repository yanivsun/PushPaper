[
    {
        "名称": "2025 [2505.11820] Chain-of-Model Learning for Language Model.pdf",
        "作者": "Kaitao Song, Xiaohua Wang, Xu Tan, Huiqiang Jiang, Chengruidong Zhang, Yongliang Shen, Cen LU, Zihao Li, Zifan Song, Caihua Shan, Yansen Wang, Kan Ren, Xiaoqing Zheng, Tao Qin, Yuqing Yang, Dongsheng Li, Lili Qiu",
        "摘要": "摘要：在本文中，我们提出了一种新颖的学习范式，称为链式模型（Chain-of-Model, CoM），它将因果关系融入到每一层的隐藏状态中，形成链式结构，从而在模型训练中引入了极高的扩展效率，并在部署中提供了推理的灵活性。我们引入了链式表示（Chain-of-Representation, CoR）的概念，将每一层的隐藏状态表示为多个子表示（即链）的组合。在每一层中，输出表示中的每条链只能查看输入表示中所有前面的链。因此，基于CoM框架构建的模型可以通过基于先前模型（即链）增加链来逐步扩大模型规模，并通过使用不同数量的链提供多种大小不一的子模型以实现弹性推理。基于这一原则，我们设计了链式语言模型（Chain-of-Language-Model, CoLM），将CoM的理念融入到Transformer架构的每一层中。基于CoLM，我们进一步引入了CoLM-Air，采用了键值（KV）共享机制，在第一条链内计算所有键和值，然后在所有链中共享。该设计展示了额外的扩展性，如实现无缝语言模型切换、预填充加速等。实验结果表明，我们的CoLM系列可以达到与标准Transformer相当的性能，同时提供了更大的灵活性，如通过渐进扩展提高训练效率，并提供多样化的模型大小以实现弹性推理，为构建语言模型开辟了一条新途径。我们的代码将在未来发布于此URL。\n\n作者：宋开涛，王晓华，谭旭，姜辉强，张成瑞栋，沈永良，鲁岑，李子豪，宋子凡，单才华，王言森，任嵌，郑小青，秦涛，杨玉庆，李东升，邱丽丽\n\n链接：[点击查看原文](https://arxiv.org/pdf/2505.11820.pdf)",
        "地址": "https://arxiv.org/pdf/2505.11820.pdf"
    },
    {
        "名称": "2025 [2505.13417] AdaptThink: Reasoning Models Can Learn When to Think.pdf",
        "作者": "Jiajie Zhang, Nianyi Lin, Lei Hou, Ling Feng, Juanzi Li",
        "摘要": "摘要：最近，大型推理模型通过采用类似人类的深入思考在各种任务上取得了令人印象深刻的表现。然而，冗长的思考过程显著增加了推理开销，使得效率成为关键瓶颈。在这项工作中，我们首先证明了NoThinking，即提示推理模型跳过思考并直接生成最终解决方案，是一种在性能和效率方面对相对简单任务的更优选择。受此启发，我们提出了AdaptThink，这是一种新的强化学习算法，用于教推理模型根据问题难度自适应地选择最佳思考模式。具体来说，AdaptThink有两个核心组件：（1）一个约束优化目标，鼓励模型选择NoThinking，同时保持整体性能；（2）一个重要性采样策略，在策略训练过程中平衡Thinking和NoThinking样本，从而实现冷启动，并允许模型在整个训练过程中探索和利用这两种思考模式。我们的实验表明，AdaptThink在显著降低推理成本的同时进一步提高了性能。值得注意的是，在三个数学数据集上，AdaptThink将DeepSeek-R1-Distill-Qwen-1.5B的平均响应长度减少了53%，并将其准确性提高了2.4%，突显了自适应思考模式选择在优化推理质量和效率之间平衡的前景。我们的代码和模型可在此网址获得。",
        "地址": "https://arxiv.org/pdf/2505.13417.pdf"
    },
    {
        "名称": "2025 [2505.11896] AdaCoT: Pareto-Optimal Adaptive Chain-of-Thought Triggering via Reinforcement Learning.pdf",
        "作者": "Chenwei Lou, Zewei Sun, Xinnian Liang, Meng Qu, Wei Shen, Wenqi Wang, Yuntao Li, Qingping Yang, Shuangzhi Wu",
        "摘要": "摘要：大型语言模型（LLMs）展示出了显著的能力，但在需要复杂推理的任务中常常面临挑战。尽管思维链（CoT）提示能显著增强推理能力，它无差别地为所有查询生成冗长的推理步骤，导致计算成本和效率低下，特别是对于简单输入。为了解决这一关键问题，我们引入了AdaCoT（自适应思维链），一个新颖的框架，使得LLMs能够自适应地决定何时调用CoT。AdaCoT将自适应推理表述为一个帕累托优化问题，寻求在模型性能与CoT调用相关的成本（包括频率和计算开销）之间平衡。我们提出了一种基于强化学习（RL）的方法，特别是利用近端策略优化（PPO），通过调整惩罚系数来动态控制CoT触发决策边界，从而使模型能够根据隐含查询复杂度确定CoT的必要性。一个关键的技术贡献是选择性损失屏蔽（SLM），旨在多阶段RL训练中防止决策边界坍塌，确保稳健和稳定的自适应触发。实验结果表明，AdaCoT成功地探索了帕累托前沿，对于不需要复杂推理的查询，显著减少了CoT的使用。例如，在我们的生产流量测试集中，AdaCoT将CoT触发率降低到3.18%，并减少了69.06%的平均响应标记，同时在复杂任务上保持了高性能。\n\n作者：Lou Chenwei，Sun Zewei，Liang Xinnian，Qu Meng，Shen Wei，Wang Wenqi，Li Yuntao，Yang Qingping，Wu Shuangzhi",
        "地址": "https://arxiv.org/pdf/2505.11896.pdf"
    },
    {
        "名称": "2025 [2505.11254] Delta Attention: Fast and Accurate Sparse Attention Inference by Delta Correction.pdf",
        "作者": "Jeffrey Willette, Heejun Lee, Sung Ju Hwang",
        "摘要": "摘要：Transformers的注意力机制具有二次复杂性，这导致对长序列进行推理时的高推理成本和延迟。然而，注意力矩阵大多是稀疏的，这意味着可以省略许多条目以进行高效计算。稀疏注意力推理方法旨在减轻这种计算负担；然而，它们也伴随着性能下降的问题。我们发现这种性能下降的一个原因是稀疏计算导致了注意力输出中的分布性偏移。这种分布性偏移会导致解码时的查询无法与预填充阶段的相应密钥很好地对齐，从而导致性能下降。我们提出了一种简单、新颖且有效的程序来纠正这种分布性偏移，使稀疏注意力输出的分布更接近于二次注意力。我们的方法可以应用于任何稀疏注意力方法之上，平均可提高36 %的性能，当应用于包含Sink Tokens的滑动窗口注意力时，能够恢复二次注意力在131K RULER基准测试中的88%的准确性，同时只增加很小的开销。我们的方法能够在保持大约 98.5 %的稀疏性的情况下注释满函数注意力，使我们的模型在处理1M Token预填充时比 Flash Attention 2 快32 倍。\n\n作者：Jeffrey Willette，Heejun Lee，Sung Ju Hwang\n\n标题：Delta Attention: Fast and Accurate Sparse Attention Inference by Delta Correction\n\n链接：https://arxiv.org/pdf/2505.11254.pdf",
        "地址": "https://arxiv.org/pdf/2505.11254.pdf"
    },
    {
        "名称": "2025 [2505.13227] Scaling Computer-Use Grounding via User Interface Decomposition and Synthesis.pdf",
        "作者": "Tianbao Xie, Jiaqi Deng, Xiaochuan Li, Junlin Yang, Haoyuan Wu, Jixuan Chen, Wenjing Hu, Xinyuan Wang, Yuhui Xu, Zekun Wang, Yiheng Xu, Junli Wang, Doyen Sahoo, Tao Yu, Caiming Xiong",
        "摘要": "摘要：图形用户界面（GUI）解析，即将自然语言指令映射到图形用户界面的具体操作的能力，仍是计算机使用代理开发中的一个重要瓶颈。目前的基准测试将解析任务简化为短的指代表达，未能捕捉需要软件常识、布局理解和细粒度操作能力的现实交互的复杂性。为了解决这些局限性，我们引入了OSWorld-G，这是一项全面的基准测试，包括564个精细注释的样本，涵盖文本匹配、元素识别、布局理解和精准操作等多种任务类型。此外，我们合成并发布了最大的计算机使用解析数据集Jedi，通过任务的多视角解耦包含400万个示例。我们在Jedi上训练的多尺度模型表明其通过在ScreenSpot-v2、ScreenSpot-Pro和我们的OSWorld-G上优于现有方法，从而证明了其有效性。此外，我们证明通过Jedi改进的解析能力直接增强了通用基础模型在复杂计算机任务中的智能能力，使OSWorld的性能从5%提高到27%。通过详细的消融研究，我们确定了影响解析性能的关键因素，并验证了结合针对不同界面元素的专门数据能实现对新界面的组成性泛化。所有基准测试、数据、检查点和代码都是开源的，可在此HTTPS URL获取。",
        "地址": "https://arxiv.org/pdf/2505.13227.pdf"
    },
    {
        "名称": "2025 [2505.13379] Thinkless: LLM Learns When to Think.pdf",
        "作者": "Gongfan Fang, Xinyin Ma, Xinchao Wang",
        "摘要": "摘要：具有扩展思维链推理能力的推理语言模型在需要复杂逻辑推断的任务中展示了卓越的性能。然而，在所有查询中应用复杂推理通常会导致显著的计算效率低下，特别是当许多问题可以采用简单解决方案时。这引发了一个开放性问题：LLM 能否学会在何时进行思考？为了解答这个问题，我们提出了 Thinkless，这是一种可学习的框架，使 LLM 能够根据任务复杂性和模型能力自适应地选择简洁推理和详细推理。Thinkless 在强化学习范式下训练，采用两个控制标记，<short> 用于简洁响应，<think> 用于详细推理。我们方法的核心是一个解耦分组相对策略优化（DeGRPO）算法，它将混合推理的学习目标分解为两个组成部分：(1) 控制标记损失，用于控制推理模式的选择；(2) 响应损失，用于提高生成答案的准确性。这种解耦的形式化允许对每个目标的贡献进行细粒度控制，稳定训练，并有效防止在普通 GRPO 中观察到的崩溃现象。实验证明，在 Minerva Algebra、MATH-500 和 GSM8K 等多个基准上，Thinkless 能够将长链推理的使用减少50％-90％，显著提高推理语言模型的效率。代码可在此 https URL 获取。",
        "地址": "https://arxiv.org/pdf/2505.13379.pdf"
    },
    {
        "名称": "2025 [2505.13389] Faster Video Diffusion with Trainable Sparse Attention.pdf",
        "作者": "Peiyuan Zhang, Haofeng Huang, Yongqi Chen, Will Lin, Zhengzhong Liu, Ion Stoica, Eric P. Xing, Hao Zhang",
        "摘要": "摘要: 扩展视频扩散变压器（DiTs）受到其二次3D注意力的限制，即使大多数注意力集中在一小部分位置。我们将这一观察转化为VSA，一种可训练、在硬件上高效的稀疏注意力，替代了训练和推理时的全注意力。在VSA中，一个轻量级的粗略阶段将标记池化成块，并识别高权重的“关键标记”；一个细致阶段则仅在这些块内计算标记级注意力，以确保运算效率。这形成了一个可端到端训练的单一可微核，不需要事后分析，并保持了85%的FlashAttention3 MFU。我们通过在60M到14亿参数的DiTs预训练，进行了大量的消融研究和扩展法实验。VSA达到了一个帕累托点，将训练FLOPS减少了2.53倍，而扩散损失没有下降。改造开源的Wan-2.1模型使注意力时间加快了6倍，端到端生成时间从31秒减少到18秒，且质量相当。这些结果表明了可训练的稀疏注意力作为全注意力的实际替代方案，并且是进一步扩展视频扩散模型的关键推动力。",
        "地址": "https://arxiv.org/pdf/2505.13389.pdf"
    },
    {
        "名称": "2025 [2505.12082] Model Merging in Pre-training of Large Language Models.pdf",
        "作者": "Yunshui Li, Yiyuan Ma, Shen Yan, Chaoyi Zhang, Jing Liu, Jianqiao Lu, Ziwen Xu, Mengzhao Chen, Minrui Wang, Shiyi Zhan, Jin Ma, Xunhao Lai, Yao Luo, Xingyan Bin, Hongbin Ren, Mingji Han, Wenhao Hao, Bairen Yi, LingJun Liu, Bole Ma, Xiaoying Jia, Zhou Xun, Siyuan Qiao, Liang Xiang, Yonghui Wu",
        "摘要": "摘要：模型合并已成为增强大型语言模型的一项有前景的技术，尽管其在大规模预训练中的应用尚未得到充分探索。在本文中，我们对预训练过程中的模型合并技术进行了全面调查。通过对从数百万到超过1000亿个参数的密集和专家混合（MoE）架构的广泛实验，我们证明了使用恒定学习率训练的检查点合并不仅实现了显著的性能改进，还能够准确预测退火行为。这些改进不仅使模型开发更高效，而且大大降低了训练成本。我们对合并策略和超参数进行了详细的消融研究，提供了新见解并揭示了新的应用。通过全面的实验分析，我们为开源社区提供了有效模型合并的实用预训练指南。\n\n来源：Yunshui Li, Yiyuan Ma, Shen Yan, Chaoyi Zhang, Jing Liu, Jianqiao Lu, Ziwen Xu, Mengzhao Chen, Minrui Wang, Shiyi Zhan, Jin Ma, Xunhao Lai, Yao Luo, Xingyan Bin, Hongbin Ren, Mingji Han, Wenhao Hao, Bairen Yi, LingJun Liu, Bole Ma, Xiaoying Jia, Zhou Xun, Siyuan Qiao, Liang Xiang, Yonghui Wu",
        "地址": "https://arxiv.org/pdf/2505.12082.pdf"
    },
    {
        "名称": "2025 [2505.13308] Seek in the Dark: Reasoning via Test-Time Instance-Level Policy Gradient in Latent Space.pdf",
        "作者": "Hengli Li, Chenxi Li, Tong Wu, Xuekai Zhu, Yuxuan Wang, Zhaoxin Yu, Eric Hanchen Jiang, Song-Chun Zhu, Zixia Jia, Ying Nian Wu, Zilong Zheng",
        "摘要": "摘要: 推理能力是人类智能的核心组成部分，在追求通用人工智能（AGI）的过程中，始终对大型语言模型（LLMs）构成重大挑战。尽管在训练扩展法则下模型性能有所提高，但仍然存在重大挑战，特别是在训练算法方面，例如灾难性遗忘以及新颖训练数据的有限可用性。作为一种替代方法，测试时扩展通过增加测试时计算量而不更新参数来提升推理性能。与先前关注于标记空间的方法不同，我们提出利用潜在空间进行更有效的推理和更好地遵循测试时扩展法则。我们介绍了LatentSeek，一种通过模型潜在空间内的测试时实例级适应（TTIA）来增强LLMs推理能力的新框架。具体而言，LatentSeek利用策略梯度来迭代更新潜在表示，这由自生成的奖励信号引导。LatentSeek在包括GSM8K、MATH-500和AIME2024在内的多个推理基准上以及多个LLM架构中进行评估。结果显示，LatentSeek始终优于强基线方法，如连贯思考提示和基于微调的方法。此外，我们的分析表明，LatentSeek非常高效，通常在几次迭代内即可针对平均复杂度的问题收敛，同时受益于额外的迭代次数，从而凸显了潜在空间测试时扩展的潜力。这些发现表明，LatentSeek是增强LLMs推理能力的轻量级、可扩展且有效的解决方案。",
        "地址": "https://arxiv.org/pdf/2505.13308.pdf"
    },
    {
        "名称": "2025 [2505.13427] MM-PRM: Enhancing Multimodal Mathematical Reasoning with Scalable Step-Level Supervision.pdf",
        "作者": "Lingxiao Du, Fanqing Meng, Zongkai Liu, Zhixiang Zhou, Ping Luo, Qiaosheng Zhang, Wenqi Shao",
        "摘要": "摘要：尽管多模态大型语言模型（MLLMs）在视觉-语言理解方面取得了令人印象深刻的进展，但它们在复杂的多步骤推理任务中仍然存在困难，通常会产生逻辑不一致或部分正确的解决方案。一个关键的限制在于缺乏对中间推理步骤的细粒度监督。为了解决这个问题，我们提出了MM-PRM，一种在完全自动化、可扩展框架内训练的过程奖励模型。我们首先构建了MM-Policy，这是一个在多样的数学推理数据上训练的强大多模态模型。然后，我们构建了MM-K12，这是一个包含10000个具有可验证答案的多模态数学问题的精心编制的数据集，作为种子数据。利用基于蒙特卡洛树搜索（MCTS）的管道，我们生成了超过700,000个步骤级别的注释，无需人工标记。所得的PRM在Best-of-N推理设置中用于对候选推理路径进行评分，并在领域内（MM-K12测试集）和领域外（如OlympiadBench，MathVista等）基准测试中取得了显著改善。进一步的分析确认了软标签、更小的学习率和路径多样性在优化PRM性能中的有效性。MM-PRM表明，过程监督是增强多模态推理系统逻辑稳健性的有力工具。我们在此https URL上发布了所有代码和数据。\n\n来源：https://arxiv.org/pdf/2505.13427.pdf",
        "地址": "https://arxiv.org/pdf/2505.13427.pdf"
    },
    {
        "名称": "2025 [2505.13215] Hybrid 3D-4D Gaussian Splatting for Fast Dynamic Scene Representation.pdf",
        "作者": "Seungjun Oh, Younggeun Lee, Hyejin Jeon, Eunbyung Park",
        "摘要": "摘要：最近在动态3D场景重建方面的进展显示出令人鼓舞的结果，使得高保真3D新视图合成具有更好的时间一致性。其中，4D高斯点绘（4D Gaussian Splatting，简称4DGS）由于其能够建模高保真空间和时间变化而成为一种有吸引力的方法。然而，现有方法由于在静态区域冗余分配4D高斯，导致显著的计算和内存开销，这也可能降低图像质量。在这项工作中，我们引入了混合3D-4D高斯点绘（3D-4DGS），一种新的框架，通过自适应地用3D高斯表示静态区域，同时保留4D高斯用于动态元素。我们的方法从完全4D高斯表示开始，并迭代地将时间不变的高斯转换为3D，从而显著减少参数数量并提高计算效率。同时，动态高斯保留其完整的4D表示，以高保真捕捉复杂的运动。与基本的4D高斯点绘方法相比，我们的方法在保持或提高视觉质量的同时，实现了显著更快的训练时间。",
        "地址": "https://arxiv.org/pdf/2505.13215.pdf"
    },
    {
        "名称": "2025 [2505.12805] FedSVD: Adaptive Orthogonalization for Private Federated Learning with LoRA.pdf",
        "作者": "Seanie Lee, Sangwoo Park, Dong Bok Lee, Dominik Wagner, Haebin Seong, Tobias Bocklet, Juho Lee, Sung Ju Hwang",
        "摘要": "摘要：低秩适应 (LoRA) 通过在冻结的预训练权重中引入两个可训练的低秩矩阵的乘积，被广泛用于在联邦学习 (FL) 中进行高效的语言模型微调。然而，当与不同隐私保护随机梯度下降 (DP-SGD) 结合时，LoRA 面临着显著的噪声放大问题：DP-SGD会扰动每个样本的梯度，而LoRA更新中的矩阵乘法 ($BA$) 则加剧了这一现象。冻结一个矩阵（如 $A$）可以减少噪声但限制了模型的表现，通常导致适应不理想。为了解决这个问题，我们提出了FedSVD，一种基于奇异值分解 (SVD) 的全局重参数化方法。我们的方法中，每个客户仅优化 $B$ 矩阵并将其传输到服务器。服务器聚合 $B$ 矩阵，使用之前的 $A$ 计算乘积 $BA$，并通过SVD重构结果。这样就得到了新的自适应 $A$，由 $BA$ 的正交右奇异向量组成，以及包含剩余SVD分量的更新的 $B$。这种重参数化避免了噪声的平方放大，同时允许 $A$ 更好地捕捉聚合更新的主要方向。此外，$A$ 的正交结构在理论分析中确认了在 DP-SGD 下约束了 $B$ 的梯度范数，并且保留了更多信号。因此，FedSVD在各种隐私设置和基准测试中始终改善了稳定性和性能，在隐私保护和非隐私保护模式下均优于相关的基线。\n\n作者：Seanie Lee, Sangwoo Park, Dong Bok Lee, Dominik Wagner, Haebin Seong, Tobias Bocklet, Juho Lee, Sung Ju Hwang\n\n评论：预印本\n\nURL：https://arxiv.org/pdf/2505.12805.pdf\n\n标题：2025 [2505.12805] FedSVD: Adaptive Orthogonalization for Private Federated Learning with LoRA",
        "地址": "https://arxiv.org/pdf/2505.12805.pdf"
    },
    {
        "名称": "2025 [2505.12504] CPGD: Toward Stable Rule-based Reinforcement Learning for Language Models.pdf",
        "作者": "Zongkai Liu, Fanqing Meng, Lingxiao Du, Zhixiang Zhou, Chao Yu, Wenqi Shao, Qiaosheng Zhang",
        "摘要": "摘要：近期在基于规则的强化学习（RL）方面的进展显著提高了语言模型（LM）通过规则奖励进行推理的能力。然而，现有的RL方法——如GRPO、REINFORCE++和RLOO——通常存在训练不稳定性的问题，其中大幅度的策略更新和不当的剪裁可能导致训练崩溃。为了解决该问题，我们提出了具有策略漂移约束的剪裁策略梯度优化（CPGD），这是一种旨在稳定语言模型策略学习的创新算法。CPGD基于KL散度引入策略漂移约束动态调整策略更新，并利用比率对数剪裁机制以防止过度策略更新。我们为CPGD提供了理论依据，并通过实证分析表明其能够缓解先前方法中观察到的不稳定性。此外，我们证明CPGD在显著提高性能的同时保持了训练的稳定性。我们的实现兼顾理论严谨性和实用性，为LM的后训练提供了一种稳健的RL替代方法。我们的代码可从此[https URL](https://arxiv.org/pdf/2505.12504.pdf)获取。",
        "地址": "https://arxiv.org/pdf/2505.12504.pdf"
    },
    {
        "名称": "2025 [2505.12992] Fractured Chain-of-Thought Reasoning.pdf",
        "作者": "Baohao Liao, Hanze Dong, Yuhui Xu, Doyen Sahoo, Christof Monz, Junnan Li, Caiming Xiong",
        "摘要": "摘要：推理时扩展技术通过在推理时使用额外的计算资源，而无需重新训练，大大增强了大型语言模型（LLMs）的推理能力。同样，链式思维（CoT）提示及其扩展版长链思维，通过生成丰富的中间推理路径提高了准确性，但这些方法会导致大量的标记成本，阻碍了其在对延迟敏感的环境中的部署。在这项工作中，我们首先展示了截断的链式思维，在推理未完成时中止，直接生成最终答案，通常匹配完整的链式思维采样，同时使用的标记显著减少。基于这一见解，我们引入了“断裂采样”，这是一种统一的推理策略，通过三个正交轴在完整链式思维和仅解答采样之间进行插值：(1) 推理路径的数量，(2) 每条路径的最终解答数量，(3) 推理轨迹被截断的深度。通过在五个不同推理基准和多个模型规模上的广泛实验，我们证明了断裂采样始终实现卓越的准确性与成本权衡，在给定的标记预算下实现陡峭的对数线性扩展增益。我们的分析揭示了如何在这些维度上分配计算资源以最大化性能，为更高效和可扩展的LLM推理铺平了道路。\n\n—— 作者: Baohao Liao, Hanze Dong, Yuhui Xu, Doyen Sahoo, Christof Monz, Junnan Li, Caiming Xiong",
        "地址": "https://arxiv.org/pdf/2505.12992.pdf"
    },
    {
        "名称": "2025 [2505.13444] ChartMuseum: Testing Visual Reasoning Capabilities of Large Vision-Language Models.pdf",
        "作者": "Liyan Tang, Grace Kim, Xinyu Zhao, Thom Lake, Wenxuan Ding, Fangcong Yin, Prasann Singhal, Manya Wadhwa, Zeyu Leo Liu, Zayne Sprague, Ramya Namuduri, Bodun Hu, Juan Diego Rodriguez, Puyuan Peng, Greg Durrett",
        "摘要": "摘要：\n图表理解对大规模视觉语言模型（LVLMs）提出了独特的挑战，因为这需要整合复杂的文本和视觉推理能力。然而，目前的LVLMs在这些技能之间表现出显著的不平衡，特别是在难以通过文本执行的视觉推理方面表现不佳。我们使用一个仅通过视觉推理才能解决的合成数据集进行案例研究，结果显示随着视觉复杂性增加，模型性能显著下降，而人类表现依然稳健。我们随后引入了ChartMuseum，这是一个新的图表问答（QA）基准，包含1,162个专家标注的问题，跨越多种推理类型，来自184个来源的真实图表，专门用于评估复杂的视觉和文本推理。不像之前的图表理解基准——前沿模型表现相似且接近饱和——我们的基准暴露了模型和人类表现之间的显著差距，并有效区分了模型能力：虽然人类达到93%的准确率，表现最好的模型Gemini-2.5-Pro只有63.0%，而领先的开源LVLM Qwen2.5-VL-72B-Instruct只有38.5%。此外，在主要需要视觉推理的问题上，所有模型的性能相比于文本推理重的问题下降了35%-55%。最后，我们的定性错误分析揭示了当前LVLMs在特定类别的视觉推理中遇到的挑战。\n\n翻译：\n图表理解对大规模视觉语言模型（LVLMs）提出了独特的挑战，因为这需要整合复杂的文本和视觉推理能力。然而，目前的LVLMs在这些技能之间表现出显著的不平衡，特别是在难以通过文本执行的视觉推理方面表现不佳。我们使用一个仅通过视觉推理才能解决的合成数据集进行案例研究，结果显示随着视觉复杂性增加，模型性能显著下降，而人类表现依然稳健。我们随后引入了ChartMuseum，这是一个新的图表问答（QA）基准，包含1,162个专家标注的问题，跨越多种推理类型，来自184个来源的真实图表，专门用于评估复杂的视觉和文本推理。不像之前的图表理解基准——前沿模型表现相似且接近饱和——我们的基准暴露了模型和人类表现之间的显著差距，并有效区分了模型能力：虽然人类达到93%的准确率，表现最好的模型Gemini-2.5-Pro只有63.0%，而领先的开源LVLM Qwen2.5-VL-72B-Instruct 只有38.5%。此外，在主要需要视觉推理的问题上，所有模型的性能相比于文本推理重的问题下降了35%-55%。最后，我们的定性错误分析揭示了当前LVLMs在特定类别的视觉推理中遇到的挑战。",
        "地址": "https://arxiv.org/pdf/2505.13444.pdf"
    },
    {
        "名称": "2025 [2505.12346] SEED-GRPO: Semantic Entropy Enhanced GRPO for Uncertainty-Aware Policy Optimization.pdf",
        "作者": "Minghan Chen, Guikun Chen, Wenguan Wang, Yi Yang",
        "摘要": "摘要：大型语言模型（LLMs）在面对不同输入提示（问题）时表现出不同程度的信心：有些能生成一致的、语义相似的答案，而有些则产生多样或矛盾的输出。这种变化反映了LLM对输入提示的不确定性，这是模型理解问题信心程度的一个信号。然而，传统的群体相对策略优化（GRPO）在策略更新过程中平等对待所有提示，忽视了这种重要的信息。为了解决这一限制，我们提出了基于语义熵增强的GRPO（SEED-GRPO），它明确测量了LLM对输入提示的语义熵的不确定性。语义熵衡量的是在给定提示下多次生成的答案的语义多样性，并用它来调节策略更新的幅度。这种不确定性感知的训练机制使得策略更新幅度可以根据问题的不确定性进行动态调整。在高不确定性问题上进行更为保守的更新，同时在有信心的问题上保持原有的学习信号。在五个数学推理基准（AIME24 56.7, AMC 68.7, MATH 83.4, Minerva 34.2, 和 OlympiadBench 48.0）上的实验结果表明，SEED-GRPO在平均准确率方面达到了新的最先进水平，验证了不确定性感知策略优化的有效性。",
        "地址": "https://arxiv.org/pdf/2505.12346.pdf"
    },
    {
        "名称": "2025 [2505.11932] Neuro-Symbolic Query Compiler.pdf",
        "作者": "Yuyao Zhang, Zhicheng Dou, Xiaoxi Li, Jiajie Jin, Yongkang Wu, Zhonghua Li, Qi Ye, Ji-Rong Wen",
        "摘要": "摘要：在资源受限和处理具有嵌套结构及依赖关系的复杂查询的情况下，实现检索增强生成（RAG）系统内搜索意图的精确识别仍然是一个具有挑战性的目标。本文提出了QCompiler，这是一个受语言语法规则和编译器设计启发的神经符号框架，以弥合这一差距。理论上设计了一种最小但却足够的巴科斯-诺尔形式（BNF）语法 $G[q]$ 来形式化复杂查询。与之前的方法不同，这种语法在保持完整性的同时最小化了冗余。在此基础上，QCompiler包括一个查询表达式翻译器，一个词法语法解析器和一个递归下降处理器，将查询编译成抽象语法树（AST）以供执行。叶节点中子查询的原子性确保了更精确的文档检索和响应生成，显著提高了RAG系统处理复杂查询的能力。",
        "地址": "https://arxiv.org/pdf/2505.11932.pdf"
    },
    {
        "名称": "2025 [2505.12081] VisionReasoner: Unified Visual Perception and Reasoning via Reinforcement Learning.pdf",
        "作者": "Yuqi Liu, Tianyuan Qu, Zhisheng Zhong, Bohao Peng, Shu Liu, Bei Yu, Jiaya Jia",
        "摘要": "摘要: 大型视觉-语言模型表现出处理多种视觉感知任务的内在能力。在本文中，我们介绍了 VisionReasoner，这是一个能够在共享模型内推理和解决多种视觉感知任务的统一框架。具体来说，通过设计新颖的多物体认知学习策略和系统的任务重构，VisionReasoner 增强了其分析视觉输入的推理能力，并在统一框架内解决了各种感知任务。该模型在响应用户查询之前生成结构化的推理过程，以交付所需的输出。为了严格评估统一视觉感知能力，我们在跨越检测、分割和计数三个关键领域的十个不同任务上评估了 VisionReasoner。实验结果表明，作为一个统一模型，VisionReasoner 的性能优越，相较于 Qwen2.5VL，在 COCO（检测）上以 29.1%的相对优势，在 ReasonSeg（分割）上以 22.1%的相对优势，在 CountBench（计数）上以 15.3%的相对优势超越了它。",
        "地址": "https://arxiv.org/pdf/2505.12081.pdf"
    },
    {
        "名称": "2025 [2505.07704] Through the Looking Glass: Common Sense Consistency Evaluation of Weird Images.pdf",
        "作者": "Elisei Rykov, Kseniia Petrushina, Kseniia Titova, Anton Razzhigaev, Alexander Panchenko, Vasily Konovalov",
        "摘要": "摘要：在人工智能研究中，衡量真实图像的视觉效果是一项复杂的任务。例如，沙漠中一个拿着吸尘器的男孩的图像就违反了常识。我们引入了一种新方法，我们称之为\"Through the Looking Glass\"（TLG），利用大型视觉-语言模型（LVLMs）和基于Transformer的编码器来评估图像的常识一致性。通过利用LVLMs从这些图像中提取原子事实，我们获得了准确的事实的混合体。接下来通过对编码的原子事实进行紧凑的注意力池分类器微调。我们的TLG在WHOOPS!和WEIRD数据集上实现了新的最先进性能，同时利用了一个紧凑的微调组件。",
        "地址": "https://arxiv.org/pdf/2505.07704.pdf"
    },
    {
        "名称": "2025 [2505.13180] ViPlan: A Benchmark for Visual Planning with Symbolic Predicates and Vision-Language Models.pdf",
        "作者": "Matteo Merler, Nicola Dainese, Minttu Alakuijala, Giovanni Bonetta, Pietro Ferrazzi, Yu Tian, Bernardo Magnini, Pekka Marttinen",
        "摘要": "摘要：将大型语言模型与符号规划器结合起来，相较于自然语言中的规划，能够获得可验证和有依据的计划。在最近的工作中，这一想法被扩展到使用视觉-语言模型（VLMs）的视觉领域。然而，由于缺乏通用的环境、评估协议和模型覆盖范围，VLM支持的符号方法与直接使用VLM进行规划的方法之间难以进行严格的比较。我们引入了ViPlan，这是第一个使用符号谓词和VLM进行视觉规划的开源基准。ViPlan在两个领域中的一系列逐渐增加难度的任务中具有特色：经典Blocksworld规划问题的视觉变体和模拟家庭机器人环境。我们在多个尺寸的九个开源VLM系列中进行基准测试，并选择了部分封闭模型，评估了基于VLM的符号规划和直接使用模型提出行动的效果。我们发现，在Blocksworld中，符号规划优于直接VLM规划，因为准确的图像基础至关重要；而在家庭机器人任务中，常识知识和从错误中恢复的能力则显得更加有利。最后，我们表明，在大多数模型和方法中，使用连锁思维提示没有显著的利益，这表明当前的VLM仍然在视觉推理方面存在困难。\n\n翻译：摘要：将大型语言模型与符号规划器结合起来是一种有前途的方法，与自然语言中的规划相比，可以获得可验证和有依据的计划，最近的工作将该想法扩展到使用视觉语言模型（VLMs）的视觉领域。然而，由于缺乏通用的环境、评估协议和模型覆盖范围，将VLM支持的符号方法与直接使用VLM进行规划的方法之间的严格比较变得困难。我们推出了ViPlan，这是第一个开源的符号谓词和VLM视觉规划基准。ViPlan在两个领域中的一系列任务中逐步增加难度：经典的Blocksworld规划问题的视觉变体和模拟家庭机器人环境。我们对多个尺寸的九个开源VLM系列以及选定的封闭模型进行了基准测试，评估了基于VLM的符号规划和直接使用模型来提议行动的效果。我们发现，在Blocksworld中，符号规划优于直接的VLM规划，因为准确的图像基础至关重要；而在家庭机器人任务中，常识知识和从错误中恢复的能力是有利的。最后，我们表明，在大多数模型和方法中，使用连锁思维提示没有显著的利益，这表明当前的VLM在视觉推理方面仍然存在困难。",
        "地址": "https://arxiv.org/pdf/2505.13180.pdf"
    },
    {
        "名称": "2025 [2505.13840] EfficientLLM: Efficiency in Large Language Models.pdf",
        "作者": "Zhengqing Yuan, Weixiang Sun, Yixin Liu, Huichi Zhou, Rong Zhou, Yiyang Li, Zheyuan Zhang, Wei Song, Yue Huang, Haolong Jia, Keerthiram Murugesan, Yu Wang, Lifang He, Jianfeng Gao, Lichao Sun, Yanfang Ye",
        "摘要": "摘要：大型语言模型（LLMs）推动了显著的进展，但其不断增长的参数量和上下文窗口导致了计算、能源和金钱成本的极大消耗。我们介绍了EfficientLLM，这是一项新颖的基准测试，也是首个全面的实证研究，评估大规模LLM的效率技术。研究在一个生产级集群（48xGH200，8xH200 GPUs）上进行，系统地探索了三个关键轴：（1）架构预训练（高效注意力变体：MQA、GQA、MLA、NSA；稀疏专家混合（MoE）），（2）微调（参数高效的方法：LoRA、RSLoRA、DoRA），（3）推理（量化方法：int4、float16）。我们定义了六个细粒度指标（内存利用率、计算利用率、延迟、吞吐量、能耗、压缩率）来捕捉硬件饱和、延迟-吞吐平衡和碳成本。通过评估超过100种模型-技术组合（0.5B-72B参数），我们得出三大核心见解：（i）效率涉及可量化的权衡：没有一种方法是普遍最优的；例如，MoE减少了FLOPs并提高了准确性，但导致VRAM增加了40%，而int4量化在内存/能耗上减少了最高达3.9倍，但准确性下降了3-5%。（ii）最优解依赖于任务和规模：对于受限设备，MQA提供了最佳的内存-延迟权衡，MLA在质量关键任务中达到了最低困惑度，而RSLoRA在超过14B参数时效率超过了LoRA。（iii）技术具有跨模态的通用性：我们将评估扩展到大型视觉模型（Stable Diffusion 3.5，Wan 2.1）和视觉-语言模型（Qwen2.5-VL），证实了其有效的迁移能力。通过开源数据集、评估管道和排行榜，EfficientLLM为研究人员和工程师提供了在下代基础模型的效率-性能领域中导航的基本指导。",
        "地址": "https://arxiv.org/pdf/2505.13840.pdf"
    },
    {
        "名称": "2025 [2505.11855] When AI Co-Scientists Fail: SPOT-a Benchmark for Automated Verification of Scientific Research.pdf",
        "作者": "Guijin Son, Jiwoo Hong, Honglu Fan, Heejeong Nam, Hyunwoo Ko, Seungwon Lim, Jinyeop Song, Jinha Choi, Gonçalo Paulo, Youngjae Yu, Stella Biderman",
        "摘要": "摘要：近期在大型语言模型(LLMs)方面的进展推动了自动化科学发现的愿景，通常被称为AI共科学家。迄今为止，先前的工作将这些系统视为生成型共同作者，负责制定假设、整合代码或撰写手稿。在这项工作中，我们探索了一种补充应用：使用LLMs作为验证器自动化科学手稿的学术验证。为此，我们引入了SPOT，一个包含83篇已发表论文的数据集，并配有91个足以促使更正或撤回的重大错误，经过实际作者和人类注释者的交叉验证。评估在SPOT上的最先进LLMs，我们发现没有一个模型的回忆率超过21.1％或准确率超过6.1％（o3取得了最佳成绩，其他几乎为零）。此外，置信估计一律较低，在八次独立运行中，模型很少重新发现相同的错误，从而削弱了它们的可靠性。最终，与领域专家的定性分析表明，即使是最强的模型也会犯类似于学生级别的由于误解产生的错误。这些发现突显了当前LLM能力与可靠AI辅助学术验证的要求之间的巨大差距。",
        "地址": "https://arxiv.org/pdf/2505.11855.pdf"
    },
    {
        "名称": "2025 [2505.13388] R3: Robust Rubric-Agnostic Reward Models.pdf",
        "作者": "David Anugraha, Zilu Tang, Lester James V. Miranda, Hanyang Zhao, Mohammad Rifqi Farhansyah, Garry Kuwanto, Derry Wijaya, Genta Indra Winata",
        "摘要": "摘要:奖赏模型对于使语言模型的输出符合人类偏好至关重要，然而现有的方法往往缺乏可控性和可解释性。这些模型通常针对狭窄的目标进行优化，限制了它们在更广泛的下游任务中的泛化能力。此外，它们的标量输出在没有上下文推理的情况下难以解释。为了解决这些限制，我们引入了R3，这是一种新颖的奖赏建模框架，它与评价标准无关，可以在多个评价维度上泛化，并提供可解释、有理有据的评分分配。R3使语言模型的评价更加透明和灵活，支持与多种人类价值观和用例的强健对齐。我们的模型、数据和代码作为开源提供，详见https URL。",
        "地址": "https://arxiv.org/pdf/2505.13388.pdf"
    },
    {
        "名称": "2025 [2505.12849] Accelerate TarFlow Sampling with GS-Jacobi Iteration.pdf",
        "作者": "Ben Liu, Zhen Qin",
        "摘要": "摘要：图像生成模型已经在广泛的应用中取得了显著成果。作为其中的一个例子，TarFlow模型将transformer架构与规范化流模型结合，在多个基准测试中达到了最先进的结果。然而，由于基于因果形式的一致性需要顺序计算，TarFlow的采样过程极其缓慢。本文通过一系列优化策略，展示了利用高斯-赛德尔-雅可比（GS-Jacobi）迭代方法，可以大大加快TarFlow的采样速度。具体而言，我们发现TarFlow模型中的块具有不同的重要性：少数块在图像生成任务中起主要作用，而其他块的贡献相对较小；某些块对初始值很敏感，容易出现数值溢出，而其他块则相对稳健。基于这两个特征，我们提出了收敛排名度量（CRM）和初始猜测度量（IGM）：CRM用于识别一个TarFlow块是“简单的”（少数迭代即可收敛）还是“困难的”（需要更多迭代）；IGM用于评估迭代的初值是否良好。对四种TarFlow模型的实验表明，GS-Jacobi采样在不降低生成图像质量（通过FID度量）的情况下，可以显著提高采样效率，在Img128cond中加速了4.53倍，在AFHQ中加速了5.32倍，在Img64uncond中加速了2.96倍，在Img64cond中加速了2.51倍。代码和检查点在本文的链接中可获取。\n\n五页评论，包含17页，7个图表，5个表格。\n\n论文网址：https://arxiv.org/pdf/2505.12849.pdf\n\n标题：[2505.12849] 使用GS-Jacobi迭代加速TarFlow采样",
        "地址": "https://arxiv.org/pdf/2505.12849.pdf"
    },
    {
        "名称": "2025 [2505.12058] Tiny QA Benchmark++: Ultra-Lightweight, Synthetic Multilingual Dataset Generation & Smoke-Tests for Continuous LLM Evaluation.pdf",
        "作者": "Vincent Koc",
        "摘要": "摘要：Tiny QA Benchmark++ (TQB++) 提供了一种超轻量级、多语言的烟测试套件，设计用于为大语言模型（LLM）管道提供单元测试风格的安全网数据集，该数据集在几秒钟内运行，成本极低。TQB++ 诞生于 Comet Opik 提示优化 SDK 的紧密反馈循环需求中，在这种情况下，等待重量级基准测试会打断开发人员的工作流程。TQB++ 将一个包含52个项目的英语黄金集（小于20 kB）与一个基于无提供商依赖的 LiteLLM 构建的小型合成数据生成器 pypi 包结合起来。该生成器让从业者可以在任何语言、领域或难度下生成自己的小型数据包，而十个现成的数据包已经涵盖了阿拉伯语、中文、法语、德语、日语、韩语、葡萄牙语、俄语、西班牙语和土耳其语。每个数据集都附带 Croissant 元数据和 OpenAI-Evals、LangChain 和标准 CI 工具的即插即用文件，因此团队可以直接将确定性的微基准测试插入到拉取请求门、提示工程循环和生产仪表板中，而无需动用 GPU 预算。完整的 TQB++ 运行仅增加几秒钟的管道延迟，但可靠地在全规模套件如 MMLU 或 BIG-Bench 完成配置之前标记提示模板错误、分词器漂移和微调副作用。整个框架的发布旨在加速生成式 AI 生态系统中的持续、资源高效的质量保证。",
        "地址": "https://arxiv.org/pdf/2505.12058.pdf"
    },
    {
        "名称": "2025 [2505.13181] Efficient Speech Language Modeling via Energy Distance in Continuous Latent Space.pdf",
        "作者": "Zhengrui Ma, Yang Feng, Chenze Shao, Fandong Meng, Jie Zhou, Min Zhang",
        "摘要": "摘要：我们介绍了SLED，一种通过将语音波形编码为连续潜在表征序列，并使用能量距离目标进行自回归建模的替代语音语言建模方法。能量距离通过对比模拟样本和目标样本，提供了分布间隙的分析测量，从而使训练能够有效地捕捉潜在的连续自回归分布。通过绕过对残差向量量化的依赖，SLED避免了离散化错误，并且不需要现有语音语言模型中常见的复杂层次架构。它在保留语音信息丰富性的同时简化了整体建模流程，并保持了推理效率。实证结果表明，SLED在零样本和流式语音合成中都实现了强大的性能，显示出其在通用语音语言模型中的广泛应用潜力。",
        "地址": "https://arxiv.org/pdf/2505.13181.pdf"
    },
    {
        "名称": "2025 [2505.13437] FinePhys: Fine-grained Human Action Generation by Explicitly Incorporating Physical Laws for Effective Skeletal Guidance.pdf",
        "作者": "Dian Shao, Mingfei Shi, Shengda Xu, Haodong Chen, Yongle Huang, Binglu Wang",
        "摘要": "摘要：尽管视频生成技术已经取得了显著进展，但合成物理上合理的人类动作仍然是一个持续的挑战，特别是在建模细粒度语义和复杂的时间动态方面。例如，生成类似“0.5转体换腿腾跃”的体操动作对当前方法提出了巨大的挑战，经常产生不满意的结果。为了弥补这一差距，我们提出了FinePhys，一种细粒度人类动作生成框架，通过物理法则获得有效的骨骼指引。具体来说，FinePhys首先以在线方式估计2D姿态，然后通过上下文学习进行2D到3D维度提升。为了缓解纯数据驱动3D姿态的不稳定性和有限的可解释性，我们进一步引入了一种基于物理的运动重新估计模块，该模块由欧拉-拉格朗日方程驱动，通过双向时间更新计算关节加速度。物理预测的3D姿态然后与数据驱动的姿态融合，提供多尺度的2D热图指引扩散过程。在FineGym三个细粒度动作子集（FX-JUMP，FX-TURN和FX-SALTO）上的评估结果表明，FinePhys显著优于竞争基线。综合的定性结果进一步证明了FinePhys生成更加自然和合理的细粒度人类动作的能力。\n\n作者：邵典，石铭菲，徐盛达，陈浩东，黄永乐，王秉麓\n\n备注：CVPR 2025\n\n链接：https://arxiv.org/pdf/2505.13437.pdf\n\n标题：2025 [2505.13437] FinePhys: 通过显式将物理法则纳入有效骨骼指引来生成细粒度人类动作",
        "地址": "https://arxiv.org/pdf/2505.13437.pdf"
    },
    {
        "名称": "2025 [2505.10238] MTVCrafter: 4D Motion Tokenization for Open-World Human Image Animation.pdf",
        "作者": "Yanbo Ding, Xirui Hu, Zhizhi Guo, Yali Wang",
        "摘要": "摘要：人像动画由于其在数字人类中的广泛应用而受到越来越多的关注并迅速发展。然而，现有方法在很大程度上依赖二维渲染的姿态图像进行动作指导，这限制了泛化性，并舍弃了开放世界动画所需的重要三维信息。为了解决这个问题，我们提出了MTVCrafter（Motion Tokenization Video Crafter），这是第一个直接对原始三维运动序列（即四维运动）进行建模的人像动画框架。具体来说，我们引入了4DMoT（四维运动标记器）来量化三维运动序列为四维运动标记。与二维渲染的姿态图像相比，四维运动标记提供了更为稳健的时空线索，避免了姿态图像与角色之间严格的像素级对齐，从而实现了更灵活和解耦的控制。随后，我们引入了MV-DiT（动作感知视频DiT）。通过设计独特的具有四维位置编码的动作注意力机制，MV-DiT可以有效利用四维运动标记，作为在复杂三维世界中进行人像动画的紧凑但富有表现力的上下文。因此，这标志着该领域的重要进展，并为姿态引导的人像视频生成开辟了新方向。实验表明，我们的MTVCrafter实现了最先进的结果，FID-VID为6.98，超越第二名65%。得益于稳健的动作标记，MTVCrafter还能够良好地泛化到各种风格和场景中的多样化开放世界角色（单/多、全身/半身）。我们的视频演示和代码请见此：https URL。",
        "地址": "https://arxiv.org/pdf/2505.10238.pdf"
    },
    {
        "名称": "2025 [2505.12996] ExTrans: Multilingual Deep Reasoning Translation via Exemplar-Enhanced Reinforcement Learning.pdf",
        "作者": "Jiaan Wang, Fandong Meng, Jie Zhou",
        "摘要": "摘要: 近年来，大型推理模型（LRMs）的出现，例如OpenAI-o1和DeepSeek-R1，在复杂问题（如数学和编程）中展示了令人印象深刻的能力。一些开创性的研究尝试将LRMs在神经机器翻译（MT）中的成功引入。他们尝试通过强化学习（RL）构建具有深度推理MT能力的LRMs。尽管取得了一些进展，但这些尝试通常集中在几种资源丰富的语言（如英语和中文），其他语言的表现尚不清楚。此外，前人工作的奖励建模方法并未充分释放强化学习在MT中的潜力。在这项工作中，我们首先设计了一种新的奖励建模方法，将策略MT模型的翻译结果与强大的LRM（即DeepSeek-R1-671B）进行比较，并量化比较结果以提供奖励。实验结果证明了这种奖励建模方法的优势。以Qwen2.5-7B-Instruct为骨干，训练后的模型在文学翻译中达到了新的最先进性能，优于包括OpenAI-o1和DeepSeeK-R1在内的强大LRMs。此外，我们将我们的方法扩展到包括11种语言的多语言设置。通过精心设计的轻量级RL奖励建模，我们可以简单地将强大的MT能力从单一方向转移到多个（即90个）翻译方向，并在多语言MT性能中取得令人印象深刻的成绩。\n\n作者: 王家安，孟繁东，周杰\n\n评论: 12页，2幅图\n\n网址: [https://arxiv.org/pdf/2505.12996.pdf](https://arxiv.org/pdf/2505.12996.pdf)\n\n标题: 2025 [2505.12996] ExTrans: 多语言深度推理翻译通过范例增强的强化学习",
        "地址": "https://arxiv.org/pdf/2505.12996.pdf"
    },
    {
        "名称": "2025 [2505.12120] HISTAI: An Open-Source, Large-Scale Whole Slide Image Dataset for Computational Pathology.pdf",
        "作者": "Dmitry Nechaev, Alexey Pchelnikov, Ekaterina Ivanova",
        "摘要": "摘要: 数字病理学（DP）的最新进展，尤其是通过人工智能和基础模型，强调了大规模、多样化和详细注释数据集的重要性。尽管它们在这一领域中至关重要，但公开可用的全幻灯片图像（WSI）数据集往往缺乏足够的规模、组织多样性和全面的临床元数据，从而限制了AI模型的鲁棒性和普遍适用性。为此，我们介绍了HISTAI数据集，这是一个大型、多模态、开放访问的WSI集合，包含来自各种组织类型的超过6万张幻灯片。HISTAI数据集中的每个病例都附有广泛的临床元数据，包括诊断、人口信息、详细的病理注释和标准化的诊断编码。该数据集旨在填补现有资源中的空白，促进创新、可重复性以及临床相关计算病理学解决方案的发展。该数据集可在此https URL访问。\n\n来源： 'https://arxiv.org/pdf/2505.12120.pdf'",
        "地址": "https://arxiv.org/pdf/2505.12120.pdf"
    },
    {
        "名称": "2025 [2505.11497] QVGen: Pushing the Limit of Quantized Video Generative Models.pdf",
        "作者": "Yushi Huang, Ruihao Gong, Jing Liu, Yifu Ding, Chengtao Lv, Haotong Qin, Jun Zhang",
        "摘要": "摘要：视频扩散模型（DMs）已经实现了高质量的视频合成。然而，它们的高计算和内存需求对实际应用部署构成了严重挑战，即使在高端GPU上也是如此。量化作为一种常见的解决方案，已经在降低图像DMs的成本方面证明了其显著成功，但直接应用于视频DMs仍然无效。本文提出了QVGen，这是一种新颖的量化感知训练（QAT）框架，专为极低比特量化（例如4-bit或以下）的高性能和推理高效的视频DMs设计。我们首先进行理论分析，证明减少梯度范数对于促进QAT的收敛至关重要。为此，我们引入了辅助模块（$\\Phi$）来减小大的量化误差，从而显著提高收敛性。为了消除$\\Phi$ 的推理开销，我们提出了一种逐步消除$\\Phi$ 的秩衰减策略。在这一策略中，我们反复使用奇异值分解（SVD）和提出的基于秩的正则化$\\mathbf{\\gamma}$ 来识别和减少低贡献组件。这一策略在零推理开销的情况下保持了性能。在四种最先进（SOTA）视频DMs上的广泛实验，参数规模从1.3B到14B不等，表明QVGen是第一个在4-bit设置下达到全精度可比质量的方法。此外，它显著优于现有方法。例如，我们的3-bit CogVideoX-2B在动态度量上提高了25.28，在场景一致性上提高了8.43（基于VBench）。\n\n这项工作由以下作者完成：Yushi Huang, Ruihao Gong, Jing Liu, Yifu Ding, Chengtao Lv, Haotong Qin, Jun Zhang。文章的详细信息可通过以下链接获取：[https://arxiv.org/pdf/2505.11497.pdf](https://arxiv.org/pdf/2505.11497.pdf)，代码将在论文被接受后发布。",
        "地址": "https://arxiv.org/pdf/2505.11497.pdf"
    },
    {
        "名称": "2025 [2505.11484] SoftCoT++: Test-Time Scaling with Soft Chain-of-Thought Reasoning.pdf",
        "作者": "Yige Xu, Xu Guo, Zhiwei Zeng, Chunyan Miao",
        "摘要": "摘要：测试时间缩放（TTS）指的是在推理过程中分配额外的计算资源以提高推理性能的方法，而无需更改模型的参数。虽然现有的TTS方法通过生成更多的中间步骤在离散的token空间中操作，最近的Coconut和SoftCoT的研究表明，在连续的潜在空间中进行思考可以进一步增强推理性能。这些潜在的思维编码了信息丰富的思维，而没有与自回归token生成相关的信息损失，激发了对连续空间推理的兴趣。与在离散解码中通过重复采样来探索不同的推理路径相比，连续空间中的潜在表示对于给定的输入时是固定的，这限制了多样化的探索，因为所有解码路径都源自相同的潜在思维。为了解决这一限制，我们引入了SoftCoT++，通过允许对思维路径进行多样化的探索，将SoftCoT扩展到测试时间缩放范式。具体而言，我们通过多个专门的初始token扰动潜在思维，并应用对比学习来促进软思维表示之间的多样性。在五个推理基准和两种不同的LLM架构上的实验表明，SoftCoT++显著提升了SoftCoT，并且在自一致性缩放方面也优于SoftCoT。此外，它与传统的缩放技术（如自一致性）显示出很强的兼容性。源代码可在此https URL获得。",
        "地址": "https://arxiv.org/pdf/2505.11484.pdf"
    },
    {
        "名称": "2025 [2505.12872] From Grunts to Grammar: Emergent Language from Cooperative Foraging.pdf",
        "作者": "Maytus Piriyajitakonkij, Rujikorn Charakorn, Weicheng Tao, Wei Pan, Mingfei Sun, Cheston Tan, Mengmi Zhang",
        "摘要": "摘要：早期的穴居人依靠手势、声声和简单的信号来协调、计划、躲避捕食者以及分享资源。如今，人类使用复杂的语言进行合作以取得显著成果。是什么推动了这种沟通进化？语言如何出现、适应并成为团队合作的关键？理解语言的起源仍然是一个挑战。语言学和人类学中的一个主要假说认为，语言是为了满足早期人类合作的生态和社会需求而进化的。语言不是孤立出现的，而是通过共享的生存目标产生的。受此观点启发，我们在多智能体觅食游戏中研究了语言的出现。这些环境设计反映了被认为影响沟通进化的认知和生态约束。智能体在一个共享的网格世界中操作，对其他智能体和环境只有部分了解，必须协作完成如拾取高价值目标或执行按时间顺序排列的动作等游戏。使用端到端深度强化学习，智能体从头开始学习动作和沟通策略。我们发现，智能体开发了具有自然语言标志性特征的沟通协议：任意性、可交换性、移位、文化传递和组成性。我们量化了每个特性，并分析了不同因素（如人口规模和时间依赖性）如何影响新兴语言的特定方面。我们的框架作为一个平台，用于研究语言如何在部分可观测性、时间推理和合作目标的体现中进化。我们将公开所有数据、代码和模型。\n\n作者：Maytus Piriyajitakonkij, Rujikorn Charakorn, Weicheng Tao, Wei Pan, Mingfei Sun, Cheston Tan, Mengmi Zhang\n\n链接：https://arxiv.org/pdf/2505.12872.pdf\n\n标题：从咕哝到语法：从合作觅食中出现的语言",
        "地址": "https://arxiv.org/pdf/2505.12872.pdf"
    },
    {
        "名称": "2025 [2505.12781] A Token is Worth over 1,000 Tokens: Efficient Knowledge Distillation through Low-Rank Clone.pdf",
        "作者": "Jitai Hao, Qiang Huang, Hao Liu, Xinyan Xiao, Zhaochun Ren, Jun Yu",
        "摘要": "摘要：\n训练高性能的小型语言模型（SLMs）即使在利用知识蒸馏和从较大的教师模型进行剪枝的情况下，仍然代价不菲。现有研究通常面临三个关键挑战：(1) 硬剪枝导致的信息损失，(2) 表示对齐效率低下，(3) 特别是来自前馈网络（FFNs）的信息激活未得到充分利用。为解决这些问题，我们引入了低秩克隆（LRC），这是一种旨在构建行为等效于强大教师模型的SLMs的高效预训练方法。LRC训练了一组低秩投影矩阵，通过压缩教师权重来实现软剪枝，并通过对齐学生激活（包括FFN信号）与教师激活来实现激活克隆。这个统一的设计最大限度地实现了知识转移，同时消除了对显式对齐模块的需求。我们使用开源教师模型（例如，Llama-3.2-3B-Instruct, Qwen2.5-3B/7B-Instruct）进行了广泛实验，结果表明LRC匹配或超越了使用万亿级别token训练的最先进模型，而仅使用了20B的tokens，达到了超过1,000倍的训练效率。我们的代码和模型检查点可在此https URL和此https URL获取。",
        "地址": "https://arxiv.org/pdf/2505.12781.pdf"
    },
    {
        "名称": "2025 [2505.11988] TechniqueRAG: Retrieval Augmented Generation for Adversarial Technique Annotation in Cyber Threat Intelligence Text.pdf",
        "作者": "Ahmed Lekssays, Utsav Shukla, Husrev Taha Sencar, Md Rizwan Parvez",
        "摘要": "摘要：准确识别安全文本中的对抗技术对于有效的网络防御至关重要。然而，现有方法面临着一个基本的权衡：它们要么依赖于通用模型，精度有限，要么需要资源密集的流程，依赖于大量标注数据和任务特定的优化，例如自定义的硬负样本挖掘和去噪，这些资源在专业领域中很少可用。我们提出了TechniqueRAG，这是一种特定领域的检索增强生成（RAG）框架，通过集成现成的检索器、指令调整的大型语言模型（LLM）和最少的文本-技术对来弥合这一差距。我们的方法通过仅对生成组件在有限的域内示例上进行微调来解决数据稀缺问题，从而避免了资源密集型的检索训练。尽管传统的RAG将检索与生成相结合，以减轻幻觉问题，但它依赖于通用检索器通常会引入嘈杂的候选项，限制了特定领域的精度。为了解决这一问题，我们通过零样本LLM重新排序来提高检索质量和领域特异性，这种方法显式地将检索到的候选与对抗技术对齐。在多个安全基准上的实验表明，TechniqueRAG无需广泛的任务特定优化或标注数据，即可实现最先进的性能，同时全面的分析提供了进一步的见解。\n\n作者：Ahmed Lekssays, Utsav Shukla, Husrev Taha Sencar, Md Rizwan Parvez\n\n评论：已被ACL 2025（Findings）接收\n\n链接：https://arxiv.org/pdf/2505.11988.pdf\n\n标题：TechniqueRAG: 用于网络威胁情报文本中对抗技术注释的检索增强生成技术",
        "地址": "https://arxiv.org/pdf/2505.11988.pdf"
    },
    {
        "名称": "2025 [2505.11733] MedCaseReasoning: Evaluating and learning diagnostic reasoning from clinical case reports.pdf",
        "作者": "Kevin Wu, Eric Wu, Rahul Thapa, Kevin Wei, Angela Zhang, Arvind Suresh, Jacqueline J. Tao, Min Woo Sun, Alejandro Lozano, James Zou",
        "摘要": "摘要：医生和患者越来越多地使用大型语言模型(LLMs)来诊断临床病例。然而，与数学或编程等领域不同，在这些领域中，正确性可以通过最终答案客观地定义，医学诊断不仅要求结果准确，还要求推理过程准确。目前，广泛使用的医学基准如MedQA和MMLU仅评估最终答案的准确性，忽略了临床推理过程的质量和忠实性。为了应对这一限制，我们引入了MedCaseReasoning，这是第一个用于评估LLMs与临床医生撰写的诊断推理对齐能力的开放数据集。该数据集包括14,489个诊断问答病例，每个病例都附有详细的推理陈述，这些陈述源自开放访问的医学病例报告。我们在MedCaseReasoning上评估了最先进的推理LLMs，发现它们在诊断和推理方面存在显著不足：例如，表现最佳的开源模型DeepSeek-R1在10次测试中的诊断准确率仅为48%，仅提及了64%的临床医生推理陈述（召回率）。然而，我们表明，通过在来源于MedCaseReasoning的推理轨迹上微调LLMs，可以显著提高诊断准确性和临床推理召回率，平均相对增益分别为29%和41%。开放数据集、代码和模型可在此网址获得： https://arxiv.org/pdf/2505.11733.pdf。",
        "地址": "https://arxiv.org/pdf/2505.11733.pdf"
    },
    {
        "名称": "2025 [2505.11475] HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages.pdf",
        "作者": "Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Hoo-Chang Shin, Felipe Soares, Alexander Bukharin, Ellie Evans, Yi Dong, Oleksii Kuchaiev",
        "摘要": "摘要：偏好数据集对于使用人类反馈强化学习（RLHF）训练通用领域的指令跟踪语言模型至关重要。每一次数据集的发布都提高了对未来数据收集的期望，这意味着需要不断提高公开可用的偏好数据的质量和多样性。为了解决这一需求，我们介绍了HelpSteer3-Preference，这是一份具有宽松许可（CC-BY-4.0）的高质量人工注释偏好数据集，包含超过40,000个样本。这些样本涵盖了大型语言模型（LLMs）的各种现实世界应用，包括与STEM、编程和多语言场景相关的任务。使用HelpSteer3-Preference，我们训练了奖励模型（RMs），这些模型在RM-Bench（82.4%）和JudgeBench（73.7%）上取得了顶级性能。这比现有RMs的最佳报告结果有了显著提升（约10%的绝对值）。我们展示了HelpSteer3-Preference还可以用于训练生成RMs以及如何使用我们的RMs对策略模型进行RLHF对齐。数据集（CC-BY-4.0）:此链接。\n\n作者：Zhilin Wang, Jiaqi Zeng, Olivier Delalleau, Hoo-Chang Shin, Felipe Soares, Alexander Bukharin, Ellie Evans, Yi Dong, Oleksii Kuchaiev\n\n评论：38页，2个图\n\n链接：https://arxiv.org/pdf/2505.11475.pdf\n\n标题：2025 [2505.11475] HelpSteer3-Preference: Open Human-Annotated Preference Data across Diverse Tasks and Languages.pdf",
        "地址": "https://arxiv.org/pdf/2505.11475.pdf"
    },
    {
        "名称": "2025 [2505.10420] Learned Lightweight Smartphone ISP with Unpaired Data.pdf",
        "作者": "Andrei Arhire, Radu Timofte",
        "摘要": "摘要：图像信号处理器（ISP）是现代智能手机摄像头中的基本组件，负责将RAW传感器图像数据转换为RGB图像，重点关注感知质量。最近的研究强调了深度学习方法的潜力及其捕捉细节的能力，质量越来越接近专业相机。在开发学习型ISP时，一个困难且昂贵的步骤是获取像素级对齐的配对数据，将智能手机摄像头传感器捕捉的原始数据映射到高质量参考图像。在这项工作中，我们提出了一种新的训练方法，用于学习型ISP，消除了对内容匹配的原始图像和真实数据之间的直接对应关系的需求。我们的未配对方法使用由对抗训练指导的多项损失函数，通过多个处理来自预训练网络的特征图的判别器来保持内容结构，同时从目标RGB数据集中学习颜色和纹理特征。使用适用于移动设备的轻量级神经网络架构作为骨干，我们在苏黎世RAW到RGB和富士UltraISP数据集上评估了我们的方法。与配对训练方法相比，我们的未配对学习策略显示出强大的潜力，并在多个评估指标上实现了高保真度。代码和预训练模型可在此URL获得。\n\n作者：Andrei Arhire, Radu Timofte\n\n备注：已被CVPRW 2025接受\n\n链接：https://arxiv.org/pdf/2505.10420.pdf\n\n标题：2025 [2505.10420] Learned Lightweight Smartphone ISP with Unpaired Data.pdf",
        "地址": "https://arxiv.org/pdf/2505.10420.pdf"
    },
    {
        "名称": "2025 [2505.12257] LLM Context Conditioning and PWP Prompting for Multimodal Validation of Chemical Formulas.pdf",
        "作者": "Evgeny Markhasin",
        "摘要": "摘要：识别复杂科学和技术文档中的细微技术错误（尤其是需要多模态解释的，如图像中的公式）对大型语言模型（LLMs）来说是一个显著的挑战，因为它们固有的错误纠正倾向可能掩盖不准确性。本概念验证研究探讨了一种结构化的LLM上下文调控方法，基于持久性工作流程提示（PWP）原理，以此作为推理时调节这种LLM行为的方法。该方法旨在提高现成通用LLMs（特别是Gemini 2.5 Pro和ChatGPT Plus o3）的验证任务准确性，关键在于仅依赖其标准聊天界面，而无需API访问或模型修改。为探索这一方法，我们专注于验证一个已知包含文字和图像错误的复杂测试论文中的化学公式。评估了几种提示策略：基本提示不可靠，而适应 PWP 结构以严格调控 LLM 的分析心态的方法似乎改善了两个模型的文本错误识别能力。值得注意的是，这种方法还引导 Gemini 2.5 Pro 多次识别出手动审查时曾忽视的细微图片公式错误，ChatGPT Plus o3 在我们的测试中未能做到这一点。这些初步发现强调了妨碍详细验证的特定LLM操作模式，并表明基于PWP的上下文调控为开发更稳健的LLM驱动分析工作流程提供了一种有前途且高度可行的技术，尤其适用于需要在科学和技术文档中进行细致错误检测的任务。要验证这种方法的广泛适用性，还需进行广泛的验证。\n\n翻译：（完成）",
        "地址": "https://arxiv.org/pdf/2505.12257.pdf"
    },
    {
        "名称": "2025 [2505.10831] Creating General User Models from Computer Use.pdf",
        "作者": "Omar Shaikh, Shardul Sapkota, Shan Rizvi, Eric Horvitz, Joon Sung Park, Diyi Yang, Michael S. Bernstein",
        "摘要": "摘要：人机交互领域长期以来设想的技术是能够理解我们的——包括我们的偏好和习惯，以及我们日常行为的时间和目的。然而，目前的用户模型仍然是零散的，专门为特定应用程序量身定做，无法进行满足这些愿景所需的灵活推理。本文提出了一种通用用户模型（GUM）架构，通过观察用户与计算机的任何交互来学习有关用户的信息。GUM以用户的任何非结构化观察（例如，设备截图）作为输入，并构建捕获用户知识和偏好的置信度加权命题。GUM可以从与朋友的消息中推断出用户正在筹备他们即将参加的婚礼。或者通过观察多次停滞的编辑和转向阅读相关工作，识别用户在与合作者的反馈中遇到了困难。GUM引入了一种架构，用于从多模态观察中推断用户的新命题，检索相关命题以提供上下文，并不断修订现有命题。为了展示GUM启用应用的广度，我们演示了它们如何为基于聊天的助手提供上下文，管理操作系统通知以选择性地展示重要信息，并使交互代理能够适应跨应用的偏好。我们还实例化了主动助手（GUMBO），它们使用GUM来发现并执行对用户有用的建议。在我们的评估中，我们发现GUM对用户的推断是校准且准确的，并且基于GUM构建的助手能够主动识别并执行用户不会明确请求的操作。总的来说，GUM引入了利用多模态模型理解非结构化上下文的方法，实现了人机交互的长期愿景，并启用了预见用户需求的全新交互系统。",
        "地址": "https://arxiv.org/pdf/2505.10831.pdf"
    },
    {
        "名称": "2025 [2505.03332] AI-Driven Scholarly Peer Review via Persistent Workflow Prompting, Meta-Prompting, and Meta-Reasoning.pdf",
        "作者": "Evgeny Markhasin",
        "摘要": "摘要：科学手稿的严格同行评审对大型语言模型（LLMs）而言是极大的挑战，这一方面是由于数据的限制，另一方面是由于专家推理的复杂性。本文提出了持续工作流提示（Persistent Workflow Prompting, PWP），这是一种可能广泛适用的提示工程方法，旨在利用标准的LLM聊天接口（零编码、无API）来弥补这一差距。我们展示了一个用于实验化学手稿批判性分析的概念验证PWP提示，该提示具有层次化、模块化架构（通过Markdown结构化），定义了详细的分析工作流。我们通过迭代应用元提示技术和元推理，系统地编纂专家评审工作流程，包括隐性知识，以开发这个PWP提示。PWP提示在会话开始时提交一次，装备LLM以持续工作流被后续查询触发，引导现代推理LLMs进行系统的、多模式的评估。演示显示，PWP引导的LLM能够在测试案例中识别出主要的研究方法缺陷，同时减少了LLM输入偏差，并执行复杂任务，包括区分主张与证据、整合文本/图片/图表分析推断参数、执行定量可行性检查、将估计值与主张进行比较，以及评估先验合理性。为确保透明度并促进复制，我们提供了完整的提示、详细的演示分析和互动聊天记录作为辅助资源。除了具体应用之外，这项工作还提供了对元开发过程本身的见解，突显了由详细工作流形式化所启发的PWP在利用现成的LLMs进行复杂科学任务分析中的潜力。",
        "地址": "https://arxiv.org/pdf/2505.03332.pdf"
    },
    {
        "名称": "2025 [2505.12973] Fast, Not Fancy: Rethinking G2P with Rich Data and Rule-Based Models.pdf",
        "作者": "Mahta Fetrat Qharabagh, Zahra Dehghanian, Hamid R. Rabiee",
        "摘要": "摘要：同形异义词消歧在由字母到音素（G2P）转换中，特别是对于低资源语言，仍然是一个重大挑战。这个挑战有两个方面：（1）创建平衡且全面的同形异义词数据集既费力又昂贵，（2）特定的消歧策略会引入额外的延迟，使它们不适用于实时应用，如屏幕阅读器和其他辅助工具。在本文中，我们解决了这两个问题。首先，我们提出了一个半自动化的同形异义词数据集构建流程，介绍了通过该流程生成的HomoRich数据集，并通过将其应用于增强基于深度学习的波斯语G2P系统，展示了其有效性。其次，我们倡导范式转变——利用丰富的离线数据集来开发适用于对延迟敏感的辅助应用（如屏幕阅读器）的快速规则方法。为此，我们改进了最著名的规则基础G2P系统之一，即eSpeak，使其成为一个快速且同形异义词感知版本，HomoFast eSpeak。我们的结果显示，基于深度学习的系统和eSpeak系统在同形异义词消歧准确率方面大约提高了30%。\n\n翻译者：Mahta Fetrat Qharabagh，Zahra Dehghanian，Hamid R. Rabiee",
        "地址": "https://arxiv.org/pdf/2505.12973.pdf"
    },
    {
        "名称": "2025 [2505.13511] Can AI Freelancers Compete? Benchmarking Earnings, Reliability, and Task Success at Scale.pdf",
        "作者": "David Noever, Forrest McKee",
        "摘要": "摘要：本研究探讨了大型语言模型(LLMs)作为现实世界任务的自主代理，包括自由职业的软件开发。本文提出了一个新的基准，用于评估LLMs在源自经济数据的自由职业编程和数据分析任务中的表现。我们使用从Kaggle自由职业者数据集中的工作发布创建的合成任务构建了该基准，所有任务的价格均以美元标准化（中位数固定项目价格约为250美元，平均为306美元）。每个任务都附有结构化的输入输出测试用例和一个估计的价格标签，便于自动正确性检查和货币绩效评估。这种方法受到OpenAI最近的SWE-Lancer基准的启发（包含1,400个价值总共100万美元的真实Upwork任务）。然而，我们的框架通过使用可编程测试的任务和预测价格值简化了评估，使其高度可扩展和可重复。在这个基准上，我们评估了四个现代LLMs——Claude 3.5 Haiku、GPT-4o-mini、Qwen 2.5和Mistral。我们报告了每个模型的准确性（任务成功率和测试用例通过率）以及其达到的总“自由职业收入”（解决任务的价格总和）。结果表明，Claude 3.5 Haiku表现最佳，赚取了约152万美元，其次是GPT-4o-mini，为149万美元，然后是Qwen 2.5（133万美元）和Mistral（70万美元）。我们分析了每个任务的错误分布，并观察到最强的模型解决了最多的任务，很少在任何项目上完全失败。我们讨论了这些结果对人工智能作为自由职业开发者的可行性的影响、我们自动化基准方法的优缺点，以及在结构化任务上的表现与真实世界自由职业工作的复杂性之间的差距。",
        "地址": "https://arxiv.org/pdf/2505.13511.pdf"
    }
]