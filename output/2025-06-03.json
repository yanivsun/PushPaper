[
    {
        "名称": "2025 [2506.01939] Beyond the 80/20 Rule: High-Entropy Minority Tokens Drive Effective Reinforcement Learning for LLM Reasoning.pdf",
        "作者": "Shenzhi Wang, Le Yu, Chang Gao, Chujie Zheng, Shixuan Liu, Rui Lu, Kai Dang, Xionghui Chen, Jianxin Yang, Zhenru Zhang, Yuqiong Liu, An Yang, Andrew Zhao, Yang Yue, Shiji Song, Bowen Yu, Gao Huang, Junyang Lin",
        "摘要": "摘要：具有可验证奖励的强化学习（RLVR）作为增强大型语言模型（LLMs）推理能力的强大方法出现，但其机制尚未完全理解。在这项工作中，我们通过新颖的令牌熵模式视角对RLVR进行了开创性探索，全面分析了不同令牌如何影响推理性能。通过在链式思维（CoT）推理中检查令牌熵模式，我们观察到只有少数令牌表现出高熵，这些令牌作为关键分叉，引导模型走向不同的推理路径。此外，研究RLVR训练期间熵模式的演变发现，RLVR主要遵循基础模型的熵模式，主要调整高熵令牌的熵。这些发现强调了高熵令牌（即分叉令牌）对RLVR的重要性。我们最终通过限制策略梯度更新到分叉令牌来改进RLVR，并发现了一项超越80/20法则的结果：仅使用20%的令牌时，性能与在Qwen3-8B基础模型上进行全面梯度更新相当，并在Qwen3-32B（在AIME'25上提高11.04，在AIME'24上提高7.71）和Qwen3-14B（在AIME'25上提高4.79，在AIME'24上提高5.21）基础模型上显著超过全面梯度更新，显示出强大的扩展性趋势。相对地，仅在表现出80%最低熵的令牌上进行训练会导致性能显著下降。这些发现表明，RLVR的效力主要来自于优化决定推理方向的高熵令牌。总体而言，我们的结果强调了通过令牌熵视角理解RLVR的潜力，并通过利用高熵少数令牌来进一步提升LLM推理。",
        "地址": "https://arxiv.org/pdf/2506.01939.pdf"
    },
    {
        "名称": "2025 [2505.24760] REASONING GYM: Reasoning Environments for Reinforcement Learning with Verifiable Rewards.pdf",
        "作者": "Zafir Stojanovski, Oliver Stanley, Joe Sharratt, Richard Jones, Abdulhakeem Adefioye, Jean Kaddour, Andreas Köpf",
        "摘要": "摘要：我们介绍了Reasoning Gym (RG)，这是一个用于强化学习并具有可验证奖励的推理环境库。它提供了超过100个数据生成器和验证器，涵盖了多个领域，包括代数、算术、计算、认知、几何、图论、逻辑以及各种常见游戏。其核心创新在于能够生成几乎无限的训练数据，并且复杂性可调，而不像大多数以前的推理数据集，通常是固定的。这种程序化生成方法允许在不同难度级别上进行持续评估。我们的实验结果证明了RG在推理模型的评估和强化学习方面的有效性。",
        "地址": "https://arxiv.org/pdf/2505.24760.pdf"
    },
    {
        "名称": "2025 [2506.01844] SmolVLA: A Vision-Language-Action Model for Affordable and Efficient Robotics.pdf",
        "作者": "Mustafa Shukor, Dana Aubakirova, Francesco Capuano, Pepijn Kooijmans, Steven Palma, Adil Zouitine, Michel Aractingi, Caroline Pascal, Martino Russi, Andres Marafioti, Simon Alibert, Matthieu Cord, Thomas Wolf, Remi Cadene",
        "摘要": "论文标题: 2025 [2506.01844] SmolVLA: A Vision-Language-Action Model for Affordable and Efficient Robotics\n\n摘要: 视觉-语言模型（VLMs）预训练于大规模多模态数据集上，编码了丰富的视觉和语言知识，使其成为机器人技术的重要基础。与从零开始训练机器人策略相比，最近的方法将VLMs适配为视觉-语言-动作（VLA）模型，从而实现自然语言驱动的感知和控制。然而，现有的VLAs通常都非常庞大——通常包含数十亿参数——导致训练成本高，实际部署能力有限。此外，它们依赖于学术和工业数据集，忽视了越来越多的由低成本机器人平台收集的社区数据。在这项工作中，我们提出了SmolVLA，一种小型、高效且由社区驱动的VLA，大幅降低了训练和推理成本，同时保持了竞争性能。SmolVLA被设计为可在单个GPU上训练，并可部署在消费级GPU甚至CPU上。为了进一步提高响应能力，我们引入了一个异步推理栈，将感知和动作预测与动作执行解耦，从而实现更高的控制率和分块动作生成。尽管体积紧凑，SmolVLA实现了与大10倍的VLA相当的性能。我们在一系列模拟和现实世界的机器人基准上评估了SmolVLA，并发布了所有代码、预训练模型和训练数据。",
        "地址": "https://arxiv.org/pdf/2506.01844.pdf"
    },
    {
        "名称": "2025 [2506.00539] ARIA: Training Language Agents with Intention-Driven Reward Aggregation.pdf",
        "作者": "Ruihan Yang, Yikai Zhang, Aili Chen, Xintao Wang, Siyu Yuan, Jiangjie Chen, Deqing Yang, Yanghua Xiao",
        "摘要": "摘要：大型语言模型（LLMs）使代理能够通过自由形式的语言交互执行复杂的推理和决策。然而，在开放式语言动作环境（例如，谈判或问答游戏）中，动作空间可以表示为一种联合分布的标记，从而产生指数级大的动作空间。在这样的空间中采样动作可能导致极端的奖励稀疏性，这带来较大的奖励方差，阻碍了有效的强化学习（RL）。为了解决这个问题，我们提出了ARIA，一种在意图空间中聚合奖励的方法，以实现高效且有效的语言代理训练。ARIA旨在将自然语言动作从高维联合标记分布空间投射到低维意图空间，在那里语义相似的动作被聚类并分配共享奖励。这种意图感知的奖励聚合通过稠密化奖励信号来减少奖励方差，促进更好的策略优化。大量实验证明，ARIA不仅显著减少了策略梯度方差，还在四项后续任务中实现了平均9.95%的显著性能提升，始终优于离线和在线RL基线模型。",
        "地址": "https://arxiv.org/pdf/2506.00539.pdf"
    },
    {
        "名称": "2025 [2506.00996] Temporal In-Context Fine-Tuning for Versatile Control of Video Diffusion Models.pdf",
        "作者": "Kinam Kim, Junha Hyung, Jaegul Choo",
        "摘要": "摘要：最近在文本到视频扩散模型方面的进展使得高质量视频合成成为可能，但在数据和计算有限的情况下，可控生成仍然具有挑战性。现有的条件生成微调方法通常依赖于外部编码器或架构修改，这需要大规模数据集，并且通常仅限于空间对齐的条件，限制了灵活性和可扩展性。在这项工作中，我们介绍了时序上下文微调（TIC-FT），这是一种有效且多功能的方法，用于使预训练的视频扩散模型适应多种条件生成任务。我们关键的想法是沿时间轴连接条件帧和目标帧，并插入噪声水平逐渐增加的中间缓冲帧。这些缓冲帧使过渡更加平滑，使微调过程与预训练模型的时序动态对齐。TIC-FT不需要架构修改，并且在仅有10-30个训练样本的情况下即可实现强性能。我们通过一系列任务验证了我们的方法，包括图像到视频和视频到视频生成，使用大型基模型如CogVideoX-5B和Wan-14B。大量实验证明，TIC-FT在条件保真度和视觉质量方面优于现有基线，同时在训练和推理方面保持高度效率。\n\n翻译：\n最近在文本到视频扩散模型方面的进展使得高质量视频合成成为可能，但在数据和计算有限的情况下，可控生成仍然具有挑战性。现有的条件生成微调方法通常依赖于外部编码器或架构修改，这需要大规模数据集并且通常仅限于空间对齐的条件，限制了灵活性和可扩展性。在这项工作中，我们提出了一种高效且多功能的方法来对预训练视频扩散模型进行适应，用于各种条件生成任务，称为时序上下文微调（TIC-FT）。我们的核心观点是沿时间轴连接条件帧和目标帧，并插入噪声水平逐渐增加的中间缓冲帧。这些缓冲帧使过渡更加平滑，使微调过程与预训练模型的时序动态对齐。TIC-FT无需架构修改，并且在仅有10-30个训练样本的情况下即可实现良好的性能。我们通过一系列任务验证了我们的方法，包括图像到视频和视频到视频生成，使用大型基模型如CogVideoX-5B和Wan-14B。大量实验表明，TIC-FT在条件保真度和视觉质量方面优于现有基线，同时在训练和推理中保持高度效率。",
        "地址": "https://arxiv.org/pdf/2506.00996.pdf"
    },
    {
        "名称": "2025 [2506.01853] ShapeLLM-Omni: A Native Multimodal LLM for 3D Generation and Understanding.pdf",
        "作者": "Junliang Ye, Zhengyi Wang, Ruowen Zhao, Shenghao Xie, Jun Zhu",
        "摘要": "摘要：近来，随着ChatGPT-4o强大的文本生成图像能力受到越来越多的关注，人们开始重视原生多模态大型语言模型。然而，它的多模态能力仍然局限于图像和文本。除了图像之外，理解和生成三维内容的能力同样重要。为了解决这一差距，我们提出了ShapeLLM-Omni，一个能够理解和生成三维资产以及进行文本生成的原生三维大型语言模型。首先，我们训练了一个三维向量量化变分自编码器（VQVAE），它将三维对象映射到离散潜在空间中，以实现高效且准确的形状表示和重构。基于三维感知离散标记，我们创新性地构建了一个名为3D-Alpaca的大规模连续训练数据集，涵盖了生成、理解和编辑，为未来研究和训练提供了丰富的资源。最后，我们通过对Qwen-2.5-vl-7B-Instruct模型在3D-Alpaca数据集上进行基于指令的训练，我们的工作提供了一个扩展多模态模型的有效尝试，具有基础的三维能力，这为未来三维原生AI的研究做出了贡献。\n\n项目页面：此 https URL",
        "地址": "https://arxiv.org/pdf/2506.01853.pdf"
    },
    {
        "名称": "2025 [2506.00411] LoHoVLA: A Unified Vision-Language-Action Model for Long-Horizon Embodied Tasks.pdf",
        "作者": "Yi Yang, Jiaxuan Sun, Siqi Kou, Yihan Wang, Zhijie Deng",
        "摘要": "摘要：现实世界中的具身代理需要面对长远的任务，这些任务具有需要多步骤解决方案的高层次目标，超出单一行为的范畴。成功导航这些任务需要高层次任务规划（即将目标分解为子任务）和低层次运动控制（即生成精确的机器人动作）。虽然现有的视觉语言动作（VLA）模型和层次结构在具身任务中具有潜力，但前者在规划方面常常表现不佳，后者可能会受到协调问题的影响，从而阻碍性能。我们提出了一种用于长远任务的新统一VLA框架，称为LoHoVLA，以克服这些限制。LoHoVLA利用一个大型预训练的视觉语言模型（VLM）作为主干，联合生成语言和动作令牌，分别用于子任务生成和机器人动作预测。这种共享表示促进了任务间的更好泛化。此外，LoHoVLA采用了分层闭环控制机制，以减轻起源于高层次规划和低层次控制的错误。为了训练LoHoVLA，我们引入了LoHoSet，这是一个基于Ravens模拟器建立的数据集，包含20个长远任务，每个任务有1000个专家演示，由视觉观察、语言目标、子任务和机器人动作组成。实验结果表明，LoHoVLA在Ravens模拟器中的长远具身任务方面显著优于分层和标准VLA方法。这些发现突显了统一架构在推进可泛化具身智能方面的潜力。\n\n作者：杨逸、孙嘉轩、寇斯琪、王亦涵、邓志杰\n\n链接：https://arxiv.org/pdf/2506.00411.pdf\n\n标题：LoHoVLA：用于长远具身任务的统一视觉-语言-动作模型",
        "地址": "https://arxiv.org/pdf/2506.00411.pdf"
    },
    {
        "名称": "2025 [2506.01713] SRPO: Enhancing Multimodal LLM Reasoning via Reflection-Aware Reinforcement Learning.pdf",
        "作者": "Zhongwei Wan, Zhihao Dou, Che Liu, Yu Zhang, Dongfei Cui, Qinjian Zhao, Hui Shen, Jing Xiong, Yi Xin, Yifan Jiang, Yangfan He, Mi Zhang, Shen Yan",
        "摘要": "摘要：多模态大型语言模型（MLLMs）在推理任务中表现出有希望的能力，但在需要显式自我反思和自我纠正的复杂问题上仍然存在困难，尤其是与其单模态文本模型相比。现有的反思方法过于简单，难以生成有意义且具有指导性的反馈，这是因为预训练模型的推理能力和知识限制在初始训练期间基本固定。为了解决这些挑战，我们提出了通过群体相对政策优化（SRPO）增强多模态语言模型推理的自我反思方法，这是一个专门设计的两阶段反思感知强化学习（RL）框架，旨在增强多模态LLM推理能力。在第一阶段，我们在高级MLLM的指导下构建了一个高质量的、以反思为重点的数据集，该模型基于初始反应生成反思，以帮助政策模型学习推理和自我反思。在第二阶段，我们在GRPO框架内引入了一种新的奖励机制，鼓励简洁且具认知意义的反思，同时避免冗余。在包括MathVista、MathVision、MathVerse和MMMU-Pro在内的多个多模态推理基准上的广泛实验中，使用Qwen-2.5-VL-7B和Qwen-2.5-VL-32B进行测试，结果表明SRPO显著优于现有的最先进模型，在推理准确性和反思质量方面取得了显著的改善。\n\n翻译摘要：多模态大型语言模型（MLLMs）在推理任务中表现出了有希望的能力，但在处理需要显式自反和自我纠正的复杂问题时，仍然存在困难，尤其是与它们的单模态文本模型相比。现有的反思方法过于简单，难以生成有意义和有指导性的反馈，因为预训练模型的推理能力和知识限制在初始训练期间基本固定。为了解决这些挑战，我们提出了一种通过群体相对政策优化（SRPO）增强多模态大型语言模型推理的自我反思方法，这是一个专门设计的两阶段反思感知强化学习（RL）框架，旨在增强多模态LLM的推理能力。在第一阶段，我们在先进的MLLM的指导下构建了一个高质量的以反思为重点的数据集，该模型基于初始反应生成反思，以帮助策略模型学习推理和自我反思。在第二阶段，我们在GRPO框架内引入了一种新的奖励机制，鼓励简洁且具认知意义的反思，同时避免冗余。大量实验表明，在包括MathVista、MathVision、MathVerse和MMMU-Pro在内的多个多模态推理基准上，使用Qwen-2.5-VL-7B和Qwen-2.5-VL-32B进行测试后，SRPO显著优于现有最先进模型，在推理准确性和反思质量方面取得了显著改进。",
        "地址": "https://arxiv.org/pdf/2506.01713.pdf"
    },
    {
        "名称": "2025 [2506.01667] EarthMind: Towards Multi-Granular and Multi-Sensor Earth Observation with Large Multimodal Models.pdf",
        "作者": "Yan Shu, Bin Ren, Zhitong Xiong, Danda Pani Paudel, Luc Van Gool, Begum Demir, Nicu Sebe, Paolo Rota",
        "摘要": "摘要：大型多模态模型（LMMs）在各种视觉-语言任务中表现出强劲的性能。然而，它们在全面理解地球观测（EO）数据方面通常遇到困难，而这种数据对于监控环境及人类活动对其的影响至关重要。在这项工作中，我们提出了EarthMind，这是一种用于多粒度和多传感器EO数据理解的新型视觉-语言框架。EarthMind具有两个核心组件：（1）空间注意力提示（SAP），它在LLM内重新分配注意力以增强像素级理解；（2）跨模态融合，它将异质模态对齐到共享空间，并根据信息密度自适应地重新加权标记以实现有效融合。为了方便多传感器融合评估，我们提出了EarthMind-Bench，这是一个包含超过2000个人工注释的多传感器图像-问题对的综合基准，涵盖了广泛的感知和推理任务。大量实验展示了EarthMind的有效性。它在EarthMind-Bench上实现了最先进的性能，尽管规模仅为4B，却超过了GPT-4o。此外，EarthMind在多个公共EO基准上优于现有方法，展示了其在统一框架中处理多粒度和多传感器挑战的潜力。",
        "地址": "https://arxiv.org/pdf/2506.01667.pdf"
    },
    {
        "名称": "2025 [2505.24298] AReaL: A Large-Scale Asynchronous Reinforcement Learning System for Language Reasoning.pdf",
        "作者": "Wei Fu, Jiaxuan Gao, Xujie Shen, Chen Zhu, Zhiyu Mei, Chuyi He, Shusheng Xu, Guo Wei, Jun Mei, Jiashu Wang, Tongkai Yang, Binhang Yuan, Yi Wu",
        "摘要": "摘要：强化学习（RL）已成为训练大型语言模型（LLMs），特别是推理任务的热门范式。有效的RL训练LLMs需要大规模并行化，并迫切需要高效的训练系统。目前大多数现有的大规模RL系统对于LLMs都是同步的，通过在批量设置中交替生成和训练，其中每个训练批次中的回合都是由相同（或最新）的模型生成的。这稳定了RL训练但遭受严重的系统级效率问题。生成必须等待批次中的最长输出完成后再进行模型更新，导致GPU未充分利用。我们提出了AReaL，一个完全异步的RL系统，它完全将生成与训练解耦。AReaL中的回合工作者连续生成新的输出而无需等待，而训练工作者在收集到一批数据时随时更新模型。AReaL还结合了一系列系统级优化，导致显着更高的GPU利用率。为了稳定RL训练，AReaL平衡了回合和训练工作者的工作量，以控制数据陈旧性，并采用增强陈旧性的PPO变体更好地处理过时的训练样本。在数学和代码推理基准上的大量实验表明，AReaL与具有相同数量GPU的最佳同步系统相比，训练速度提高了最多2.57倍，并达到了或甚至改善了最终性能。AReaL的代码可在此网址获取。",
        "地址": "https://arxiv.org/pdf/2505.24298.pdf"
    },
    {
        "名称": "2025 [2506.01863] Unified Scaling Laws for Compressed Representations.pdf",
        "作者": "Andrei Panferov, Alexandra Volkova, Ionut-Vlad Modoranu, Vage Egiazarian, Mher Safaryan, Dan Alistarh",
        "摘要": "摘要: \n在机器学习领域，缩放定律通过基于模型大小、计算量和数据量实现模型性能的可预测缩放，推动了最新进展。同时，AI计算成本的增加推动了模型压缩技术的应用，特别是量化和稀疏化技术，以减轻大规模训练和推理所带来的巨大计算需求。本文研究了缩放定律与压缩格式之间的相互影响，探讨了一个统一的缩放框架是否能在各种压缩表示（例如稀疏、标量量化、稀疏量化甚至矢量量化格式）下准确预测模型性能。我们的主要贡献包括验证一个通用缩放定律公式，并展示它在各种压缩类型中都具有适用性。基于此，我们主要发现，理论上和实证上均表明存在一个简单的“容量”指标——基于表示拟合随机高斯数据的能力，它可以稳健地预测多种压缩表示下的参数效率。在实际方面，我们扩展了我们的公式来直接比较不同压缩格式的准确性潜力，并提出了更好的算法来在稀疏量化格式上进行训练。\n\n作者: Andrei Panferov，Alexandra Volkova，Ionut-Vlad Modoranu，Vage Egiazarian，Mher Safaryan，Dan Alistarh\n\n评论: 预印本\n\nURL: https://arxiv.org/pdf/2506.01863.pdf\n\n标题: 2025 [2506.01863] 统一压缩表示的缩放定律",
        "地址": "https://arxiv.org/pdf/2506.01863.pdf"
    },
    {
        "名称": "2025 [2505.24846] MiCRo: Mixture Modeling and Context-aware Routing for Personalized Preference Learning.pdf",
        "作者": "Jingyan Shen, Jiarui Yao, Rui Yang, Yifan Sun, Feng Luo, Rui Pan, Tong Zhang, Han Zhao",
        "摘要": "摘要: 奖励建模是在应用来自人类反馈的强化学习（RLHF）以调整大语言模型（LLMs）时构建安全基础模型的关键步骤。然而，基于布拉德利-特里（BT）模型的奖励建模假设了一个全球奖励函数，未能捕捉本质上多样化和异质的人类偏好。因此，这种过度简化限制了LLMs在支持个性化和多元化调整上的能力。从理论上看，我们证明当人类偏好遵循多样化子组的混合分布时，单一的BT模型会有不可减少的错误。虽然现有解决方案，如具细粒度注释的多目标学习，有助于解决这一问题，但它们成本高昂且受到预定义属性的限制，未能充分捕捉人类价值的丰富性。在这项工作中，我们提出了MiCRo，一个通过利用大规模二进制偏好数据集无需显式细粒度注释来增强个性化偏好学习的两阶段框架。在第一阶段，MiCRo引入了识上下文混合建模方法以捕捉多样化的人类偏好。在第二阶段，MiCRo结合了一种在线路由策略，根据特定上下文动态调整混合权重以解决模糊性，从而以最少的额外监督实现高效且可扩展的偏好适应。在多个偏好数据集上的实验表明，MiCRo有效地捕捉了多样化的人类偏好，并显著改善了下游个性化。",
        "地址": "https://arxiv.org/pdf/2505.24846.pdf"
    },
    {
        "名称": "2025 [2506.01413] Incentivizing Reasoning for Advanced Instruction-Following of Large Language Models.pdf",
        "作者": "Yulei Qin, Gang Li, Zongyi Li, Zihan Xu, Yuchen Shi, Zhekai Lin, Xiao Cui, Ke Li, Xing Sun",
        "摘要": "摘要: 现有的大型语言模型（LLMs）在遵循复杂指令时面临挑战，特别是当多个约束以并行、链式和分支结构组织时。一种直观的解决方案，即Chain-of-Thought（CoT），有望普遍提高LLMs的能力。然而，我们发现，原始的CoT由于其简单地解释指令的表面推理模式，对性能产生了负面影响。它未能剖析约束的组成部分，以识别它们在类型和维度层次上的关系。为此，我们提出了一种系统方法，通过激励测试时的推理来提高LLMs处理复杂指令的能力。首先，我们从现有分类法的复杂指令分解开始，提出了一种可重现的数据获取方法。其次，我们利用具有可验证规则中心奖励信号的强化学习（RL），专门培养指令遵循的推理能力。我们通过样本对比解决了复杂指令下推理的浅层、非本质特性，以强化CoT。我们还利用专家行为克隆，促进从快思维的LLMs向熟练推理者的稳定分布转变。在七个综合基准上的广泛评估确认了所提出方法的有效性，其中一个1.5B的LLM实现了11.74%的增益，其性能可与一个8B的LLM媲美。代码和数据可在此HTTPS URL获得。",
        "地址": "https://arxiv.org/pdf/2506.01413.pdf"
    },
    {
        "名称": "2025 [2506.01952] WebChoreArena: Evaluating Web Browsing Agents on Realistic Tedious Web Tasks.pdf",
        "作者": "Atsuyuki Miyai, Zaiying Zhao, Kazuki Egashira, Atsuki Sato, Tatsumi Sunada, Shota Onohara, Hiromasa Yamanishi, Mashiro Toyooka, Kunato Nishina, Ryoma Maeda, Kiyoharu Aizawa, Toshihiko Yamasaki",
        "摘要": "摘要：\n由大型语言模型（LLM）驱动的网页浏览代理以类似人类的方式操作网页浏览器，并为自动化广泛的日常任务提供了一条高度透明的途径。随着网页代理的能力不断增强并在一般浏览任务中表现出色，一个关键问题浮现出来：它们能否超越一般浏览，稳健地处理那些繁琐复杂或人类常常不愿意亲自去做的任务？在本文中，我们介绍了WebChoreArena，这是一种全新的、可完全复现的基准测试，包含532个精心策划的任务，旨在扩展WebArena的范畴，涵盖更多劳动密集和繁琐的任务。WebChoreArena系统地整合了三个关键挑战：(i)需要在观察中准确提取大量信息的大量记忆任务；(ii)要求精确数学推理的计算任务；以及(iii)需要跨多个网页的长期记忆任务。基于完全可复现且被广泛采用的四个WebArena仿真环境之上，WebChoreArena确保严格的可复现性，并能够与已有的WebArena基准进行公平、直接的比较，从而提供关于代理进展的重要见解。我们的实验结果表明，随着LLM的演进，例如GPT-4o、Claude 3.7 Sonnet和Gemini 2.5 Pro，在WebChoreArena上的表现显著提升。这些发现表明，WebChoreArena非常适合更清晰地衡量最先进的LLM的进展。然而，结果也表明，即使是Gemini 2.5 Pro，与WebArena相比，仍有很大的改进空间，突显了WebChoreArena所带来的挑战增加。\n\n来源：https://arxiv.org/pdf/2506.01952.pdf",
        "地址": "https://arxiv.org/pdf/2506.01952.pdf"
    },
    {
        "名称": "2025 [2505.24523] Stress-testing Machine Generated Text Detection: Shifting Language Models Writing Style to Fool Detectors.pdf",
        "作者": "Andrea Pedrotti, Michele Papucci, Cristiano Ciaccio, Alessio Miaschi, Giovanni Puccetti, Felice Dell'Orletta, Andrea Esuli",
        "摘要": "摘要：最近在生成式人工智能和大型语言模型（LLMs）方面的进展使得生成高度真实的合成内容成为可能，这引发了人们对其可能被恶意使用（例如虚假信息和操控）的担忧。此外，由于缺乏评估在现实世界场景中泛化能力的坚实基准，检测机器生成文本（MGT）仍具有挑战性。在这项工作中，我们提出了一种测试最新MGT检测器（例如，Mage、Radar、LLM-DetectAIve）对语言学导向的对抗攻击的抵御能力的方法。为了挑战检测器，我们使用直接偏好优化（DPO）微调语言模型，将MGT样式转变为人类书写文本（HWT）。这利用了检测器对风格线索的依赖，使新的生成内容更难以检测。此外，我们分析了对齐引起的语言变化以及检测器用于检测MGT文本的特征。我们的结果表明，检测器可以通过相对较少的例子轻易被欺骗，导致检测性能显著下降。这突出了改进检测方法的重要性，并使其能够在域内文本中表现出稳健性。\n\n作者：Andrea Pedrotti、Michele Papucci、Cristiano Ciaccio、Alessio Miaschi、Giovanni Puccetti、Felice Dell'Orletta、Andrea Esuli\n\n评论：已被《ACL 2025 Findings》接受\n\n网址：https://arxiv.org/pdf/2505.24523.pdf\n\n标题：2025 [2505.24523] MGT检测的压力测试：改变语言模型书写风格来欺骗检测器",
        "地址": "https://arxiv.org/pdf/2505.24523.pdf"
    },
    {
        "名称": "2025 [2505.24183] CodeV-R1: Reasoning-Enhanced Verilog Generation.pdf",
        "作者": "Yaoyu Zhu, Di Huang, Hanqi Lyu, Xiaoyun Zhang, Chongxiao Li, Wenxuan Shi, Yutong Wu, Jianan Mu, Jinghua Wang, Yang Zhao, Pengwei Jin, Shuyao Cheng, Shengwen Liang, Xishan Zhang, Rui Zhang, Zidong Du, Qi Guo, Xing Hu, Yunji Chen",
        "摘要": "摘要: 通过具备可验证奖励的强化学习（RLVR）训练的大型语言模型（LLMs）在具有明确、自动化验证的任务（如软件编程和数学问题）上取得了突破。然而，将RLVR扩展到电子设计自动化（EDA），尤其是从自然语言（NL）规格自动生成硬件描述语言（HDLs）如Verilog面临三大关键挑战：缺乏自动化和准确的验证环境，优质NL代码对的稀缺性，以及RLVR的高昂计算成本。为此，我们介绍了用于训练Verilog生成LLMs的RLVR框架——CodeV-R1。首先，我们开发了一个基于规则的测试平台生成器，能够对比黄金参考执行稳健等效性检查。其次，我们提出了一种回环数据合成方法，将开源的Verilog片段与LLM生成的NL描述配对，通过生成的测试平台验证代码-NL-代码的一致性，并过滤掉不等价的示例以生成高质量数据集。第三，我们采用两阶段“蒸馏再RL”训练管道：蒸馏用于推理能力的冷启动，然后采用自适应DAPO，我们的新型RLVR算法，可以通过自适应调整采样率来减少训练成本。最终模型CodeV-R1-7B在VerilogEval v2和RTLLM v1.1上的通过率分别达到了68.6%和72.9%，超越了之前的最新技术水平12~20%，并且匹配甚至超过了671B DeepSeek-R1的性能。我们将发布我们的模型、训练管道和数据集，以推动EDA和LLM社区的研究。",
        "地址": "https://arxiv.org/pdf/2505.24183.pdf"
    },
    {
        "名称": "2025 [2505.21179] Normalized Attention Guidance: Universal Negative Guidance for Diffusion Models.pdf",
        "作者": "Dar-Yen Chen, Hmrishav Bandyopadhyay, Kai Zou, Yi-Zhe Song",
        "摘要": "摘要：负向引导--明确地抑制不需要的属性--在扩散模型中，特别是在少量步数采样机制中依然是一个基本挑战。虽然无分类器引导（Classifier-Free Guidance，CFG）在标准设置下表现良好，但由于正负分支之间的预测分歧，它在激进的采样步数压缩下会失效。我们提出了归一化注意力引导（Normalized Attention Guidance，NAG），这是一种高效、无需训练的机制，通过基于L1的归一化和细化在注意力空间中应用外推。NAG在CFG失效的情况下恢复了有效的负向引导，同时保持了保真度。与现有方法不同，NAG在架构（UNet、DiT）、采样机制（少步、多步）和模态（图像、视频）之间具有通用性，作为一种\\textit{通用}插件，计算开销极小。通过广泛的实验，我们展示了在文本对齐（CLIP Score）、保真度（FID, PFID）和人类感知质量（ImageReward）方面的一致改进。我们的消融研究验证了每个设计组件的有效性，而用户研究也证实了对NAG引导输出的显著偏好。作为一种无需重新训练的与模型无关的推理时间方法，NAG为所有现代扩散框架提供了简便的负向引导——附录中有伪代码！\n\n作者：Dar-Yen Chen, Hmrishav Bandyopadhyay, Kai Zou, Yi-Zhe Song\n\n链接：https://arxiv.org/pdf/2505.21179.pdf\n\n标题：2025 [2505.21179] 归一化注意力引导：扩散模型的通用负向引导",
        "地址": "https://arxiv.org/pdf/2505.21179.pdf"
    },
    {
        "名称": "2025 [2506.01928] Esoteric Language Models.pdf",
        "作者": "Subham Sekhar Sahoo, Zhihan Yang, Yash Akhauri, Johnna Liu, Deepansha Singh, Zhoujun Cheng, Zhengzhong Liu, Eric Xing, John Thickstun, Arash Vahdat",
        "摘要": "摘要: 基于扩散的语言模型通过实现并行和可控的生成，为自回归（AR）模型提供了一种引人注目的替代方案。在这一系列模型中，掩蔽扩散模型（MDMs）表现最为强劲，但在困惑度上仍不如AR模型，并且缺乏关键的推理效率特征——最显著的是KV缓存。在这项工作中，我们引入了Eso-LMs，这是一类融合了AR和MDM范式的新模型，能够在面对困惑度时实现平滑插值，同时克服各自的局限性。Eso-LMs在标准语言建模基准测试中设立了新的性能标杆。重要的是，我们首次为MDMs引入了KV缓存，同时保留了并行生成，大大提高了推理效率。结合优化的采样计划，我们的方法比标准MDMs快多达65倍，比以前的半自回归方法快4倍。我们在项目页面上提供代码和模型检查点：[此网址](此网址)。",
        "地址": "https://arxiv.org/pdf/2506.01928.pdf"
    },
    {
        "名称": "2025 [2506.00979] IVY-FAKE: A Unified Explainable Framework and Benchmark for Image and Video AIGC Detection.pdf",
        "作者": "Wayne Zhang, Changjiang Jiang, Zhonghao Zhang, Chenyang Si, Fengchang Yu, Wei Peng",
        "摘要": "摘要：人工智能生成内容（AIGC）在视觉领域的快速发展，凭借扩散架构等复杂生成框架，产生了高度逼真的合成图像和视频。虽然这些突破带来了巨大的机遇，但同时也引发了对内容真实性和完整性的重大担忧。许多当前的AIGC检测方法作为黑箱二元分类器运行，提供有限的可解释性，并且没有一种方法支持在统一框架中检测图像和视频。这种双重限制削弱了模型的透明性，降低了可信度，并阻碍了实际部署。为了解决这些挑战，我们介绍了IVY-FAKE，这是一个专门为可解释的多模态AIGC检测设计的新颖、统一和大规模的数据集。与之前的基准测试相比，IVY-FAKE包含超过150,000个富注释的训练样本（图像和视频）和18,700个评估示例，每个示例都伴有详细的自然语言推理，超越了简单的二元标签。在此基础上，我们提出了Ivy可解释检测器（IVY-XDETECTOR），这是一个统一的AIGC检测和可解释架构，可以对图像和视频内容进行解释性检测。我们的统一视觉语言模型在多个图像和视频检测基准测试中实现了最先进的性能，突显了我们数据集和建模框架所实现的重大进步。我们的数据可在此网址公开获取。\n\n作者：Wayne Zhang, Changjiang Jiang, Zhonghao Zhang, Chenyang Si, Fengchang Yu, Wei Peng\n\n评论：20页,13个图表,7张表格\n\n网址：https://arxiv.org/pdf/2506.00979.pdf\n\n标题：2025 [2506.00979] IVY-FAKE: 用于图像和视频AIGC检测的统一可解释框架和基准测试",
        "地址": "https://arxiv.org/pdf/2506.00979.pdf"
    },
    {
        "名称": "2025 [2505.24842] Cascading Adversarial Bias from Injection to Distillation in Language Models.pdf",
        "作者": "Harsh Chaudhari, Jamie Hayes, Matthew Jagielski, Ilia Shumailov, Milad Nasr, Alina Oprea",
        "摘要": "摘要: 模型蒸馏已成为构建较小、可部署的语言模型并保留较大系统能力的必要手段。然而，广泛的部署引发了对抵抗对抗性操控的担忧。本文研究了蒸馏模型在训练期间对抗性注入偏见内容的脆弱性。我们展示了对手可以通过最小的数据污染将微妙的偏见注入教师模型，这些偏见会传播到学生模型并显著放大。我们提出了两种传播模式：非针对性传播，偏见影响多个任务；针对性传播，集中在特定任务同时在其他地方保持正常表现。仅使用25个污染样本（污染率0.25%），学生模型在针对性场景中生成偏见响应的频率为76.9%，高于教师模型的69.4%。对于非针对性传播，在未见任务中，学生模型中的对抗性偏见出现频率是教师模型的6倍-29倍。我们在六种偏见类型（针对性广告、钓鱼链接、叙事操控、不安全编码实践），各种蒸馏方法和跨文本、代码生成的不同模态中验证了这些发现。我们的评价揭示当前防御机制——困惑度过滤、偏见检测系统和基于LLM的自动评分框架——对这些攻击存在不足。结果暴露了蒸馏模型中的重大安全漏洞，突显了专门防护措施的需求。我们提出了构建有效的对抗性偏见缓解策略的实用设计原则。\n\n作者: Harsh Chaudhari, Jamie Hayes, Matthew Jagielski, Ilia Shumailov, Milad Nasr, Alina Oprea\n\n链接: https://arxiv.org/pdf/2505.24842.pdf\n\n标题: 2025 [2505.24842] 从注入到蒸馏的级联对抗性偏见在语言模型中的传播.pdf",
        "地址": "https://arxiv.org/pdf/2505.24842.pdf"
    },
    {
        "名称": "2025 [2506.01084] zip2zip: Inference-Time Adaptive Vocabularies for Language Models via Token Compression.pdf",
        "作者": "Saibo Geng, Nathan Ranchin, Yunzhen yao, Maxime Peyrard, Chris Wendler, Michael Gastpar, Robert West",
        "摘要": "摘要: 分词效率在大规模语言模型(LLM)的性能和成本方面起着关键作用，但大多数模型依赖于为通用语料库优化的静态分词器。这些分词器的固定词汇通常难以适应特定领域或语言的输入，导致更长的分词序列和更高的计算成本。我们提出zip2zip，一个使LLM能够在推理时动态调整词汇表的框架，从而生成更少的分词并加快推理速度。zip2zip包括三个关键组成部分：(1) 基于Lempel-Ziv-Welch(LZW)压缩的分词器，它能够在运行时将分词逐步压缩成可重用的“超分词”，(2) 一个在运行时计算新形成的超分词嵌入的嵌入层，(3) 一个因果语言模型变体，它训练模型在超分词压缩序列上运行。我们显示，通过参数高效微调，一个现有的LLM可以在10 GPU小时内实现zip2zip改造。结果显示，通过zip2zip，LLM能够在推理时有效地学习使用超分词，减少输入和输出序列长度20-60%，显著改善推理延迟。",
        "地址": "https://arxiv.org/pdf/2506.01084.pdf"
    },
    {
        "名称": "2025 [2506.00512] Pro3D-Editor : A Progressive-Views Perspective for Consistent and Precise 3D Editing.pdf",
        "作者": "Yang Zheng, Mengqi Huang, Nan Chen, Zhendong Mao",
        "摘要": "摘要: 文本指导的3D编辑旨在精确编辑语义相关的局部3D区域，这在从3D游戏到电影制作的各种实际应用中具有显著潜力。现有方法通常遵循一个视图无差别的范式：不加区分地编辑2D视图并将其投射回3D空间。然而，它们忽略了不同跨视图的相互依赖性，导致不一致的多视图编辑。在这项研究中，我们认为理想的一致3D编辑可以通过一个\\textit{逐步视图范式}来实现，该范式将编辑语义从编辑显著视图传播到其他编辑稀疏视图。具体来说，我们提出了\\textit{Pro3D-Editor}，一个新颖的框架，主要包括主要视图采样器、关键视图渲染和全视图精炼器。主要视图采样器动态采样和编辑最显著的视图作为主要视图。关键视图渲染通过其视图专家混合低秩自适应 (MoVE-LoRA) 准确地将编辑语义从主要视图传播到其他关键视图。全视图精炼器基于编辑的多视图编辑和精炼3D对象。大量实验表明，我们的方法在编辑准确性和空间一致性方面优于现有方法。",
        "地址": "https://arxiv.org/pdf/2506.00512.pdf"
    },
    {
        "名称": "2025 [2505.24452] Stepsize anything: A unified learning rate schedule for budgeted-iteration training.pdf",
        "作者": "Anda Tang, Yiming Dong, Yutao Zeng, zhou Xun, Zhouchen Lin",
        "摘要": "摘要：日益增长的计算成本和有限的资源凸显了预算迭代训练的关键需求，其目标是在预定迭代内实现最佳学习。学习率调度基本上决定了不同网络和任务的性能，尤其是在预算迭代场景中，它们的设计仍然主要是凭经验，缺乏理论依据。此外，最佳学习率调度需要广泛的试验和错误选择，使训练过程复杂化。在这项工作中，我们提出了统一预算感知（UBA）调度，这是一种有理论基础的学习率调度，在不同受限训练条件下的各种架构和任务中始终优于常用调度。此外，我们通过构建一个新的训练预算感知优化框架，弥合了差距，明确考虑了对景观曲率的鲁棒性。在此框架下，我们推导出由单一超参数$\\varphi$控制的UBA调度，提供了灵活性与简洁性的权衡，消除了每个网络的数值优化需求。此外，我们建立了$\\varphi$与条件数之间的理论关联，为我们的方法增加了解释和合理性。我们证明了不同$\\varphi$值的收敛性，并通过理论分析和实证提供选择的实际指导。实验结果表明，在不同训练迭代预算下，UBA在各种视觉和语言任务中（涉及网络架构如ResNet、OLMo）始终优于常用调度。",
        "地址": "https://arxiv.org/pdf/2505.24452.pdf"
    },
    {
        "名称": "2025 [2506.01920] From Guidelines to Practice: A New Paradigm for Arabic Language Model Evaluation.pdf",
        "作者": "Serry Sibaee, Omer Nacar, Adel Ammar, Yasser Al-Habashi, Abdulrahman Al-Batati, Wadii Boulila",
        "摘要": "摘要: 本文通过建立全面的理论指导方针和引入新的评估框架，解决了阿拉伯语语言模型评估中的关键空白。我们首先分析了现有的阿拉伯语评估数据集，发现了语言准确性、文化一致性和方法严格性方面的显著问题。为了克服这些在大语言模型（LLM）中的局限性，我们提出了阿拉伯语深度迷你数据集（ADMD），这是一个精心策划的集合，包含了490个涵盖十个主要领域（42个子领域，见图1）的挑战性问题。利用ADMD，我们评估了五个领先的语言模型：GPT-4、Claude 3.5 Sonnet、Gemini Flash 1.5、CommandR 100B和Qwen-Max。我们的结果揭示了不同领域之间模型性能的显著差异，特别是在需要深厚文化理解和专业知识的领域中存在特别的挑战。Claude 3.5 Sonnet在整体准确性方面表现最好，达到了30%，在阿拉伯数学理论、阿拉伯语言和伊斯兰领域中显示出相对优势。这项工作为改进阿拉伯语语言模型评估提供了理论基础和实用见解，强调了文化能力和技术能力的重要性。",
        "地址": "https://arxiv.org/pdf/2506.01920.pdf"
    },
    {
        "名称": "2025 [2506.01920] From Guidelines to Practice: A New Paradigm for Arabic Language Model Evaluation.pdf",
        "作者": "Serry Sibaee, Omer Nacar, Adel Ammar, Yasser Al-Habashi, Abdulrahman Al-Batati, Wadii Boulila",
        "摘要": "摘要：本文通过建立全面的理论指导方针和引入一种新颖的评估框架，解决了阿拉伯语语言模型评估中的关键问题。我们首先分析了现有的阿拉伯语评估数据集，发现了在语言准确性、文化适应性和方法严谨性方面的显著问题。为了弥补大型语言模型（LLMs）的这些不足，我们提出了阿拉伯语深度迷你数据集（ADMD），该数据集是精心策划的，包含了10个主要领域的490个具有挑战性的问题（42个子领域，见图1）。使用ADMD，我们评估了五个领先的语言模型：GPT-4、Claude 3.5 Sonnet、Gemini Flash 1.5、CommandR 100B和Qwen-Max。我们的结果揭示了不同领域中模型表现的显著差异，尤其是在需要深厚文化理解和专业知识的领域，挑战尤为明显。Claude 3.5 Sonnet在整体准确性上表现最佳，为30%，在阿拉伯语数学理论、阿拉伯语语言和伊斯兰领域表现出相对优势。该研究为改进阿拉伯语语言模型评估提供了理论基础和实践见解，强调了文化能力与技术能力并重的重要性。",
        "地址": "https://arxiv.org/pdf/2506.01920.pdf"
    },
    {
        "名称": "2025 [2506.01484] LLM in the Loop: Creating the PARADEHATE Dataset for Hate Speech Detoxification.pdf",
        "作者": "Shuzhou Yuan, Ercong Nie, Lukas Kouba, Ashish Yashwanth Kangen, Helmut Schmid, Hinrich Schutze, Michael Farber",
        "摘要": "摘要: \n随着有害内容在网络上的普遍存在，解毒——即将有害语言重写为无毒文本的任务——变得越来越重要。然而，由于人工注释的成本和敏感性，高质量的解毒并行数据集，尤其是针对仇恨言论的，依然稀缺。在本文中，我们提出了一种新颖的基于GPT-4o-mini的自动解毒管道。我们首先通过用大规模语言模型(LLM)替代人工注释来复制ParaDetox管道，并展示了LLM的表现与人工注释相当。在此基础上，我们构建了PARADEHATE，一个专门用于仇恨言论解毒的大规模并行数据集。我们发布了PARADEHATE作为一个包含超过8000对仇恨/非仇恨文本对的基准数据集，并评估了广泛的基线方法。实验结果显示，在PARADEHATE上微调的诸如BART等模型在风格准确性、内容保留和流畅性方面取得了更好的表现，展示了LLM生成的解毒文本作为人工注释的一种可扩展替代方案的有效性。\n\n作者：Shuzhou Yuan, Ercong Nie, Lukas Kouba, Ashish Yashwanth Kangen, Helmut Schmid, Hinrich Schutze, Michael Farber",
        "地址": "https://arxiv.org/pdf/2506.01484.pdf"
    },
    {
        "名称": "2025 [2506.00789] RARE: Retrieval-Aware Robustness Evaluation for Retrieval-Augmented Generation Systems.pdf",
        "作者": "Yixiao Zeng, Tianyu Cao, Danqing Wang, Xinran Zhao, Zimeng Qiu, Morteza Ziyadi, Tongshuang Wu, Lei Li",
        "摘要": "摘要：检索增强生成（RAG）提高了答案的时效性和真实性。然而，现有评估很少测试这些系统在处理真实世界噪音、求解内部和外部检索上下文冲突或快速变化的事实时的表现。我们介绍了检索感知鲁棒性评估（RARE），一个统一框架和大规模基准，联合对动态、时间敏感语料库中的查询和文档扰动进行压力测试。RARE的一个核心特性是知识图驱动的合成管道（RARE-Get），它自动从定制语料库中提取单跳和多跳关系，并生成多级问题集，无需人工干预。利用这一管道，我们构建了一个跨400份专家级时间敏感的金融、经济和政策文档和48,322个问题的数据集（RARE-Set），其分布随着基础来源变化而变化。为了量化恢复力，我们形式化了检索条件的鲁棒性度量（RARE-Met），这些度量捕捉了模型在查询、文档或现实世界的检索结果系统性改变时保持正确或恢复能力的能力。我们的结果显示，RAG系统对扰动表现出惊人的脆弱性，文档鲁棒性始终是弱点，无论生成器规模或架构。RAG系统在所有领域的多跳查询上的鲁棒性始终低于单跳查询。\n\n翻译后的摘要：\n\n检索增强生成（RAG）提高了答案的时效性和真实性。然而，现有评估很少测试这些系统在处理真实世界噪音、内部与外部检索上下文冲突或急速变化的事实时的表现。我们介绍了检索感知鲁棒性评估（RARE），一个统一的框架和大规模基准，通过对动态、时效性语料库中的查询和文档扰动进行压力测试。RARE的一个核心特点是知识图驱动的合成管道（RARE-Get），它可以自动从定制语料库中提取单跳和多跳关系，并生成多个级别的问题集，无需人工干预。利用该管道，我们构建了一个数据集（RARE-Set），涵盖了400份专家级的时间敏感性金融、经济和政策文档以及48,322个问题，其分布随着基础来源的变化而变化。为了量化系统的恢复能力，我们形式化了检索条件的鲁棒性度量（RARE-Met），这些度量捕捉了模型在查询、文档或现实世界的检索结果系统性改变时保持正确或恢复能力的能力。我们的结果表明，RAG系统对扰动表现出惊人的脆弱性，文档的鲁棒性一贯是最薄弱的环节，无论生成器的规模或架构如何。在所有领域，相较于单跳查询，RAG系统在多跳查询上的鲁棒性始终较低。",
        "地址": "https://arxiv.org/pdf/2506.00789.pdf"
    },
    {
        "名称": "2025 [2505.24086] ComposeAnything: Composite Object Priors for Text-to-Image Generation.pdf",
        "作者": "Zeeshan Khan, Shizhe Chen, Cordelia Schmid",
        "摘要": "摘要：从文本生成涉及复杂和新颖对象排列的图像仍然是当前文本到图像 (T2I) 模型面临的一个重大挑战。尽管之前的基于布局的方法通过二维布局中的空间约束改进了对象排列，但它们常常难以捕捉到三维的定位，并且在质量和一致性方面有所牺牲。在这项工作中，我们提出了ComposeAnything，这是一个无需重新训练现有T2I模型便能改进组合图像生成的新框架。我们的方法首先利用大型语言模型 (LLMs) 的链式思维推理能力从文本中生成2.5D语义布局，这些布局包括加强了深度信息和详细说明的二维对象边界框。基于此布局，我们生成了一个空间和深度感知的粗略对象组合，捕捉预期的构图，作为替换扩散式T2I模型中随机噪声初始化的强大且可解释的先验。这种先验通过对象先验强化和空间控制去噪引导去噪过程，使得组合对象和一致背景的生成更加顺畅，同时允许对不准确的先验进行优化。ComposeAnything在处理具有二维/三维空间排列、大量对象和超现实构图的提示时，优于在T2I-CompBench和NSR-1K基准测试中的最新方法。人类评估进一步证明我们的模型能够生成高质量的图像，并忠实地反映文本中的构图。\n\n翻译：生成文本涉及复杂和新颖对象排列的图像仍然是当前文本到图像 (T2I) 模型的一大挑战。尽管之前基于布局的方法通过二维布局中的空间约束改善了对象排列，但这些方法往往难以捕捉三维定位，并且质量和一致性有所下降。在这项工作中，我们介绍了ComposeAnything，一个无需重新训练现有T2I模型就能改进组合作图的新框架。我们的方法首先利用LLM的链式思维推理能力，根据文本生成2.5D语义布局，这些布局由二维对象边界框和增强的深度信息以及详细的说明组成。基于这个布局，我们生成了一个空间和深度感知的对象粗合成，它捕捉预期构图，作为替换扩散式T2I模型中随机噪声初始化的强大且可解释的先验。这一先验通过对象先验强化和空间控制去噪引导去噪过程，使组合对象和一致背景的生成更加顺畅，同时允许优化不准确的先验。ComposeAnything在T2I-CompBench和NSR-1K基准测试中针对二维/三维空间排列、大量对象和超现实构图提示的情况下表现优于当前最新方法。人类评估进一步证明我们的模型生成了高质量图像，其构图忠实反映了文本内容。",
        "地址": "https://arxiv.org/pdf/2505.24086.pdf"
    },
    {
        "名称": "2025 [2505.22954] Darwin Godel Machine: Open-Ended Evolution of Self-Improving Agents.pdf",
        "作者": "Jenny Zhang, Shengran Hu, Cong Lu, Robert Lange, Jeff Clune",
        "摘要": "摘要：当前的人工智能系统具有人工设计的固定架构，无法自主连续地提升自身能力。人工智能的进步本身可以被自动化。如果能够安全地实现，这将加速人工智能的发展，使我们能够更早享受其带来的好处。元学习可以自动发现新的算法，但受限于一阶改进和人为设计的搜索空间。哥德尔机提出了一个理论替代方案：一种能够不断以可证明的有益方式修改自己的自我改进的人工智能。不幸的是，证明大多数更改在实际中是净有益的几乎是不可能的。我们提出了达尔文哥德尔机（DGM），这是一种能迭代性修改自身代码（从而也改进其修改自身代码库的能力）并通过编码基准测试实证验证每一个更改的自我改进系统。受达尔文进化论和开放式研究启发，DGM维护一个生成的编码代理库。它通过从库中抽样代理并使用基础模型创建所抽样代理的新有趣版本来增长库。这种开放式探索形成了多样化、高质量代理的不断增长的树，允许在搜索空间中平行探索许多不同路径。实验证明，DGM自动改进其编码能力（例如，更好的代码编辑工具、长上下文窗口管理、同行评审机制），在SWE-bench上的性能从20.0%提高到50.0%，在Polyglot上的性能从14.2%提高到30.7%。此外，DGM显著优于不具备自我改进或开放式探索的基线。所有实验都在安全措施下进行（例如，沙盒环境和人工监督）。DGM朝着自我改进的人工智能迈出了重要一步，它能够在逐渐展开的路径中收集自身的垫脚石，通向无尽的创新。\n\n作者：Jenny Zhang, Shengran Hu, Cong Lu, Robert Lange, Jeff Clune\n\n备注：代码在此 https URL\n\n链接：https://arxiv.org/pdf/2505.22954.pdf\n\n标题：2025 [2505.22954] 达尔文哥德尔机：自我改进代理的开放式进化.pdf",
        "地址": "https://arxiv.org/pdf/2505.22954.pdf"
    },
    {
        "名称": "2025 [2505.21724] OmniResponse: Online Multimodal Conversational Response Generation in Dyadic Interactions.pdf",
        "作者": "Cheng Luo, Jianghui Wang, Bing Li, Siyang Song, Bernard Ghanem",
        "摘要": "摘要: 在本文中，我们介绍了一种新的任务——在线多模态对话响应生成(OMCRG)，旨在根据说话者的多模态输入同步生成口头和非口头的听者反馈。OMCRG反映了自然的二人互动，并在生成的听者音频和面部反应之间实现同步方面提出了新的挑战。为了解决这些挑战，我们创新性地引入文本作为中间模态来桥接音频和面部反应。因此，我们提出了OmniResponse，一种多模态大型语言模型(MLLM)，可自回归式生成高质量的多模态听者响应。OmniResponse利用预训练的LLM并增强了两个新组件：Chrono-Text，它在时间上锚定生成的文本标记，和TempoVoice，一种可控的在线文本转语音(TTS)模块，同步生成语音和面部反应。为了支持进一步的OMCRG研究，我们提出了ResponseNet，一个新的数据集，包含696个高质量的二人互动，具有同步的分屏视频、多通道音频、转录和面部行为注释。在ResponseNet上进行的综合评估表明，OmniResponse在语义语音内容、视听同步和生成质量方面显著优于基线模型。",
        "地址": "https://arxiv.org/pdf/2505.21724.pdf"
    },
    {
        "名称": "2025 [2506.00723] Pitfalls in Evaluating Language Model Forecasters.pdf",
        "作者": "Daniel Paleka, Shashwat Goel, Jonas Geiping, Florian Tramèr",
        "摘要": "摘要：大型语言模型（LLMs）最近已应用于预测任务，一些研究工作声称这些系统可以匹敌或超过人类的表现。在本文中，我们认为作为一个社区，我们应该对这样的结论保持谨慎，因为评估LLM预测器具有独特的挑战性。我们识别了两类广泛的问题：（1）由于多种形式的时间泄漏，难以信任评估结果；（2）难以从评估表现推断到现实世界的预测。通过系统分析和以前工作的具体例子，我们展示了评估缺陷如何引发对当前和未来性能声明的担忧。我们认为需要更严格的评估方法来自信地评估LLMs的预测能力。",
        "地址": "https://arxiv.org/pdf/2506.00723.pdf"
    },
    {
        "名称": "2025 [2505.19621] Think Again! The Effect of Test-Time Compute on Preferences, Opinions, and Beliefs of Large Language Models.pdf",
        "作者": "George Kour, Itay Nakash, Ateret Anaby-Tavor, Michal Shmueli-Scheuer",
        "摘要": "**摘要**: 随着大型语言模型（LLMs）在日常生活中的深入整合并对决策产生越来越大的影响，评估它们是否以及在何种程度上表现出主观偏好、观点和信仰变得至关重要。这些倾向可能源于模型内部的偏见，这可能会影响它们的行为、对用户提供的建议和推荐，并可能强化某些观点。本文提出了偏好、观点和信仰调查（POBs），这是一个用于评估LLMs在社会、文化、伦理和个人领域中的主观倾向的基准。我们应用了我们的基准来评估领先的开源和闭源LLMs，测量诸如可靠性、中立性和一致性等所需特性。此外，我们通过推理和自我反思机制研究了增加测试时间计算对这些指标的影响。尽管这些机制在其他任务中效果显著，但我们的结果表明，它们在我们的领域中仅提供有限的增益。此外，我们揭示了更新的模型版本变得越来越不一致，并且更多地偏向特定观点，突显了一个盲点和一个令人担忧的趋势。POBS: this https URL",
        "地址": "https://arxiv.org/pdf/2505.19621.pdf"
    },
    {
        "名称": "2025 [2506.01074] How Programming Concepts and Neurons Are Shared in Code Language Models.pdf",
        "作者": "Amir Hossein Kargaran, Yihong Liu, François Yvon, Hinrich Schütze",
        "摘要": "摘要: 多项研究已经探讨了大型语言模型（LLMs）在编程任务中的机制，但大多数集中在单语环境中的编程语言（PLs）。在本文中，我们研究了多个编程语言和英语在LLM概念空间中的关系。我们使用两个基于Llama的模型对21对编程语言进行少样本翻译任务。通过在任务过程中解码中间层的嵌入，我们观察到概念空间更接近于英语（包括编程语言关键词），并在中间层的后半部分为英语标记分配了较高的概率。我们分析了11种编程语言和英语的神经元激活情况，发现虽然特定语言的神经元主要集中在底层，但专属于每种编程语言的神经元趋向于出现在顶层。对于与多种其他编程语言高度一致的编程语言，识别其特定语言的神经元并不可行。这些编程语言通常比其他编程语言的关键词集更大，并且无论在翻译任务中的输入/输出编程语言为何，它们都更接近模型的概念空间。我们的研究结果提供了关于LLM如何内部表示编程语言的见解，揭示了模型概念空间的结构模式。代码可在此https URL获得。\n\n作者: Amir Hossein Kargaran, Yihong Liu, François Yvon, Hinrich Schütze\n\n评论: ACL Findings 2025\n\nURL: https://arxiv.org/pdf/2506.01074.pdf\n\n标题: 2025 [2506.01074] 编程概念和神经元在代码语言模型中的共享方式.pdf",
        "地址": "https://arxiv.org/pdf/2506.01074.pdf"
    },
    {
        "名称": "2025 [2506.00930] Aligning VLM Assistants with Personalized Situated Cognition.pdf",
        "作者": "Yongqi Li, Shen Zhou, Xiaohu Li, Xin Miao, Jintao Wen, Mayi Xu, Jianhao Chen, Birong Pan, Hankun Kang, Yuanyuan Zhu, Ming Zhong, Tieyun Qian",
        "摘要": "摘要: 视觉语言模型(VLMs)已成为人类管理视觉任务的宝贵助手，能够符合一般人类目标，如无害和无幻觉。然而，背景多样化的人们即使在相同情况下也有不同的认知。因此，他们可能对VLM助手有个性化的期望。这突显了将VLM助手与个性化情境认知对齐以提供现实世界帮助的迫切需要。为研究这一问题，我们首先简化它，用角色集(Role-Set)的社会学概念来描述个人。然后，我们建议通过评估个人行为来检验是否实现个性化对齐。此外，我们构建了一个名为PCogAlignBench的基准，包含18k实例和20个具有不同角色集的个人。最后，我们提出了一个名为PCogAlign的框架，构建了一个基于认知和行为的奖励模型，以实现个性化对齐。实验结果和人工评估表明了PCogAlignBench的可靠性和我们提出的PCogAlign的有效性。我们将在此https URL上开源构建的基准和代码。",
        "地址": "https://arxiv.org/pdf/2506.00930.pdf"
    },
    {
        "名称": "2025 [2506.00772] LIFT the Veil for the Truth: Principal Weights Emerge after Rank Reduction for Reasoning-Focused Supervised Fine-Tuning.pdf",
        "作者": "Zihang Liu, Tianyu Pang, Oleg Balabanov, Chaoqun Yang, Tianjin Huang, Lu Yin, Yaoqing Yang, Shiwei Liu",
        "摘要": "摘要：最近的研究表明，在少量高质量数据集上进行监督微调可以使大规模语言模型（LLM）获得强大的推理能力。然而，全面微调（Full FT）虽然功能强大，但计算成本高且容易过拟合和灾难性遗忘，特别是在数据有限的情况下。稀疏微调此前通过仅更新小部分模型参数取得了显著成功，在效率与效果之间提供了一个有前途的折衷。然而，在LLM时代，由于难以识别对推理至关重要的参数，它已落后于时代。在这项工作中，我们提出低秩近似后的最大值权重是微调的关键权重，我们称之为主要权重。令人惊讶的是，虽然基于幅度的稀疏微调在LLM微调中表现不佳，但在降秩后变得非常有效。这些见解激励了我们的方法：低秩通知稀疏微调（LIFT）。LIFT在整个训练过程中仅更新前5%的主要权重，并在推理任务上始终优于Full FT，同时保持与流行的参数高效微调方法相当的内存效率。除了在目标领域如算术推理上表现强劲外，LIFT还保留了最多20%的源领域知识，相对于Full FT和LoRA。我们的代码可在以下网址获取：this https URL。\n\n作者：Zihang Liu, Tianyu Pang, Oleg Balabanov, Chaoqun Yang, Tianjin Huang, Lu Yin, Yaoqing Yang, Shiwei Liu\n\n评论：ICML 2025\n\n标题：揭示真相：主要权重在降秩后出现，用于推理集中的监督微调",
        "地址": "https://arxiv.org/pdf/2506.00772.pdf"
    },
    {
        "名称": "2025 [2506.00530] CityLens: Benchmarking Large Language-Vision Models for Urban Socioeconomic Sensing.pdf",
        "作者": "Tianhui Liu, Jie Feng, Hetian Pang, Xin Zhang, Tianjian Ouyang, Zhiyuan Zhang, Yong Li",
        "摘要": "摘要：通过视觉数据了解城市社会经济状况是一项富有挑战性但对可持续城市发展和政策规划至关重要的任务。在这项研究中，我们介绍了CityLens，这是一套全面的基准，用于评估大规模语言-视觉模型（LLVMs）在卫星和街景图像中预测社会经济指标的能力。我们构建了一个涵盖全球17个城市的多模态数据集，涉及六个关键领域：经济、教育、犯罪、交通、健康和环境，反映了城市生活的多方面特征。基于该数据集，我们定义了11个预测任务并使用了三种评估范式：直接指标预测、标准化指标估算和基于特征的回归。我们对17个最先进的LLVMs进行了这些任务的基准测试。我们的结果表明，尽管LLVMs展示了令人期待的感知和推理能力，但它们在预测城市社会经济指标方面仍然存在局限性。CityLens提供了一个统一框架，用于诊断这些局限性并指导未来使用LLVMs理解和预测城市社会经济模式的努力。我们的代码和数据集通过这个网址开源。\n\n作者：刘天慧、冯杰、庞赫天、张欣、欧阳天健、张志远、李勇\n\n链接：https://arxiv.org/pdf/2506.00530.pdf\n\n标题：CityLens：大规模语言-视觉模型用于城市社会经济感知的基准测试",
        "地址": "https://arxiv.org/pdf/2506.00530.pdf"
    },
    {
        "名称": "2025 [2506.00523] SenseFlow: Scaling Distribution Matching for Flow-based Text-to-Image Distillation.pdf",
        "作者": "Xingtong Ge, Xin Zhang, Tongda Xu, Yi Zhang, Xinjie Zhang, Yan Wang, Jun Zhang",
        "摘要": "摘要：分布匹配蒸馏（DMD）已经成功应用于文本到图像扩散模型，例如Stable Diffusion（SD） 1.5。然而，普通DMD在大规模基于流的文本到图像模型上面临收敛困难，例如SD 3.5和FLUX。在本文中，我们首先分析了应用普通DMD在大规模模型时存在的问题。然后，为了克服可扩展性挑战，我们提出了隐式分布对齐（IDA）来规范生成器和伪分布之间的距离。此外，我们提出了段内指导（ISG）来重新定位教师模型的时间步重要性分布。仅使用IDA，DMD便可在SD 3.5上收敛；同时使用IDA和ISG，DMD在SD 3.5和FLUX 1 dev上收敛。结合其他改进，如增强的判别器模型，我们的最终模型称为SenseFlow，在基于扩散的文本到图像模型（例如SDXL）和流匹配模型（例如SD 3.5 Large和FLUX）的蒸馏中实现了优越的性能。源代码将会在此https URL提供。\n\n作者：葛兴同，张鑫，徐同大，张毅，张欣杰，王岩，张俊。  \n评论：正在审核中。  \n链接：https://arxiv.org/pdf/2506.00523.pdf  \n标题：2025 [2506.00523] SenseFlow: Scaling Distribution Matching for Flow-based Text-to-Image Distillation.pdf",
        "地址": "https://arxiv.org/pdf/2506.00523.pdf"
    },
    {
        "名称": "2025 [2506.00385] MagiCodec: Simple Masked Gaussian-Injected Codec for High-Fidelity Reconstruction and Generation.pdf",
        "作者": "Yakun Song, Jiawei Chen, Xiaobin Zhuang, Chenpeng Du, Ziyang Ma, Jian Wu, Jian Cong, Dongya Jia, Zhuo Chen, Yuping Wang, Yuxuan Wang, Xie Chen",
        "摘要": "摘要：神经音频编解码器在将原始音频波形高效地映射到离散的token表示上取得了显著进展，这些token表示是当前音频生成模型的基础。然而，大多数现有的编解码器主要在重建质量方面进行优化，往往忽略了编码后的token在下游模型中的可用性。为了解决这一瓶颈问题，我们提出了$\\\\textbf{MagiCodec}$，一种新型的基于单层流式Transformer的音频编解码器。MagiCodec通过多阶段培训流程，包括高斯噪声注入和潜在规则化，明确地提升生成代码的语义表达能力，同时保持高重建保真度。我们在频域中解析推导了噪声注入的效果，证明其在减弱高频成分和促进鲁棒token化方面的有效性。广泛的实验评估表明，MagiCodec在重建质量和下游任务方面均超过了现有的最先进编解码器。值得注意的是，MagiCodec生成的tokens呈现出类似自然语言的齐夫分布，从而提高了与基于语言模型的生成架构的兼容性。代码和预训练模型可以在该URL获取。\n\n翻译：神经音频编解码器在将原始音频波形高效地映射到离散的token表示上取得了显著进展，这些token表示是当前音频生成模型的基础。然而，大多数现有的编解码器主要在重建质量方面进行优化，往往忽略了编码后的token在下游模型中的可用性。为了解决这一瓶颈问题，我们提出了MagiCodec，一种新型的基于单层流式Transformer的音频编解码器。MagiCodec通过多阶段培训流程，包括高斯噪声注入和潜在规则化，明确地提升生成代码的语义表达能力，同时保持高重建保真度。我们在频域中解析推导了噪声注入的效果，证明其在减弱高频成分和促进鲁棒token化方面的有效性。广泛的实验评估表明，MagiCodec在重建质量和下游任务方面均超过了现有的最先进编解码器。值得注意的是，MagiCodec生成的tokens呈现出类似自然语言的齐夫分布，从而提高了与基于语言模型的生成架构的兼容性。代码和预训练模型可以在该URL获取。",
        "地址": "https://arxiv.org/pdf/2506.00385.pdf"
    },
    {
        "名称": "2025 [2506.00381] Neuro2Semantic: A Transfer Learning Framework for Semantic Reconstruction of Continuous Language from Human Intracranial EEG.pdf",
        "作者": "Siavash Shams, Richard Antonello, Gavin Mischler, Stephan Bickel, Ashesh Mehta, Nima Mesgarani",
        "摘要": "摘要: 从神经信号解码连续语言在神经科学和人工智能的交叉领域仍然是一个重大挑战。我们介绍了一种新框架Neuro2Semantic，它从颅内脑电图(iEEG)记录中重构感知语音的语义内容。我们的方法包括两个阶段：第一阶段，一个基于LSTM的适配器将神经信号与预训练的文本嵌入对齐；第二阶段，校正模块直接从这些对齐的嵌入中生成连续的自然文本。这种灵活的方法克服了先前解码方法的局限性，实现了不受约束的文本生成。Neuro2Semantic仅需30分钟的神经数据便能表现出色，在低数据环境下超越了最新的先进方法。这些结果突显了在脑机接口和神经解码技术中的实际应用潜力。\n\n作者: Siavash Shams, Richard Antonello, Gavin Mischler, Stephan Bickel, Ashesh Mehta, Nima Mesgarani\n\n备注: 已被Interspeech 2025接受。代码可在该链接获取。\n\n链接: https://arxiv.org/pdf/2506.00381.pdf\n\n标题: Neuro2Semantic: 一种通过人类颅内脑电图实现连续语言语义重构的迁移学习框架",
        "地址": "https://arxiv.org/pdf/2506.00381.pdf"
    },
    {
        "名称": "2025 [2505.21668] R1-Code-Interpreter: Training LLMs to Reason with Code via Supervised and Reinforcement Learning.pdf",
        "作者": "Yongchao Chen, Yueying Liu, Junwei Zhou, Yilun Hao, Jingquan Wang, Yang Zhang, Chuchu Fan",
        "摘要": "摘要：尽管R1类模型在推理和规划方面取得了进展，但大型语言模型（LLMs）在需要精确计算、符号操作、优化和算法推理的任务中仍然存在困难，其中文本推理缺乏代码执行的严谨性。一个关键挑战是使LLMs能够决定何时使用文本推理与代码生成。虽然OpenAI训练模型在需要时调用代码解释器，公共研究缺乏指导，以便使预训练LLMs有效利用代码并在多种任务中泛化。我们提出了R1-Code-Interpreter，一个通过多轮监督微调（SFT）和强化学习（RL）训练的文本LLM扩展，它能够在逐步推理过程中自主生成多个代码查询。我们选取了144个推理和规划任务（107个用于训练，37个用于测试），每个任务包含200多个多样化问题。我们使用各种SFT和RL策略微调Qwen-2.5模型（3B/7B/14B），研究不同的答案格式、推理与非推理模型、冷启动与热启动、GRPO与PPO、以及掩码与非掩码代码输出。与以前在狭窄领域进行的RL工作不同，我们发现代码解释器训练由于任务多样性高和代码执行成本昂贵而显著困难，强调SFT阶段的关键作用。我们的最终模型R1-CI-14B将37个测试任务的平均准确率从44.0%提高到64.1%，优于GPT-4o（仅文本：58.6%），并接近GPT-4o配备代码解释器（70.9%），通过代码生成实现了新兴的自检行为。数据集、代码和模型可在此https URL和此https URL获得。",
        "地址": "https://arxiv.org/pdf/2505.21668.pdf"
    },
    {
        "名称": "2025 [2505.20285] MaskSearch: A Universal Pre-Training Framework to Enhance Agentic Search Capability.pdf",
        "作者": "Weiqi Wu, Xin Guan, Shen Huang, Yong Jiang, Pengjun Xie, Fei Huang, Jiuxin Cao, Hai Zhao, Jingren Zhou",
        "摘要": "Retrieval-Augmented Language Models (RALMs) 代表一种经典范式，其中模型通过使用专门模块检索的外部知识来增强生成能力。代理技术的最新进展使大型语言模型(LLMs)能够自主利用工具进行检索、规划和推理。虽然现有的基于训练的方法显示出前景，但它们的代理能力受到训练期间使用的任务特定数据固有特性的限制。为了进一步增强代理的通用搜索能力，我们提出了一种新的预训练框架，MaskSearch。在预训练阶段，我们引入了检索增强掩码预测(RAMP)任务，其中模型学习利用搜索工具填充大量预训练数据中的掩码跨度，从而获得LLMs的通用检索和推理能力。之后，模型在下游任务上进行训练以实现进一步改进。我们应用监督微调(SFT)和强化学习(RL)进行训练。对于SFT,我们结合基于代理和蒸馏的方法生成训练数据，首先是由规划者、重写者、观察者组成的多代理系统，然后是自我演化的教师模型。而对于RL，我们采用DAPO作为训练框架，并采用由答案奖励和格式奖励组成的混合奖励系统。此外我们引入了一种课程学习方法，使模型能够根据掩码跨度的数量逐步学习从较容易到较具挑战性的实例。我们在开放域多跳问题回答的场景中评估我们的框架的效果。通过广泛的实验，我们证明MaskSearch显著增强了基于LLM的搜索代理在域内和域外下游任务上的表现。",
        "地址": "https://arxiv.org/pdf/2505.20285.pdf"
    },
    {
        "名称": "2025 [2505.16122] Plan and Budget: Effective and Efficient Test-Time Scaling on Large Language Model Reasoning.pdf",
        "作者": "Junhong Lin, Xinyue Zeng, Jie Zhu, Song Wang, Julian Shun, Jun Wu, Dawei Zhou",
        "摘要": "摘要：大型语言模型（LLMs）在复杂推理任务中取得了显著成功，但其推理仍然在计算上效率低下。我们观察到许多流行的LLMs中存在一种常见的失败模式，即过度思考，其中模型即使对于简单查询也会生成冗长且无关的推理轨迹。最近的工作试图通过强制固定的令牌预算来缓解这一问题，但这可能导致在处理更难的问题时出现思维不足的情况。通过实证分析，我们发现这种低效通常源于不明确的问题解决策略。为了形式化这一点，我们开发了一个理论模型，BBAM（贝叶斯预算分配模型），该模型将推理建模为具有不同不确定性的子问题的序列，并引入了$E^3$度量来捕捉正确性和计算效率之间的权衡。基于BBAM的理论结果，我们提出了一个与模型无关的测试时间框架Plan-and-Budget，它将复杂查询分解为子问题，并根据估计的复杂性使用自适应调度分配令牌预算。Plan-and-Budget在一系列任务和模型中提高了推理效率，实现了高达70%的准确率提升，39%的令牌减少以及187.5%的$E^3$改善。值得注意的是，它使较小的模型（DS-Qwen-32B）的效率达到了较大模型（DS-LLaMA-70B）的水平，展示了Plan-and-Budget无需重新训练即可弥合性能差距的能力。我们的代码可在此网址获取：https://arxiv.org/pdf/2505.16122.pdf。",
        "地址": "https://arxiv.org/pdf/2505.16122.pdf"
    },
    {
        "名称": "2025 [2505.17127] Pixels Versus Priors: Controlling Knowledge Priors in Vision-Language Models through Visual Counterfacts.pdf",
        "作者": "Michal Golovanevsky, William Rudman, Michael Lepori, Amir Bar, Ritambhara Singh, Carsten Eickhoff",
        "摘要": "摘要：多模态大型语言模型（MLLMs）在视觉问答等任务中表现良好，但尚不清楚它们的推理更多地依赖于记忆的世界知识还是输入图像中的视觉信息。为了研究这一点，我们引入了Visual CounterFact，这是一个将世界知识先验（例如，红色草莓）直接与视觉输入（例如，蓝色草莓）相冲突的视觉逼真反事实的新数据集。使用Visual CounterFact，我们展示了模型预测最初反映了记忆的先验，但在中后层时转向视觉证据。这种动态揭示了两种模态之间的竞争，最终在评估过程中视觉输入会覆盖先验。为了控制这种行为，我们提出了Pixels Versus Priors（PvP）引导向量，一种通过激活水平干预控制模型输出朝向世界知识或视觉输入的机制。平均而言，PvP成功地将92.5%的颜色预测和74.6%的大小预测从先验转移到反事实。这些发现共同提供了新的工具来解释和控制多模态模型中的事实行为。",
        "地址": "https://arxiv.org/pdf/2505.17127.pdf"
    },
    {
        "名称": "2025 [2506.01062] SealQA: Raising the Bar for Reasoning in Search-Augmented Language Models.pdf",
        "作者": "Thinh Pham, Nguyen Nguyen, Pratibha Zunjare, Weiyuan Chen, Yu-Min Tseng, Tu Vu",
        "摘要": "摘要: 我们介绍了 SealQA，这是一项新的挑战基准，用于评估搜索增强语言模型在事实寻求问题上的表现，其中网络搜索可能产生冲突、噪音或无用的结果。 SealQA 有三种形式: (1) Seal-0（主要）和 (2) Seal-Hard，评估事实的准确性和推理能力，其中 Seal-0 着重于那些聊天模型（例如 GPT-4.1）通常几乎无法达到准确的问题；(3) LongSeal，扩展了 SealQA，用于测试长文本、多文档推理的“隐藏在堆中的针”设置。我们的评估揭示了当前模型的关键限制：即使是前沿的大规模语言模型在所有 SealQA 的形式上表现也很差。在 Seal-0 上，前沿代理模型配备如 o3 和 o4-mini 等工具在其最佳推理努力下仅分别达到 17.1% 和 6.3% 的准确度。我们发现，高级推理模型如 DeepSeek-R1-671B 和 o3-mini 对噪音搜索结果高度脆弱。特别是，增加测试时的计算能力并不能在 o3-mini、o4-mini 和 o3 上获得可靠的提升，性能往往在早期达到顶峰甚至下降。此外，尽管最新的模型受“中间迷失”问题影响较小，但在 LongSeal 面对大量干扰因素时仍无法可靠地识别相关文件。为了促进未来的工作，我们在此网址发布了 SealQA。",
        "地址": "https://arxiv.org/pdf/2506.01062.pdf"
    },
    {
        "名称": "2025 [2506.00469] Massively Multilingual Adaptation of Large Language Models Using Bilingual Translation Data.pdf",
        "作者": "Shaoxiong Ji, Zihao Li, Jaakko Paavola, Indraneil Paul, Hengyu Luo, Jörg Tiedemann",
        "摘要": "摘要：本文研究了大规模多语言持续预训练实践中的一个关键设计决策——平行数据的纳入。具体来说，我们研究了双语翻译数据对Llama3系列模型适应500种语言的大规模多语言的影响。为此，我们构建了MaLA双语翻译语料库，其中包含来自2500多种语言对的数据。随后，我们开发了EMMA-500 Llama 3套件的四个大规模多语言模型，这些模型在多样化数据混合上持续预训练达到671B个标记，并探索了有或没有双语翻译数据的持续预训练效果。通过7项任务和12个基准的综合评估表明，双语数据的确增强了语言迁移和表现，特别是对于资源匮乏的语言。我们开源了MaLA语料库、EMMA-500 Llama 3套件工件、代码和模型生成品。",
        "地址": "https://arxiv.org/pdf/2506.00469.pdf"
    },
    {
        "名称": "2025 [2505.24216] Shuffle PatchMix Augmentation with Confidence-Margin Weighted Pseudo-Labels for Enhanced Source-Free Domain Adaptation.pdf",
        "作者": "Prasanna Reddy Pulakurthi, Majid Rabbani, Jamison Heard, Sohail Dianat, Celso M. de Melo, Raghuveer Rao",
        "摘要": "摘要：这项研究探讨了无源域适应（SFDA），即模型在没有源数据的情况下适应目标域。引入了一种新的增强技术，Shuffle PatchMix（SPM），以及一种新的重加权策略以提升性能。SPM通过打乱和混合图像块来生成多样且具有挑战性的增强图像，而重加权策略则优先考虑可靠的伪标签以减轻标签噪声。这些技术在较小的数据集如PACS上特别有效，因为在这些数据集上过拟合和伪标签的噪声风险更高。在三个主要基准上达到了最先进的结果：PACS、VisDA-C和DomainNet-126。尤其是在PACS上，单目标和多目标环境中分别观察到7.3%（79.4%到86.7%）和7.2%的改进，而在DomainNet-126和VisDA-C上则分别获得了2.8%和0.7%的提升。这种先进的增强与稳健的伪标签重加权组合为SFDA建立了新的基准。代码可在此URL获得。\n\n作者：Prasanna Reddy Pulakurthi, Majid Rabbani, Jamison Heard, Sohail Dianat, Celso M. de Melo, Raghuveer Rao\n\n备注：6页，3个图，5个表，已被IEEE ICIP 2025接收\n\nURL：https://arxiv.org/pdf/2505.24216.pdf\n\n标题：2025 [2505.24216] 通过置信边距加权伪标签的Shuffle PatchMix增强技术提升无源域适应性能.pdf",
        "地址": "https://arxiv.org/pdf/2505.24216.pdf"
    },
    {
        "名称": "2025 [2505.22865] BinauralFlow: A Causal and Streamable Approach for High-Quality Binaural Speech Synthesis with Flow Matching Models.pdf",
        "作者": "Susan Liang, Dejan Markovic, Israel D. Gebru, Steven Krenn, Todd Keebler, Jacob Sandakly, Frank Yu, Samuel Hassel, Chenliang Xu, Alexander Richard",
        "摘要": "摘要：双耳渲染旨在根据单声道音频以及说话者和听众的位置合成模仿自然听觉的双耳音频。尽管已经提出了许多方法来解决这个问题，但它们在渲染质量和流式推理方面仍然存在困难。合成与真实录音无法区分的高质量双耳音频需要精确建模双耳线索、房间混响和环境声音。此外，现实应用需要流式推理。为了解决这些挑战，我们提出了一种基于流匹配的流式双耳语音合成框架，称为BinauralFlow。我们认为双耳渲染是一个生成问题而不是回归问题，并设计了一个条件流匹配模型来渲染高质量音频。此外，我们设计了一个因果U-Net架构，该架构仅基于过去信息估计当前音频帧，旨在定制生成模型用于流式推理。最后，我们引入了一个连续推理管道，结合流式STFT/ISTFT操作、缓冲池、中点求解器和提前跳过调度，以提高渲染的连续性和速度。定量和定性评估显示了我们的方法相对于最先进方法的优越性。感知研究进一步表明，我们的模型与真实录音几乎无法区分，混淆率为42%。",
        "地址": "https://arxiv.org/pdf/2505.22865.pdf"
    },
    {
        "名称": "2025 [2505.18128] Frankentext: Stitching random text fragments into long-form narratives.pdf",
        "作者": "Chau Minh Pham, Jenna Russell, Dzung Pham, Mohit Iyyer",
        "摘要": "摘要：我们介绍了Frankentexts，这是一种新的长篇叙事，由语言模型在极端限制下生成，其中大多数标记（例如，90%）必须从人类写作中逐字复制。这项任务对于可控生成来说是一个具有挑战性的测试，要求模型满足写作提示、整合不同的文本片段，并仍然生成连贯的叙事。为了生成Frankentexts，我们指示模型通过选择和组合人类写的段落来生成草稿，然后在保持用户指定的复制比例的同时迭代修改草稿。我们从三个方面评估生成的Frankentexts：写作质量、指令遵从性和可检测性。Gemini-2.5-Pro在这项任务中表现出色：81%的Frankentexts是连贯的，且100%与提示相关。值得注意的是，多达59%的这些输出被如Pangram这样的检测器错误分类为人类写作，揭示了AI文本检测器的局限性。人类注释者有时可以通过其突然的语气变化和各段间不一致的语法来识别Frankentexts，特别是在较长的生成中。除了展示具有挑战性的生成任务外，Frankentexts还邀请大家讨论如何为这种新的灰色写作区域建立有效的检测器，为混合作者身份检测提供训练数据，并作为研究人类与AI共同写作过程的沙箱。",
        "地址": "https://arxiv.org/pdf/2505.18128.pdf"
    },
    {
        "名称": "2025 [2505.15772] MIKU-PAL: An Automated and Standardized Multi-Modal Method for Speech Paralinguistic and Affect Labeling.pdf",
        "作者": "Yifan Cheng, Ruoyi Zhang, Jiatong Shi",
        "摘要": "摘要：获取具有高度一致性的大规模情感语音数据仍然是语音合成的一个挑战。本文提出了MIKU-PAL，一种从未标记视频数据中提取高一致性情感语音的全自动多模态流水线。通过利用人脸检测和跟踪算法，我们开发了一个使用多模态大语言模型（MLLM）的自动情感分析系统。我们的结果表明，MIKU-PAL在达到人类水平的准确度（在MELD数据集上为68.5%）和优越的一致性（弗利斯卡帕系数为0.93）的同时，比人工注释更加便宜和快速。借助于MIKU-PAL的高质量、灵活和一致的注释，我们可以标注多达26种细粒度的语音情感类别，并通过人工注释者验证，合理性评分为83%。基于我们提出的系统，我们进一步发布了一个细粒度情感语音数据集MIKU-EmoBench（131.2小时），作为情感文本到语音和视觉语音克隆的新基准。",
        "地址": "https://arxiv.org/pdf/2505.15772.pdf"
    },
    {
        "名称": "2025 [2506.01666] Synthesis of discrete-continuous quantum circuits with multimodal diffusion models.pdf",
        "作者": "Florian Fürrutter, Zohim Chandani, Ikko Hamamura, Hans J. Briegel, Gorka Muñoz-Gil",
        "摘要": "摘要: 高效编译量子操作仍然是量子计算扩展的主要瓶颈。当前最先进的方法通过结合搜索算法和基于梯度的参数优化来实现低编译误差，但它们需要长时间运行，并需要多次调用量子硬件或昂贵的经典仿真，使其扩展受到限制。最近，机器学习模型作为一种替代方法出现，但它们目前仅限于离散门集。在这里，我们引入了一种多模态去噪扩散模型，该模型同时生成电路的结构及其连续参数，以编译目标幺正矩阵。它利用两个独立的扩散过程，一个用于离散门选择，另一个用于参数预测。我们对该模型进行了不同实验的基准测试，分析了该方法在不同量子比特数量、电路深度和参数化门比例下的准确性。最后，通过利用其快速电路生成，我们创建了用于特定操作的大型电路数据集，并使用这些数据集提取有价值的启发式方法，帮助我们发现量子电路合成的新见解。",
        "地址": "https://arxiv.org/pdf/2506.01666.pdf"
    }
]