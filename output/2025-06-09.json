[
    {
        "名称": "2025 [2505.21115] Will It Still Be True Tomorrow? Multilingual Evergreen Question Classification to Improve Trustworthy QA.pdf",
        "作者": "Sergey Pletenev, Maria Marina, Nikolay Ivanov, Daria Galimzianova, Nikita Krayko, Mikhail Salnikov, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii",
        "摘要": "摘要: 大型语言模型 (LLMs) 在问答 (QA) 任务中经常出现幻觉现象。一个关键但未被充分探索的因素是问题的时间特性——它们是常青的（答案随时间保持稳定）还是可变的（答案会发生改变）。在这项工作中，我们引入了EverGreenQA，这是第一个带有常青标签的多语种QA数据集，支持评估和训练。使用EverGreenQA，我们对12个现代LLMs进行基准测试，以评估它们是否通过明确的判断（通过言语表达）或隐含的信号（通过不确定性信号）来编码问题的时间特性。我们还训练了EG-E5，这是一个轻量级的多语种分类器，在这个任务中实现了最先进的性能。最后，我们展示了常青分类在三个应用中的实际实用性：改进自我知识估计、过滤QA数据集和解释GPT-4o的检索行为。\n\n作者: Sergey Pletenev, Maria Marina, Nikolay Ivanov, Daria Galimzianova, Nikita Krayko, Mikhail Salnikov, Vasily Konovalov, Alexander Panchenko, Viktor Moskvoretskii\n\n标题: 2025 [2505.21115] 它明天还会是真的吗？多语种常青问题分类以改进可信问答\n\nURL: https://arxiv.org/pdf/2505.21115.pdf",
        "地址": "https://arxiv.org/pdf/2505.21115.pdf"
    },
    {
        "名称": "2025 [2506.01111] FusionAudio-1.2M: Towards Fine-grained Audio Captioning with Multimodal Contextual Fusion.pdf",
        "作者": "Shunian Chen, Xinyuan Xie, Zheshu Chen, Liyan Zhao, Owen Lee, Zhan Su, Qilin Sun, Benyou Wang",
        "摘要": "摘要：高质量、大规模的音频字幕对于推进音频理解至关重要，但现有自动化方法生成的字幕通常缺乏细腻的细节和语境准确性，主要是因为它们依赖于有限的单模态或表面上的多模态信息。受到人类听觉感知的启发，人类听觉巧妙地整合跨模态线索并执行复杂的听觉场景分析，我们引入了一种新颖的双阶段自动化流程。该流程首先使用专门的预训练模型来提取各种语境线索（例如：言语、音乐、一般声音以及相关视频中的视觉信息）。然后，一个大型语言模型（LLM）综合这些丰富的多模态输入，生成详细且具有语境意识的音频字幕。本文的主要贡献包括：(1) 提出了一种可扩展的细粒度音频字幕生成方法；(2) FusionAudio，一个包含120万个这种详细字幕和600万QA对的新大规模数据集；(3) 使用FusionAudio开发的增强音频模型，特别是一个基于CLAP的音频编码器，具有优异的音频-文本对齐和指令跟随能力。本文为更加细腻和准确的复杂音频环境的自动化理解铺平了道路。代码和数据可以在这个URL中找到。\n\n翻译作者：陈书年，谢昕元，陈哲恕，赵立岩，李欧文，苏展，孙启霖，王本友\n\nURL：https://arxiv.org/pdf/2506.01111.pdf\n\n标题：2025 [2506.01111] FusionAudio-1.2M: 通过多模态语境融合实现细粒度的音频字幕生成",
        "地址": "https://arxiv.org/pdf/2506.01111.pdf"
    },
    {
        "名称": "2025 [2506.05523] MORSE-500: A Programmatically Controllable Video Benchmark to Stress-Test Multimodal Reasoning.pdf",
        "作者": "Zikui Cai, Andrew Wang, Anirudh Satheesh, Ankit Nakhawa, Hyunwoo Jae, Keenan Powell, Minghui Liu, Neel Jay, Sungbin Oh, Xiyao Wang, Yongyuan Liang, Tom Goldstein, Furong Huang",
        "摘要": "摘要: 尽管视觉语言模型（VLMs）快速发展，目前的多模态推理基准在三个关键维度上仍然存在不足。首先，它们过度依赖静态图像，未能捕捉真实世界环境的时间复杂性。其次，它们过于关注数学问题解决，忽视了实现强大多模态智能所需的广泛推理技能——包括抽象、物理、规划、空间和时间能力。第三，许多基准测试很快达到饱和，提供有限的余地来诊断失败模式或测量持续进展。我们引入了MORSE-500（多模态推理压力测试环境），这是一个由500个完全脚本化剪辑组成的视频基准测试，包含六个互补推理类别的问题。每个实例都是使用确定性Python脚本（通过Manim、Matplotlib、MoviePy）、生成视频模型和精选的真实剪辑程序生成的。这种脚本驱动设计允许对视觉复杂性、干扰物密度和时间动态进行细粒度控制——使难度能够随着模型改进而系统化地提升。与静态基准测试在达到饱和后变得过时不同，MORSE-500旨在进化：其可控生成管道支持创建任意挑战性的新实例，使其非常适合对下一代模型进行压力测试。针对各种先进系统的初步实验，包括当时最强的Gemini 2.5 Pro和OpenAI o3以及强劲的开源模型，揭示了所有类别中存在显著的性能差距，特别是在抽象和规划任务中。我们发布了完整的数据集、生成脚本和评估工具，以支持透明、可重复和前瞻性的多模态推理研究。",
        "地址": "https://arxiv.org/pdf/2506.05523.pdf"
    },
    {
        "名称": "2025 [2506.05629] Leveraging Self-Attention for Input-Dependent Soft Prompting in LLMs.pdf",
        "作者": "Ananth Muppidi, Abhilash Nandy, Sambaran Bandyopadhyay",
        "摘要": "摘要：大型语言模型在特定领域任务中的表现需要微调，这既是计算昂贵的，也在技术上具有挑战性。本文集中讨论一种参数高效微调的软提示方法，这是一种通过学习少量参数使预训练模型适应下游任务的有前途的方法。我们提出了一种新的具有自注意机制的输入依赖软提示技术（ID-SPAM），它基于输入标记生成软提示，并对不同重要性的标记进行关注。我们的方法简单高效，保持可训练参数数量较少。我们展示了该方法在各种任务上的优越性，并展示了其改进的零样本领域迁移能力。",
        "地址": "https://arxiv.org/pdf/2506.05629.pdf"
    },
    {
        "名称": "2025 [2506.05446] Sentinel: SOTA model to protect against prompt injections.pdf",
        "作者": "Dror Ivry, Oran Nahum",
        "摘要": "摘要: 大型语言模型（LLMs）虽然越来越强大，但仍容易受到提示注入攻击，这种攻击会导致模型偏离预期指令。本文介绍了 Sentinel，一种基于\\\\answerdotai/ModernBERT-large架构的新型检测模型 qualifire/prompt-injection-sentinel。通过利用ModernBERT的高级特性，并在包含一些开源和私有集合的广泛多样化数据集上进行微调，Sentinel实现了最先进的性能。这个数据集融合了各种攻击类型，从角色扮演和指令劫持到试图生成偏见内容，以及广泛范围的良性指令，其中私有数据集特别针对细微的错误修正和实际中的错误分类。在一个全面的未见内部测试集中，Sentinel表现出平均准确率为0.987，F1分数为0.980。此外，在公共基准测试中进行评估时，它始终优于强基准模型如 protectai/deberta-v3-base-prompt-injection-v2。本文详细描述了 Sentinel 的架构、精心的数据集策划、训练方法及全面评估，突出了其卓越的检测能力。",
        "地址": "https://arxiv.org/pdf/2506.05446.pdf"
    },
    {
        "名称": "2025 [2506.05573] PartCrafter: Structured 3D Mesh Generation via Compositional Latent Diffusion Transformers.pdf",
        "作者": "Yuchen Lin, Chenguo Lin, Panwang Pan, Honglei Yan, Yiqiang Feng, Yadong Mu, Katerina Fragkiadaki",
        "摘要": "摘要: 我们介绍了PartCrafter，这是第一个结构化的3D生成模型，可以从单个RGB图像联合生成多个语义上有意义和几何上独立的3D网格。与现有的方法不同，后者要么生成单一的3D形状，要么采用两阶段流水线（即首先分割图像然后重建每个部分），PartCrafter采用一个统一的、组合生成架构，不依赖预分割的输入。在一张图像的条件下，它能够同时去噪多个3D部分，实现端到端的部分感知生成，无论是单个对象还是复杂的多对象场景。PartCrafter基于预训练的3D网格扩散变压器（DiT），该变压器在整个对象上进行训练，继承了预训练的权重、编码器和解码器，并引入了两个关键创新：(1) 一个组合的潜空间，其中每个3D部分由一组独立的潜令牌表示；(2) 一个分层的注意机制，使在个体部分内和所有部分之间进行结构化的信息流动，确保全球一致性，同时在生成过程中保持部分级别的细节。为了支持部分级别的监督，我们通过从大型3D对象数据库中挖掘部分级别的标注来编制一个新数据集。实验表明，PartCrafter在生成可分解的3D网格方面优于现有方法，包括那些在输入图像中不直接可见的部分，这展示了部分感知生成先验在3D理解和合成中的优势。代码和训练数据将会发布。",
        "地址": "https://arxiv.org/pdf/2506.05573.pdf"
    },
    {
        "名称": "2025 [2506.01872] Is Extending Modality The Right Path Towards Omni-Modality?.pdf",
        "作者": "Tinghui Zhu, Kai Zhang, Muhao Chen, Yu Su",
        "摘要": "摘要：全模态语言模型（OLM）旨在整合和推理多种输入模态——例如文本、图像、视频和音频——同时保持强大的语言能力。尽管最近取得了进展，现有的模型，尤其是开源模型，距离真正的全模态性还有很远，它们难以在训练的特定模态对之外进行泛化，或者在处理多模态输入时实现强大的性能。我们研究了扩展模态的效果，这是一种训练多模态模型的主导技术，其中现成的语言模型在目标领域和语言数据上进行微调。具体来说，我们调查了三个关键问题：（1）模态扩展是否会削弱核心语言能力？（2）模型合并能否有效地集成独立微调的模态特定模型，以实现全模态性？（3）与顺序扩展相比，全模态性扩展是否带来更好的知识共享和泛化能力？通过广泛的实验，我们分析了这些权衡，并提供了有关使用当前方法实现真正全模态性的可行性的见解。\n\n作者：朱廷辉、张凯、陈木豪、苏宇\n\n链接：https://arxiv.org/pdf/2506.01872.pdf\n\n标题：2025 [2506.01872] 扩展模态是通向全模态性之路吗？",
        "地址": "https://arxiv.org/pdf/2506.01872.pdf"
    },
    {
        "名称": "2025 [2506.06276] STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis.pdf",
        "作者": "Jiatao Gu, Tianrong Chen, David Berthelot, Huangjie Zheng, Yuyang Wang, Ruixiang Zhang, Laurent Dinh, Miguel Angel Bautista, Josh Susskind, Shuangfei Zhai",
        "摘要": "摘要: 我们介绍了STARFlow，这是一种基于正则化流的可扩展生成模型，在高分辨率图像合成方面表现强劲。STARFlow的核心是Transformer Autoregressive Flow (TARFlow)，它结合了正则化流的表现力和自回归Transformer的结构化建模能力。我们首先确定了TARFlow在连续分布建模中的理论普适性。基于这一基础，我们引入了几个关键的架构和算法创新，以显著增强扩展性：(1) 深浅结合设计，其中一个深度Transformer块捕获大部分模型的表示能力，由几个浅层Transformer块补充，这些块计算效率高但有重大益处；(2) 在预训练自动编码器的潜在空间中建模，比直接在像素级建模更有效；(3) 一种新的引导算法显著提升样本质量。重要的是，我们的模型仍然是端到端的正则化流，能够在连续空间中进行精确的最大似然训练而无需离散化。STARFlow在类条件和文本条件图像生成任务中实现了具有竞争力的表现，样本质量接近最先进的扩散模型。据我们所知，这项工作是第一个成功展示正则化流在该规模和分辨率下有效运行的例子。",
        "地址": "https://arxiv.org/pdf/2506.06276.pdf"
    },
    {
        "名称": "2025 [2506.05984] Audio-Aware Large Language Models as Judges for Speaking Styles.pdf",
        "作者": "Cheng-Han Chiang, Xiaofei Wang, Chung-Ching Lin, Kevin Lin, Linjie Li, Radu Kopetz, Yao Qian, Zhendong Wang, Zhengyuan Yang, Hung-yi Lee, Lijuan Wang",
        "摘要": "摘要：具有音频感知能力的大型语言模型（ALLMs）可以理解音频输入中的文本和非文本信息。本文探讨了使用ALLMs作为自动评判员来评估演讲的讲话风格。我们使用ALLM评判员来评估SLMs在两个任务中生成的演讲：声音风格指令遵循和角色扮演。我们考虑的讲话风格包括情感、音量、讲话速度、词语强调、音调控制以及非语言元素。我们使用四个口语语言模型（SLMs）完成这两个任务，并用人类和ALLMs来评判SLMs的响应。我们比较了两个ALLM评判员，GPT-4o-audio和Gemini-2.5-pro，与人类评估结果，并显示出Gemini与人类评判的一致性与人类评估者之间的一致性相当。这些有希望的结果表明，ALLMs可以作为评判员来评估SLMs。我们的结果还揭示了当前的SLMs，即使是GPT-4o-audio，在控制讲话风格和生成自然对话方面仍有改进空间。",
        "地址": "https://arxiv.org/pdf/2506.05984.pdf"
    },
    {
        "名称": "2025 [2506.06253] Bridging Perspectives: A Survey on Cross-view Collaborative Intelligence with Egocentric-Exocentric Vision.pdf",
        "作者": "Yuping He, Yifei Huang, Guo Chen, Lidong Lu, Baoqi Pei, Jilan Xu, Tong Lu, Yoichi Sato",
        "摘要": "摘要：从自我中心(第一人称)和外部中心(第三人称)视角感知世界是人类认知的基础，能够对动态环境进行丰富且互补的理解。近年来，让机器利用这两种视角的协同潜力已经成为视频理解领域一个引人注目的研究方向。在这项综述中，我们对从自我中心和外部中心视角进行视频理解进行全面回顾。我们首先强调了结合自我中心和外部中心技术的实际应用，展望它们在各个领域潜在的协作。然后，我们识别了实现这些应用的关键研究任务。接下来，我们系统性地组织并回顾了最近在三个主要研究方向上的进展：（1）利用自我中心数据增强外部中心理解，（2）使用外部中心数据改进自我中心分析，以及（3）统一两种视角的联合学习框架。对于每个方向，我们分析了一组多样化的任务和相关工作。此外，我们讨论了支持这两种视角研究的基准数据集，评估它们的范围、多样性和适用性。最后，我们讨论了当前工作的局限性并提出了有前景的未来研究方向。通过汇集两种视角的见解，我们的目标是激发视频理解和人工智能领域的进步，使机器更接近于以人类的方式感知世界。相关工作的GitHub仓库可以在此链接找到。\n\n链接: [https://arxiv.org/pdf/2506.06253.pdf](https://arxiv.org/pdf/2506.06253.pdf)",
        "地址": "https://arxiv.org/pdf/2506.06253.pdf"
    },
    {
        "名称": "2025 [2506.06199] 3DFlowAction: Learning Cross-Embodiment Manipulation from 3D Flow World Model.pdf",
        "作者": "Hongyan Zhi, Peihao Chen, Siyuan Zhou, Yubo Dong, Quanxi Wu, Lei Han, Mingkui Tan",
        "摘要": "摘要：操控任务一直是机器人面临的挑战，而人类能够轻松地与物体进行复杂交互，例如将杯子挂在杯架上。一个关键原因是缺乏用于教机器人操控技能的庞大且统一的数据集。目前的机器人数据集通常在一个简单场景中记录机器人在不同动作空间中的动作。这阻碍了机器人在多样化场景中学习统一且强大的动作表示。观察人类如何理解操控任务，我们发现理解物体在3D空间中的移动是指导动作的重要线索。这种线索与执行主体无关，适用于人类和不同的机器人。受此启发，我们旨在从人类和机器人操控数据中学习一个3D流动世界模型。该模型预测交互物体在3D空间中的未来运动，为操控动作规划提供指导。具体来说，我们通过移动物体自动检测管道合成了一个大规模3D光流数据集，命名为ManiFlow-110k。然后，一个基于视频扩散的世界模型从这些数据中学习操控物理，生成基于语言指令的3D光流轨迹。通过生成的3D物体光流，我们提出一种流动引导渲染机制，该机制渲染预测的最终状态并利用GPT-4o评估预测的光流是否与任务描述一致。这使机器人具备闭环规划能力。最后，我们将预测的3D光流视为优化策略的约束，确定一段机器人操控动作。大量实验展示了在多样化机器人操控任务中的强大泛化能力以及无需硬件特定训练的可靠跨主体适应能力。\n\n翻译：\n操控任务一直是机器人面临的挑战，而人类能够轻松地与物体进行复杂交互，例如将杯子挂在杯架上。一个关键原因是缺乏用于教机器人操控技能的庞大且统一的数据集。目前的机器人数据集通常在一个简单场景中记录机器人在不同动作空间中的动作。这阻碍了机器人在多样化场景中学习统一且强大的动作表示。观察人类如何理解操控任务，我们发现理解物体在3D空间中的移动是指导动作的重要线索。这种线索与执行主体无关，适用于人类和不同的机器人。受此启发，我们旨在从人类和机器人操控数据中学习一个3D流动世界模型。该模型预测交互物体在3D空间中的未来运动，为操控动作规划提供指导。具体来说，我们通过移动物体自动检测管道合成了一个大规模3D光流数据集，命名为ManiFlow-110k。然后，一个基于视频扩散的世界模型从这些数据中学习操控物理，生成基于语言指令的3D光流轨迹。通过生成的3D物体光流，我们提出一种流动引导渲染机制，该机制渲染预测的最终状态并利用GPT-4o评估预测的光流是否与任务描述一致。这使机器人具备闭环规划能力。最后，我们将预测的3D光流视为优化策略的约束，确定一段机器人操控动作。大量实验展示了在多样化机器人操控任务中的强大泛化能力以及无需硬件特定训练的可靠跨主体适应能力。",
        "地址": "https://arxiv.org/pdf/2506.06199.pdf"
    },
    {
        "名称": "2025 [2506.05817] CodeContests+: High-Quality Test Case Generation for Competitive Programming.pdf",
        "作者": "Zihan Wang, Siyao Liu, Yang Sun, Hongyan Li, Kai Shen",
        "摘要": "摘要：由于其高推理难度和精确的正确性反馈，竞争性编程已成为训练和评估大型语言模型（LLMs）推理能力的关键任务。然而，尽管大量公共问题数据（如问题描述和解决方案）可用，但这些问题的测试用例通常难以获得。因此，测试用例生成是构建大规模数据集的必要任务，测试用例的质量直接决定了评估的准确性。在本文中，我们介绍了一种基于LLMs的代理系统，它为竞争编程问题创建高质量的测试用例。我们将此系统应用于CodeContests数据集，并提出了一个改进测试用例的新版本，名为CodeContests+。我们评估了CodeContestsPlus中测试用例的质量。首先，我们使用了172万标有通过/失败标签的提交来检查这些测试用例在评估中的准确性。结果表明CodeContests+比CodeContests具有显著更高的准确性，尤其是显著更高的真阳性率（TPR）。随后，我们在LLMs强化学习（RL）实验中进一步确认了测试用例质量的改进对RL带来的显著优势。\n\n作者：王子涵，刘思尧，孙阳，李宏艳，沈凯\n\n评论：28页，7个图表\n\n链接：https://arxiv.org/pdf/2506.05817.pdf\n\n标题：2025 [2506.05817] CodeContests+：高质量的竞赛编程测试用例生成",
        "地址": "https://arxiv.org/pdf/2506.05817.pdf"
    },
    {
        "名称": "2025 [2506.04255] HASHIRU: Hierarchical Agent System for Hybrid Intelligent Resource Utilization.pdf",
        "作者": "Kunal Pai, Parth Shah, Harshil Patel",
        "摘要": "摘要：快速发展的大型语言模型（LLM）正在推动自主多代理系统（MAS）的发展。然而，当前框架通常缺乏灵活性、资源意识、模型多样性和自主工具创建。本文介绍了HASHIRU（混合智能资源利用的分层代理系统），这是一种新的MAS框架，增强了灵活性、资源效率和适应性。HASHIRU具有一个动态管理专门\"员工\"代理的\"CEO\"代理，根据任务需求和资源约束（成本、内存）实例化。这种混合智能优先使用较小的本地LLM（通过Ollama），在必要时灵活使用外部API和较大模型。一个包含招聘/解雇成本的经济模型促进了团队稳定和高效的资源分配。该系统还包括自主API工具创建和记忆功能。对学术论文审查（58%成功）、安全评估（JailbreakBench子集100%成功）和复杂推理（在GSM8K上超越Gemini 2.0 Flash：96% vs. 61%；JEEBench：80% vs. 68.3%；SVAMP：92% vs. 84%）等任务的评估展示了HASHIRU的能力。案例研究展示了其通过生成自主成本模型、工具集成和预算管理的自我改进。通过动态分层控制、资源意识的混合智能和自主功能扩展，HASHIRU提供了一种更强大、高效和适应性的MAS方法。源代码和基准分别在此https URL和此https URL提供，应要求提供在线演示在此https URL提供。",
        "地址": "https://arxiv.org/pdf/2506.04255.pdf"
    },
    {
        "名称": "2025 [2506.05673] Peer-Ranked Precision: Creating a Foundational Dataset for Fine-Tuning Vision Models from DataSeeds' Annotated Imagery.pdf",
        "作者": "Sajjad Abdoli, Freeman Lewin, Gediminas Vasiliauskas, Fabian Schonholz",
        "摘要": "摘要：现代人工智能（AI）模型的发展，特别是应用于计算机视觉和图像生成任务的扩散模型，正在经历开发方法上的范式转变。传统上以\"模型为中心\"的方法为主，主要通过越来越复杂的模型架构和超参数优化来追求性能提升，而现在该领域开始认可一种更细致的\"数据为中心\"的方法。这种新兴框架将训练数据的质量、结构和相关性作为模型性能的主要驱动力。为了实现这一范式转变，我们引入了样本数据集（\"DSD\"），该数据集初步由大约10,610张高质量的人类同行评定摄影图像及其广泛的多层次注释组成。DSD是一个基础的计算机视觉数据集，旨在为商业图像数据集树立新的标准。DSD代表了该网站超过一亿张图片目录中的一小部分，为强大的商业和多模态AI开发提供了必要的可扩展基础。通过深入的探索性分析，我们记录了DSD在特定模型上对已知基准产生的定量改进，并公开了评估中使用的代码和训练模型。",
        "地址": "https://arxiv.org/pdf/2506.05673.pdf"
    },
    {
        "名称": "2025 [2506.05433] Prefix Grouper: Efficient GRPO Training through Shared-Prefix Forward.pdf",
        "作者": "Zikang Liu, Tongtian Yue, Yepeng Tang, Longteng Guo, Junxian Cai, Qingbin Liu, Xi Chen, Jing Liu",
        "摘要": "摘要：组相对策略优化（GRPO）通过相同输入前缀之间候选输出的相对比较来计算梯度，从而增强策略学习。尽管其效果显著，但在处理长共享前缀时，GRPO会引入大量计算开销，因为每个组成员都必须重复编码这些前缀。这种低效性在长上下文学习场景中成为主要的可扩展性瓶颈。我们提出了前缀分组器，一种通过共享前缀前向策略消除冗余前缀计算的高效GRPO训练算法。具体而言，通过将自注意力重构为两部分，我们的方法使共享前缀仅需编码一次，同时保持完全的可微性，并与端到端训练兼容。我们提供了前缀分组器在训练等效于标准GRPO的理论和实证证据：它产生相同的前向输出和后向梯度，确保优化动态和最终策略性能不变。实证实验表明，前缀分组器在显著降低训练计算成本的同时取得了一致结果，尤其是在长前缀场景中。该方法完全即插即用：与现有的基于GRPO的架构兼容，并可作为直接替换无缝集成到当前训练管道中，仅需对输入构建和注意力计算进行最小改动。前缀分组器在相同计算预算下允许使用更大组规模，从而提高GRPO在更复杂任务和更大模型上的可扩展性。代码现已在此 https URL 可用。",
        "地址": "https://arxiv.org/pdf/2506.05433.pdf"
    },
    {
        "名称": "2025 [2506.06091] MIRIAD: Augmenting LLMs with millions of medical query-response pairs.pdf",
        "作者": "Qinyue Zheng, Salman Abdullah, Sam Rawal, Cyril Zakka, Sophie Ostmeier, Maximilian Purk, Eduardo Reis, Eric J. Topol, Jure Leskovec, Michael Moor",
        "摘要": "摘要：大型语言模型（LLMs）势必会通过先进的决策支持和灵活的聊天助手改变医疗保健。然而，LLMs容易生成不准确的医学内容。为了使LLMs基于高质量的医学知识，LLMs通过RAG装备了外部知识，其中非结构化的医学知识被拆分成小的文本块，可以选择性地检索并集成到LLMs的上下文中。然而，现有的RAG流水线依赖于原始的非结构化医学文本，这可能是噪声、未经筛选的且难以让LLMs有效利用系统化的方法来组织医学知识，以最佳方式展示给LLMs普遍缺乏。为了解决这些挑战，我们引入了MIRIAD，一个大规模、经过筛选的包含5,821,948个医学问答对的语料库，每个问答都从同行评审的医学文献中的段落重新措辞并以半自动化流水线结合LLM生成、筛选、基础和人工注释为基础。与之前依赖非结构化文本的医学语料库不同，MIRIAD将网络规模的医学知识封装在操作化的查询回应格式中，从而实现更有针对性的检索。在具有挑战性的医学问答基准测试中实验表明，与使用相同来源语料和相同数量的检索文本的非结构化RAG基线相比，使用MIRIAD增强LLMs准确率提高了最多6.7%。此外，MIRIAD提高了LLMs检测医学幻觉的能力，提升了22.5%至37%（F1评分增加）。我们进一步介绍了MIRIAD-Atlas，一个覆盖56个医学领域的MIRIAD互动地图，使临床用户能够可视化探索、搜索和优化医学知识。MIRIAD有望解锁大量下游应用，包括医学信息检索器、增强的RAG应用和知识基础的聊天界面，最终使在医疗保健中更可靠的LLMs应用成为可能。",
        "地址": "https://arxiv.org/pdf/2506.06091.pdf"
    },
    {
        "名称": "2025 [2506.05579] When Models Know More Than They Can Explain: Quantifying Knowledge Transfer in Human-AI Collaboration.pdf",
        "作者": "Quan Shi, Carlos E. Jimenez, Shunyu Yao, Nick Haber, Diyi Yang, Karthik Narasimhan",
        "摘要": "摘要：最近在人工智能推理领域的进展推动了多种任务的显著改进。一个关键的悬而未决的问题是，这些改进是否也带来了更好的知识迁移：即模型以使人类能够理解、应用和学习的方式交流推理的能力。为了解这一问题，我们引入了“知识整合与迁移评估”（KITE），这是一个针对人类与人工智能知识迁移能力的概念和实验框架，并进行了第一个明确设计用于测量这一能力的大规模人类研究（N=118）。在我们的两阶段设置中，人类首先与人工智能共同策划解决问题的策略，然后独立实施解决方案，孤立模型解释对人类理解的影响。我们的研究结果表明，尽管模型基准表现与协作结果相关，但这种关系明显不一致，特点是存在显著的离群值，表明知识迁移需要专门的优化。我们的分析确定了影响成功知识迁移的行为和战略因素。我们发布了代码、数据集和评估框架，以支持未来对交流一致模型的研究。",
        "地址": "https://arxiv.org/pdf/2506.05579.pdf"
    },
    {
        "名称": "2025 [2506.04120] Splatting Physical Scenes: End-to-End Real-to-Sim from Imperfect Robot Data.pdf",
        "作者": "Ben Moran, Mauro Comi, Arunkumar Byravan, Steven Bohez, Tom Erez, Zhibin Li, Leonard Hasenclever",
        "摘要": "摘要：从现实世界的机器人运动中直接创建准确的物理模拟对于安全、可扩展和经济的机器人学习具有重要价值，但这一过程却极具挑战性。真实的机器人数据受到遮挡、噪声相机姿态和动态场景元素的影响，这阻碍了未见物体几何准确和逼真数字双胞胎的创建。我们提出一种新颖的从现实到模拟的框架，同时解决所有这些挑战。我们的核心见解是将3D高斯喷溅的逼真渲染与适合物理模拟的显式对象网格融合在单一表示中的混合场景表示。我们提出一个端到端的优化管道，利用MuJoCo中的可微渲染和可微物理，同时优化场景的所有组件——从对象几何和外观到机器人姿态和物理参数——直接从原始和不精确的机器人轨迹中进行优化。这种统一的优化使我们能够同时实现高保真对象网格重建、生成逼真的新视图以及无标注的机器人姿态校准。我们展示了我们方法的有效性，无论是在模拟中还是在使用ALOHA 2双手操作器的实际复杂序列中，使从现实到模拟的流程更加实用和稳健。",
        "地址": "https://arxiv.org/pdf/2506.04120.pdf"
    },
    {
        "名称": "2025 [2506.05551] When Semantics Mislead Vision: Mitigating Large Multimodal Models Hallucinations in Scene Text Spotting and Understanding.pdf",
        "作者": "Yan Shu, Hangui Lin, Yexin Liu, Yan Zhang, Gangyan Zeng, Yan Li, Yu Zhou, Ser-Nam Lim, Harry Yang, Nicu Sebe",
        "摘要": "摘要：大型多模态模型（LMMs）在视觉感知和推理方面取得了显著进展。然而，当面对视觉上模糊或非语义的场景文本时，它们往往难以准确地识别和理解内容，经常生成语义上合理但视觉上错误的答案，我们称之为语义幻觉。在这项工作中，我们调查了语义幻觉的根本原因，并发现一个关键结果：在LLM中的Transformer层对场景文本区域具有更强的注意力焦点时，更不容易产生语义幻觉。因此，我们提出了一个无需训练的语义幻觉缓解框架，包括两个关键组件：(1) ZoomText，一种粗到细的策略，能够在没有外部探测器的情况下识别潜在的文本区域；(2) Grounded Layer Correction，自适应地利用不易产生幻觉的层的内部表示来指导解码，纠正非语义样本的幻觉输出，同时保留有意义的样本的语义。为了进行严格的评估，我们引入了TextHalu-Bench，该基准包含超过1730个样本，涵盖语义和非语义案例，并配有手工整理的问答对，用于测试模型幻觉。大量实验表明，我们的方法不仅有效缓解了语义幻觉，还在场景文本识别和理解的公开基准上取得了出色的性能。",
        "地址": "https://arxiv.org/pdf/2506.05551.pdf"
    },
    {
        "名称": "2025 [2506.04755] Truth in the Few: High-Value Data Selection for Efficient Multi-Modal Reasoning.pdf",
        "作者": "Shenshen Li, Kaiyuan Deng, Lei Wang, Hao Yang, Chong Peng, Peng Yan, Fumin Shen, Heng Tao Shen, Xing Xu",
        "摘要": "摘要: 尽管多模态大语言模型（MLLMs）通过强化学习在复杂推理任务上取得了显著进展，通常认为需要大量的训练数据来提高多模态推理能力，这难免导致数据冗余和巨大的计算成本。然而，较小的高价值数据集能否在多模态推理上匹配或超过整个语料库？在这项工作中，我们通过一个关键观察挑战这一假设：有意义的多模态推理仅由训练样本的稀疏子集（称为认知样本）触发，而大多数样本贡献微小。基于这一洞察，我们提出了一种名为推理激活潜力（RAP）的新颖数据选择范式，该范式通过两个互补估计器来识别认知样本：1) 基于潜在结果模型原理的因果差异估计器（CDE），通过比较多模态与仅文本输入之间的输出，消除过度依赖语言先验的样本；2) 注意力置信度估计器（ACE），利用基于token的自注意力机制，在中间推理阶段丢弃由不相关但过度强调的tokens支配的样本。此外，我们提出了一个难度感知替换模块（DRM）以将琐碎实例替换为具有认知挑战的实例，从而确保复杂性以实现稳健的多模态推理。六个数据集上的实验表明，我们的RAP方法仅使用9.3%的训练数据就能持续获得优异表现，同时减少超过43%的计算成本。我们的代码可以在这个https URL获取。",
        "地址": "https://arxiv.org/pdf/2506.04755.pdf"
    },
    {
        "名称": "2025 [2506.00649] GuideX: Guided Synthetic Data Generation for Zero-Shot Information Extraction.pdf",
        "作者": "Neil De La Fuente, Oscar Sainz, Iker García-Ferrero, Eneko Agirre",
        "摘要": "摘要：信息提取（IE）系统传统上是特定于领域的，需要昂贵的适应过程，包括专家设计的模式、数据注释和模型训练。尽管大型语言模型在零样本信息提取方面表现出希望，但在标签定义不同的未见领域中，性能显著下降。本文介绍了GUIDEX，一种新方法，能够自动定义特定领域的模式，推断指南，并生成合成标注实例，从而更好地进行跨领域泛化。通过GUIDEX微调Llama 3.1，在七个零样本命名实体识别基准上设立了新的技术标杆。使用GUIDEX训练的模型在没有人工标注数据的情况下，相比以前的方法可以提高最多7个F1分数，结合人工标注数据时可提高近2个F1分数。使用GUIDEX训练的模型表现出对复杂、特定领域的注释模式的增强理解。代码、模型和合成数据集可通过以下网址获得： https://arxiv.org/pdf/2506.00649.pdf",
        "地址": "https://arxiv.org/pdf/2506.00649.pdf"
    },
    {
        "名称": "2025 [2506.03828] AssetOpsBench: Benchmarking AI Agents for Task Automation in Industrial Asset Operations and Maintenance.pdf",
        "作者": "Dhaval Patel, Shuxin Lin, James Rayfield, Nianjun Zhou, Roman Vaculin, Natalia Martinez, Fearghal O'donncha, Jayant Kalagnanam",
        "摘要": "摘要：本论文题为《AssetOpsBench：用于工业资产操作和维护任务自动化的AI代理基准测试》。人工智能在工业资产生命周期管理中的应用旨在自动化复杂的操作工作流，如状态监控、维护计划和干预调度，以减少人类工作量并最大限度地减少系统停机时间。传统的AI/ML方法主要是孤立地解决这些问题，仅在更广泛的操作管道中解决狭窄的任务。相反，AI代理和大型语言模型（LLMs）的出现引入了下一代机会：使整个资产生命周期实现端到端自动化。本文展望了一个未来，AI代理能够自主管理以前需要特定专家和手工协调的任务。为此，我们引入了AssetOpsBench——一个统一的框架和环境，旨在指导开发、协调和评估针对工业4.0应用的特定领域代理。我们概述了此类整体系统的关键需求，并提供了构建集成感知、推理和控制功能的现实工业运营代理的可操作见解。软件可在此链接获取：https://arxiv.org/pdf/2506.03828.pdf。\n\n作者：Dhaval Patel, Shuxin Lin, James Rayfield, Nianjun Zhou, Roman Vaculin, Natalia Martinez, Fearghal O'donncha, Jayant Kalagnanam\n\n注释：39页，18幅图\n\n链接：https://arxiv.org/pdf/2506.03828.pdf",
        "地址": "https://arxiv.org/pdf/2506.03828.pdf"
    },
    {
        "名称": "2025 [2506.02327] Medical World Model: Generative Simulation of Tumor Evolution for Treatment Planning.pdf",
        "作者": "Yijun Yang, Zhao-Yang Wang, Qiuping Liu, Shuwen Sun, Kang Wang, Rama Chellappa, Zongwei Zhou, Alan Yuille, Lei Zhu, Yu-Dong Zhang, Jieneng Chen",
        "摘要": "摘要: 提供有效的治疗和做出明智的临床决策是现代医学和临床护理的基本目标。我们对模拟疾病动态以进行临床决策感兴趣，并利用最近在大型生成模型方面的进展。为此，我们介绍了医学世界模型（MeWM），这是医学领域第一个基于临床决策对未来疾病状态进行视觉预测的世界模型。MeWM包括 (i) 作为策略模型的视觉语言模型，以及 (ii) 作为动力学模型的肿瘤生成模型。策略模型生成行动计划，例如临床治疗，而动力学模型在给定治疗条件下模拟肿瘤的进展或退化。在此基础上，我们提出了逆动力学模型，该模型将生存分析应用于模拟的治疗后肿瘤，能够评估治疗效果并选择最佳的临床行动计划。因此，提出的MeWM通过合成治疗后肿瘤来模拟疾病动态，在放射科医生评估的图灵测试中表现出最先进的特异性。同时，其逆动力学模型在优化个体化治疗方案方面在所有指标上优于医学专用GPTs。值得注意的是，MeWM 改善了介入医生的临床决策，使选择最佳TACE方案的F1得分提高了13%，为未来整合医学世界模型作为第二读者铺平了道路。",
        "地址": "https://arxiv.org/pdf/2506.02327.pdf"
    },
    {
        "名称": "2025 [2505.20698] Sparsified State-Space Models are Efficient Highway Networks.pdf",
        "作者": "Woomin Song, Jihoon Tack, Sangwoo Mo, Seunghyuk Oh, Jinwoo Shin",
        "摘要": "摘要: 状态空间模型（SSM）在序列建模方面提供了一种有前途的架构，通过用线性递归替代昂贵的自注意机制，成为变压器的替代方案。在本文中，我们提出了一种简单而有效的技巧，通过稀疏化在给定计算预算内增强SSM。我们的直觉是，由于逐渐的递归更新，SSM中的令牌具有高度冗余性，而密集的递归操作阻碍了过去信息的传递。特别是，我们观察到，在SSM的较高级别层中，冗余性更高，因为它们编码全局信息，而较低级别层编码局部信息。基于此启发，我们介绍了Simba，这是一种基于令牌剪枝的分层稀疏化方法。Simba对较高级别层进行更多的稀疏化，使较高级别层表现得像高速公路。为实现这一目标，我们提出了一种新的SSM令牌剪枝标准，通过累积局部递归来衡量令牌对最终输出的全局影响。我们证明了Simba在各种自然语言任务中以相同的FLOPS优于基线模型Mamba。此外，我们展示了高速公路的效果，表明Simba不仅提高了效率，还改善了长序列中的信息流。代码可在此网址获取。",
        "地址": "https://arxiv.org/pdf/2505.20698.pdf"
    }
]