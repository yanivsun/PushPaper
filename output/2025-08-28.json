[
    {
        "名称": "2025 [2508.15882] Beyond Transcription: Mechanistic Interpretability in ASR.pdf",
        "作者": "Neta Glazer, Yael Segal-Feldman, Hilit Segev, Aviv Shamsian, Asaf Buchnick, Gill Hetz, Ethan Fetaya, Joseph Keshet, Aviv Navon",
        "摘要": "摘要: 解释性方法最近受到广泛关注，特别是在大型语言模型的背景下，它们能够提供对语言表示、错误检测和模型行为（例如幻觉和重复）的见解。然而，尽管这些技术有可能提高自动语音识别（ASR）系统的性能和解释性，但在ASR领域，这些技术仍未得到充分探索。在这项工作中，我们调整并系统性地应用了已建立的解释性方法，如logit lens、线性探测和激活修补，以检查声学和语义信息在ASR系统各层之间的演变过程。我们的实验揭示了之前未知的内部动态，包括特定的编码器-解码器交互负责重复幻觉以及深嵌在声学表示中的语义偏差。这些见解展示了扩展和应用解释性技术于语音识别的益处，开辟了在提高模型透明度和鲁棒性方面未来研究的有前景方向。",
        "地址": "https://arxiv.org/pdf/2508.15882.pdf"
    },
    {
        "名称": "2025 [2508.19652] Self-Rewarding Vision-Language Model via Reasoning Decomposition.pdf",
        "作者": "Zongxia Li, Wenhao Yu, Chengsong Huang, Rui Liu, Zhenwen Liang, Fuxiao Liu, Jingxi Che, Dian Yu, Jordan Boyd-Graber, Haitao Mi, Dong Yu",
        "摘要": "摘要：视觉-语言模型（VLMs）经常遭遇视觉幻觉（描述图像中不存在的内容）和语言捷径（忽略视觉部分，仅依赖于文本先验）。这些问题的出现是因为多数VLMs的后训练方法依赖简单的可验证答案匹配且仅监督最终输出，导致中间的视觉推理缺乏明确指导。因此，VLMs接收的视觉信号较为稀疏，常常倾向于优先进行基于语言的推理而非视觉感知。为缓解这一问题，一些现有方法利用人工注释或外部大型模型提取标签来增加视觉监督。然而，人工注释既费工又昂贵，而外部信号由于不能适应不断变化的策略，容易导致分布转移并可能引发奖励作弊。在本文中，我们提出了一种名为Vision-SR1的自我奖励方法，通过强化学习提高视觉推理能力，而不依赖外部视觉监督。Vision-SR1将VLM推理分解为两个阶段：视觉感知和语言推理。模型首先被提示生成自包含的视觉感知，确保其足以回答问题而无需参考输入图像。为了验证这种自包含性，相同的VLM模型再次被提示以仅使用生成的感知作为输入进行语言推理以计算奖励。这种自我奖励结合了对最终输出的监督，提供了平衡的训练信号，从而增强了视觉感知和语言推理。我们的实验表明，Vision-SR1在各种视觉-语言任务中提高了视觉推理能力，减轻了视觉幻觉，减少了对语言捷径的依赖。",
        "地址": "https://arxiv.org/pdf/2508.19652.pdf"
    },
    {
        "名称": "2025 [2508.20072] Discrete Diffusion VLA: Bringing Discrete Diffusion to Action Decoding in Vision-Language-Action Policies.pdf",
        "作者": "Zhixuan Liang, Yizhuo Li, Tianshuo Yang, Chengyue Wu, Sitong Mao, Liuao Pei, Xiaokang Yang, Jiangmiao Pang, Yao Mu, Ping Luo",
        "摘要": "摘要: 视觉-语言-行动 (VLA) 模型将大型视觉语言骨干网络适配为将图像和指令映射到机器人动作。然而，现有的VLA解码器要么在固定的从左到右顺序中自回归生成动作，要么将连续的扩散或流匹配头附加到骨干网络之外，这需要专门的训练和迭代采样，阻碍了统一、可扩展的架构。我们提出了一种离散扩散VLA，一种单一的变压器策略，使用离散扩散建模离散化动作块，并使用与VLM骨干相同的交叉熵目标进行训练。设计保留了扩散的逐步细化范式，同时与VLM的离散标记接口天然兼容。我们的方法实现了自适应解码顺序，先解决简单的动作元素，再解决较难的，并通过次级重掩在精细化轮次中重新审视不确定的预测，从而提高一致性并实现强大的错误修正。该统一解码器保留了预训练的视觉语言先验，支持并行解码，打破了自回归瓶颈，减少了函数评估的次数。离散扩散VLA在LIBERO上达到了96.3%的平均成功率，在SimplerEnv Fractal上达到了71.2%的视觉匹配率，并在SimplerEnv Bridge上达到了49.3%的整体表现，均优于自回归和连续扩散基线。这些发现表明，离散扩散动作解码器支持精确的动作建模和一致的训练，为将VLA扩展到更大的模型和数据集奠定了基础。",
        "地址": "https://arxiv.org/pdf/2508.20072.pdf"
    },
    {
        "名称": "2025 [2508.19827] Analysing Chain of Thought Dynamics: Active Guidance or Unfaithful Post-hoc Rationalisation?.pdf",
        "作者": "Samuel Lewis-Lim, Xingwei Tan, Zhixue Zhao, Nikolaos Aletras",
        "摘要": "摘要(翻译为中文):\n最近的研究表明，对于软推理问题（如分析推理和常识推理），连锁思维（Chain-of-Thought, CoT）的收益有限。CoT也可能与模型的实际推理不一致。我们在经过指令调整、推理和推理提炼的模型中，调查了CoT在软推理任务中的动态和一致性。我们的研究结果揭示了这些模型如何依赖CoT的差异，并表明CoT的影响和一致性并不总是一致的。",
        "地址": "https://arxiv.org/pdf/2508.19827.pdf"
    },
    {
        "名称": "2025 [2508.19320] MIDAS: Multimodal Interactive Digital-humAn Synthesis via Real-time Autoregressive Video Generation.pdf",
        "作者": "Ming Chen, Liyuan Cui, Wenyuan Zhang, Haoxian Zhang, Yan Zhou, Xiaohan Li, Songlin Tang, Jiwen Liu, Borui Liao, Hejia Chen, Xiaoqiang Liu, Pengfei Wan",
        "摘要": "摘要：互动式数字人视频生成近年来受到了广泛关注并取得了显著进展。然而，现有的方法在实时交互中，处理多样化输入信号的能力有限，主要因高计算成本和有限的可控性而面临挑战。在本研究中，我们提出了一种自回归视频生成框架，实现了交互性强的多模态控制和低延迟的流式推断。通过对一个标准的大型语言模型（LLM）进行最小修订，我们的框架能够接受包括音频、姿态和文本在内的多模态条件编码，并输出空间和语义上连贯的表示，指导扩散头的去噪过程。为此，我们构建了一个包含约2万小时多来源对话数据的大规模对话数据集，为训练提供丰富的对话场景。我们进一步引入了一个具有高达64倍压缩比的深度压缩自动编码器，有效减轻了自回归模型长时间推断的负担。在双工对话、多语言人类合成和交互式世界模型方面进行的广泛实验，突出了我们的方法在低延迟、高效率和细粒度多模态可控性方面的优势。\n\n作者：陈明，崔礼元，张文远，张浩贤，周延，李啸寒，唐松林，刘吉文，廖博瑞，陈何佳，刘晓强，万鹏飞",
        "地址": "https://arxiv.org/pdf/2508.19320.pdf"
    },
    {
        "名称": "2025 [2508.20096] CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning.pdf",
        "作者": "Zeyi Sun, Yuhang Cao, Jianze Liang, Qiushi Sun, Ziyu Liu, Zhixiong Zhang, Yuhang Zang, Xiaoyi Dong, Kai Chen, Dahua Lin, Jiaqi Wang",
        "摘要": "摘要: 为图形用户界面（GUI）设计自主代理在科学计算等专业领域面临显著挑战，这些领域既需要长远规划又需要精确执行。现有的方法存在一个权衡：通用代理在规划方面表现出色，但在执行方面表现不佳，而专业代理则相反。最近的组合框架尝试通过结合规划器和执行者来弥合这一差距，但它们通常是静态且不可训练的，无法从经验中进行适应。这是一个重要的限制，考虑到科学领域高质量数据的匮乏。为了应对这些限制，我们引入了CODA，一个新的可训练组合框架，整合了通用规划器（Cerebrum）和专业执行器（Cerebellum），通过专门的两阶段管道进行训练。第一阶段，专业化阶段，我们采用分离的GRPO方法为每个科学应用单独训练专家规划器，从少量的任务轨迹开始。第二阶段，泛化阶段，我们聚合所有成功的专家轨迹以建立一个综合数据集，然后用于最终规划器的监督微调。这使得CODA具备了稳健的执行和跨领域泛化能力。在ScienceBoard基准测试的四个具有挑战性的应用上，CODA显著优于基线，并在开源模型中建立了新的标准。\n\n作者: 孙泽义, 曹宇航, 梁建泽, 孙秋实, 刘子钰, 张志雄, 臧宇航, 董晓怡, 陈凯, 林达华, 王珈琪\n评论: 代码可通过这个网址获取: this https URL\n网址: https://arxiv.org/pdf/2508.20096.pdf\n标题: CODA: Coordinating the Cerebrum and Cerebellum for a Dual-Brain Computer Use Agent with Decoupled Reinforcement Learning",
        "地址": "https://arxiv.org/pdf/2508.20096.pdf"
    },
    {
        "名称": "2025 [2508.19228] Predicting the Order of Upcoming Tokens Improves Language Modeling.pdf",
        "作者": "Zayd M. K. Zuhri, Erland Hilman Fuadi, Alham Fikri Aji",
        "摘要": "摘要：多标记预测（MTP）被提出作为辅助目标来改善语言模型训练中的下一个标记预测（NTP），但在标准自然语言处理（NLP）基准上显示出不一致的改进，表现不佳。我们认为，MTP精确地预测未来标记作为辅助损失过于困难。相反，我们提出标记顺序预测（TOP），它通过学习排序损失来训练模型按标记的接近度排列即将到来的标记。与MTP的多层变压器相比，TOP仅需一个额外的未嵌入层。我们预训练了包含340M、1.8B和7B参数的模型，使用NTP、MTP和TOP目标。在八个标准NLP基准上的结果显示，TOP在整体上优于NTP和MTP，即使在更大规模上也是如此。我们的代码可以在这个https网址找到。\n\n翻译：摘要：多标记预测（MTP）已经被提出作为辅助目标来改善语言模型训练中的下一个标记预测（NTP），但在标准自然语言处理（NLP）基准上显示出不一致的改进，表现不佳。我们认为，MTP的准确未来标记预测作为辅助损失过于困难。相反，我们提出标记顺序预测（TOP），它通过使用学习排序损失来训练模型按其接近度排列未来标记。与MTP的多个变压器层相比，TOP只需要一个额外的反嵌入层。我们使用NTP、MTP和TOP目标对340M、1.8B和7B参数的模型进行了预训练。八个标准NLP基准上的结果显示，即使在大规模下，TOP总体上也优于NTP和MTP。我们的代码可在此HTTPS网址下载。",
        "地址": "https://arxiv.org/pdf/2508.19228.pdf"
    },
    {
        "名称": "2025 [2508.17924] Gaze into the Heart: A Multi-View Video Dataset for rPPG and Health Biomarkers Estimation.pdf",
        "作者": "Konstantin Egorov, Stepan Botman, Pavel Blinov, Galina Zubkova, Anton Ivaschenko, Alexander Kolsanov, Andrey Savchenko",
        "摘要": "摘要：远程光电容积描记术 (rPPG) 的进展受到现有公开数据集的关键问题的限制：规模小、面部视频的隐私问题以及缺乏条件多样性。本文引入了一种新颖的综合大型多视角视频数据集，用于 rPPG 和健康生物标志物的估计。我们的数据集包含来自600名受试者的3600个同步视频记录，这些记录是在多种不同条件（休息和运动后）下使用多个消费级摄像机从不同角度捕获的。为了实现生理状态的多模态分析，每个录音都配有100 Hz 的 PPG 信号和延伸的健康指标，例如心电图、动脉血压、生物标志物、体温、血氧饱和度、呼吸频率和应激水平。利用这些数据，我们训练了一个高效的 rPPG 模型，并在跨数据集场景中将其质量与现有方法进行比较。我们的数据集和模型的公开发布预计将显著加速 AI 医疗助手的发展进程。",
        "地址": "https://arxiv.org/pdf/2508.17924.pdf"
    },
    {
        "名称": "2025 [2508.19982] Diffusion Language Models Know the Answer Before Decoding.pdf",
        "作者": "Pengxiang Li, Yefan Zhou, Dilxat Muhtar, Lu Yin, Shilin Yan, Li Shen, Yi Liang, Soroush Vosoughi, Shiwei Liu",
        "摘要": "摘要：扩散语言模型（DLMs）作为自回归方法的替代方案，最近开始受到关注，它们提供了并行序列生成和灵活的标记顺序。然而，由于双向注意力的开销和高质量输出所需的大量细化步骤，DLMs的推理速度仍然比自回归模型慢。在这项工作中，我们强调并利用了DLMs一个被忽视的特性——早期答案收敛：在许多情况下，正确答案在最终解码步骤之前的一半步骤中已能被内部识别，无论是在半自回归还是随机重新掩码规划下。例如，在GSM8K和MMLU上，分别多达97%和99%的实例可以使用仅一半的细化步骤正确解码。基于这一观察，我们引入了Prophet，一种无需训练的快速解码模式，能够实现早期承诺解码。具体而言，Prophet根据前两个预测候选者之间的信心差异动态决定是否继续细化或“全力以赴”（即在一步中解码所有剩余的标记）。它无缝集成到现有的DLM实现中，不会产生显著开销，也不需要额外的训练。对LLaDA-8B和Dream-7B在多个任务上的实证评估表明，Prophet在保持高生成质量的同时，将解码步骤减少了最多3.4倍。这些结果将DLM解码重新定义为一个停止采样的问题，并证明早期解码收敛提供了一种简单而强大的机制用于加速DLM推理，能够与现有的加速技术互补。我们的代码在这个链接公开提供：https://arxiv.org/pdf/2508.19982.pdf。",
        "地址": "https://arxiv.org/pdf/2508.19982.pdf"
    },
    {
        "名称": "2025 [2508.19229] StepWiser: Stepwise Generative Judges for Wiser Reasoning.pdf",
        "作者": "Wei Xiong, Wenting Zhao, Weizhe Yuan, Olga Golovneva, Tong Zhang, Jason Weston, Sainbayar Sukhbaatar",
        "摘要": "摘要：随着模型越来越多地利用多步骤推理策略来解决复杂问题，监督这些中间步骤的逻辑有效性已成为一个关键的研究挑战。过程奖励模型通过提供逐步反馈来解决这一问题，但当前的方法有两个主要缺点：它们通常作为分类器工作但不提供解释，并且依赖于使用静态数据集的监督微调，限制了泛化能力。受最近进展的启发，我们将逐步奖励建模从分类任务重新框定为推理任务本身。因此，我们提出了一个生成判决模型来推理策略模型的推理步骤（即元推理），在给出最终判决之前输出思维令牌。我们的模型StepWiser通过使用滚动的相对结果进行强化学习训练。我们证明它在（i）中间步骤上提供了比现有方法更好的判决准确性；（ii）可以在训练时用于改进策略模型；（iii）改善了推理时的搜索。\n\n翻译：摘要：随着模型越来越多地利用多步骤推理策略来解决复杂问题，监督这些中间步骤的逻辑有效性已成为一个关键的研究挑战。过程奖励模型通过提供逐步反馈来解决这一问题，但当前的方法有两个主要缺点：它们通常作为分类器工作但不提供解释，并且依赖于使用静态数据集的监督微调，限制了泛化能力。受最近进展的启发，我们将逐步奖励建模从分类任务重新框定为推理任务本身。因此，我们提出了一个生成判决模型来推理策略模型的推理步骤（即元推理），在给出最终判决之前输出思维令牌。我们的模型StepWiser通过使用滚动的相对结果进行强化学习训练。我们证明它在（i）中间步骤上提供了比现有方法更好的判决准确性；（ii）可以在训练时用于改进策略模型；（iii）改善了推理时的搜索。",
        "地址": "https://arxiv.org/pdf/2508.19229.pdf"
    },
    {
        "名称": "2025 [2508.19493] Mind the Third Eye! Benchmarking Privacy Awareness in MLLM-powered Smartphone Agents.pdf",
        "作者": "Zhixin Lin, Jungang Li, Shidong Pan, Yibo Shi, Yue Yao, Dongliang Xu",
        "摘要": "摘要：智能手机为用户带来了显著的便利性，但也使设备能够广泛记录各种类型的个人信息。现有的由多模态大型语言模型（MLLMs）驱动的智能手机代理在自动化不同任务方面表现出色。然而，作为代价，这些代理在操作过程中获得了大量访问用户敏感个人信息的权限。为了全面了解这些代理的隐私意识，我们提出了据我们所知的第一个涵盖7,138个场景的大规模基准。此外，对于场景中的隐私上下文，我们注释了其类型（例如账户凭证）、敏感性级别和位置。然后我们仔细对七种现有的主流智能手机代理进行了基准测试。我们的结果表明，几乎所有被测试的代理的隐私意识（RA）表现都不令人满意，即便有明确提示，其表现也低于60%。总体而言，闭源代理的隐私能力优于开源代理，其中Gemini 2.0-flash表现最佳，达到67%的RA。我们还发现，代理的隐私检测能力与场景的敏感度级别高度相关，即更高敏感度级别的场景通常更容易识别。我们希望这些发现能够启发研究界重新思考关于智能手机代理的不平衡实用性与隐私权之间的权衡。我们的代码和基准测试可在此网址获得。",
        "地址": "https://arxiv.org/pdf/2508.19493.pdf"
    },
    {
        "名称": "2025 [2508.20088] AudioStory: Generating Long-Form Narrative Audio with Large Language Models.pdf",
        "作者": "Yuxin Guo, Teng Wang, Yuying Ge, Shijie Ma, Yixiao Ge, Wei Zou, Ying Shan",
        "摘要": "摘要：近期在文本到音频 (TTA) 生成方面的进展在合成短音频剪辑方面表现出色，但在长篇叙事音频的生成上存在困难，这需要时间上的连贯性和结构推理能力。为了解决这一差距，我们提出了AudioStory，这是一种将大型语言模型 (LLM) 与 TTA 系统相结合的统一框架，用于生成结构化的长篇音频叙事。AudioStory 具有强大的指令跟随推理生成能力。它利用 LLM 将复杂的叙事查询分解为具有上下文提示的时序子任务，从而实现连贯的场景转换和情感语调一致。AudioStory 具有两个吸引人的特点：（1）解耦桥接机制：AudioStory 将 LLM-扩散器的协作解耦为两个专门组件，即用于事件内语义对齐的桥接查询和用于跨事件连贯性保持的残差查询。（2）端到端训练：通过在单一的端到端框架中统一指令理解和音频生成，AudioStory 消除了模块化训练流水线的需求，同时增强了组件之间的协同作用。此外，我们建立了一个基准AudioStory-10K，涵盖了动画声音景观和自然声音叙述等多种领域。大量实验表明，AudioStory 在单一音频生成和叙事音频生成方面优于之前的 TTA 基准，在指令跟随能力和音频保真度方面均有超越。我们的代码可以在该网址找到：https://arxiv.org/pdf/2508.20088.pdf",
        "地址": "https://arxiv.org/pdf/2508.20088.pdf"
    },
    {
        "名称": "2025 [2508.19527] MotionFlux: Efficient Text-Guided Motion Generation through Rectified Flow Matching and Preference Alignment.pdf",
        "作者": "Zhiting Gao, Dan Song, Diqiong Jiang, Chao Xue, An-An Liu",
        "摘要": "摘要：动作生成对虚拟角色和具身代理的动画制作至关重要。尽管最近的文本驱动方法取得了重大进展，但它们往往难以实现语言描述与动作语义的精确对齐，并且在缓慢的多步推理方面表现出效率低下。为了解决这些问题，我们引入了TMR++对齐偏好优化（TAPO），一个创新框架，它将微妙的动作变化与文本修饰符对齐，并通过迭代调整来强化语义基础。为了进一步实现实时合成，我们提出了基于确定性校正流匹配的高速生成框架MotionFLUX。与传统的扩散模型需要数百步去噪不同，MotionFLUX在噪声分布和动作空间之间构建了最佳运输路径，促进了实时合成。线性概率路径减少了顺序方法中典型的多步采样需求，显著加快了推理时间，同时保持了动作质量。实验结果表明，TAPO和MotionFLUX共同构成了一个统一系统，在语义一致性和动作质量方面均优于现有最先进的方法，同时也加快了生成速度。代码和预训练模型将会发布。",
        "地址": "https://arxiv.org/pdf/2508.19527.pdf"
    },
    {
        "名称": "2025 [2508.18179] SEAM: Semantically Equivalent Across Modalities Benchmark for Vision-Language Models.pdf",
        "作者": "Zhenwei Tang, Difan Jiao, Blair Yang, Ashton Anderson",
        "摘要": "摘要: 评估视觉-语言模型 (VLMs) 是否能够在不同表示形式中保持一致推理是具有挑战性的，因为模态比较通常受到任务差异和信息不对称的影响。我们介绍了 SEAM，这是一个基准，配对四个具有现有标准化文本和视觉符号表示的领域中的语义等效输入。通过在模态之间采用不同的符号系统，与基于 OCR 的图像-文本配对相比，SEAM提供了对 VLMs 的文本-符号和视觉-空间推理能力的严格比较评估。在对21个当代模型的评估中，我们观察到系统的模态不平衡：尽管问题包含语义上等效的信息，但视觉在整体表现上常常落后于语言，并且跨模态协议相对较低。我们的错误分析揭示了两个主要原因：来自领域符号化的文本感知失败和引发幻觉的视觉感知失败。我们还表明，我们的结果在很大程度上对视觉转换具有鲁棒性。SEAM为测量和改进模态无关推理建立了一个受控的、语义等效的环境。",
        "地址": "https://arxiv.org/pdf/2508.18179.pdf"
    },
    {
        "名称": "2025 [2508.20033] DeepScholar-Bench: A Live Benchmark and Automated Evaluation for Generative Research Synthesis.pdf",
        "作者": "Liana Patel, Negar Arabzadeh, Harshit Gupta, Ankita Sundar, Ion Stoica, Matei Zaharia, Carlos Guestrin",
        "摘要": "摘要：研究和综合知识的能力是人类专业知识和进步的核心。一类新兴的系统通过生成性研究综合，提供这些令人兴奋的功能，进行实时网络检索并将发现的资源综合到长篇引用的摘要中。然而，评估此类系统仍然是一个开放的挑战：现有的问答基准测试关注的是简短的事实回复，而专家策划的数据集则有过时和数据污染的风险。两者都未能捕捉真实研究综合任务的复杂性和变化。本研究引入了DeepScholar-bench，一个实时基准测试和整体自动化评估框架，旨在评估生成性研究综合。DeepScholar-bench从近期高质量的ArXiv论文中抽取查询，专注于一个真实的研究综合任务：通过检索、综合和引用先前的研究生成论文的相关工作部分。我们的评估框架从知识综合、检索质量和可验证性三个关键维度全面评估性能。我们还开发了DeepScholar-base，一个高效实现于LOTUS API的参考管道。使用DeepScholar-bench框架，我们对现有的开源系统进行了系统评估，包括Search AI、OpenAI的DeepResearch和DeepScholar-base。我们发现DeepScholar-base建立了一个强大的基线，表现优于其他方法。此外，我们发现DeepScholar-bench远未饱和，没有系统在所有指标上超过19%的得分。这些结果强调了DeepScholar-bench的难度，以及它对于迈向能够生成性研究综合的AI系统的重要性。我们的代码在此https网址提供。\n\n作者：Liana Patel, Negar Arabzadeh, Harshit Gupta, Ankita Sundar, Ion Stoica, Matei Zaharia, Carlos Guestrin\n\n链接：https://arxiv.org/pdf/2508.20033.pdf",
        "地址": "https://arxiv.org/pdf/2508.20033.pdf"
    },
    {
        "名称": "2025 [2508.19559] Taming the Chaos: Coordinated Autoscaling for Heterogeneous and Disaggregated LLM Inference.pdf",
        "作者": "Rongzhi Li, Ruogu Du, Zefang Chu, Sida Zhao, Chunlei Han, Zuocheng Shi, Yiwen Shao, Huanle Han, Long Huang, Zherui Liu, Shufan Liu",
        "摘要": "摘要：服务大规模语言模型（LLMs）是一项GPU密集型任务，传统的自动扩展方法在现代的预填充-解码（P/D）解耦架构中表现不佳。尽管这种架构转变具有强大功能，但也引入了重大的操作挑战，包括异构硬件的低效使用、网络瓶颈以及预填充和解码阶段之间的关键失衡。我们介绍了HeteroScale，这是一个解决P/D解耦服务核心挑战的协调自动扩展框架。HeteroScale结合了一个拓扑感知的调度器，能够适应异构硬件和网络限制，并采用了一种新颖的指标驱动策略，这种策略源自首个大规模的生产环境自动扩展信号实证研究。通过利用单一的、强健的指标同时扩展预填充和解码池，HeteroScale在确保高效、适应性资源管理的同时，还保持了架构平衡。在数万台GPU的大规模生产环境中部署之后，HeteroScale证明了其有效性，平均GPU利用率显著提高了26.6个百分点，每天节省了数十万GPU小时，同时还确保了严格的服务水平目标。",
        "地址": "https://arxiv.org/pdf/2508.19559.pdf"
    },
    {
        "名称": "2025 [2508.16067] Training a Foundation Model for Materials on a Budget.pdf",
        "作者": "Teddy Koker, Tess Smidt",
        "摘要": "摘要: 材料建模的基础模型正在迅速发展，但它们的训练仍然昂贵，这使得许多研究小组无法使用最先进的方法。我们引入了Nequix，这是一种紧凑的E(3)-等变潜力模型，它将简化的NequIP设计与现代训练实践相结合，包括等变均方根层归一化和Muon优化器，以在显著降低计算需求的同时保持准确性。Nequix在JAX中构建，具有70万个参数，并在500 A100-GPU小时内训练完成。在Matbench-Discovery和MDR Phonon基准测试中，Nequix总排名第三，而其训练成本不到大多数其他方法的四分之一，并且其推理速度比当前排名第一的模型快一个数量级。我们在此发布模型权重和完全可重现的代码库。\n\n作者: Teddy Koker, Tess Smidt\n\n链接: [2025 [2508.16067] Training a Foundation Model for Materials on a Budget.pdf](https://arxiv.org/pdf/2508.16067.pdf)",
        "地址": "https://arxiv.org/pdf/2508.16067.pdf"
    }
]