[
    {
        "名称": "2025 [2509.04664] Why Language Models Hallucinate.pdf",
        "作者": "Adam Tauman Kalai, Ofir Nachum, Santosh S. Vempala, Edwin Zhang",
        "摘要": "摘要: 就像学生面对困难的考试问题一样，大型语言模型在不确定时有时会猜测，产生合理但不正确的陈述，而不是承认不确定性。这种“幻觉”即使在最先进的系统中仍然存在，并削弱了信任。我们认为语言模型产生幻觉是因为训练和评估过程奖励猜测而不是承认不确定性，我们分析了现代训练管道中幻觉的统计原因。幻觉不必神秘——它们只是二元分类中的错误。如果无法将不正确的陈述与事实区分开，那么预训练语言模型中的幻觉将通过自然的统计压力产生。然后我们认为幻觉持续存在是由于大多数评估的评分方式——语言模型被优化为优秀的考试者，在不确定时猜测会提高考试成绩。这种惩罚不确定响应的“流行病”只能通过社会技术缓解来解决：修改现有的基准评分，这些基准评分是错位的但支配排行榜，而不是引入额外的幻觉评估。这种改变可能会引导该领域走向更值得信赖的人工智能系统。\n\n作者: Adam Tauman Kalai, Ofir Nachum, Santosh S. Vempala, Edwin Zhang\n\n链接: https://arxiv.org/pdf/2509.04664.pdf\n\n标题: 2025 [2509.04664] 为什么语言模型会产生幻觉.pdf",
        "地址": "https://arxiv.org/pdf/2509.04664.pdf"
    },
    {
        "名称": "2025 [2509.05208] Symbolic Graphics Programming with Large Language Models.pdf",
        "作者": "Yamei Chen, Haoquan Zhang, Yangyi Huang, Zeju Qiu, Kaipeng Zhang, Yandong Wen, Weiyang Liu",
        "摘要": "摘要：大语言模型（LLMs）在程序合成方面表现出色，但其生成精确视觉内容的符号图形程序（SGPs）的能力尚未得到充分探索。我们研究了符号图形编程，其目标是从自然语言描述中生成SGP。此任务也提供了一个观察LLMs理解视觉世界的视角，通过提示它们生成从SGPs渲染的图像。在各种SGPs中，我们的论文坚持使用可扩展矢量图形（SVGs）。我们首先考察了LLMs生成SGPs的能力。为此，我们引入了SGP-GenBench，这是一个涵盖对象保真度、场景保真度和组合性（属性绑定、空间关系、数字性）的综合基准。在SGP-GenBench上，我们发现前沿专有模型显著优于开源模型，并且性能与一般编码能力有很好的相关性。出于这一差距的动机，我们旨在提高LLMs生成SGPs的能力。我们提出了一种基于可验证奖励的强化学习（RL）方法，其中格式有效性门确保可渲染的SVG，并通过强大的视觉编码器（例如，SigLIP用于文本-图像和DINO用于图像-图像）将跨模态奖励与文本和渲染图像对齐。应用于Qwen-2.5-7B，我们的方法显著提高了SVG生成质量和语义，达到了与前沿系统相当的性能。我们进一步分析了训练动态，显示出RL诱导了（i）将对象精细分解为可控原语和（ii）改善场景连贯性的上下文细节。我们的结果表明，符号图形编程为跨模态基础提供了一个精确且可解释的视角。",
        "地址": "https://arxiv.org/pdf/2509.05208.pdf"
    },
    {
        "名称": "2025 [2509.04185] Set Block Decoding is a Language Model Inference Accelerator.pdf",
        "作者": "Itai Gat, Heli Ben-Hamu, Marton Havasi, Daniel Haziza, Jeremy Reizenstein, Gabriel Synnaeve, David Lopez-Paz, Brian Karrer, Yaron Lipman",
        "摘要": "摘要：自回归下一个标记预测语言模型提供了强大的能力，但在实际部署中面临显著挑战，主要是由于推理的高计算和内存成本，特别是在解码阶段。我们介绍了Set Block Decoding (SBD)，这是一种简单而灵活的范式，通过在单一架构内结合标准下一个标记预测（NTP）和掩码标记预测（MATP）来加速生成。SBD允许模型并行采样多个不必为连续的未来标记，这是与之前加速方法的关键区别。这种灵活性允许使用离散扩散文献中的高级求解器，在不牺牲准确性的情况下提供显著的加速。SBD不需要架构更改或额外的训练超参数，保持与精确的KV缓存兼容，并且可以通过微调现有的下一个标记预测模型来实现。通过微调Llama-3.1 8B和Qwen-3 8B，我们证明了SBD实现了生成所需前向传递数量的3-5倍减少，同时达到与等效的NTP训练相同的表现。\n\n翻译为中文的摘要：\n自回归下一个标记预测语言模型提供了强大的功能，但在实际应用中面临推理阶段高计算和内存成本的显著挑战。我们提出了一种简单且灵活的加速生成范式——Set Block Decoding (SBD)，它在单一架构中结合标准下一个标记预测(NTP)和掩码标记预测(MATP)。SBD允许模型并行采样多个未来标记，这些标记不一定是连续的，这是与现有加速方法的关键区别。这种灵活性允许模型使用离散扩散领域的高级求解器，在保证准确性的前提下显著加速生成。SBD不需要对模型架构进行修改或添加额外的训练超参数，能与精确的KV缓存兼容，并且可以通过微调现有的NTP模型来实现。通过微调Llama-3.1 8B和Qwen-3 8B，我们展示了SBD可将生成所需的前向传递数量减少3-5倍，同时达到与等效的NTP训练相同的性能。",
        "地址": "https://arxiv.org/pdf/2509.04185.pdf"
    },
    {
        "名称": "2025 [2509.04744] WildScore: Benchmarking MLLMs in-the-Wild Symbolic Music Reasoning.pdf",
        "作者": "Gagan Mundada, Yash Vishe, Amit Namburi, Xin Xu, Zachary Novack, Julian McAuley, Junda Wu",
        "摘要": "摘要：最近在多模态大型语言模型（MLLMs）方面的进展展示了其在各种视觉-语言任务中的出色能力。然而，它们在多模态符号音乐领域的推理能力尚未得到充分探索。我们介绍了WildScore，这是首个在真实环境中进行多模态符号音乐推理和分析的基准，旨在评估MLLMs解读真实音乐乐谱和回答复杂音乐学问题的能力。WildScore中的每个实例均来自真实的音乐作品，并伴有真实用户生成的问题和讨论，捕捉了实践音乐分析的复杂性。为了便于系统评估，我们提出了一个系统化分类法，包括高层次和细粒度的音乐学本体。此外，我们将复杂音乐推理框架设定为多项选择题回答，允许对MLLMs的符号音乐理解进行控制和可扩展的评估。对先进的MLLMs在WildScore上的实证基准测试揭示了它们在视觉符号推理中的有趣模式，展示了有希望的方向和MLLMs在符号音乐推理和分析中存在的持续挑战。我们发布了数据集和代码。",
        "地址": "https://arxiv.org/pdf/2509.04744.pdf"
    },
    {
        "名称": "2025 [2509.05263] LatticeWorld: A Multimodal Large Language Model-Empowered Framework for Interactive Complex World Generation.pdf",
        "作者": "Yinglin Duan, Zhengxia Zou, Tongwei Gu, Wei Jia, Zhan Zhao, Luyi Xu, Xinzhu Liu, Yenan Lin, Hao Jiang, Kang Chen, Shuang Qiu",
        "摘要": "摘要: 最近的研究越来越关注开发3D世界模型，用于模拟复杂的现实世界场景。世界模型在多个领域中有广泛应用，包括具身人工智能、自动驾驶、娱乐等。更真实的模拟且具有准确的物理特性可以有效缩小从模拟到现实的差距，并使我们更加方便地收集真实世界的信息。虽然传统的手动建模已经允许创建虚拟3D场景，现代方法则利用先进的机器学习算法进行3D世界生成，最近的进展主要集中在基于用户指令生成虚拟世界的生成方法上。本研究探索了这种研究方向，提出了LatticeWorld，一个简单但有效的3D世界生成框架，简化了3D环境的工业生产流程。LatticeWorld利用轻量级LLM（如LLaMA-2-7B）以及工业级渲染引擎（例如Unreal Engine 5），生成一个动态环境。我们提出的框架接受文本描述和视觉指令作为多模态输入，并创建具有动态代理的大规模3D互动世界，特点包括竞赛式的多代理互动、高保真物理模拟和实时渲染。我们进行了全面实验来评价LatticeWorld，结果显示其在场景布局生成和视觉保真度方面具有卓越的准确性。此外，与传统手动生产方法相比，LatticeWorld在工业生产效率上提高超过90倍，并保持高的创造质量。我们的演示视频可在此链接观看。\n\n演示视频链接：https://arxiv.org/pdf/2509.05263.pdf",
        "地址": "https://arxiv.org/pdf/2509.05263.pdf"
    },
    {
        "名称": "2025 [2509.03680] LuxDiT: Lighting Estimation with Video Diffusion Transformer.pdf",
        "作者": "Ruofan Liang, Kai He, Zan Gojcic, Igor Gilitschenski, Sanja Fidler, Nandita Vijaykumar, Zian Wang",
        "摘要": "摘要：从单张图像或视频估计场景光照是计算机视觉和图形学中长期存在的挑战。基于学习的方法受到稀缺的高动态范围（HDR）环境地图的限制，这些地图捕获成本高且种类有限。尽管最近的生成模型为图像合成提供了强大的先验，但由于依赖于间接视觉线索、需要推断全局（非局部）上下文以及恢复高动态范围输出，光照估计仍然困难。我们提出了LuxDiT，这是一种新颖的数据驱动方法，通过微调视频扩散变压器来生成基于视觉输入的HDR环境地图。在具有多样光照条件的大型合成数据集上训练，本模型学习从间接视觉线索中推断照明，并能有效泛化到现实场景。为提高输入和预测环境地图之间的语义对齐，我们使用收集的HDR全景图引入了一种低秩适应微调策略。我们的方法产生准确的光照预测，具有逼真的高频角度细节，在定量和定性评估中均优于现有的最先进技术。\n\n作者：Ruofan Liang, Kai He, Zan Gojcic, Igor Gilitschenski, Sanja Fidler, Nandita Vijaykumar, Zian Wang\n\n评论：项目页面：this https URL\n\n网址：https://arxiv.org/pdf/2509.03680.pdf\n\n标题：2025 [2509.03680] LuxDiT: 用视频扩散变压器进行光照估计.pdf",
        "地址": "https://arxiv.org/pdf/2509.03680.pdf"
    },
    {
        "名称": "2025 [2509.05296] WinT3R: Window-Based Streaming Reconstruction with Camera Token Pool.pdf",
        "作者": "Zizun Li, Jianjun Zhou, Yifan Wang, Haoyu Guo, Wenzheng Chang, Yang Zhou, Haoyi Zhu, Junyi Chen, Chunhua Shen, Tong He",
        "摘要": "摘要：我们提出了WinT3R，一种能够在线预测精确相机姿态和高质量点云地图的前馈重建模型。之前的方法存在重建质量和实时性能之间的权衡。为了解决这个问题，我们首先引入了滑动窗口机制，确保窗口内帧之间的信息交换，从而在不进行大量计算的情况下提高几何预测的质量。此外，我们利用紧凑的相机表示并维护一个全局相机令牌池，增强了相机姿态估计的可靠性而不牺牲效率。这些设计使得WinT3R在在线重建质量、相机姿态估计和重建速度方面实现了最新的性能，并通过对不同数据集的大量实验进行了验证。代码和模型已公开提供，可在此https URL获取。\n\n翻译：我们提出了WinT3R，一种能够在线预测精确相机姿态和高质量点云地图的前馈重建模型。先前的方法在重建质量和实时性能之间存在权衡。为了应对这一问题，我们首先引入了一种滑动窗口机制，确保窗口内的帧之间进行充分的信息交换，从而在不进行大量计算的情况下提高几何预测的质量。此外，我们利用相机的紧凑表示并维护一个全局相机令牌池，这增强了相机姿态估计的可靠性，同时不牺牲效率。这些设计使WinT3R在在线重建质量、相机姿态估计和重建速度方面实现了最先进的性能，并通过对各种数据集的大量实验进行了验证。代码和模型已公开提供，可在此https URL获取。",
        "地址": "https://arxiv.org/pdf/2509.05296.pdf"
    },
    {
        "名称": "2025 [2509.03800] MedVista3D: Vision-Language Modeling for Reducing Diagnostic Errors in 3D CT Disease Detection, Understanding and Reporting.pdf",
        "作者": "Yuheng Li, Yenho Chen, Yuxiang Lai, Jike Zhong, Vanessa Wildman, Xiaofeng Yang",
        "摘要": "摘要：放射诊断错误——读片错误、无意盲视和沟通失败——在临床实践中仍然普遍存在。这些问题通常源于错过了局部异常、缺乏全局上下文以及报告语言的差异性。在3D影像中，这些挑战尤为突出，医生必须检查每个扫描中的数百张切片。解决这些问题需要系统具有精确的局部检测、全局体积级推理和语义一致的自然语言报告。然而，现有的3D视觉-语言模型无法联结满足这三个需求，它们缺乏局部-全局理解空间推理，并在处理未经整理的放射学报告的变量性和噪音方面遇到困难。我们提出MedVista3D，一个用于3D CT分析的多尺度语义增强视觉-语言预训练框架。为了实现联合疾病检测和整体解释，MedVista3D在完整体积上下文中执行局部和全局图像-文本对齐，以进行细粒度表示学习。为了应对报告的变量性，我们应用语言模型改写，并引入一个放射学语义匹配库以进行语义感知对齐。MedVista3D在零样本疾病分类、报告检索和医学视觉问答方面取得了最先进的性能，同时能够很好地转移到器官分割和预后预测。代码和数据集将被发布。",
        "地址": "https://arxiv.org/pdf/2509.03800.pdf"
    },
    {
        "名称": "2025 [2509.04013] On Robustness and Reliability of Benchmark-Based Evaluation of LLMs.pdf",
        "作者": "Riccardo Lunardi, Vincenzo Della Mea, Stefano Mizzaro, Kevin Roitero",
        "摘要": "以下是该学术论文摘要的中文翻译：\n\n摘要：大型语言模型（LLMs）的有效性通常通过MMLU、ARC-C或HellaSwag等基准来评价，这些基准中的问题以原始措辞呈现，因此格式固定且标准化。然而，现实世界的应用涉及语言的多样性，要求模型在不同的同义表达下仍能保持其有效性。在本研究中，我们系统评估了LLMs对基准问题的同义问句的稳健性，并调查基于基准的评价是否能可靠衡量模型能力。我们系统地生成了跨六个不同常见基准的所有问题的各种同义问句，并测量了34个不同规模和有效性的最新LLMs的结果变化情况。我们的研究发现，虽然LLMs的排名在同义问句输入下相对稳定，但其绝对有效性评分发生变化并显著下降。这表明LLMs在应对语言多样性方面存在困难，令人担忧其泛化能力和评价方法。此外，观察到的性能下降挑战了基于基准的评价的可靠性，表明高基准得分可能无法完全反映模型应对现实输入变化的稳健性。我们讨论了这些发现对LLM评价方法的影响，强调需要能更好反映实际部署场景的稳健性基准。\n\n评论：已被ECAI 2025接受\n\n作者：Riccardo Lunardi, Vincenzo Della Mea, Stefano Mizzaro, Kevin Roitero\n\n链接：https://arxiv.org/pdf/2509.04013.pdf\n\n标题：2025 [2509.04013] 关于基于基准的LLM评估的稳健性和可靠性",
        "地址": "https://arxiv.org/pdf/2509.04013.pdf"
    },
    {
        "名称": "2025 [2509.04504] Behavioral Fingerprinting of Large Language Models.pdf",
        "作者": "Zehua Pei, Hui-Ling Zhen, Ying Zhang, Zhiyuan Yang, Xing Li, Xianzhi Yu, Mingxuan Yuan, Bei Yu",
        "摘要": "摘要: 目前，大型语言模型 (LLMs) 的基准测试主要集中在性能指标上，往往未能捕捉到区分它们的细微行为特征。本文介绍了一种新颖的“行为指纹识别”框架，旨在通过创建模型内在认知和互动风格的多方面特征，超越传统评估。通过使用精心设计的 \\textit{诊断提示套件} 和创新的自动化评估管道（其中一个强大的 LLM 充当公正的裁判），我们分析了十八个在能力等级上不同的模型。我们的结果揭示了 LLM 领域中的一个关键分歧：虽然抽象和因果推理等核心能力在顶级模型之间趋于一致，但涉Alignment（对齐）相关的行为如阿谀奉承（sycophancy）和语义强劲性（semantic robustness）则显著不同。我们还记录了跨模型的默认人格聚类（ISTJ/ESTJ），这可能反映了常见的对齐激励机制。总体来看，这表明模型的互动性质不是其规模或推理能力的自然属性，而是特定且高度可变的开发者对齐策略的直接结果。我们的框架提供了一种可重复和可扩展的方法，以揭示这些深层行为差异。\n\n项目: https://arxiv.org/pdf/2509.04504.pdf",
        "地址": "https://arxiv.org/pdf/2509.04504.pdf"
    },
    {
        "名称": "2025 [2509.04575] Bootstrapping Task Spaces for Self-Improvement.pdf",
        "作者": "Minqi Jiang, Andrei Lupu, Yoram Bachrach",
        "摘要": "摘要：许多任务领域的进展源于对先前解决尝试的反复修订。在推理时训练能够可靠自我改进的代理是强化学习（RL）的一个自然目标，然而，天真的方法假定了一个固定的最大迭代深度，这既可能代价高昂又显得武断。我们提出了探索迭代（ExIt），这是一组自我课程RL方法，直接利用自我改进任务的递归结构来训练大型语言模型（LLM）在推理时执行多步自我改进，同时只训练在最有信息量的单步迭代上。ExIt通过有选择地采样在一次事件中遇到的最有信息的中间部分历史，来扩展任务空间，并将这些起点作为新的自我迭代任务实例，用于训练自我改进策略。ExIt还能与显性探索机制配对，以保持更大的任务多样性。在涵盖竞赛数学、多回合工具使用和机器学习工程的多个领域中，我们展示了ExIt策略，无论是从单个还是多个任务实例出发，都能产生在保留的任务实例上表现出强推理时自我改进的策略，并且能够在推理预算延伸到训练期间平均迭代深度之外的情况下，迭代实现更高的性能。\n\n翻译：在许多任务领域，进展源于对先前解决尝试的反复修订。在推理时训练能够可靠自我改进的代理是强化学习（RL）的一个自然目标，然而，天真的方法假定了一个固定的最大迭代深度，这既可能代价高昂又显得武断。我们提出了探索迭代（ExIt），这是一组自我课程RL方法，直接利用自我改进任务的递归结构来训练大型语言模型（LLM）在推理时执行多步自我改进，同时只训练在最有信息量的单步迭代上。ExIt通过有选择地采样在一次事件中遇到的最有信息的中间部分历史，来扩展任务空间，并将这些起点作为新的自我迭代任务实例，用于训练自我改进策略。ExIt还能与显性探索机制配对，以保持更大的任务多样性。在涵盖竞赛数学、多回合工具使用和机器学习工程的多个领域中，我们展示了ExIt策略，无论是从单个还是多个任务实例出发，都能产生在保留的任务实例上表现出强推理时自我改进的策略，并且能够在推理预算延伸到训练期间平均迭代深度之外的情况下，迭代实现更高的性能。",
        "地址": "https://arxiv.org/pdf/2509.04575.pdf"
    },
    {
        "名称": "2025 [2509.02437] U-ARM : Ultra low-cost general teleoperation interface for robot manipulation.pdf",
        "作者": "Yanwen Zou, Zhaoye Zhou, Chenyang Shi, Zewei Ye, Junda Huang, Yan Ding, Bo Zhao",
        "摘要": "摘要：我们提出了U-Arm，一种低成本且快速适应的主从遥操作框架，旨在与大多数现有的商品机器人手臂接口。我们的系统通过三种结构不同的3D打印主臂来支持遥操作，这些主臂共享一致的控制逻辑，从而实现与各种商用机器人配置的无缝兼容性。与之前的开源主从接口相比，我们进一步优化了机械设计和伺服选择，6自由度主臂的材料清单（BOM）成本仅为50.5美元，7自由度版本为56.8美元。为了增强可用性，我们通过工程方法、机械和控制优化来缓解控制冗余自由度的常见挑战。实验结果表明，与另一种低成本遥操作接口Joycon相比，U-Arm的数据收集效率提高了39%，并在多种操作场景下实现了相当的任务成功率。我们已经开源了三个配置的所有CAD模型，并提供了用于验证遥操作工作流程的仿真支持。我们还开源了使用U-Arm收集的真实世界操作数据。项目网站是this https URL。\n\n作者：Yanwen Zou, Zhaoye Zhou, Chenyang Shi, Zewei Ye, Junda Huang, Yan Ding, Bo Zhao\n\nURL: https://arxiv.org/pdf/2509.02437.pdf\n\n标题：2025 [2509.02437] U-ARM：超低成本通用遥操作接口用于机器人操作",
        "地址": "https://arxiv.org/pdf/2509.02437.pdf"
    }
]