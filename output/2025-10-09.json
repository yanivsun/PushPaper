[
    {
        "名称": "2025 [2510.03215] Cache-to-Cache: Direct Semantic Communication Between Large Language Models.pdf",
        "作者": "Tianyu Fu, Zihan Min, Hanling Zhang, Jichao Yan, Guohao Dai, Wanli Ouyang, Yu Wang",
        "摘要": "摘要: 多LLM系统利用不同大型语言模型的优势，实现单个模型无法达到的性能和效率提升。在现有设计中，LLMs通过文本进行通信，迫使内部表示转化为输出标记序列。这一过程不仅丢失了丰富的语义信息，还带来了逐字生成的延迟。基于这些限制，我们提出了一个问题：LLMs能否以超越文本的形式进行通信？甲骨文实验表明，丰富KV-Cache的语义可以在不增加缓存大小的情况下提高响应质量，支持KV-Cache作为模型间通信的有效媒介。因此，我们提出了Cache-to-Cache (C2C)，一种用于LLMs之间直接语义通信的新范式。C2C使用神经网络来投射和融合源模型的KV缓存与目标模型的KV缓存，实现直接的语义传输。一个可学习的门控机制选择受益于缓存通信的目标层。与文本通信相比，C2C利用了两个模型的深层次、专业化语义，同时避免了显式的中间文本生成。实验结果表明，C2C的平均准确率比单个模型高出8.5-10.5%。它还比文本通信范式高出约3.0-5.0%，同时在延迟方面实现了平均2.0倍的加速。我们的代码可以在这个URL上找到。",
        "地址": "https://arxiv.org/pdf/2510.03215.pdf"
    },
    {
        "名称": "2025 [2510.06590] Ming-UniVision: Joint Image Understanding and Generation with a Unified Continuous Tokenizer.pdf",
        "作者": "Ziyuan Huang, DanDan Zheng, Cheng Zou, Rui Liu, Xiaolong Wang, Kaixiang Ji, Weilong Chai, Jianxin Sun, Libin Wang, Yongjie Lv, Taozhi Huang, Jiajia Liu, Qingpei Guo, Ming Yang, Jingdong Chen, Jun Zhou",
        "摘要": "摘要：视觉标记仍然是通过自回归模式统一视觉理解和生成的核心挑战。现有方法通常在离散潜在空间中使用标记器，以与大型语言模型的标记对齐，而量化误差会限制语义表现力，并削弱视觉-语言理解的能力。为了解决这个问题，我们引入了MingTok，这是一类具有连续潜在空间的新型视觉标记器，用于统一自回归生成和理解。虽然理解任务更倾向于判别性的高维特征，但生成任务更喜欢紧凑的低级编码。因此，为了调和这些相互竞争的需求，MingTok采用了一个三阶段的顺序架构，包括低级编码、语义扩展和视觉重建。在其基础上，Ming-UniVision消除了对特定任务的视觉表示的需求，并在单一自回归预测模式下统一了多样的视觉-语言任务。通过在共享的连续空间中将理解和生成都形式化为下一个标记预测，它无缝支持多轮次、上下文中的任务，例如迭代理解、生成和编辑。经验上，我们发现使用统一的连续视觉表示调和了理解和生成任务对标记器的相互竞争需求，从而在这两个领域实现了最先进的性能。我们希望我们的发现能够促进连续领域中的统一视觉标记化。推理代码和模型权重已释放，以造福社区。",
        "地址": "https://arxiv.org/pdf/2510.06590.pdf"
    },
    {
        "名称": "2025 [2510.06308] Lumina-DiMOO: An Omni Diffusion Large Language Model for Multi-Modal Generation and Understanding.pdf",
        "作者": "Yi Xin, Qi Qin, Siqi Luo, Kaiwen Zhu, Juncheng Yan, Yan Tai, Jiayi Lei, Yuewen Cao, Keqi Wang, Yibin Wang, Jinbin Bai, Qian Yu, Dengyang Jiang, Yuandong Pu, Haoxing Chen, Le Zhuo, Junjun He, Gen Luo, Tianbin Li, Ming Hu, Jin Ye, Shenglong Ye, Bo Zhang, Chang Xu, Wenhai Wang, Hongsheng Li, Guangtao Zhai, Tianfan Xue, Bin Fu, Xiaohong Liu, Yu Qiao, Yihao Liu",
        "摘要": "摘要：我们介绍了Lumina-DiMOO，一个用于无缝多模态生成和理解的开源基础模型。Lumina-DiMOO通过使用完全离散的扩散建模来处理跨各种模态的输入和输出，区别于以往的统一模型。这种创新方法使Lumina-DiMOO在采样效率上相比以往的自回归（AR）或混合AR-扩散范式更高效，并且能够熟练地支持广泛的多模态任务，包括文本到图像生成、图像到图像生成（例如图像编辑、主题驱动生成和图像修补等）以及图像理解。Lumina-DiMOO在多个基准测试中达到了最新的性能，超越了现有的开源统一多模态模型。为了促进多模态和离散扩散模型研究的进一步发展，我们向社区开放了我们的代码和检查点。项目页面：此https链接。",
        "地址": "https://arxiv.org/pdf/2510.06308.pdf"
    },
    {
        "名称": "2025 [2510.06917] SHANKS: Simultaneous Hearing and Thinking for Spoken Language Models.pdf",
        "作者": "Cheng-Han Chiang, Xiaofei Wang, Linjie Li, Chung-Ching Lin, Kevin Lin, Shujie Liu, Zhendong Wang, Zhengyuan Yang, Hung-yi Lee, Lijuan Wang",
        "摘要": "**摘要**：当前的大型语言模型（LLMs）和口语语言模型（SLMs）只有在用户结束其轮次后才开始思考和采取行动。这阻止了模型在用户轮次期间交互，并且在等待思考时可能导致较高的响应延迟。因此，在收到完整输入后进行思考并不适合语音对话交互，实时、低延迟的交流非常重要。我们注意到人类自然地“边听边思考”，因此提出了SHANKS，一个使SLMs能够在听用户输入的同时进行未说出的链式思考的通用推理框架。SHANKS将输入语音分成固定时长的块，并在接收到块后立即根据所有先前语音和推理生成未说出的推理，同时用户继续说话。SHANKS利用这种未说出的推理决定是否打断用户并进行工具调用以完成任务。我们证明了SHANKS在两种场景中增强了实时用户-SLM交互：（1）当用户逐步解决数学问题时，SHANKS能够在用户犯错时进行聆听、推理并打断，打断准确性比不进行思考的基线高37.1%；（2）在工具增强对话中，SHANKS能够在用户轮次结束前完成56.9%的工具调用。总体而言，SHANKS推动了模型在整个对话中持续思考，而不仅仅是在轮次结束后。Shanks的动画演示可以在此https URL找到。\n\n**翻译**：\n当前的大型语言模型（LLMs）和口语语言模型（SLMs）只有在用户结束其轮次后才开始思考和采取行动。这阻止了模型在用户轮次期间交互，并且在等待思考时可能导致较高的响应延迟。因此，在收到完整输入后进行思考并不适合语音对话交互，实时、低延迟的交流非常重要。我们注意到人类自然地“边听边思考”，因此提出了SHANKS，一个使SLMs能够在听用户输入的同时进行未说出的链式思考的通用推理框架。SHANKS将输入语音分成固定时长的块，并在接收到块后立即根据所有先前语音和推理生成未说出的推理，同时用户继续说话。SHANKS利用这种未说出的推理决定是否打断用户并进行工具调用以完成任务。我们证明了SHANKS在两种场景中增强了实时用户-SLM交互：（1）当用户逐步解决数学问题时，SHANKS能够在用户犯错时进行聆听、推理并打断，打断准确性比不进行思考的基线高37.1%；（2）在工具增强对话中，SHANKS能够在用户轮次结束前完成56.9%的工具调用。总体而言，SHANKS推动了模型在整个对话中持续思考，而不仅仅是在轮次结束后。Shanks的动画演示可以在此https URL找到。",
        "地址": "https://arxiv.org/pdf/2510.06917.pdf"
    },
    {
        "名称": "2025 [2510.06710] RLinf-VLA: A Unified and Efficient Framework for VLA+RL Training.pdf",
        "作者": "Hongzhi Zang, Mingjie Wei, Si Xu, Yongji Wu, Zhen Guo, Yuanqing Wang, Hao Lin, Liangzhi Shi, Yuqing Xie, Zhexuan Xu, Zhihao Liu, Kang Chen, Wenhao Tang, Quanlu Zhang, Weinan Zhang, Chao Yu, Yu Wang",
        "摘要": "摘要：视觉和语言基础模型的最新进展显著推动了多模态理解、推理和生成，从而激发了通过视觉-语言-行动（VLA）模型将这些能力扩展到具身设置的兴趣激增。然而，大多数VLA模型仍然通过监督微调（SFT）进行训练，这种方法难以在分布变化时泛化，导致错误积累。强化学习（RL）提供了一种有前途的替代方案，通过互动直接优化任务性能，但现有尝试仍然分散，缺乏统一平台进行模型架构和算法设计的公平和系统比较。为了解决这一问题，我们推出了RLinf-VLA，一个用于大规模RL训练VLA模型的统一高效框架。该系统采用高度灵活的资源分配设计，解决了在RL+VLA训练中集成渲染、训练和推断的挑战。特别地，对于GPU并行化模拟器，RLinf-VLA实现了一种新颖的混合细粒度流水线分配模式，训练速度提高了1.61倍至1.88倍。通过统一接口，RLinf-VLA无缝支持各种VLA架构（例如OpenVLA、OpenVLA-OFT）、多种RL算法（例如PPO、GRPO）和各种模拟器（例如ManiSkill、LIBERO）。在模拟中，一个统一模型在130个LIBERO任务上实现了98.11%的成功率，在25个ManiSkill任务上实现了97.66%的成功率。除了经验性能，我们的研究提炼了一套将RL应用于VLA训练的最佳实践，并揭示了这一整合中的新兴模式。此外，我们展示了在现实世界中的Franka机器人上的初步部署，RL训练的策略表现出比SFT训练的策略更强的泛化能力。我们展望RLinf-VLA作为加速和标准化具身智能研究的基础。",
        "地址": "https://arxiv.org/pdf/2510.06710.pdf"
    },
    {
        "名称": "2025 [2510.07310] MATRIX: Mask Track Alignment for Interaction-aware Video Generation.pdf",
        "作者": "Siyoon Jin, Seongchan Kim, Dahyun Chung, Jaeho Lee, Hyunwook Choi, Jisu Nam, Jiyoung Kim, Seungryong Kim",
        "摘要": "摘要: 尽管视频DiTs推进了视频生成技术，但它们在模拟多实例或主体-对象交互方面仍然存在困难。这引发了一个关键问题：这些模型如何内部表示交互？为了解答这一问题，我们创建了MATRIX-11K视频数据集，该数据集包含交互感知的字幕和多实例掩码轨迹。利用该数据集，我们进行了一项系统分析，正式提出了视频DiTs的两个视角：通过视频到文本的注意力进行语义定位，评估名词和动词标记是否捕捉到实例及其关系；通过视频到视频的注意力进行语义传播，评估实例绑定是否在不同帧之间持续存在。我们发现这两种效果集中在一小部分交互主导的层中。受此启发，我们介绍了MATRIX，一种简单有效的正则化方法，它将视频DiTs中特定层的注意力与MATRIX-11K数据集中的多实例掩码轨迹对齐，增强了语义定位和传播。我们进一步提出了InterGenEval，一种针对交互感知视频生成的评估协议。在实验中，MATRIX提升了交互的保真度和语义对齐，同时减少了漂移和幻觉。广泛的消融实验验证了我们的设计选择。代码和权重将会发布。\n\n作者: Jin Siyoon, Kim Seongchan, Chung Dahyun, Lee Jaeho, Choi Hyunwook, Nam Jisu, Kim Jiyoung, Kim Seungryong\n\n链接: https://arxiv.org/pdf/2510.07310.pdf\n\n评论: 项目页面可在此HTTPS URL访问。",
        "地址": "https://arxiv.org/pdf/2510.07310.pdf"
    },
    {
        "名称": "2025 [2510.07315] Vibe Checker: Aligning Code Evaluation with Human Preference.pdf",
        "作者": "Ming Zhong, Xiang Zhou, Ting-Yun Chang, Qingze Wang, Nan Xu, Xiance Si, Dan Garrette, Shyam Upadhyay, Jeremiah Liu, Jiawei Han, Benoit Schillings, Jiao Sun",
        "摘要": "摘要： 大型语言模型（LLMs）促进了vibe编码，在这种编码方式中，用户利用LLMs通过自然语言交互生成并反复修改代码，直到其通过vibe检查。Vibe检查与现实世界中的人类偏好相关，超越了功能性：解决方案应当感觉正确，读取干净，保留意图，并保持正确。然而，目前的代码评估仍停留在pass@k并且仅捕捉到功能性正确性，忽略了用户日常应用的非功能性指令。在本文中，我们假设指令遵循是vibe检查背后代表人类编码偏好的缺失部分，除了功能性正确性以外。为了以可量化信号量化模型的代码指令遵循能力，我们提出了VeriCode，这是一个包含30条可验证代码指令的分类法，并附有相应的确定性验证器。我们使用该分类法扩展了已建立的评估套件，从而产生了Vibe Checker，一个评估代码指令遵循和功能性正确性的测试平台。在评估了31个领先的LLMs后，我们展示了即便是最强大的模型也难以遵守多条指令，并表现出明显的功能性退化。最重要的是，功能性正确性和指令遵循的综合得分与人类偏好最为相关，后者在现实世界的编程任务中成为主要区分因子。我们的工作识别出了vibe检查的核心因素，为基准测试和开发更符合用户编码偏好的模型提供了一条具体路径。",
        "地址": "https://arxiv.org/pdf/2510.07315.pdf"
    },
    {
        "名称": "2025 [2510.07318] Artificial Hippocampus Networks for Efficient Long-Context Modeling.pdf",
        "作者": "Yunhao Fang, Weihao Yu, Shu Zhong, Qinghao Ye, Xuehan Xiong, Lai Wei",
        "摘要": "摘要：长序列建模面临着在RNN类模型中的压缩固定尺寸记忆效率与基于注意力的Transformer中无损增长记忆保真度之间的根本矛盾。受认知科学中多存储模型的启发，我们引入了人工神经网络的记忆框架。我们的方法在Transformer的KV缓存中保持滑动窗口作为无损短期记忆，同时一个名为人工海马网络（AHN）的可学习模块反复压缩窗口外的信息到固定尺寸的紧凑长期记忆中。为了验证这一框架，我们使用现代的RNN类架构实例化AHN，包括Mamba2、DeltaNet和Gated DeltaNet。在长上下文基准LV-Eval和InfiniteBench上的广泛实验表明，AHN增强模型持续优于滑动窗口基线，并且在显著降低计算和内存需求的同时，实现了可比甚至优于全注意力模型的性能。例如，为Qwen2.5-3B-Instruct增加AHN可将推理FLOPs减少40.5%，内存缓存减少74.0%，同时将其在LV-Eval（128k序列长度）上的平均分数从4.41提高到5.88。代码可在此https URL获得。\n\n作者：Yunhao Fang, Weihao Yu, Shu Zhong, Qinghao Ye, Xuehan Xiong, Lai Wei\n\n评论：代码：此https URL\n\n网址：https://arxiv.org/pdf/2510.07318.pdf\n\n标题：2025 [2510.07318] 有效长上下文建模的人工海马网络.pdf",
        "地址": "https://arxiv.org/pdf/2510.07318.pdf"
    },
    {
        "名称": "2025 [2510.04678] Multi-Agent Tool-Integrated Policy Optimization.pdf",
        "作者": "Zhanfeng Mo, Xingxuan Li, Yuntao Chen, Lidong Bing",
        "摘要": "摘要：大型语言模型（LLMs）越来越多地依赖于多轮次工具集成规划来完成知识密集型和复杂的推理任务。现有的实施通常依赖于单一代理，但它们存在上下文长度有限和工具响应噪声的问题。一个自然的解决方案是采用带有规划者和工人代理的多代理框架来管理上下文。然而，没有现有的方法支持工具集成多代理框架的有效强化学习训练后阶段。为了解决这一空白，我们提出了多代理工具集成政策优化（MATPO），它允许在单个LLM实例中使用角色特定提示通过强化学习训练不同角色（规划者和工人）。MATPO是从规划者和工人的演练中提取出来的一种有原则的信用分配机制。这种设计消除了部署多个LLM的需求，这将非常占用内存，同时保留了专门化的优势。在GAIA-text、WebWalkerQA和FRAMES上的实验表明，MATPO较单代理基线实现了平均18.38%的相对性能提升，并表现出对噪声工具输出的更强鲁棒性。我们的研究结果突出了在单个LLM中统一多个代理角色的有效性，并为稳定高效的多代理强化学习训练提供了实践见解。",
        "地址": "https://arxiv.org/pdf/2510.04678.pdf"
    },
    {
        "名称": "2025 [2510.05644] The African Languages Lab: A Collaborative Approach to Advancing Low-Resource African NLP.pdf",
        "作者": "Sheriff Issaka, Keyi Wang, Yinka Ajibola, Oluwatumininu Samuel-Ipaye, Zhaoyi Zhang, Nicte Aguillon Jimenez, Evans Kofi Agyei, Abraham Lin, Rohan Ramachandran, Sadick Abdul Mumin, Faith Nchifor, Mohammed Shuraim, Lieqi Liu, Erick Rosas Gonzalez, Sylvester Kpei, Jemimah Osei, Carlene Ajeneza, Persis Boateng, Prisca Adwoa Dufie Yeboah, Saadia Gabriel",
        "摘要": "摘要: 尽管非洲语言几乎占世界语言的三分之一，但现代自然语言处理（NLP）技术仍然严重忽视非洲语言，其中88%被归类为严重代表不足或在计算语言学中完全被忽略。我们提出了非洲语言实验室（All Lab），这是一个综合研究计划，通过系统的数据收集、模型开发和能力建设来解决这一技术差距。我们的贡献包括：（1）一个质量控制的数据收集流程，产生了最大规模的经过验证的非洲多模态语音和文本数据集，涵盖了40种语言，包含190亿个单语文本标记和12,628小时的对齐语音数据；（2）广泛的实验验证表明，我们的数据集结合微调可以显著提高基线模型的性能，在31种评估语言中平均提高+23.69 ChrF++、+0.33 COMET和+15.34 BLEU点；（3）一个结构化研究项目，成功指导了15位早期职业研究人员，建立了可持续的本地能力。我们的比较评估与谷歌翻译相比，显示了在几种语言上的竞争性能，同时指出了需要继续开发的领域。\n\n作者: Sheriff Issaka, Keyi Wang, Yinka Ajibola, Oluwatumininu Samuel-Ipaye, Zhaoyi Zhang, Nicte Aguillon Jimenez, Evans Kofi Agyei, Abraham Lin, Rohan Ramachandran, Sadick Abdul Mumin, Faith Nchifor, Mohammed Shuraim, Lieqi Liu, Erick Rosas Gonzalez, Sylvester Kpei, Jemimah Osei, Carlene Ajeneza, Persis Boateng, Prisca Adwoa Dufie Yeboah, Saadia Gabriel\n\n网址: https://arxiv.org/pdf/2510.05644.pdf\n\n标题: 2025 [2510.05644] 非洲语言实验室：推进低资源非洲NLP的协作方法",
        "地址": "https://arxiv.org/pdf/2510.05644.pdf"
    },
    {
        "名称": "2025 [2510.04230] Pushing on Multilingual Reasoning Models with Language-Mixed Chain-of-Thought.pdf",
        "作者": "Guijin Son, Donghun Yang, Hitesh Laxmichand Patel, Amit Agarwal, Hyunwoo Ko, Chanuk Lim, Srikant Panda, Minhyuk Kim, Nikunj Drolia, Dasol Choi, Kyong-Ha Lee, Youngjae Yu",
        "摘要": "摘要（中文翻译）：\n\n摘要：最近的前沿模型采用长链式思维推理来探索上下文中的解决方案空间，并实现更强的性能。尽管许多研究致力于通过蒸馏技术打造更小但功能强大的模型，但大多数研究集中在英语方面，对特定语言的推理知之甚少。为弥合这一差距，我们首先介绍**语言混合链式思维（Language-Mixed CoT）**，这是一种在推理过程中在英语和目标语言之间切换的推理模式，以英语为锚点，在推理中表现出色，同时尽量减少翻译人工痕迹。作为一个韩语案例研究，我们整理了**Yi-Sang**：包括从网络问答、考试、STEM和代码中收集的579万条韩语原生提示；由Qwen3-32B生成的370万条长推理轨迹；以及一个目标为26万的高产子集。我们在六个模型家族（Qwen2.5，Llama-3.1，Gemma-3等）中训练了九个模型（4B-35B）。我们的最佳模型**KO-REAson-35B**实现了最先进的性能，整体平均得分最高（64.0 ± 25），在9项基准测试中排名第一的有5项，其余4项排名第二。小型和中型模型也有显著收益，在所评估的九项基准测试中的平均提高为+18.6分。消融实验表明，**语言混合链式思维（Language-Mixed CoT）**比单语言链式思维更有效，也导致跨语言和多模态的性能提升。我们发布了我们的数据整理管道、评估系统、数据集和模型，以推进特定语言推理的研究。数据和模型收集：https://arxiv.org/pdf/2510.04230.pdf。",
        "地址": "https://arxiv.org/pdf/2510.04230.pdf"
    },
    {
        "名称": "2025 [2510.04212] Why Low-Precision Transformer Training Fails: An Analysis on Flash Attention.pdf",
        "作者": "Haiquan Qiu, Quanming Yao",
        "摘要": "摘要：计算效率的追求推动了在训练transformer模型时采用低精度格式。然而，这一进展通常受到臭名昭著的训练不稳定性的阻碍。本文首次为一个长期存在且未解决的故障案例提供了机制解释，其中在低精度环境中使用闪存注意力（flash attention）训练会导致灾难性损失爆炸。我们的深入分析揭示，这一失败不是随机的，而是由两个相互交织的现象引起的：在注意机制中出现相似的低秩表示和低精度算术中固有的偏差舍入误差的复合效应。我们展示了这些因素如何形成一个恶性循环的错误累积，导致权重更新受到破坏，最终破坏训练动态。为了验证我们的发现，我们引入了一个最小的修改，减少了闪存注意力中的舍入误差偏差。这个简单的改变稳定了训练过程，从而验证了我们的分析，并为这个持久的问题提供了一个实际的解决方案。\n\n翻译：计算效率的追求推动了在训练transformer模型时采用低精度格式。然而，这一进展通常受到臭名昭著的训练不稳定性的阻碍。本文首次为一个长期存在且未解决的故障案例提供了机制解释，其中在低精度环境中使用闪存注意力（flash attention）训练会导致灾难性损失爆炸。我们的深入分析揭示，这一失败不是随机的，而是由两个相互交织的现象引起的：在注意机制中出现相似的低秩表示和低精度算术中固有的偏差舍入误差的复合效应。我们展示了这些因素如何形成一个恶性循环的错误累积，导致权重更新受到破坏，最终破坏训练动态。为了验证我们的发现，我们引入了一个最小的修改，减少了闪存注意力中的舍入误差偏差。这个简单的改变稳定了训练过程，从而验证了我们的分析，并为这个持久的问题提供了一个实际的解决方案。\n\n年份：2025\n\n作者：Haiquan Qiu, Quanming Yao\n\n评论：19页，10个图\n\n网址：https://arxiv.org/pdf/2510.04212.pdf\n\n标题：2025 [2510.04212] 为什么低精度Transformer训练会失败：对闪存注意力的分析.pdf",
        "地址": "https://arxiv.org/pdf/2510.04212.pdf"
    },
    {
        "名称": "2025 [2510.04204] CALM Before the STORM: Unlocking Native Reasoning for Optimization Modeling.pdf",
        "作者": "Zhengyang Tang, Zihan Ye, Chenyu Huang, Xuhan Huang, Chengpeng Li, Sihang Li, Guanhua Chen, Ming Yan, Zizhuo Wang, Hongyuan Zha, Dayiheng Liu, Benyou Wang",
        "摘要": "摘要：大型推理模型（LRMs）在复杂的多步骤推理中展示了强大的能力，为自动化优化建模开辟了新的机会。然而，现有的领域适应方法最初是为早期的指令调整模型设计的，通常未能利用现代LRMs的高级推理模式——特别是，我们显示了直接在传统的非反思数据集上进行微调的増益有限。为充分利用LRMs固有的推理能力，我们提出了CALM（Corrective Adaptation with Lightweight Modification），一个框架，逐步在其本地推理模式下优化LRMs以进行建模任务。在CALM中，专家干预者识别推理缺陷并提供简洁的纠正提示，LRM 结合这些提示以生成改进的推理轨迹。通过监督微调，这些干预修改了少于2.6％的生成令牌，但生成了高质量的数据以进行软适应。经过适应后的模型通过强化学习进一步改进。在CALM的基础上，我们开发了STORM（Smart Thinking Optimization Reasoning Model），一个拥有4B参数的LRM，在五个流行的优化建模基准测试中实现了新的64.9％的平均准确率，与一个671B的LRM表现相当。这些结果表明，基于提示的动态数据合成既保留又放大了现代LRMs固有的推理模式，为在具有挑战性的优化建模任务中实现专家级别的性能提供了一条更高效和可扩展的途径。\n\n评论：正在进行中的工作\n\n作者：郑阳唐，叶紫涵，黄晨宇，黄徐晗，李成鹏，李思航，陈冠华，严明，王子卓，查洪源，刘大闳，王奔游",
        "地址": "https://arxiv.org/pdf/2510.04204.pdf"
    },
    {
        "名称": "2025 [2510.07019] Native Hybrid Attention for Efficient Sequence Modeling.pdf",
        "作者": "Jusen Du, Jiaxi Hu, Tao Zhang, Weigao Sun, Yu Cheng",
        "摘要": "摘要：变压器在序列建模方面表现出色，但面临二次复杂性，而线性注意力提供了更高的效率，但在长上下文的回忆准确性方面往往会有所折损。在这项工作中，我们引入了本地混合注意力（Native Hybrid Attention，NHA），这是一种新颖的线性和全注意力混合架构，将层内和层间混合集成到统一的层设计中。NHA通过线性RNN更新的键值槽保持长时间的上下文，并通过滑动窗口增加短期标记。然后对所有键和值应用一个软注意力操作，使每个标记和每个头的加权上下文无须额外的融合参数。层间行为通过单一超参数（滑动窗口大小）控制，使得在纯线性和全注意力之间的平滑调整同时保持所有层的结构统一。实验结果表明，NHA在回忆密集和常识推理任务上超越了变压器和其他混合基准。此外，预训练的大型语言模型（LLM）可以通过NHA进行结构混合，实现竞争性精度，同时带来显著的效率提升。代码可在此https URL获取。\n\n作者：杜菊森，胡佳曦，张涛，孙魏高，程瑜\n\n备注：技术报告，16页\n\n链接：https://arxiv.org/pdf/2510.07019.pdf\n\n标题：2025 [2510.07019] 本地混合注意力用于高效序列建模",
        "地址": "https://arxiv.org/pdf/2510.07019.pdf"
    },
    {
        "名称": "2025 [2510.06751] OBS-Diff: Accurate Pruning For Diffusion Models in One-Shot.pdf",
        "作者": "Junhan Zhu, Hesong Wang, Mingluo Su, Zefang Wang, Huan Wang",
        "摘要": "摘要：大规模文本生成图像扩散模型虽然功能强大，但计算成本高昂。由于扩散模型的迭代去噪特性，现有的一次性网络剪枝方法难以直接应用于它们。为了解决这一问题，本文提出了OBS-Diff，一种能够精确且无需训练地压缩大规模文本生成图像扩散模型的全新一次性剪枝框架。具体来说，(i) OBS-Diff复兴了经典的Optimal Brain Surgeon (OBS)，使其适应现代扩散模型的复杂架构，并支持多种剪枝粒度，包括非结构化、N:M半结构化和结构化（MHA头和FFN神经元）稀疏性；(ii) 为了使剪枝标准与扩散过程的迭代动态相一致，通过从错误累积的角度审视问题，我们提出了一种新颖的时间步长感知Hessian构造，该构造结合了对数递减加权方案，赋予较早时间步更大的重要性以减轻潜在的错误累积；(iii) 此外，提出了一种计算效率高的逐组顺序剪枝策略，以分摊昂贵的校准过程。广泛的实验表明，OBS-Diff在扩散模型的一次性剪枝中达到了最先进水平，实现了推理加速，同时视觉质量几乎没有下降。",
        "地址": "https://arxiv.org/pdf/2510.06751.pdf"
    },
    {
        "名称": "2025 [2510.06557] The Markovian Thinker.pdf",
        "作者": "Milad Aghajohari, Kamran Chitsaz, Amirhossein Kazemnejad, Sarath Chandar, Alessandro Sordoni, Aaron Courville, Siva Reddy",
        "摘要": "摘要：近年来，强化学习（RL）已成为训练进行长链思维（LongCoT）的推理大规模语言模型（LLM）的强有力方法。然而，标准的RL“思维环境”，即状态是提示加上所有先前的推理令牌，使得状态无界，并迫使基于注意力的策略在思考长度增加时需要进行二次计算。我们重新审视了环境本身，提出了马尔科夫思维，这是一种通过在恒定大小状态下推进推理的范例，从而解耦思维长度和上下文大小。作为直接结果，这实现了线性计算并保持恒定内存。我们通过Delethink实例化了这一想法，这是一个将推理结构化为固定大小块的RL环境。在每个块内，模型正常思考；在边界处，环境重置上下文并通过短暂的携带重新初始化提示语。通过RL，策略学习在每个块末端编写一个足够用于重置后无缝继续推理的文本状态。在该环境中训练的R1-Distill 1.5B模型在8K-令牌块中进行推理，但思考可达到24K令牌，匹配或超过使用24K预算训练的LongCoT-RL。在测试时的扩展下，Delethink继续改进，而LongCoT开始停滞。线性计算的影响显著：我们实证估算，在96K平均思考长度时LongCoT-RL需要27个H100-月，而Delethink仅需7个。在RL初始化时的分析显示，即使是现成的推理模型（1.5B-120B）也能够在各种基准测试中零样本地采样马尔科夫轨迹，从而提供有用的样本使RL在规模上有效。我们的结果表明，重新设计思维环境是一种强有力的杠杆：它使非常长的推理成为可能而没有二次计算的开销，并为高效、可扩展的推理LLMs开辟了道路。",
        "地址": "https://arxiv.org/pdf/2510.06557.pdf"
    },
    {
        "名称": "2025 [2510.05862] Revisiting Long-context Modeling from Context Denoising Perspective.pdf",
        "作者": "Zecheng Tang, Baibei Ji, Juntao Li, Lijun Wu, Haijia Gui, Min Zhang",
        "摘要": "摘要: 长上下文模型(LCMs)在处理长序列时表现出巨大潜力，促进了许多现实世界的应用。LCMs的成功在于其能够定位上下文中的隐含关键信息以进行进一步预测。然而，最近的研究表明，LCMs往往易受上下文噪音的影响，即不相关的令牌可能会误导模型注意力。在本文中，我们对上下文噪音进行了细粒度分析，并提出了一个有效的度量指标——积分梯度(IG)评分，以检测和量化上下文中的噪音信息。我们的研究发现，即使简单地减轻检测到的上下文噪音，也能显著提高模型对关键令牌的关注，并有益于后续预测。在此基础上，我们提出了上下文去噪训练(CDT)，这是一种简单而有效的训练策略，能够提高对关键令牌的关注，并增强其对模型预测的影响。我们在四项任务上进行了广泛实验，在上下文窗口缩放和长上下文对齐设置下，证明了CDT的优越性。值得注意的是，当使用CDT进行训练时，一个开源的8B模型可以达到与GPT-4o(51.00)相媲美的性能(50.92)。\n\n作者: Zecheng Tang, Baibei Ji, Juntao Li, Lijun Wu, Haijia Gui, Min Zhang\n链接: https://arxiv.org/pdf/2510.05862.pdf\n标题: 2025 [2510.05862] 从上下文去噪视角重新审视长上下文模型.pdf",
        "地址": "https://arxiv.org/pdf/2510.05862.pdf"
    },
    {
        "名称": "2025 [2510.07238] When Benchmarks Age: Temporal Misalignment through Large Language Model Factuality Evaluation.pdf",
        "作者": "Xunyi Jiang, Dingyi Chang, Julian McAuley, Xin Xu",
        "摘要": "摘要：大型语言模型（LLM）的快速发展和现实世界的演变已经超过了广泛使用的评估基准的静态性质，令人担忧的是这些基准在评估LLM事实性方面的可靠性。尽管大量研究继续依赖流行但陈旧的基准，但它们与现实世界事实和现代LLM的时间错位及其对LLM事实性评估的影响仍未被充分探索。因此，在这项工作中，我们通过检查五个流行的事实性基准和跨不同年份发布的八个LLM，系统地调查了这一问题。针对现有事实检索管道和三项指标进行了调整，以量化基准老化及其对LLM事实性评估的影响。实验结果和分析表明，广泛使用的事实性基准中的相当一部分样本已经过时，导致LLM事实性评估的不可靠。我们希望我们的工作能提供测试平台来评估事实性评估基准的可靠性，并激励更多关于基准老化问题的研究。代码可以在这个网址中获得：https URL。",
        "地址": "https://arxiv.org/pdf/2510.07238.pdf"
    },
    {
        "名称": "2025 [2510.07143] Are We Using the Right Benchmark: An Evaluation Framework for Visual Token Compression Methods.pdf",
        "作者": "Chenfei Liao, Wensong Wang, Zichen Wen, Xu Zheng, Yiyu Wang, Haocong He, Yuanhuiyi Lyu, Lutao Jiang, Xin Zou, Yuqian Fu, Bin Ren, Linfeng Zhang, Xuming Hu",
        "摘要": "摘要: 最近加速多模态大型语言模型（MLLMs）推理的努力主要集中在视觉标记压缩上。这些方法的效果通常通过在既定基准上测量准确性下降来评估，比较压缩前后模型的表现。然而，这些基准原本是为了评估MLLMs感知和推理能力，而不是评估压缩技术。因此直接应用它们来进行视觉标记压缩会引入任务不匹配。令人惊讶的是，我们的研究发现简单的图像降采样在多个广泛使用的基准上始终优于许多高级压缩方法。通过广泛的实验，我们得出以下观察结果：（i）当前基准对于视觉标记压缩任务来说是噪音。（ii）降采样能够作为数据过滤器来评估视觉标记压缩任务中样本的难度。基于这些发现，我们提出了VTC-Bench，这是一种包括数据过滤机制的评估框架，用于消除现有基准的噪音，从而能够更公平和更准确地评估视觉标记压缩方法。所有数据和代码可在此https URL获取。",
        "地址": "https://arxiv.org/pdf/2510.07143.pdf"
    },
    {
        "名称": "2025 [2510.05057] StaMo: Unsupervised Learning of Generalizable Robot Motion from Compact State Representation.pdf",
        "作者": "Mingyu Liu, Jiuhe Shu, Hui Chen, Zeju Li, Canyu Zhao, Jiange Yang, Shenyuan Gao, Hao Chen, Chunhua Shen",
        "摘要": "摘要：在具身智能领域，一个基本挑战是开发高效的状态表示以进行有效的世界建模和决策。然而，现有方法往往在实现这一平衡时失败，导致表示要么过于冗余，要么缺乏任务关键信息。我们提出了一种无监督的方法，使用轻量级编码器和预训练的扩散变换器（DiT）解码器来学习高度压缩的双标记状态表示，利用其强大的生成先验。我们的表示高效、可解释，并无缝集成到现有基于VLA的模型中，在LIBERO上提升了14.3%的性能，在实际任务成功率上提高了30%，且推理开销最小。更重要的是，我们发现通过潜在插值获得的这些标记之间的差异，自然作为一种高度有效的潜在动作，可以进一步解码为可执行的机器人动作。这种新兴能力揭示了我们的表示在没有明确监督的情况下捕捉到结构化动态。我们称这种方法为StaMo，因为它能够从压缩的状态表示中学习到普遍适用的机器人运动，这些状态表示是从静态图像编码而来的，挑战了目前依赖复杂架构和视频数据来学习潜在动作的普遍依赖性。所产生的潜在动作还增强了策略协同训练，比以前的方法提高了10.4%，并且解释性更强。此外，我们的方法在各种数据源上有效扩展，包括实际机器人数据、模拟和人类自中心视频。",
        "地址": "https://arxiv.org/pdf/2510.05057.pdf"
    },
    {
        "名称": "2025 [2510.01954] Patch-as-Decodable-Token: Towards Unified Multi-Modal Vision Tasks in MLLMs.pdf",
        "作者": "Yongyi Su, Haojie Zhang, Shijie Li, Nanqing Liu, Jingyi Liao, Junyi Pan, Yuan Liu, Xiaofen Xing, Chong Sun, Chen Li, Nancy F. Chen, Shuicheng Yan, Xulei Yang, Xun Xu",
        "摘要": "摘要：近年来，多模态大型语言模型(MLLMs)发展迅速。然而，现有的视觉任务方法往往依赖于间接表示，如生成坐标作为检测的文本，这限制了性能并阻碍了密集预测任务，如分割。为克服这些挑战，我们提出了Patch-as-Decodable Token(PaDT)，一种统一的范式，使MLLMs能够直接生成文本和各种视觉输出。PaDT的核心是视觉参考令牌(VRTs)，它们来源于查询图像的视觉补丁嵌入，并与LLM的输出文本令牌无缝交错。一个轻量级解码器将LLM的输出转化为检测、分割和基础预测。与以往的方法不同，PaDT在每次前向传递中独立处理VRTs，并动态扩展嵌入表，从而改善相似对象之间的定位和区分。我们进一步为PaDT制定了一种训练策略，通过随机选择VRTs进行监督微调，并引入每个令牌的交叉熵损失。我们在四个视觉感知和理解任务上的实证研究表明，PaDT始终达到最先进的性能，甚至与显著更大的MLLM模型相比。代码可在此https URL获得。",
        "地址": "https://arxiv.org/pdf/2510.01954.pdf"
    },
    {
        "名称": "2025 [2510.06783] TTRV: Test-Time Reinforcement Learning for Vision Language Models.pdf",
        "作者": "Akshit Singh, Shyam Marjit, Wei Lin, Paul Gavrikov, Serena Yeung-Levy, Hilde Kuehne, Rogerio Feris, Sivan Doveh, James Glass, M. Jehanzeb Mirza",
        "摘要": "摘要: 现有的从强化学习中提取奖励信号的方法通常依赖于标记数据和专门的训练分割，这与人类直接从环境中学习的方式形成鲜明对比。在这项工作中，我们提出了TTRV来增强视觉语言理解，方法是在推理时动态调整模型，不需要任何标记数据。具体来说，我们通过设计基于基础模型输出频率的奖励机制来增强群相对策略优化(GRPO)框架，同时对每个测试样本进行多次推理。此外，我们还通过同时奖励模型获得低输出熵来控制模型输出的多样性。我们的方法在对象识别和视觉问答(VQA)方面均取得了一致的提升，分别提高了最高达52.4%和29.8%，以及平均提升了24.6%和10.0%。在图像识别中，TTRV应用于InternVL 8B在8个基准测试中平均超越GPT-4o 2.3%，同时在VQA方面保持高度竞争力，证明了测试时强化学习可以匹敌或超过最强的专有模型。最后，我们发现了测试时强化学习对视觉语言模型的许多有趣特性：例如，即使在极其数据受限的场景中，只对单个随机选择的无标签测试样本进行适应，TTRV仍然在识别任务中非平凡地提高了最高达5.5%。",
        "地址": "https://arxiv.org/pdf/2510.06783.pdf"
    },
    {
        "名称": "2025 [2510.07313] WristWorld: Generating Wrist-Views via 4D World Models for Robotic Manipulation.pdf",
        "作者": "Zezhong Qian, Xiaowei Chi, Yuming Li, Shizun Wang, Zhiyuan Qin, Xiaozhu Ju, Sirui Han, Shanghang Zhang",
        "摘要": "摘要：腕视观察对于VLA模型至关重要，因为它们捕捉精细的手-物体交互，直接提升操作性能。然而，大规模数据集很少包含这种记录，导致丰富的锚视图与稀缺的腕视图之间存在显著差距。现有的世界模型无法弥合这一差距，因为它们需要一个腕视图的首帧，因此无法仅从锚视图生成腕视图视频。在这种差距中，最近的视觉几何模型如VGGT，通过几何和跨视角先验使得解决极端视角转换变得可能。受到这些见解的启发，我们提出了WristWorld，这是第一个仅从锚视图生成腕视图视频的4D世界模型。WristWorld分两个阶段进行操作：（i）重建阶段，扩展VGGT并结合我们的空间投影一致性（SPC）损失来估算几何一致的腕视图姿态和4D点云；（ii）生成阶段，使用我们的视频生成模型从重建的视角合成时间上连贯的腕视图视频。在Droid、Calvin和Franka Panda上的实验表明，WristWorld实现了最先进的视频生成，具有卓越的空间一致性，同时也提升了VLA性能，使Calvin的平均任务完成长度提高了3.81%，并缩小了42.4%锚-腕视图差距。",
        "地址": "https://arxiv.org/pdf/2510.07313.pdf"
    },
    {
        "名称": "2025 [2510.07307] MLE-Smith: Scaling MLE Tasks with Automated Multi-Agent Pipeline.pdf",
        "作者": "Rushi Qiang, Yuchen Zhuang, Anikait Singh, Percy Liang, Chao Zhang, Sherry Yang, Bo Dai",
        "摘要": "摘要：尽管语言模型（LM）在自动化机器学习工程（MLE）方面取得了显著进展，但高质量MLE训练数据的获取仍然受到极大限制。当前的MLE基准测试由于依赖静态的、手工整理的任务，导致可扩展性低且适用性有限，需要耗费大量时间和手动努力来生产。我们介绍了MLE-Smith，这是一种完全自动化的多代理管道，通过高效的生成-验证-执行范式，将原始数据集转化为竞赛风格的MLE挑战，从而扩展MLE任务的规模，并保证可验证的质量、实际可用性和丰富的多样性。MLE-Smith中的多代理管道推动了结构化任务设计和标准化重构，并结合了一种混合验证机制，强制执行严格的结构规则和高级语义合理性。它进一步通过交互式执行验证经验上的可解性和现实世界的可信度。我们应用MLE-Smith处理了224个现实世界的数据集，并生成了跨多个类别、目标和模态的606个任务，展示了MLE-Smith在各种现实世界数据集上的有效性。对生成任务的评估表明，八个主流和尖端LLM在MLE-Smith任务上的表现与其在精心设计的人类任务上的表现密切相关，突显了MLE-Smith在扩大MLE任务规模的同时保持任务质量的有效性。",
        "地址": "https://arxiv.org/pdf/2510.07307.pdf"
    },
    {
        "名称": "2025 [2510.01982] $\\text{G}^2$RPO: Granular GRPO for Precise Reward in Flow Models.pdf",
        "作者": "Yujie Zhou, Pengyang Ling, Jiazi Bu, Yibin Wang, Yuhang Zang, Jiaqi Wang, Li Niu, Guangtao Zhai",
        "摘要": "摘要：将在线强化学习（RL）集成到扩散和流动模型中，近年来成为将生成模型与人类偏好对齐的一种有前途的方法。在去噪过程中，通过随机微分方程（SDE）进行随机采样，以生成多种去噪方向用于强化学习探索。虽然现有方法能够有效地探索潜在的高价值样本，但由于稀疏和狭窄的奖励信号，它们在偏好对齐方面表现不佳。为了解决这些问题，我们提出了一种新的Granular-GRPO ($\\text{G}^2$RPO )框架，该框架在流动模型的强化学习中实现了对采样方向的精确和全面的奖励评估。具体而言，提出了一种单一随机采样策略，以支持逐步随机探索，同时强制奖励与注入噪声之间的高度相关性，从而对每次SDE扰动实现真实的奖励。同时，为了消除固定粒度去噪固有的偏差，我们引入了一个多粒度优势集成模块，该模块聚合在多个扩散尺度计算的优势，从而产生对采样方向更加全面和鲁棒的评估。对各种奖励模型进行的实验，包括域内和域外评估，表明我们的$\\text{G}^2$RPO显著优于现有基于流动的GRPO基线，突出了其有效性和鲁棒性。",
        "地址": "https://arxiv.org/pdf/2510.01982.pdf"
    },
    {
        "名称": "2025 [2510.06953] Revisiting the Uniform Information Density Hypothesis in LLM Reasoning Traces.pdf",
        "作者": "Minju Gwak, Guijin Son, Jaehyung Kim",
        "摘要": "摘要翻译：\n\n抽象：统一信息密度（UID）假设表明，有效的沟通会保持信息流的稳定。在这项工作中，我们在大语言模型（LLM）推理路径的背景下重新审视这一原则，探讨步骤级别的一致性是否反映推理质量。为此，我们提出了一种基于熵的逐步信息密度指标，并引入了两种互补的一致性度量：局部和全局一致性分数。在六个不同推理基准上的实验显示，步骤级别的一致性不仅提供了强有力的理论视角，还带来了实际性能的提升；例如，选择信息密度更均匀的推理路径能在AIME2025基准上相对于基线提高10-32%的准确率。我们的分析进一步揭示，正确的推理路径通常避免信息密度的急速上升，而错误的路径则表现出不规则的信息爆发。结果表明，受到UID启发的信息密度测量作为推理质量的预测指标优于其他内在信号。这些结果突出了信息密度的一致性作为构建更可靠和更准确的推理系统的强大诊断和选择标准。\n\n作者：Minju Gwak, Guijin Son, Jaehyung Kim\n\nURL：https://arxiv.org/pdf/2510.06953.pdf\n\n标题：2025 [2510.06953] 在LLM推理路径中重新审视统一信息密度假设.pdf",
        "地址": "https://arxiv.org/pdf/2510.06953.pdf"
    },
    {
        "名称": "2025 [2509.24375] Reinforcement Mid-Training.pdf",
        "作者": "Yijun Tian, Shaoyu Chen, Zhichao Xu, Yawei Wang, Jinhe Bi, Peng Han, Wei Wang",
        "摘要": "摘要: 最先进的大型语言模型的发展通常被理解为一个包括预训练和后训练的两阶段过程。我们指出需要一个额外的中间阶段，称为强化中期训练，具有潜在的强大性能提升。在本文中，我们正式定义了这个问题，并确定了三个关键挑战：（1）由于过多的推理步骤导致的低效训练，（2）忽视了不平衡的标记熵分布，（3）对标记信息的利用不足。为了解决这些挑战，我们提出了RMT，一个高效、自适应、统一的强化中期训练框架，具有多种创新组件。特别地，我们首先引入了一个动态标记预算机制，限制不必要的推理步骤并缓解模型过度思考。接下来，我们设计了一种基于课程的自适应采样方法，促进从简单到困难标记的渐进学习轨迹。最后，我们提出了一种结合强化学习和下一个标记预测的双重训练策略，确保对关键标记的有针对性的学习并充分利用所有标记信息。大量实验表明，RMT优于最先进的方法，在语言建模中实现了高达+64.91%的性能提升，仅使用了21%的推理长度。我们还展示了强化中期训练后的检查点可以促进随后的后期训练，在数学领域实现了高达+18.76%的改进。\n\n作者: 田逸君, 陈少宇, 徐志超, 王亚伟, 毕金和, 韩鹏, 王威\n\n链接: https://arxiv.org/pdf/2509.24375.pdf\n\n标题: 2025 [2509.24375] 强化中期训练.pdf",
        "地址": "https://arxiv.org/pdf/2509.24375.pdf"
    },
    {
        "名称": "2025 [2510.06855] Online Generic Event Boundary Detection.pdf",
        "作者": "Hyungrok Jung, Daneul Kim, Seunggyun Lim, Jeany Son, Jonghyun Choi",
        "摘要": "摘要：通用事件边界检测（GEBD）旨在通过人类感知的视角解释长时视频。然而，目前的GEBD方法需要处理完整的视频帧才能做出预测，而不同于人类在线实时处理数据。为了弥合这一差距，我们引入了一项新任务，即在线通用事件边界检测（On-GEBD），旨在即时检测流式视频中通用事件的边界。该任务面临实时识别微妙且无分类标准事件变化的独特挑战，而不能访问未来帧。为了解决这些挑战，我们提出了一种新的On-GEBD框架，即Estimator，受事件分割理论（EST）的启发，该理论解释了人类如何通过利用预测与实际信息之间的差异来将正在进行的活动分割成事件。我们的框架由两个关键组件组成：一致事件预测器（CEA）和在线边界判别器（OBD）。具体来说，CEA仅基于先前帧生成反映当前事件动态的未来帧预测。然后，OBD测量预测误差并通过对过去错误进行统计测试自适应调整阈值，以捕捉多样且微妙的事件转变。实验结果表明，Estimator在Kinetics-GEBD和TAPOS数据集上表现优于所有最近在线视频理解模型的基线，并达到了与之前离线GEBD方法相当的性能。",
        "地址": "https://arxiv.org/pdf/2510.06855.pdf"
    },
    {
        "名称": "2025 [2510.06673] Heptapod: Language Modeling on Visual Signals.pdf",
        "作者": "Yongxin Zhu, Jiawei Chen, Yuanzhe Chen, Zhuo Chen, Dongya Jia, Jian Cong, Xiaobin Zhuang, Yuping Wang, Yuxuan Wang",
        "摘要": "摘要: 我们介绍了Heptapod，这是一种遵循语言建模基本原则的图像自回归模型。Heptapod 采用了因果注意力，消除对CFG的依赖，并且避开了语义标记器的趋势。我们的关键创新是下一步二维分布预测：一个聚焦于重建的视觉标记器的因果Transformer，学习在每个时间步上预测整个二维图像空间网格的分布。这个学习目标将自回归框架的顺序建模与遮掩自编码的整体自监督学习统一起来，使模型能够通过生成训练捕捉全面的图像语义。在ImageNet生成基准测试中，Heptapod达到了2.70的FID，显著超越了之前的因果自回归方法。我们希望我们的工作能够激发对视觉信号及其外更多语言建模的原则性思考。",
        "地址": "https://arxiv.org/pdf/2510.06673.pdf"
    },
    {
        "名称": "2025 [2510.05491] NorMuon: Making Muon more efficient and scalable.pdf",
        "作者": "Zichong Li, Liming Liu, Chen Liang, Weizhu Chen, Tuo Zhao",
        "摘要": "摘要：优化器的选择对大型语言模型（LLMs）的训练效率和计算成本有显著影响。最近，Muon优化器通过对参数更新进行正交化，改善了优化几何结构，显示出潜在前景。尽管Muon已成为Adam的候选接班者，但如何结合两者优势的潜力尚未被系统地研究。在这项工作中，我们提出了NorMuon（Neuron-wise Normalized Muon），一种将正交化和神经元级别自适应学习率相结合的优化器。我们的分析表明，尽管Muon有效减少了条件数，但其更新结果表现出高度不均匀的神经元范数，导致某些神经元在优化过程中占主导地位。NorMuon通过保持每个神经元的二阶动量统计，并在正交化后应用行级规范化，解决了这一不平衡问题，确保了参数的均衡利用，同时保留了Muon的调节优势。为了实现大规模部署，我们开发了一种高效的分布式实现，采用FSDP2框架战略性地在设备间分配正交化计算。跨多个模型规模的实验表明，NorMuon的训练效率 consistently优于Adam和Muon，在1.1 B预训练环境中，比Adam提高了21.74%，比Muon提高了11.31%，同时保持了与Muon相当的内存占用。我们的研究结果表明，正交化和自适应学习率是互补而非竞争的方法，为大型深度学习中的优化器设计开辟了新的途径。",
        "地址": "https://arxiv.org/pdf/2510.05491.pdf"
    },
    {
        "名称": "2025 [2510.04999] Bridging Text and Video Generation: A Survey.pdf",
        "作者": "Nilay Kumar, Priyansh Bhandari, G. Maragatham",
        "摘要": "摘要: 文本到视频（T2V）生成技术有潜力通过从自然语言提示创建连贯的视觉内容，变革教育、营销、娱乐以及为视觉或阅读理解能力受限的个人提供辅助技术等多个领域。自其诞生以来，该领域从对抗模型发展到基于扩散的模型，产生了更高保真度、时间一致性的输出。然而，挑战依然存在，如对齐、长程连贯性和计算效率。为应对这一不断变化的形势，我们对文本到视频生成模型进行了全面综述，追踪其从早期的GANs和VAEs到混合扩散-变压器（DiT）架构的发展，详细说明这些模型如何工作，解决了其前身的哪些限制，以及为何需要转向新的架构范式以克服质量、连贯性和控制方面的挑战。我们系统地介绍了这些被调查的文本到视频模型所训练和评估的数据集，支持可重复性并评估训练这些模型的可访问性，我们详细介绍了它们的训练配置，包括硬件规格、GPU数量、批处理大小、学习率、优化器、训练时期和其他关键超参数。此外，我们还概述了评估这些模型常用的评价指标，并展示了它们在标准基准上的表现，同时讨论了这些指标的局限性和向更整体、感知对齐的评价策略的转变。最后，从我们的分析中我们列出了当前的开放挑战并提出了一些有前景的未来方向， 为未来研究人员在推进T2V研究和应用方面提供了探索和建设的视角。\n\n作者: Nilay Kumar, Priyansh Bhandari, G. Maragatham\n\n链接: https://arxiv.org/pdf/2510.04999.pdf\n\n标题: 2025 [2510.04999] Bridging Text and Video Generation: A Survey",
        "地址": "https://arxiv.org/pdf/2510.04999.pdf"
    },
    {
        "名称": "2025 [2510.06261] AlphaApollo: Orchestrating Foundation Models and Professional Tools into a Self-Evolving System for Deep Agentic Reasoning.pdf",
        "作者": "Zhanke Zhou, Chentao Cao, Xiao Feng, Xuan Li, Zongze Li, Xiangyu Lu, Jiangchao Yao, Weikai Huang, Linrui Xu, Tian Cheng, Guanyu Jiang, Yiming Zheng, Brando Miranda, Tongliang Liu, Sanmi Koyejo, Masashi Sugiyama, Bo Han",
        "摘要": "摘要：我们提出AlphaApollo，一个自我进化的代理推理系统，旨在解决基础模型（FM）推理中的两个瓶颈——有限的模型内在容量和不可靠的测试时迭代。AlphaApollo通过专业工具协调多个模型来实现深思熟虑的、可验证的推理。它结合了（i）一个计算工具（带有数值和符号库的Python）和（ii）一个检索工具（任务相关的外部信息）来执行精确计算并作出决定。该系统通过共享状态地图支持多轮、多模型解决方案进化，该地图记录候选者、可执行检查和迭代改进的反馈。在多个模型的AIME 2024/2025评估中，AlphaApollo表现出一致的增益：Qwen2.5-14B-Instruct的Average@32提高了5.15%，Pass@32提高了23.34%；Llama-3.3-70B-Instruct的Average@32提高了8.91%，Pass@32提高了26.67%。工具使用分析表明，超过80%的工具调用成功执行，始终优于非工具基线，从而提升了FM的能力上限。更多的实证结果和实现细节将更新在这个https URL。\n\n翻译后的摘要：我们提出AlphaApollo，一个自我进化的代理推理系统，旨在解决基础模型推理中的两个瓶颈——有限的模型内在容量和不可靠的测试时迭代。AlphaApollo通过专业工具协调多个模型来实现深思熟虑、可验证的推理。它结合计算工具（带有数值和符号库的Python）和检索工具（任务相关的外部信息）来执行精确计算并作出决策。该系统通过共享状态图支持多轮、多模型解决方案的进化，记录候选者、可执行检查和迭代改进的反馈。在对多个模型的AIME 2024/2025评估中，AlphaApollo表现出一致的增益：Qwen2.5-14B-Instruct的Average@32提高了5.15%，Pass@32提高了23.34%；Llama-3.3-70B-Instruct的Average@32提高了8.91%，Pass@32提高了26.67%。工具使用分析表明，超过80%的工具调用成功执行，一直优于非工具基线，从而提升了基础模型的能力上限。更多的实证结果和实现细节将更新在此URL。",
        "地址": "https://arxiv.org/pdf/2510.06261.pdf"
    },
    {
        "名称": "2025 [2510.07041] U-Bench: A Comprehensive Understanding of U-Net through 100-Variant Benchmarking.pdf",
        "作者": "Fenghe Tang, Chengqi Dong, Wenxin Ma, Zikang Xu, Heqin Zhu, Zihang Jiang, Rongsheng Wang, Yuhao Wang, Chenxu Wu, Shaohua Kevin Zhou",
        "摘要": "摘要: 在过去的十年中，U-Net一直是医学图像分割中的主要架构，导致了数千种U型变体的开发。尽管广泛应用，但由于统计验证不足以及在多样化数据集上的效率和泛化能力的有限考虑，仍然没有一个全面的基准来系统地评估其性能和实用性。为弥补这一差距，我们提出了U-Bench，这是首个大规模、统计严格的基准，评估了100种U-Net变体在28个数据集和10种成像模态上的表现。我们的贡献有三个方面: (1) 综合评估：U-Bench在三个关键维度上评估模型：统计稳健性、零样本泛化能力和计算效率。我们引入了一种新的指标U-Score，它共同捕捉了性能-效率的权衡，提供了一个面向部署的模型进展视角。 (2) 系统分析和模型选择指导：我们总结了大规模评估中的关键发现，并系统地分析了数据集特征和架构范例对模型性能的影响。基于这些见解，我们提出了一个模型顾问代理，用于指导研究人员为特定数据集和任务选择最合适的模型。 (3) 公开可用性：我们提供了所有代码、模型、协议和权重，使社区能够重现我们的结果并用未来的方法扩展基准。总之，U-Bench不仅揭示了以前评估中的不足，还为公平、可重复和实际相关的基准测试奠定了基础，使其成为未来十年中基于U-Net的分割模型的基准项目。该项目可访问: this https URL。代码可用：this https URL。\n\n将代码和项目访问链接替换为实际链接即可完成访问。",
        "地址": "https://arxiv.org/pdf/2510.07041.pdf"
    },
    {
        "名称": "2025 [2510.07037] Beyond Monolingual Assumptions: A Survey of Code-Switched NLP in the Era of Large Language Models.pdf",
        "作者": "Rajvee Sheth, Samridhi Raj Sinha, Mahavir Patil, Himanshu Beniwal, Mayank Singh",
        "摘要": "摘要：语言交替（Code-switching，简称CSW），即在单一话语中交替使用多种语言和文字，是多语言自然语言处理（NLP）中的一个基本挑战，即使在大型语言模型（LLMs）快速发展的今天也是如此。大多数LLM在处理混合语言输入时仍然存在困难，受限于CSW数据集和评估偏差，阻碍了其在多语言社会中的部署。本文综述了首个全面分析CSW感知的LLM研究，回顾了涵盖五个研究领域、12个NLP任务、30多个数据集和80多种语言的308项研究。我们按架构、训练策略和评估方法对最近的进展进行了分类，概述了LLM如何重塑CSW建模以及存在的挑战。文章最后提出了一个注重包容性数据集、公平评估和语言基础模型的路线图，以实现真正的多语言智能。所有资源的精选集合可以在此HTTPS URL中找到。\n\nauthors：Rajvee Sheth，Samridhi Raj Sinha，Mahavir Patil，Himanshu Beniwal，Mayank Singh",
        "地址": "https://arxiv.org/pdf/2510.07037.pdf"
    },
    {
        "名称": "2025 [2510.06607] Code Agent can be an End-to-end System Hacker: Benchmarking Real-world Threats of Computer-use Agent.pdf",
        "作者": "Weidi Luo, Qiming Zhang, Tianyu Lu, Xiaogeng Liu, Bin Hu, Hung-Chun Chiu, Siyuan Ma, Yizhe Zhang, Xusheng Xiao, Yinzhi Cao, Zhen Xiang, Chaowei Xiao",
        "摘要": "摘要:\n计算机使用代理（CUA）框架由大型语言模型（LLMs）或多模态LLMs（MLLMs）提供支持，作为能够感知上下文、推理并直接在软件环境中操作的助手，正在迅速成熟。其最重要的应用之一是操作系统（OS）控制。随着OS领域的CUAs日益嵌入日常操作，有必要考察其在现实世界中的安全影响，特别是CUAs是否可能被滥用于执行真实的、安全相关的攻击。现有工作存在四大主要局限：缺乏关于战术、技术和程序（TTP）的攻击者知识模型、对端到端攻击链的覆盖不完整、没有多主机和加密用户凭据的非现实环境，以及依赖于LLM作为裁判的可靠性不足。为了填补这些空白，我们提出了AdvCUA，这是与MITRE ATT&CK企业矩阵中的真实世界TTPs对齐的第一个基准，包括140个任务，其中包括40个直接恶意任务，74个基于TTP的恶意任务和26个端到端攻击链，通过硬编码评估在多主机环境沙盒中系统地评估CUAs在现实企业操作系统安全威胁下的表现。我们评估了现有的五个主流CUAs，包括ReAct、AutoGPT、Gemini CLI、Cursor CLI和Cursor IDE，基于8个基础LLMs。结果表明，当前先进的CUAs在操作系统安全相关的威胁方面覆盖不足，这些CUAs的能力降低了对定制恶意软件和深度领域专业知识的依赖，使得即便是没有经验的攻击者也能进行复杂的企业入侵，引发了对CUAs责任和安全性的社会关注。\n\n论文标题：\n“2025 [2510.06607] Code Agent can be an End-to-end System Hacker: Benchmarking Real-world Threats of Computer-use Agent”\n\n作者：\nWeidi Luo, Qiming Zhang, Tianyu Lu, Xiaogeng Liu, Bin Hu, Hung-Chun Chiu, Siyuan Ma, Yizhe Zhang, Xusheng Xiao, Yinzhi Cao, Zhen Xiang, Chaowei Xiao\n\n链接：\n[https://arxiv.org/pdf/2510.06607.pdf](https://arxiv.org/pdf/2510.06607.pdf)",
        "地址": "https://arxiv.org/pdf/2510.06607.pdf"
    },
    {
        "名称": "2025 [2509.21842] DeepTravel: An End-to-End Agentic Reinforcement Learning Framework for Autonomous Travel Planning Agents.pdf",
        "作者": "Yansong Ning, Rui Liu, Jun Wang, Kai Chen, Wei Li, Jun Fang, Kan Zheng, Naiqiang Tan, Hao Liu",
        "摘要": "摘要: 旅行规划（TP）代理最近作为一种新兴的构建模块，用于与外部工具和资源交互生成旅行行程，确保愉快的用户体验。尽管其有诸多好处，但现有研究依赖于手工提示和固定的代理工作流程，限制了更灵活和自主的TP代理。本论文提出了DeepTravel，这是一种用于构建自主旅行规划代理的端到端代理强化学习框架，它能够自主规划、执行工具并反省工具响应，以探索、验证和调整多步推理中的中间动作。为实现这一点，我们首先通过缓存交通、住宿和兴趣点数据构建了一个强大的沙盒环境，以便进行TP代理训练，而不受现实世界API限制（例如，不一致的输出）。此外，我们开发了一个分层奖励建模系统，轨迹级验证器首先检查时空可行性并过滤不满意的旅行行程，然后回合级验证器进一步验证行程细节与工具响应的一致性，从而提供高效和精确的奖励服务。最后，我们提出了回复增强的强化学习方法，使TP代理能够定期从失败经验缓冲区重播，展现出显著的代理能力。我们在DiDi企业解决方案应用程序上部署了训练后的TP代理，并进行了全面的在线和离线评估，结果表明DeepTravel使小尺寸LLM（例如，Qwen3 32B）在旅行规划任务中显著优于现有的前沿LLM，例如OpenAI o1、o3和DeepSeek R1。",
        "地址": "https://arxiv.org/pdf/2509.21842.pdf"
    },
    {
        "名称": "2025 [2510.06888] M3Retrieve: Benchmarking Multimodal Retrieval for Medicine.pdf",
        "作者": "Arkadeep Acharya, Akash Ghosh, Pradeepika Verma, Kitsuchart Pasupa, Sriparna Saha, Priti Singh",
        "摘要": "摘要: 随着检索增强生成（RAG）的日益普及，强大的检索模型变得比以往任何时候都更为重要。在医疗保健领域，结合文本和图像信息的多模态检索模型在问答、跨模态检索和多模态摘要等许多下游任务中具有重要优势，因为医疗数据通常包含这两种格式。然而，目前还没有标准的基准来评估这些模型在医疗环境中的性能。为了解决这一空白，我们推出了M3Retrieve，一个多模态医疗检索基准。M3Retrieve跨越5个领域，16个医学领域和4个不同任务，包含超过120万文本文档和16.4万多模态查询，所有数据均在经过批准的许可下收集。我们在这个基准上评估了领先的多模态检索模型，以探索特定于不同医学专业的挑战，并了解它们对检索性能的影响。通过发布M3Retrieve，我们旨在实现系统评估，促进模型创新，并加速研究，朝着构建更强大和可靠的医疗应用多模态检索系统迈进。数据集和基线代码可在此Github页面获得。",
        "地址": "https://arxiv.org/pdf/2510.06888.pdf"
    },
    {
        "名称": "2025 [2510.05891] $\\bf{D^3}$QE: Learning Discrete Distribution Discrepancy-aware Quantization Error for Autoregressive-Generated Image Detection.pdf",
        "作者": "Yanran Zhang, Bingyao Yu, Yu Zheng, Wenzhao Zheng, Yueqi Duan, Lei Chen, Jie Zhou, Jiwen Lu",
        "摘要": "摘要：视觉自回归（AR）模型的出现彻底改变了图像生成，同时为合成图像检测提出了新的挑战。与之前基于GAN或扩散的方法不同，AR模型通过离散符号预测生成图像，在图像生成质量上显著提升，并在其矢量量化表示中展现出独特特征。本文提出利用离散分布差异感知量化误差（D$^3$QE）来检测自回归生成的图像，以利用真实和虚假图像中代码表的独特模式和频率分布偏差。我们引入了一种离散分布差异感知变压器，将动态代码表频率统计集成到注意机制中，融合语义特征和量化误差潜在变量。为了评估我们的方法，我们构建了一个名为ARForensics的综合数据集，涵盖了7种主流视觉AR模型。实验表明，D$^3$QE在不同AR模型上的检测准确率和强泛化性方面表现优越，并在面对现实世界中的扰动时具有鲁棒性。代码可以在\\\\href{this https URL}{this https URL}找到。\n\n翻译完成。",
        "地址": "https://arxiv.org/pdf/2510.05891.pdf"
    },
    {
        "名称": "2025 [2510.05152] A Single Character can Make or Break Your LLM Evals.pdf",
        "作者": "Jingtong Su, Jianyu Zhang, Karen Ullrich, Léon Bottou, Mark Ibrahim",
        "摘要": "摘要: 常见的大型语言模型（LLM）评估依靠示例来引导模型的响应达到期望的风格。虽然使用示例的数量已经过研究和标准化，但如何格式化示例的选择却鲜有探讨。在评估协议和实际使用中，用户面临如何分隔上下文中的示例的选择：使用逗号？换行？分号？井号？等等。令人惊讶的是，我们发现这一看似微小的选择可以显著影响模型响应的质量。在各大领先的模型系列（Llama, Qwen, Gemma）中，例如MMLU的性能可能因选择的分隔符而变化±23%。事实上，通过仅仅改变分隔示例的单个字符，可以操纵模型排名，使任何模型处于领先地位。我们发现LLM的脆弱性贯穿于不同主题、模型系列，并且不会随着规模的扩大而改善。通过探测注意力头分数，我们发现表现良好的分隔符将注意力引导到输入中的关键标记上。最后，我们探索了提高LLM对分隔符选择的鲁棒性的方法。我们发现，在提示中指定选定的分隔符可以提高鲁棒性，并提供了选择最优分隔符的实用建议。\n\n作者: 苏景彤, 张建宇, 卡伦·乌尔里希, 莱昂·博图, 马克·易卜拉欣\n\n链接: https://arxiv.org/pdf/2510.05152.pdf\n\n标题: 单个字符可以决定你的LLM评估成败",
        "地址": "https://arxiv.org/pdf/2510.05152.pdf"
    },
    {
        "名称": "2025 [2510.07550] TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility.pdf",
        "作者": "Saman Motamed, Minghao Chen, Luc Van Gool, Iro Laina",
        "摘要": "摘要：尽管现代视频生成模型在视觉上表现出极高的逼真度，但它们经常会生成违反直观物理法则的序列，例如物体漂浮、瞬移或以不符合因果关系的方式变化。虽然人类能够轻易检测到这些不可信的现象，但目前仍然没有一种稳健的方法来定量评估视频的物理真实性。在这项工作中，我们探讨了视频语言模型（VLMs）是否可以被训练成物理可信性的可靠评判者。我们发现现有的VLMs难以识别物理违规现象，暴露出它们在时间和因果推理方面的根本局限性。为了解决这个问题，我们引入了TRAVL，这是一种结合了平衡训练数据集和轨迹感知注意力模块的微调方法，以改善VLMs的运动编码和辨别能力。为了更严格地评估物理推理，我们提出了ImplausiBench，一个包含300个视频（150个真实，150个生成）的基准，它消除了语言偏见并隔离了视觉-时间理解。我们分别用黄金标准的人类判断和更严格的LLM-as-judge指标报告了性能。TRAVL和ImplausiBench共同提供了一个统一的框架，用于探讨和提高多模态模型的物理可信性，揭示了视觉-时间理解中的一个具有挑战性且未被充分研究的方面。\n\n作者：Saman Motamed, Minghao Chen, Luc Van Gool, Iro Laina\n\n链接：https://arxiv.org/pdf/2510.07550.pdf\n\n标题：2025 [2510.07550] TRAVL: A Recipe for Making Video-Language Models Better Judges of Physics Implausibility.pdf",
        "地址": "https://arxiv.org/pdf/2510.07550.pdf"
    },
    {
        "名称": "2025 [2510.06475] PuzzlePlex: Benchmarking Foundation Models on Reasoning and Planning with Puzzles.pdf",
        "作者": "Yitao Long, Yuru Jiang, Hongjun Liu, Yilun Zhao, Jingchen Sun, Yiqiu Shen, Chen Zhao, Arman Cohan, Dennis Shasha",
        "摘要": "摘要：本研究探讨了基础模型在复杂、动态环境中的推理和规划能力及其可扩展性。我们引入了 PuzzlePlex，这是一个通过多样化的谜题集评估这些能力的基准。PuzzlePlex 包含 15 种类型的谜题，包括不同难度的确定性和随机性游戏，以及单人和双人场景。PuzzlePlex 框架为每个游戏提供了一个综合环境，并支持扩展以生成更具挑战性的实例，随着基础模型的发展。此外，我们实现了定制的游戏策略以进行比较。在此基准基础上，我们开发了细粒度的指标来衡量性能，并对指令和代码两种设置中的前沿基础模型进行了深入分析。此外，我们系统地研究了它们的扩展极限。我们的研究结果表明，在基于指令的设置中，推理模型表现优于其他模型，而基于代码的执行虽然更具挑战性，但提供了一个可扩展且高效的替代方案。PuzzlePlex 允许有针对性的评估，并指导基础模型在推理、规划和泛化方面的未来改进。",
        "地址": "https://arxiv.org/pdf/2510.06475.pdf"
    },
    {
        "名称": "2025 [2510.06426] FinLFQA: Evaluating Attributed Text Generation of LLMs in Financial Long-Form Question Answering.pdf",
        "作者": "Yitao Long, Tiansheng Hu, Yilun Zhao, Arman Cohan, Chen Zhao",
        "摘要": "摘要：大型语言模型（LLMs）在回答长篇问题时经常会产生虚假的、但表面上合理的答案。常见的缓解策略是为LLM输出提供归因。然而，现有的基准主要集中于简单的归因，检索支持文本证据作为参考。我们认为，在金融应用等现实世界场景中，归因不仅仅是参考检索。我们介绍了FinLFQA，这是一个用于评估LLMs在生成具有可靠和细致归因的复杂金融问题长篇答案能力的基准。通过人工注释，FinLFQA评估归因的三个关键方面：（1）从财报中提取支持证据，（2）中间的数值推理步骤，（3）指导推理过程的特定领域金融知识。我们进一步提供了一个覆盖答案质量和归因质量的自动评估框架。通过对多个归因生成范式中的八个LLM进行广泛实验，我们发现细化的指标对于区分模型能力很重要，端到端生成与事后方法实现了相当的性能，并且只有在外部反馈指导时迭代改进才有效。\n\n翻译：\n摘要：大型语言模型（LLMs）在回答长篇问题时经常会产生合理但事实错误的答案。一种常见的缓解策略是为LLM输出提供归因。然而，现有的基准主要集中于简单归因，通过检索支持性文本证据作为参考。我们认为，在现实世界场景中，如金融应用，归因不仅仅是参考检索。我们引入了FinLFQA，一个设计用于评估LLMs为复杂金融问题生成长篇答案的能力，同时提供可靠和细致的归因的基准。FinLFQA通过人工注释评估归因的三个关键方面：（1）从财务报告中提取支持性证据，（2）中间的数值推理步骤，以及（3）指导推理过程的特定领域金融知识。我们进一步提供了一个覆盖回答质量和归因质量的自动评估框架。通过对八个LLM在多种归因生成范式下的广泛实验，我们发现细化指标对于区分模型能力非常重要，端到端生成与事后方法实现了相似的性能，并且迭代改进只有在外部反馈指导时才有帮助。",
        "地址": "https://arxiv.org/pdf/2510.06426.pdf"
    },
    {
        "名称": "2025 [2510.04910] Glocal Information Bottleneck for Time Series Imputation.pdf",
        "作者": "Jie Yang, Kexin Zhang, Guibin Zhang, Philip S. Yu, Kaize Ding",
        "摘要": "摘要：时间序列插补（TSI）旨在恢复时间数据中缺失的值，但由于现实场景中复杂且通常高频率的缺失，这仍然是一个基本挑战。现有模型通常优化逐点重建损失，专注于恢复数值（局部信息）。然而，我们观察到在高缺失率下，这些模型在训练阶段表现良好，但在推理阶段产生较差的插补和扭曲的潜在表示分布（全局信息）。这揭示了一个关键的优化困境：当前目标缺乏全局指导，导致模型过度拟合局部噪声，无法捕获数据的全局信息。为了解决这个问题，我们提出了一种新的训练范式，Glocal信息瓶颈（Glocal-IB）。Glocal-IB是与模型无关的，并通过引入从易处理的互信息近似导出的全局对齐损失来扩展标准IB框架。该损失将掩码输入的潜在表示与其原始观测对应物对齐，帮助模型在抑制缺失值引起的噪声同时保留全局结构和局部细节，从而在高缺失率下更好地泛化。对九个数据集的广泛实验证实了Glocal-IB在缺失情况下持续提高的性能和对齐的潜在表示。我们实现的代码可在此https URL中获得。",
        "地址": "https://arxiv.org/pdf/2510.04910.pdf"
    }
]