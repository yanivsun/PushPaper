[
    {
        "名称": "2025 [2510.19600] Human-Agent Collaborative Paper-to-Page Crafting for Under $0.1.pdf",
        "作者": "Qianli Ma, Siyu Wang, Yilin Chen, Yinhao Tang, Yixiang Yang, Chang Guo, Bingjie Gao, Zhening Xing, Yanan Sun, Zhipeng Zhang",
        "摘要": "摘要：在追求科学进步的过程中，研究的传播与发现本身一样重要。然而，研究人员往往被构建项目网页的手工重复琐事分散了注意力，以便使他们的紧密论文易于访问。尽管自动化已经解决了静态幻灯片和海报的问题，但网页的动态交互性质仍是一个未解决的难题。为了解决这个差距，我们重新定义了问题，认为解决方法不是单一命令，而是协作的层次化过程。我们介绍了$\\\\textbf{AutoPage}$，一个体现这一理念的新颖多代理系统。AutoPage将论文到网页的创建过程分解为从叙述规划到多模态内容生成和交互渲染的粗到细的流水线。为对抗AI幻觉，专门的“检查员”代理对每一步进行核对，以确定符合原论文，同时选定的人工检查点确保最终产品完美符合作者的设想，将该系统从一个简单工具转变为强大的协作助手。为了严格验证我们的方法，我们还构建了$\\\\textbf{PageBench}$，这是这一新任务的首个基准。实验表明，AutoPage不仅生成高质量、视觉上吸引人的页面，而且在不到15分钟内以少于\\\\$0.1的惊人效率完成。代码和数据集将在$\\\\href{this https URL}{网页}$发布。",
        "地址": "https://arxiv.org/pdf/2510.19600.pdf"
    },
    {
        "名称": "2025 [2510.19779] AdaSPEC: Selective Knowledge Distillation for Efficient Speculative Decoders.pdf",
        "作者": "Yuezhou Hu, Jiaxin Guo, Xinyu Feng, Tuo Zhao",
        "摘要": "摘要：投机解码（SD）通过使用小的草稿模型生成预测，并由更大的目标模型验证，从而加速大型语言模型的推理。SD的有效性依赖于这些模型之间的对齐，通常通过知识蒸馏（KD）增强。然而，传统的KD方法旨在最小化草稿模型和目标模型在所有标记上的KL散度，这与SD的真正目标——最大化标记接受率——不一致。因此，由于容量限制，草稿模型往往难以完全吸收目标模型的知识，导致性能不佳。为了解决这一挑战，我们提出了AdaSPEC，一种在KD过程中引入选择性标记过滤的新方法。AdaSPEC利用参考模型识别并过滤难以拟合的标记，从而使草稿模型在简单标记上更好地与目标模型对齐。这种方法在不影响生成质量的情况下提高了整体标记接受率。我们在不同任务上评估了AdaSPEC，包括算术推理、指令跟踪、编码和摘要，使用31M/1.4B和350M/2.7B参数的模型配置。我们的结果表明，AdaSPEC在所有任务中始终优于最先进的DistillSpec方法，标记接受率提高了最多15%。代码可在此HTTPS URL公开获取。\n\n作者：Yuezhou Hu, Jiaxin Guo, Xinyu Feng, Tuo Zhao\n链接：https://arxiv.org/pdf/2510.19779.pdf\n标题：2025 [2510.19779] AdaSPEC：高效投机解码器的选择性知识蒸馏",
        "地址": "https://arxiv.org/pdf/2510.19779.pdf"
    },
    {
        "名称": "2025 [2510.20579] Open-o3 Video: Grounded Video Reasoning with Explicit Spatio-Temporal Evidence.pdf",
        "作者": "Jiahao Meng, Xiangtai Li, Haochen Wang, Yue Tan, Tao Zhang, Lingdong Kong, Yunhai Tong, Anran Wang, Zhiyang Teng, Yujing Wang, Zhuochen Wang",
        "摘要": "摘要: 大多数视频推理模型只生成文本推理线索, 而不指明关键证据何时何地出现。近年来，诸如OpenAI-o3等模型引起了人们对图像证据中心推理的广泛兴趣，但将这种能力扩展到视频中更具挑战性，因为它需要在动态场景中联合时间追踪和空间定位。我们介绍了Open-o3 Video，这是一个非代理框架，将明确的时空证据整合到视频推理中，并 cuidadosamente收集训练数据和设计训练策略以应对上述挑战。模型在回答问题时突出了关键时间戳、对象和边界框，使推理基于具体的视觉观察。为了实现这一功能，我们首先策划并建立了两个高质量的数据集，STGR-CoT-30k用于SFT，STGR-RL-36k用于RL，并精心构建了时间和空间注释，因为现有的大多数数据集仅为视频提供时间跨度或图像上的空间框，缺乏统一的时空监督和推理线索。然后，我们采用冷启动强化学习策略，利用多个特别设计的奖励共同鼓励回答准确性、时间对齐和空间精度。在V-STAR基准上，Open-o3 Video达到最先进的性能，使mAM提高了14.4％，mLGM提高了24.2％，超过了Qwen2.5-VL基准。也在一系列广泛的视频理解基准视频MME, WorldSense, VideoMMMU和TVGBench上观察到了一致的改进。除了准确性之外，Open-o3 Video产生的推理轨迹还为测试时间扩展提供了有价值的信号，提高了答案的可靠性。",
        "地址": "https://arxiv.org/pdf/2510.20579.pdf"
    },
    {
        "名称": "2025 [2510.20822] HoloCine: Holistic Generation of Cinematic Multi-Shot Long Video Narratives.pdf",
        "作者": "Yihao Meng, Hao Ouyang, Yue Yu, Qiuyu Wang, Wen Wang, Ka Leong Cheng, Hanlin Wang, Yixuan Li, Cheng Chen, Yanhong Zeng, Yujun Shen, Huamin Qu",
        "摘要": "摘要：最先进的文本生成视频模型在生成单个片段方面表现出色，但在创建连贯的、多镜头叙事方面却表现不足，而后者是讲故事的精髓所在。我们通过HoloCine模型弥合了这种“叙事鸿沟”，该模型能够整体生成整个场景，以确保从第一个镜头到最后一个镜头的全局一致性。我们的架构通过窗口交叉注意机制实现精确的导演控制，该机制将文本提示定位到特定的镜头，同时稀疏的镜头间自注意模式（镜头内部密集，但镜头之间稀疏）确保了分钟级生成所需的效率。除了在叙事连贯性方面设立了新的技术标准外，HoloCine还开发了出色的新兴能力：对角色和场景的持久记忆，以及对电影技巧的直观把握。我们的工作标志着从片段合成向自动化电影制作的关键转变，使端到端的电影创作成为一个可触及的未来。我们的代码可在以下网址找到：this https URL。",
        "地址": "https://arxiv.org/pdf/2510.20822.pdf"
    },
    {
        "名称": "2025 [2510.19304] Loopholing Discrete Diffusion: Deterministic Bypass of the Sampling Wall.pdf",
        "作者": "Mingyu Jo, Jaesik Yoon, Justin Deschenaux, Caglar Gulcehre, Sungjin Ahn",
        "摘要": "摘要：离散扩散模型通过并行解码提供了一种自回归生成的有希望的替代方案，但它们遭遇到采样壁：一旦发生分类采样，丰富的分布信息就会崩溃为单热向量，无法在步骤之间传播，迫使后续步骤以有限的信息进行操作。为缓解这一问题，我们引入了一种新的简单机制Loopholing，通过确定性的潜在路径保留该信息，形成Loopholing离散扩散模型（LDDMs）。LDDMs通过自我调节策略有效地训练，取得了显著的成效——将生成困惑度降低了多达61%，弥合了与自回归模型的差距（某些情况下甚至超越），并生成更加连贯的文本。应用于推理任务时，LDDMs还在诸如Countdown和24点游戏等算法基准测试中提升了性能。这些结果也表明，Loopholing缓解了空闲步骤和振荡问题，为高质量非自回归文本生成提供了可扩展的路径。\n\n翻译如下：\n离散扩散模型通过并行解码提供了一种有希望的替代自回归生成的方案，但它们遭遇了采样瓶颈：一旦发生分类采样，丰富的分布信息便会崩溃成单热向量，并且无法在步骤之间传播，迫使后续步骤在有限的信息下进行操作。为了缓解这一问题，我们引入了Loopholing，一种通过确定性潜在路径保留这些信息的新颖且简单的机制，从而形成了Loopholing离散扩散模型（LDDMs）。通过自我调节策略高效地训练，LDDMs获得了显著的收益--将生成困惑度降低了多达61%，弥合了与自回归模型的差距（在某些情况下甚至超越），并生成了更连贯的文本。应用于推理任务时，LDDMs在像Countdown和24游戏这样的算法基准上也提高了性能。这些结果还表明，Loopholing减轻了空闲步骤和振荡问题，为高质量非自回归文本生成提供了一条可扩展的路径。",
        "地址": "https://arxiv.org/pdf/2510.19304.pdf"
    },
    {
        "名称": "2025 [2510.20766] DyPE: Dynamic Position Extrapolation for Ultra High Resolution Diffusion.pdf",
        "作者": "Noam Issachar, Guy Yariv, Sagie Benaim, Yossi Adi, Dani Lischinski, Raanan Fattal",
        "摘要": "摘要:扩散Transformer模型能够生成具有惊人保真度和细节的图像，但由于自注意机制随着图像令牌数量的二次扩展，在超高分辨率下训练这些模型仍然极其昂贵。在本文中，我们介绍了动态位置外推（DyPE），这是一种新颖的、无需训练的方法，使预训练的扩散Transformer能够在没有额外采样成本的情况下合成远超训练数据分辨率的图像。DyPE利用扩散过程中的频谱进展特性，低频结构早期收敛，而高频结构需要更多步骤才能解决。具体来说，DyPE在每个扩散步骤动态调整模型的位置编码，使其频谱与当前生成过程阶段相匹配。此方法使我们能够生成分辨率极大超出训练分辨率的图像，例如使用FLUX生成1600万像素的图像。在多个基准测试中，DyPE持续提高性能，并在超高分辨率图像生成方面实现最先进的保真度，且分辨率越高，增益越显著。项目页面可通过此URL访问。",
        "地址": "https://arxiv.org/pdf/2510.20766.pdf"
    },
    {
        "名称": "2025 [2510.19365] The Massive Legal Embedding Benchmark (MLEB).pdf",
        "作者": "Umar Butler, Abdur-Rahman Butler, Adrian Lucas Malec",
        "摘要": "摘要翻译如下：\n\n我们介绍了大规模法律嵌入基准 (MLEB)，这是迄今为止最大的、最具多样性和最全面的开源法律信息检索基准。MLEB由十个专家注释的数据集组成，涵盖多个司法管辖区（美国、英国、欧盟、澳大利亚、爱尔兰和新加坡）、文件类型（案件、立法、监管指南、合同和文献）和任务类型（搜索、零样本分类和问答）。为了填补开源法律信息检索领域在领域和司法管辖区的空白，我们新构建了其中的七个数据集。我们记录了构建MLEB和创建新组成数据集的方法，并公开发布我们的代码、结果和数据，以协助可重复的评估。",
        "地址": "https://arxiv.org/pdf/2510.19365.pdf"
    },
    {
        "名称": "2025 [2510.20187] Every Question Has Its Own Value: Reinforcement Learning with Explicit Human Values.pdf",
        "作者": "Dian Yu, Yulai Zhao, Kishan Panaganti, Linfeng Song, Haitao Mi, Dong Yu",
        "摘要": "摘要： 我们提出了带有明确人类价值的强化学习（RLEV）方法，这种方法通过可量化的人类价值信号直接优化大型语言模型（LLM）。尽管带有可验证奖励的强化学习（RLVR）能有效在客观领域通过二元正确性奖励来训练模型，但它忽略了并非所有任务具有同等重要性。RLEV通过将人类定义的价值信号直接融入奖励函数，扩展了这一框架。使用具有明确真实价值标签的考试风格数据，RLEV在多个强化学习算法和模型规模中，一直优于仅注重正确性的基线方法。关键的是，RLEV策略不仅提高了按价值加权的准确性，还学会了一种价值敏感的终止策略：对于低价值的提示迅速结束，对于高价值的提示则更加详尽。我们证明，这种行为源自对序列结束标记的价值加权梯度放大。消融研究验证了增益与价值对齐有因果关系。在嘈杂的价值信号（如基于难度的标签）下，RLEV仍然保持稳健，表明优化明确效用函数为使LLM符合人类优先事项提供了切实可行的途径。",
        "地址": "https://arxiv.org/pdf/2510.20187.pdf"
    },
    {
        "名称": "2025 [2510.16917] SAKE: Towards Editing Auditory Attribute Knowledge of Large Audio-Language Models.pdf",
        "作者": "Chih-Kai Yang, Yen-Ting Piao, Tzu-Wen Hsu, Szu-Wei Fu, Zhehuai Chen, Ke-Han Lu, Sung-Feng Huang, Chao-Han Huck Yang, Yu-Chiang Frank Wang, Yun-Nung Chen, Hung-yi Lee",
        "摘要": "摘要：知识编辑提供了一种无需完全重新训练即可更新模型知识的有效方法，但之前的工作几乎完全集中在文本或视觉模态上。我们推出了SAKE，这是第一个专门设计用于编辑大型音频-语言模型（LALMs）中的听觉属性知识的基准。与事实更新不同，SAKE针对多个抽象的听觉属性，捕捉了超越传统文本和视觉领域的知识类型。我们在两个LALMs上对七种编辑方法进行了四个维度的基准测试：可靠性、通用性、音频/文本局部性和可移植性。结果突显了诸如保留与编辑无关的内部属性知识、将编辑推广到多模态推理、在连续更新下保持编辑等挑战。SAKE提供了一个系统化的框架，研究知识编辑如何扩展到听觉模态，开辟了在更多样化的真实世界场景中维护和适应LALMs的新方向。",
        "地址": "https://arxiv.org/pdf/2510.16917.pdf"
    },
    {
        "名称": "2025 [2510.16893] Investigating Safety Vulnerabilities of Large Audio-Language Models Under Speaker Emotional Variations.pdf",
        "作者": "Bo-Han Feng, Chien-Feng Liu, Yu-Hsuan Li Liang, Chih-Kai Yang, Szu-Wei Fu, Zhehuai Chen, Ke-Han Lu, Sung-Feng Huang, Chao-Han Huck Yang, Yu-Chiang Frank Wang, Yun-Nung Chen, Hung-yi Lee",
        "摘要": "摘要：大型音频语言模型（LALMs）通过扩展文本的LLMs（语言模型）实现对听觉的理解，为多模态应用提供了新的机会。尽管它们的感知、推理和任务表现受到广泛研究，但在副语言变化下的安全性对齐仍未被充分探索。这项工作系统地研究了说话人情绪的作用。我们构建了一个跨多种情绪和强度表达的恶意语音指令数据集，并评估了几种最先进的LALMs。我们的结果揭示了显著的安全一致性问题：不同情绪引发了不同程度的不安全反应，并且强度的影响是非单调的，中等表达通常构成最大的风险。这些发现突显了LALMs中一个被忽视的漏洞，并呼吁专门设计的对齐策略，以确保在情绪变化下的鲁棒性，这是在现实世界中可信部署的先决条件。",
        "地址": "https://arxiv.org/pdf/2510.16893.pdf"
    },
    {
        "名称": "2025 [2510.20733] Thought Communication in Multiagent Collaboration.pdf",
        "作者": "Yujia Zheng, Zhuokai Zhao, Zijian Li, Yaqi Xie, Mingze Gao, Lizhu Zhang, Kun Zhang",
        "摘要": "摘要：自然语言长久以来使人类合作成为可能，但其有损性、模糊性和间接性限制了集体智能的潜力。尽管机器不受这些限制，大多数基于大型语言模型（LLM）的多代理系统仍仅依赖自然语言，交换标记或其嵌入表示。为了超越语言，我们引入了一种新的范式，思想交流，使代理能够直接进行心灵间的互动，类似于心灵感应。为了以一种有原则的方法揭示这些潜在思想，我们将这个过程形式化为一个通用的潜变量模型，其中代理状态由潜在思想的未知函数生成。我们证明，在非参数设定下，没有辅助信息的情况下，任何一对代理之间的共享和私有潜在思想都可以被识别。此外，思想共享的全球结构，包括哪些代理共享哪些思想以及这些关系如何构建，也可以在理论保证下恢复。在已有理论的指导下，我们开发了一个框架，在通信之前从所有代理中提取潜在思想，并为每个代理分配相关思想及其共享模式。这种范式自然而然地扩展到所有模态，因为大多数观测数据都源于隐含生成过程。基于合成和真实世界基准的实验验证了该理论，并展示了思想交流的合作优势。我们希望这项工作揭示利用隐藏世界的潜力，因为通过表面观察无法解决的许多挑战仍然存在，不论计算能力或数据规模如何。",
        "地址": "https://arxiv.org/pdf/2510.20733.pdf"
    },
    {
        "名称": "2025 [2510.19944] Seed3D 1.0: From Images to High-Fidelity Simulation-Ready 3D Assets.pdf",
        "作者": "Jiashi Feng, Xiu Li, Jing Lin, Jiahang Liu, Gaohong Liu, Weiqiang Lou, Su Ma, Guang Shi, Qinlong Wang, Jun Wang, Zhongcong Xu, Xuanyu Yi, Zihao Yu, Jianfeng Zhang, Yifan Zhu, Rui Chen, Jinxin Chi, Zixian Du, Li Han, Lixin Huang, Kaihua Jiang, Yuhan Li, Guan Luo, Shuguang Wang, Qianyi Wu, Fan Yang, Junyang Zhang, Xuanmeng Zhang",
        "摘要": "摘要：开发具有实体感知的人工智能代理需要可扩展的训练环境，这些环境需要在内容多样性与物理准确性之间取得平衡。世界模拟器提供了这样的环境，但面临一些独特的限制：基于视频的方法可以生成多样化的内容，但缺乏用于互动学习的实时物理反馈；而基于物理的引擎虽然提供了准确的动态表现，但由于昂贵的人工资产创建而面临可扩展性上的限制。我们推出了Seed3D 1.0，一个能够从单张图像生成可用于模拟的3D资产的基础模型，它解决了可扩展性挑战，同时保持了物理严谨性。与现有的3D生成模型不同，我们的系统能生成具有精确几何形状、纹理对齐以及真实物理材质的资产。这些资产可以直接集成到物理引擎中，几乎不需要配置，从而能够用于机器人操作和模拟训练。除了单独的物体，该系统还能通过将物体组装成一致的环境来扩展到完整的场景生成。通过实现可扩展的模拟就绪内容创建，Seed3D 1.0为推进基于物理的世界模拟器提供了基础。Seed3D 1.0现在可通过此 https URL 访问。\n\n翻译后的摘要：\n开发具有实体感知的人工智能代理需要可扩展的训练环境，这些环境需要在内容多样性与物理准确性之间取得平衡。世界模拟器提供了这样的环境，但面临一些独特的限制：基于视频的方法可以生成多样化的内容，但缺乏用于互动学习的实时物理反馈；而基于物理的引擎虽然提供了准确的动态表现，但由于昂贵的人工资产创建而面临可扩展性上的限制。我们推出了Seed3D 1.0，一个能够从单张图像生成可用于模拟的3D资产的基础模型，它解决了可扩展性挑战，同时保持了物理严谨性。与现有的3D生成模型不同，我们的系统能生成具有精确几何形状、纹理对齐以及真实物理材质的资产。这些资产可以直接集成到物理引擎中，几乎不需要配置，从而能够用于机器人操作和模拟训练。除了单独的物体，该系统还能通过将物体组装成一致的环境来扩展到完整的场景生成。通过实现可扩展的模拟就绪内容创建，Seed3D 1.0为推进基于物理的世界模拟器提供了基础。Seed3D 1.0现在可通过此网址访问。",
        "地址": "https://arxiv.org/pdf/2510.19944.pdf"
    },
    {
        "名称": "2025 [2510.18821] Search Self-play: Pushing the Frontier of Agent Capability without Supervision.pdf",
        "作者": "Hongliang Lu, Yuhang Wen, Pengyu Cheng, Ruijin Ding, Haotian Xu, Jiaqi Guo, Chutian Wang, Haonan Chen, Xiaoxi Jiang, Guanjun Jiang",
        "摘要": "以下是摘要的中文翻译：\n\n摘要: 具有可验证奖励的强化学习（RLVR）已成为训练LLM代理的主流技术。然而，RLVR高度依赖精心设计的任务查询和相应的真实答案，以提供准确的奖励，这需要大量的人力工作并阻碍RL扩展过程，特别是在代理场景下。尽管最近有一些研究探索任务合成方法，但生成的代理任务的难度难以控制，无法提供有效的RL训练优势。为了实现具有更高可扩展性的代理RLVR，我们探索了深度搜索代理的自我对弈训练，其中学习的LLM利用多轮搜索引擎调用同时担任任务提出者和问题解决者。任务提出者旨在生成具有明确真实答案和增加任务难度的深度搜索查询。问题解决者尝试处理生成的搜索查询并输出正确的答案预测。为了确保每个生成的搜索查询都有准确的真实答案，我们收集了提出者轨迹中的所有搜索结果作为外部知识，然后进行检索增强生成（RAG），以测试所提出的查询是否可以在提供所有必要的搜索文档的情况下正确回答。在这个搜索自我对弈（SSP）游戏中，提出者和解决者通过竞争和合作共同进化它们的代理能力。通过大量实验结果，我们发现SSP可以在多种基准测试中显著提高搜索代理的性能，并且在从头开始和连续的RL训练设置下均不需要监督。代码位于这个https网址。",
        "地址": "https://arxiv.org/pdf/2510.18821.pdf"
    },
    {
        "名称": "2025 [2510.20820] LayerComposer: Interactive Personalized T2I via Spatially-Aware Layered Canvas.pdf",
        "作者": "Guocheng Gordon Qian, Ruihang Zhang, Tsai-Shien Chen, Yusuf Dalva, Anujraaj Argo Goyal, Willi Menapace, Ivan Skorokhodov, Meng Dong, Arpit Sahni, Daniil Ostashev, Ju Hu, Sergey Tulyakov, Kuan-Chieh Jackson Wang",
        "摘要": "摘要：尽管现有的个性化生成模型在视觉保真度方面表现出色，但它们缺乏对空间组合的互动控制，并且在处理多个对象时表现出较差的扩展性。为了解决这些限制，我们提出了LayerComposer，一个用于个性化、多主体文字生成图像的互动框架。我们的方法引入了两个主要贡献：（1）分层画布，这是一种新的表示形式，其中每个主体都被放置在一个不同的层上，从而实现无遮挡的组合；（2）锁定机制，能够在高保真度地保持选定层的同时，允许其余层灵活地适应周围环境。类似于专业图像编辑软件，提出的分层画布允许用户通过直观的层操作来放置、调整大小或锁定输入主体。我们多功能的锁定机制不需要架构上的变化，而是依赖于固有的位置嵌入结合一种新的补充数据采样策略。大量实验证明，LayerComposer在多主体个性化图像生成中比现有的最先进方法实现了更优越的空间控制和身份保护。\n\n作者：郭成 Gordon Qian, 张睿航, 陈才轩, 约瑟夫·达尔瓦, 阿努杰拉·阿尔戈·戈亚尔, 威利·美纳佩斯, 伊万·斯克罗霍多夫, 董猛, 阿皮特·萨尼, 丹尼尔·奥斯塔谢夫, 胡菊, 谢尔盖·图利亚科夫, 王宽捷 Jackson Wang\n\n评论：9页，预印本\n\n链接：https://arxiv.org/pdf/2510.20820.pdf\n\n标题：LayerComposer: 通过空间感知分层画布进行互动个性化文字生成图像（2025 [2510.20820]）",
        "地址": "https://arxiv.org/pdf/2510.20820.pdf"
    },
    {
        "名称": "2025 [2510.20470] Conan: Progressive Learning to Reason Like a Detective over Multi-Scale Visual Evidence.pdf",
        "作者": "Kun Ouyang, Yuanxin Liu, Linli Yao, Yishuo Cai, Hao Zhou, Jie Zhou, Fandong Meng, Xu Sun",
        "摘要": "摘要：视频推理，需要跨帧的多步演绎，仍然是多模态大型语言模型（MLLMs）的一大挑战。虽然基于强化学习（RL）的方法可以增强推理能力，但它们通常依赖文本链，导致结论不扎实或幻觉。相反，帧检索方法引入了视觉基础，但仍难以准确定位证据。为了解决这些挑战，我们提出了Conan，一个基于证据的多步视频推理框架。Conan识别上下文和证据帧，推理跨帧线索，并自适应地决定何时结束或进一步探索。为实现这一目标，我们（1）构建了Conan-91K，一个包含帧识别、证据推理和行动决策的大规模自动生成推理轨迹数据集，以及（2）设计了多阶段渐进冷启动策略，结合识别-推理-行动（AIR）RLVR训练框架共同增强多步视觉推理。在六个多步推理基准测试中，大量实验表明，Conan在准确性上平均超过基线Qwen2.5-VL-7B-Instruct 10%以上，达到了最先进的性能。此外，Conan在长视频理解任务中有效地进行了广泛验证，证明其强大的可扩展性和鲁棒性。",
        "地址": "https://arxiv.org/pdf/2510.20470.pdf"
    },
    {
        "名称": "2025 [2510.12487] Diff-XYZ: A Benchmark for Evaluating Diff Understanding.pdf",
        "作者": "Evgeniy Glukhov, Michele Conti, Egor Bogomolov, Yaroslav Golubev, Alexander Bezzubov",
        "摘要": "摘要：可靠处理代码差异对大规模编辑和重构存储库的代理来说至关重要。我们引入了Diff-XYZ，这是一个紧凑的代码差异理解基准，包括三个监督任务：应用（旧代码 + 差异 → 新代码）、反应用（新代码 - 差异 → 旧代码）和差异生成（新代码 - 旧代码 → 差异）。基准中的实例是从CommitPackFT的实际提交中抽取的三元组〈旧代码，新代码，差异〉，配有自动指标和明确的评估协议。我们利用该基准对统一差异格式进行了集中实证研究，并进行了不同差异表示方法的跨格式比较。我们的研究结果揭示了根据用例和模型大小应使用不同的格式。例如，在差异生成场景中，使用搜索替换格式表示差异对较大的模型较好，但不适用于差异分析和较小模型。Diff-XYZ基准是评估和改进LLM处理差异的可重用基础，有助于未来开发差异格式和代码编辑模型。该数据集已发布在HuggingFace Hub上：this https URL。",
        "地址": "https://arxiv.org/pdf/2510.12487.pdf"
    },
    {
        "名称": "2025 [2510.20803] ARGenSeg: Image Segmentation with Autoregressive Image Generation Model.pdf",
        "作者": "Xiaolong Wang, Lixiang Ru, Ziyuan Huang, Kaixiang Ji, Dandan Zheng, Jingdong Chen, Jun Zhou",
        "摘要": "摘要：我们提出了一种新颖的基于自回归生成的图像分割范式（ARGenSeg），在统一框架内实现多模态理解和像素级感知。以往将图像分割集成到多模态大语言模型（MLLMs）中的工作通常使用边界点表示或专用分割头。这些方法依赖于离散表示或语义提示输入特定任务解码器，限制了MLLM捕捉细粒度视觉细节的能力。为了解决这些挑战，我们引入了一种基于图像生成的MLLM分割框架，该框架自然地产生目标对象的密集掩码。我们利用MLLM输出视觉标记，并使用通用VQ-VAE将其解码为图像，使分割完全依赖于MLLM的像素级理解。为减少推理延迟，我们采用了下一尺度预测策略并行生成所需的视觉标记。广泛的实验表明，我们的方法在多个分割数据集上超过了先前的最先进方法，在推理速度上显著提升的同时保持了强大的理解能力。",
        "地址": "https://arxiv.org/pdf/2510.20803.pdf"
    },
    {
        "名称": "2025 [2510.20771] AlphaFlow: Understanding and Improving MeanFlow Models.pdf",
        "作者": "Huijie Zhang, Aliaksandr Siarohin, Willi Menapace, Michael Vasilkovsky, Sergey Tulyakov, Qing Qu, Ivan Skorokhodov",
        "摘要": "摘要：MeanFlow最近作为一种几步生成建模的强大框架出现，从头开始训练，但其成功原因尚未完全理解。在这项工作中，我们表明MeanFlow目标自然分解为两部分：轨迹流匹配和轨迹一致性。通过梯度分析，我们发现这些项强烈负相关，导致优化冲突和收敛缓慢。受这些见解的启发，我们引入了 $\\alpha$-Flow，一个统一了轨迹流匹配、Shortcut Model和MeanFlow的广泛目标家族。通过采用从轨迹流匹配平滑退火到MeanFlow的课程策略，$\\alpha$-Flow解开了冲突的目标，并实现了更好的收敛。在使用vanilla DiT框架从零开始训练在类条件ImageNet-1K 256x256上时，$\\alpha$-Flow在各个规模和设置下始终优于MeanFlow。我们最大的$\\alpha$-Flow-XL/2+模型使用vanilla DiT框架实现了新的最先进结果，FID分数分别为2.58（1-NFE）和2.15（2-NFE）。",
        "地址": "https://arxiv.org/pdf/2510.20771.pdf"
    },
    {
        "名称": "2025 [2510.20270] ImpossibleBench: Measuring LLMs' Propensity of Exploiting Test Cases.pdf",
        "作者": "Ziqian Zhong, Aditi Raghunathan, Nicholas Carlini",
        "摘要": "摘要: 为完成任务而寻找和利用“捷径”的倾向对大型语言模型（LLMs）的可靠评估和部署构成了重大风险。例如，具备单元测试访问权限的LLM代理可能会删除失败的测试，而不是修复潜在的错误。这种行为不仅破坏了基准测试结果的有效性，还破坏了现实世界中LLM编码助手部署的可靠性。为了量化、研究和减少这种行为，我们引入了ImpossibleBench，一个系统化测量LLM代理利用测试案例倾向的基准框架。ImpossibleBench通过在自然语言规范和单元测试之间引入直接冲突，从现有基准如LiveCodeBench和SWE-bench创建“不可完成”的任务变体。我们将代理在这些不可完成任务上的通过率定义为“作弊率”，任何通过都必然意味着违反规范的捷径。作为一个实用框架，ImpossibleBench不仅是评估工具，也是一个多功能工具。我们展示了它在以下方面的应用：(1)研究模型行为，揭示从简单测试修改到复杂运算符重载的细粒度作弊行为；(2)上下文工程，展示提示、测试访问和反馈回路如何影响作弊率；(3)开发监控工具，提供一个具有已验证欺骗解决方案的测试平台。我们希望ImpossibleBench成为构建更强大可靠的LLM系统的有用框架。我们的实现可以在此URL找到。\n\n作者: 种子强（Ziqian Zhong）、阿迪提·拉古纳森（Aditi Raghunathan）、尼古拉斯·卡尔尼（Nicholas Carlini）\n\n链接: https://arxiv.org/pdf/2510.20270.pdf\n\n标题: 2025年 [2510.20270] ImpossibleBench: 测量LLM对测试案例的利用倾向.pdf",
        "地址": "https://arxiv.org/pdf/2510.20270.pdf"
    },
    {
        "名称": "2025 [2510.20668] From Masks to Worlds: A Hitchhiker's Guide to World Models.pdf",
        "作者": "Jinbin Bai, Yu Lei, Hecong Wu, Yuchen Zhu, Shufan Li, Yi Xin, Xiangtai Li, Molei Tao, Aditya Grover, Ming-Hsuan Yang",
        "摘要": "摘要：本文并非典型的世界模型综述，而是为那些想要构建世界模型的人提供的指南。我们并不打算列出所有曾提及“世界模型”的论文，而是遵循一条清晰的路线：从早期统一跨模态表示学习的掩码模型，到共享单一范式的统一架构，再到闭合行动和感知环路的交互生成模型，最后到能够在时间上保持一致性的记忆增强系统。我们绕过松散相关的分支，专注于核心内容：生成的核心、交互的循环和记忆系统。我们展示了这是通往真正世界模型的最有前景的路径。\n\n—— Jinbin Bai, Yu Lei, Hecong Wu, Yuchen Zhu, Shufan Li, Yi Xin, Xiangtai Li, Molei Tao, Aditya Grover, Ming-Hsuan Yang",
        "地址": "https://arxiv.org/pdf/2510.20668.pdf"
    },
    {
        "名称": "2025 [2510.17853] CiteGuard: Faithful Citation Attribution for LLMs via Retrieval-Augmented Validation.pdf",
        "作者": "Yee Man Choi, Xuehang Guo, Yi R. (May)Fung, Qingyun Wang",
        "摘要": "摘要：大型语言模型（LLMs）作为科学写作的有力助手已经崭露头角。然而，有关生成文本的质量和可靠性的问题也随之而来，其中之一是引用的准确性和可信度。尽管最近的大部分工作依赖于诸如LLM-as-a-Judge之类的方法，但单靠LLM-as-a-Judge的可靠性也受到质疑。在这项工作中，我们将引用评估重新定义为引用归因一致性问题，即评估LLM生成的引用是否与人类作者为相同文本所包含的引用相匹配。我们提出了CiteGuard，这是一种检索感知代理框架，旨在为引用验证提供更加可靠的依据。CiteGuard将先前的基线提高了12.3%，在CiteME基准测试中达到了65.4%的准确率，与人类水平的表现（69.7%）相当。它还能够识别出替代但有效的引用。\n\n标题：CiteGuard：通过检索增强的验证实现LLMs的可靠引用归因\n作者：Yee Man Choi, Xuehang Guo, Yi R. (May)Fung, Qingyun Wang\n年份：2025\n链接：https://arxiv.org/pdf/2510.17853.pdf",
        "地址": "https://arxiv.org/pdf/2510.17853.pdf"
    },
    {
        "名称": "2025 [2510.19423] MSC-Bench: A Rigorous Benchmark for Multi-Server Tool Orchestration.pdf",
        "作者": "Jia-Kai Dong, I-Wei Huang, Chun-Tin Wu, Yi-Tien Tsai",
        "摘要": "摘要:我们引入了MSC-Bench，这是一个用于评估多跳、端到端工具编排的LLM代理的大规模基准测试，置于分层模型-上下文协议(MCP)生态系统中。现有的基准测试常常孤立地评估工具，忽视了功能重叠和跨服务器编排等挑战，导致过于乐观的评估。MSC-Bench通过构建“等功能集”的真实情况解决了这些空白，允许使用客观指标如F1分数，减少对LLM作为评判的依赖。该基准测试按五级课程组织，系统地测试代理从单一工具编排到复杂的跨服务器计划、以及对超范围请求的鲁棒性。实验表明，僵硬的层级体系在没有共同设计策略时会阻碍性能发挥，甚至最先进的代理在鲁棒性方面也表现出系统性弱点。MSC-Bench提供了一个诊断框架来揭示这些局限性，并指导开发更高效的工具使用代理。该基准测试和资源可通过以下https URL公开获取。\n\n作者: 董家凯、黄一纬、吴俊霆、蔡宜恬\n\n评论: ACL Rolling Review 2025 审稿中\n\nURL: https://arxiv.org/pdf/2510.19423.pdf\n\n标题: 2025 [2510.19423] MSC-Bench: 多服务器工具编排的严格基准测试.pdf",
        "地址": "https://arxiv.org/pdf/2510.19423.pdf"
    },
    {
        "名称": "2025 [2510.18245] Scaling Laws Meet Model Architecture: Toward Inference-Efficient LLMs.pdf",
        "作者": "Song Bian, Tao Yu, Shivaram Venkataraman, Youngsuk Park",
        "摘要": "摘要：扩展参数数量和训练数据规模已被证明是提高大型语言模型(LLM)性能的有效策略。然而，随着这些模型变得越来越强大并广泛部署，推理成本已成为一个紧迫的问题。尽管其重要性，模型准确性与推理效率之间的权衡仍未得到充分研究。在这项工作中，我们考察了关键的架构因素——隐藏层大小、参数在MLP和注意力之间的分配（mlp-to-attention ratio）以及分组查询注意力(GQA)——如何影响推理成本和准确性。我们引入了一种条件缩放法则，在Chinchilla框架中加入架构信息，并提出了一个搜索框架，用于识别同时具有推理效率和准确性的架构。为了验证我们的方法，我们训练了超过200个模型，参数范围从80M到3B，训练数据范围从8B到100B，并拟合了所提出的条件缩放法则。我们的结果表明，条件缩放法则可靠地预测了最佳架构选择，且所得到的模型优于现有的开源基准。在相同的训练预算下，优化后的架构相比于LLaMA-3.2，准确性提高了2.1%，推理吞吐量提高了42%。",
        "地址": "https://arxiv.org/pdf/2510.18245.pdf"
    },
    {
        "名称": "2025 [2510.20362] ComProScanner: A multi-agent based framework for composition-property structured data extraction from scientific literature.pdf",
        "作者": "Aritra Roy, Enrico Grisan, John Buckeridge, Chiara Gattinoni",
        "摘要": "摘要：自从各种预训练的大型语言模型问世以来，从科学文本中提取结构化知识与传统的机器学习或自然语言处理技术相比，经历了一场革命性的变化。尽管有这些进步，但可以让用户从科学文献提取中构建、验证和可视化数据集的易于使用的自动化工具仍然稀缺。因此，我们开发了ComProScanner，这个平台是一个自主的多代理平台，可促进机器可读的化学成分和性质的提取、验证、分类和可视化，并整合期刊文章中的合成数据，以创建综合数据库。我们使用100篇期刊文章和包括开源和专有模型在内的10种不同的大型语言模型，评估了我们的框架，以提取与陶瓷压电材料及其对应的压电应变系数(d33)相关的高度复杂的组成物，针对这种材料的大型数据集匮乏的问题。DeepSeek-V3-0324在所有模型中表现最佳，总体准确率显著达到了0.82。该框架提供了一个简单、用户友好且易于使用的软件包，用于从文献中提取埋藏的高度复杂的实验数据，以构建机器学习或深度学习数据集。",
        "地址": "https://arxiv.org/pdf/2510.20362.pdf"
    },
    {
        "名称": "2025 [2510.19995] Communication to Completion: Modeling Collaborative Workflows with Intelligent Multi-Agent Communication.pdf",
        "作者": "Yiming Lu, Xun Wang, Simin Ma, Shujian Liu, Sathish Reddy Indurthi, Song Wang, Haoyun Deng, Fei Liu, Kaiqiang Song",
        "摘要": "摘要: 工作空间中的复杂任务的团队合作需要多种沟通策略，但现有的多代理语言模型系统缺乏系统化的面向任务的沟通框架。我们引入了从沟通到完成(C2C)的可扩展框架，通过两个关键创新来解决这一差距：(1)对齐因子(AF)，一种新颖的度量，用于量化代理任务对齐程度，直接影响工作效率；(2)序列行动框架，将逐步执行与智能沟通决策相结合。C2C使代理能够做出成本意识的沟通选择，通过有针对性的互动动态提升任务理解。我们在三个复杂性级别和团队规模为5至17代理的真实编码工作流中评价了C2C，与无沟通和固定步骤基线进行了比较。结果显示，C2C在可以接受的沟通成本下，将任务完成时间减少了约40%。该框架在标准配置中成功完成所有任务，并且在规模化情况下保持有效性。C2C不仅建立了测量多代理系统中沟通有效性的理论基础，还提供了一个用于复杂协作任务的实用框架。",
        "地址": "https://arxiv.org/pdf/2510.19995.pdf"
    },
    {
        "名称": "2025 [2510.18413] Adamas: Hadamard Sparse Attention for Efficient Long-Context Inference.pdf",
        "作者": "Siyuan Yan, Guo-Qing Jiang, Yuchen Zhang, Xiaoxing Ma, Ran Zhu, Chun Cao, Jingwei Xu",
        "摘要": "摘要: 大型语言模型（LLMs）现在支持上下文窗口长度从数十万到数百万个标记，从而实现了诸如长文档摘要、大规模代码合成、多文档问答和持久多轮对话等应用。然而，这种扩展的上下文加剧了自注意力的二次成本，导致自回归解码的严重延迟。现有的稀疏注意力方法虽然缓解了这些成本，但依赖于启发式模式，在每个查询回忆关键键值（KV）对时表现不佳，导致准确率下降。我们提出了Adamas，这是一种为长上下文推理设计的轻量但高度准确的稀疏注意力机制。Adamas应用Hadamard变换、分桶化和2位压缩以生成紧凑的表示，并利用曼哈顿距离估算进行高效的top-k选择。实验表明，Adamas在仅有64个标记预算时可匹敌全注意力的准确性，在128个标记时实现近乎无损性能，并支持高达8倍比率的稀疏性，相较于之前的最先进（SOTA）方法，在32K长度序列上达到了高达4.4倍的自注意力和1.5倍的端到端加速。令人惊讶的是，Adamas在激进的稀疏性下也能维持与全注意力相当甚至更低的困惑度，强调了其在保持准确性方面的有效性。\n\n作者: 闫思源, 姜国庆, 张宇辰, 马晓星, 朱然, 曹春, 许经纬\n\n链接: https://arxiv.org/pdf/2510.18413.pdf\n\n标题: Adamas: Hadamard 稀疏注意力用于高效长上下文推理",
        "地址": "https://arxiv.org/pdf/2510.18413.pdf"
    },
    {
        "名称": "2025 [2510.17896] Long-Context Attention Benchmark: From Kernel Efficiency to Distributed Context Parallelism.pdf",
        "作者": "Tao Bu, Qiangang Wang, Bowen Zeng, Hanwen Sun, Yunpeng Huang, Chun Cao, Jingwei Xu",
        "摘要": "摘要:\n基于Transformer的大型语言模型（LLM）取得了显著成功，然而标准注意力机制在序列长度方面带来了计算和内存成本上的二次代价，成为长上下文训练的主要瓶颈。以前的工作沿两个方向解决这一挑战：（1）核级优化，加速稠密和稀疏注意力操作；（2）模块级策略，通常称为分布式注意力或上下文并行训练，在多设备上扩展注意力。然而，系统性评估仍然有限：操作符级比较通常不完整，而上下文并行策略通常是特定框架的，跨上下文的性能分析不明确。为了解决这些问题，我们提出了一个统一的基准，整合了具有模块化和可扩展接口的代表性注意力内核和上下文并行机制进行评估。该基准从两个关键维度评估方法：（1）注意力掩码模式，强烈影响效率、可扩展性和可用性；（2）序列长度和分布规模，决定极端长上下文训练下的性能。通过在最多96个GPU的集群上进行全面实验，我们的基准实现了可重复的比较，突出了方法特定的权衡，并为在长上下文LLM训练中设计和部署注意力机制提供了实用指导。\n\n翻译：\n2025年《长上下文注意力基准：从内核效率到分布式上下文并行》.",
        "地址": "https://arxiv.org/pdf/2510.17896.pdf"
    },
    {
        "名称": "2025 [2510.15804] Emergence of Linear Truth Encodings in Language Models.pdf",
        "作者": "Shauli Ravfogel, Gilad Yehudai, Tal Linzen, Joan Bruna, Alberto Bietti",
        "摘要": "摘要：最近的探测研究表明，大型语言模型展示了可以将真实与虚假陈述区分开的线性子空间，但它们出现的机制尚不清楚。我们引入了一个透明的单层Transformer玩具模型，它可以端到端地再现这种真值子空间，并揭示它们可能出现的一条具体路径。我们研究了一个简单的情境，即真值编码可以在其中出现：在一个数据分布中，事实陈述与其他事实陈述共现（反之亦然），这鼓励模型学习这一区别，以降低未来标记的语言模型损失。我们通过预训练的语言模型中的实验证实了这一模式。最后，在玩具模型中，我们观察到了两阶段的学习动态：网络首先在几步内记住所属的事实关联，然后在更长时间内学会线性地将真与假分开，这反过来降低了语言模型损失。总之，这些结果从机制上展示了线性真值表示如何以及为何能在语言模型中出现，并提供了实验证据支持。",
        "地址": "https://arxiv.org/pdf/2510.15804.pdf"
    }
]