[
    {
        "名称": "2025 [2511.03276] Diffusion Language Models are Super Data Learners.pdf",
        "作者": "Jinjie Ni, Qian Liu, Longxu Dou, Chao Du, Zili Wang, Hang Yan, Tianyu Pang, Michael Qizhe Shieh",
        "摘要": "摘要: 在严格控制的预训练设置下，我们观察到一种交叉现象：当独特数据有限时，通过训练更多的周期，扩散语言模型（DLMs）持续超过自回归（AR）模型。随着更多或更高质量的数据，交叉现象会推迟；随着模型的增大，交叉现象会更早出现，并在稠密和稀疏架构中持续，我们将这种优势归因于三个复合因素：（1）任意顺序建模，（2）通过迭代双向降噪实现的超密集计算，以及（3）内置的蒙特卡洛增强；输入或参数噪声在数据限制下改善AR性能，但不能弥合差距。规模化下，用约1.5万亿个标记的计算预算对10亿个独特的Python标记进行训练的1.7B DLM超过在严格匹配设置下训练的AR编码器。此外，一个具有10亿参数的DLM在HellaSwag上实现了超过56%的准确率，在MMLU上实现了超过33%的准确率，仅通过重复标准的预训练数据，而没有使用任何特殊技巧。我们还表明，在这种情况下，上升的验证交叉熵不意味着下游性能下降。\n\n楊軍, Qian 刘, 龙许 Dou, Chao 杜, 子利 王, Hang 闫, Tianyu Pang, Michael Qizhe Shieh",
        "地址": "https://arxiv.org/pdf/2511.03276.pdf"
    },
    {
        "名称": "2025 [2511.03334] UniAVGen: Unified Audio and Video Generation with Asymmetric Cross-Modal Interactions.pdf",
        "作者": "Guozhen Zhang, Zixiang Zhou, Teng Hu, Ziqiao Peng, Youliang Zhang, Yi Chen, Yuan Zhou, Qinglin Lu, Limin Wang",
        "摘要": "摘要：由于缺乏有效的跨模态建模，现有开源的音视频生成方法通常表现出嘴唇同步性差及语义一致性不足的问题。为减轻这些缺陷，我们提出了UniAVGen，一个统一的音视频联合生成框架。UniAVGen基于一个双分支的联合合成架构，结合了两个并行的扩散变压器（DiTs）来构建一个连贯的跨模态潜空间。其核心在于一种非对称的跨模态交互机制，能实现双向、时间对齐的交叉注意，从而确保准确的时空同步和语义一致性。此外，该跨模态交互还通过面部感知调制模块增强，该模块在交互过程中动态优先处理显著区域。为了在推理期间提升生成的保真度，我们还引入了模态感知的无分类引导，这是一种显著增强跨模态相关信号的新策略。值得注意的是，UniAVGen的强大联合合成设计使得在单一模型内能够无缝统一重要的音视频任务，如音视频联合生成和延续、视频到音频配音及音频驱动的视频合成。全面实验验证了，尽管训练样本大幅减少（1.3百万比30.1百万），UniAVGen在音视频同步性、音色一致性及情感一致性方面表现出全面优势。",
        "地址": "https://arxiv.org/pdf/2511.03334.pdf"
    },
    {
        "名称": "2025 [2511.03001] LEGO-Eval: Towards Fine-Grained Evaluation on Synthesizing 3D Embodied Environments with Tool Augmentation.pdf",
        "作者": "Gyeom Hwangbo, Hyungjoo Chae, Minseok Kang, Hyeonjong Ju, Soohyun Oh, Jinyoung Yeo",
        "摘要": "摘要：尽管在使用大型语言模型(LLMs)自动生成3D场景方面取得了进展，但生成的场景通常缺乏现实世界环境中的真实空间布局和对象属性。这一问题源于指令细节不够、过于粗略，因此通过更详细、细粒度的指令来指导3D场景合成，反映现实世界环境变得至关重要。没有这样的真实场景，在不切实际的环境中训练具身代理可能导致它们学习的先验知识与现实世界的物理和语义显著背离，从而在部署时性能下降。因此，验证细粒度指令与生成场景之间的一致性对于有效学习至关重要。然而，当前的评估方法，如CLIPScore和视觉-语言模型(VLMs)，往往无法可靠地评估这种一致性。这一缺陷主要源于它们对3D场景的浅层理解，导致场景组件不适当地定位。为了解决这个问题，我们引入了LEGO-Eval，这个评估框架配备了多种工具，旨在明确对场景组件进行定位，从而进行更准确的一致性评估。我们还提出了LEGO-Bench，这是一个详细指令的基准，指定了现实世界环境的复杂布局和属性。实验表明，LEGO-Eval在评估场景指令一致性方面比VLM-judge高出0.41的F1分数。使用LEGO-Bench进行基准测试揭示了当前生成方法的显著局限性。在评估的所有方法中，生成完全与细粒度指令一致的场景的成功率最高达到了10%。\n\n翻译：\n\n2025年5月{Gyeom Hwangbo, Hyungjoo Chae, Minseok Kang, Hyeonjong Ju, Soohyun Oh, Jinyoung Yeo}\n标题：《LEGO-Eval：通过工具扩展实现合成3D具身环境的细粒度评估》",
        "地址": "https://arxiv.org/pdf/2511.03001.pdf"
    },
    {
        "名称": "2025 [2511.02818] Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning.pdf",
        "作者": "Mohamed Bouadi, Pratinav Seth, Aditya Tanna, Vinay Kumar Sankarapu",
        "摘要": "摘要：\n表格数据仍然是现实世界应用中的主要格式。然而，由于异质特征类型和多尺度复杂交互的存在，开发针对表格数据的有效神经模型仍然充满挑战。最近在表格上下文学习（ICL）方面的进展，如TabPFN和TabICL，已经实现了与梯度提升树（GBTs）相媲美的最先进性能，且无需特定任务的微调。然而，当前架构存在关键限制：(1) 单一尺度特征处理忽略了层次依赖性；(2) 随表宽度二次扩展的密集注意力；以及(3) 严格的顺序组件处理阻止了迭代表示优化和跨组件通信。针对这些挑战，我们引入了Orion-MSP，这是一种具有三项关键创新的表格ICL架构：(1) 多尺度处理以捕获层次特征交互；(2) 块稀疏注意力结合了窗口化、全局和随机模式以实现可扩展的效率与长程连接；以及(3) 一种感知器风格内存，允许跨组件的安全双向信息流。在各种基准上，Orion-MSP匹配或超越了最先进的性能，并有效扩展到高维表格，确立了高效表格上下文学习的新标准。该模型已公开发布，详情可访问这个网址。\n\n作者：\nMohamed Bouadi, Pratinav Seth, Aditya Tanna, Vinay Kumar Sankarapu\n\n论文链接：\nhttps://arxiv.org/pdf/2511.02818.pdf\n\n标题：\n2025 [2511.02818] Orion-MSP: Multi-Scale Sparse Attention for Tabular In-Context Learning.pdf",
        "地址": "https://arxiv.org/pdf/2511.02818.pdf"
    },
    {
        "名称": "2025 [2511.02802] TabTune: A Unified Library for Inference and Fine-Tuning Tabular Foundation Models.pdf",
        "作者": "Aditya Tanna, Pratinav Seth, Mohamed Bouadi, Utsav Avaiya, Vinay Kumar Sankarapu",
        "摘要": "摘要：\n表格基础模型代表了一种在结构化数据学习中不断增长的范式，扩展了大规模预训练在表格领域的收益。然而，由于异构预处理管道、碎片化的API、不一致的微调过程，以及缺乏面向部署的如校准和公平性等指标的标准化评估，它们的采用仍然有限。我们提出了TabTune，这是一个通过单一界面标准化表格基础模型完整工作流程的统一库。TabTune提供对七种支持多种适应策略的最新模型的一致访问，包括零样本推理、元学习、监督微调（SFT），以及参数高效微调（PEFT）。该框架自动化模型感知预处理、内部管理架构异构性，并集成了性能、校准和公平性的评估模块。TabTune旨在实现可扩展性和可重复性，使表格基础模型的适应策略始终如一地进行基准测试。\n\n翻译：\n表格基础模型代表了一种在结构化数据学习中不断发展的新范式，将大规模预训练的优势扩展到表格领域。然而，由于异质预处理管道、分散的API、不一致的微调程序以及缺乏标准化评估面向部署的指标（如校准和公平性），这些模型的采用仍然受到限制。我们提出了TabTune，一个通过单一接口标准化表格基础模型整个工作流程的统一库。TabTune提供对七种最先进模型的一致访问，这些模型支持多种适应策略，包括零样本推理、元学习、监督微调（SFT）和参数高效微调（PEFT）。该框架实现了自动化的模型感知预处理、内管理架构的异质性，并集成了性能、校准和公平性的评估模块。TabTune旨在提供可扩展性和可重复性，使表格基础模型的适应策略能够进行一致的基准测试。",
        "地址": "https://arxiv.org/pdf/2511.02802.pdf"
    },
    {
        "名称": "2025 [2511.01294] Kinematify: Open-Vocabulary Synthesis of High-DoF Articulated Objects.pdf",
        "作者": "Jiawei Wang, Dingyou Wang, Jiaming Hu, Qixuan Zhang, Jingyi Yu, Lan Xu",
        "摘要": "摘要: 对运动结构和可动组件的深刻理解对于使机器人能够操纵物体并建模其自身的关节形式至关重要。这种理解通过关节物体体现，对于物理模拟、运动规划和策略学习等任务至关重要。然而，创建这些模型，特别是对于具有高度自由度（DoF）的物体，仍然是一个重大挑战。现有方法通常依赖于运动序列或手工编制数据集中的强假设，阻碍了可扩展性。在本文中，我们介绍了Kinematify，一个自动化框架，可直接从任意RGB图像或文本描述合成关节物体。我们的方法解决了两个核心挑战：（i）推断高自由度物体的运动拓扑结构；（ii）从静态几何中估计关节参数。为实现这一目标，我们结合了用于结构推断的MCTS搜索与几何驱动优化用于关节推理，生成物理一致且功能有效的描述。我们在来自合成和真实环境的不同输入上评估了Kinematify，展示了在配准和运动拓扑准确性方面相对于现有工作的方法的改进。\n\n作者: 王家伟, 王定友, 胡佳明, 张其轩, 于京奕, 许岚\n\n链接: https://arxiv.org/pdf/2511.01294.pdf\n\n标题: Kinematify: 开放词汇合成高度自由度（DoF）关节物体",
        "地址": "https://arxiv.org/pdf/2511.01294.pdf"
    },
    {
        "名称": "2025 [2511.03146] MME-CC: A Challenging Multi-Modal Evaluation Benchmark of Cognitive Capacity.pdf",
        "作者": "Kaiyuan Zhang, Chenghao Yang, Zhoufutu Wen, Sihang Yuan, Qiuyue Wang, Chaoyi Huang, Guosheng Zhu, He Wang, Huawenyu Lu, Jianing Wen, Jianpeng Jiao, Lishu Luo, Longxiang Liu, Sijin Wu, Xiaolei Zhu, Xuanliang Zhang, Ge Zhang, Yi Lin, Guang Shi, Chaoyou Fu, Wenhao Huang",
        "摘要": "摘要: 随着推理模型的快速扩展，多模态在人类认知中的关键作用已经变得显而易见，推动了对视觉为中心的认知行为进行探讨的日益需求。然而，现有的多模态基准要么过分强调文本推理，要么未能系统地捕捉视觉为中心的认知行为，导致对多模态语言模型（MLLMs）认知能力的评估不足。为了解决这一限制，我们引入了MME-CC（认知能力的多模态评估基准），这是一个以视觉为基础的基准，将11个具有代表性的推理任务组织为三类基本视觉信息：空间、几何和基于知识的推理，并提供对MLLMs在这些维度上的认知能力的详细分析。基于MME-CC，我们对16个具有代表性的MLLMs进行了广泛的实验。我们的研究表明，当前闭源模型总体上领先（例如，Gemini-2.5-Pro 得分为42.66，而GLM-4.5V得分为30.45），而空间和几何推理仍普遍较弱（小于或等于30%）。我们进一步识别了常见的错误模式，包括方向错误、脆弱的跨视图身份持久性以及对反事实指令的依从性差，并观察到链式思维通常遵循三阶段过程（提取 -> 推理 -> 验证），并严重依赖于视觉提取。我们希望这项工作能够促使将MLLMs的认知能力作为评估和模型设计的核心。",
        "地址": "https://arxiv.org/pdf/2511.03146.pdf"
    },
    {
        "名称": "2025 [2511.03628] LiveTradeBench: Seeking Real-World Alpha with Large Language Models.pdf",
        "作者": "Haofei Yu, Fenghai Li, Jiaxuan You",
        "摘要": "摘要: 大型语言模型（LLMs）在各种基准测试中表现出色——从知识问答和数学推理到网页代理任务——但这些测试发生在静态环境中，缺乏真实的动态和不确定性。因此，它们评估的是孤立的推理或问题解决能力，而非在不确定性下的决策。为了解决这个问题，我们引入了LiveTradeBench，这是一个用于评估LLM代理在现实和不断变化的市场中的实时交易环境。LiveTradeBench遵循三个设计原则：（一）市场价格和新闻的实时数据流，消除对离线回测的依赖，防止信息泄漏，同时捕捉实时不确定性；（二）从单资产操作到多资产配置的投资组合管理抽象，整合风险管理和跨资产推理；（三）跨结构不同的环境——美国股票和Polymarket预测市场——进行多市场评估，这些环境在波动性、流动性和信息流动方面均有所不同。在每一步中，代理观察价格、新闻及其投资组合，然后输出平衡风险和收益的百分比分配。使用LiveTradeBench，我们对21个不同家族的LLM进行了为期50天的实时评估。结果表明：（1）高LMArena分数并不意味着优越的交易成果；（2）模型显示出反映风险偏好和推理动态的独特投资组合风格；（3）一些LLM能够有效利用实时信号调整决策。这些发现揭示了静态评估与现实世界能力之间的差距，激发了测试在实时不确定性下的连续决策和一致性的基准。\n\n作者: Haofei Yu, Fenghai Li, Jiaxuan You\n\n注释: 16页\n\n链接: [https://arxiv.org/pdf/2511.03628.pdf](https://arxiv.org/pdf/2511.03628.pdf)\n\n标题: 2025 [2511.03628] LiveTradeBench: 使用大型语言模型探索现实世界中的阿尔法",
        "地址": "https://arxiv.org/pdf/2511.03628.pdf"
    },
    {
        "名称": "2025 [2511.02309] The Sequential Edge: Inverse-Entropy Voting Beats Parallel Self-Consistency at Matched Compute.pdf",
        "作者": "Aman Sharma, Paras Chopra",
        "摘要": "摘要：我们重新审视了语言模型推理的测试时标度问题，并提出了一个基本问题：在相同的标记预算和计算条件下，是并行运行多个独立链条更好，还是运行少量通过顺序步骤迭代细化的链条更好？通过对五个最新的开源模型和三个具有挑战性的推理基准的全面评估，我们发现，顺序标度中链条在先前尝试的基础上逐步改进的方法，在95.6%的配置中一致优于占主导地位的并行自一致性范式，准确率提高了最多46.7%。此外，我们引入了逆熵加权投票，这是一种新颖的无需训练的方法，可以进一步提升顺序标度的准确性。通过根据推理链条的逆熵对答案进行加权，我们的成功率超过了并行多数，并将其确立为最佳测试时标度策略。我们的发现从根本上挑战了自Wang等人的自一致性解码 (Wang et al., 2022) 以来支配测试时标度的并行推理正统观念，将顺序细化定位为现代大型语言模型推理的稳健默认方法，并需要在推理时优化方法上进行范式转变。",
        "地址": "https://arxiv.org/pdf/2511.02309.pdf"
    },
    {
        "名称": "2025 [2511.03718] Grounded Misunderstandings in Asymmetric Dialogue: A Perspectivist Annotation Scheme for MapTask.pdf",
        "作者": "Nan Li, Albert Gatt, Massimo Poesio",
        "摘要": "摘要: 协作对话依赖于参与者逐步建立共同的理解，但在不对称的环境中，他们可能会在指代不同实体的情况下误以为彼此理解一致。我们为HCRC MapTask 语料库（Anderson et al., 1991）引入了一种视角注释方案，该方案分别捕捉说话者和听者对每个指代表达的理解，从而使我们能够追踪理解如何随时间的推移而产生、分歧和修复。使用一种受方案约束的大型语言模型注释管道，我们获得了1.3万条带有可靠性估计的注释指代表达，并分析了由此产生的理解状态。结果显示，一旦词汇变体被统一，完全误解的情况很少见，但多样性上的差异系统地引发了分歧，这揭示了表面上的共同理解如何掩盖指代的错位。我们的框架既提供了一种资源，也提供了一种分析视角，用于研究基础误解和评估（V）LLM 在协作对话中建模基于视角的理解能力。\n\n作者: Nan Li, Albert Gatt, Massimo Poesio\n\n评论: 11页，3个图，5个表；正在审稿中\n\n链接: [https://arxiv.org/pdf/2511.03718.pdf](https://arxiv.org/pdf/2511.03718.pdf)\n\n标题: 2025 [2511.03718] 在不对称对话中的基础误解：MapTask的视角注释方案",
        "地址": "https://arxiv.org/pdf/2511.03718.pdf"
    },
    {
        "名称": "2025 [2511.02358] Let Multimodal Embedders Learn When to Augment Query via Adaptive Query Augmentation.pdf",
        "作者": "Wongyu Kim, Hochang Lee, Sanghak Lee, Yoonsung Kim, Jaehyun Park",
        "摘要": "摘要：查询增强通过将更多信息添加到查询中使其更具意义，以找到相关文档。目前的研究提出了基于大语言模型（LLM）的嵌入器，它们通过利用LLM的生成能力，以多任务方式学习嵌入表示和生成查询增强。在推理过程中，这些联合训练的嵌入器进行了查询增强，随后进行嵌入，显示出了有效的结果。然而，增强每个查询会导致显著的嵌入延迟，而查询增强对某些查询的性能有害。此外，以前的方法未在多模态环境中进行探索。为了解决这些问题，我们提出了M-Solomon，这是一种通用的多模态嵌入器，能够自适应地决定何时增强查询。我们的方法首先在数据集层面将训练数据集的查询分为两组：一组包括需要增强的查询，另一组包括不需要增强的查询。然后，我们介绍了一种合成过程，通过利用强大的多模态LLM（MLLM）为需要增强的查询生成适当的增强内容。接下来，我们提出自适应查询增强。通过此步骤，M-Solomon能够在必要时进行查询增强，对需要增强的查询通过生成前缀/augment的合成增强进行学习，而对其他查询则生成简单字符串/embed。实验结果表明，M-Solomon不仅大幅度超越了未进行增强的基线，而且在嵌入延迟显著加快的情况下超越了始终使用增强的基线。\n\n作者：Wongyu Kim, Hochang Lee, Sanghak Lee, Yoonsung Kim, Jaehyun Park\n\n评论：已被MMGenSR Workshop（CIKM 2025）接受\n\n链接：https://arxiv.org/pdf/2511.02358.pdf\n\n标题：2025 [2511.02358] 通过自适应查询增强让多模态嵌入器学习何时增强查询",
        "地址": "https://arxiv.org/pdf/2511.02358.pdf"
    }
]