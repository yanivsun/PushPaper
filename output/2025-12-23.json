[
    {
        "名称": "2025 [2512.16676] DataFlow: An LLM-Driven Framework for Unified Data Preparation and Workflow Automation in the Era of Data-Centric AI.pdf",
        "作者": "Hao Liang, Xiaochen Ma, Zhou Liu, Zhen Hao Wong, Zhengyang Zhao, Zimo Meng, Runming He, Chengyu Shen, Qifeng Cai, Zhaoyang Han, Meiyi Qiang, Yalin Feng, Tianyi Bai, Zewei Pan, Ziyi Guo, Yizhen Jiang, Jingwen Deng, Qijie You, Peichao Lai, Tianyu Guo, Chi Hsu Tsai, Hengyi Feng, Rui Hu, Wenkai Yu, Junbo Niu, Bohan Zeng, Ruichuan An, Lu Ma, Jihao Huang, Yaowei Zheng, Conghui He, Linpeng Tang, Bin Cui, Weinan E, Wentao Zhang",
        "摘要": "摘要：随着大型语言模型（LLMs）对高质量数据的需求迅速增长，迫切需要可扩展、可靠且语义丰富的数据准备管道。然而，当前的实践仍然主要依赖于零散的脚本和松散定义的工作流，这些缺乏原理性抽象，阻碍了可重复性，并且对模型环中的数据生成支持有限。为了解决这些挑战，我们提出了DataFlow，一个统一且可扩展的LLM驱动数据准备框架。DataFlow以系统级抽象为设计，允许模块化、可重用和可组合的数据转换，并提供类似PyTorch的管道构建API，用于构建可调试和优化的数据流。该框架包括近200个可重用操作员和六个跨越文本、数学推理、代码、Text-to-SQL、代理RAG和大规模知识提取的领域通用管道。为了进一步提高可用性，我们引入了DataFlow-Agent，它通过操作员合成、管道规划和迭代验证，将自然语言规范自动翻译为可执行的管道。在六个具有代表性的用例中，DataFlow一致地提高了下游LLM的性能。我们的数学、代码和文本管道优于精心制作的人类数据集和专门的合成基线，在Text-to-SQL中相对于SynSQL实现了高达+3%的执行准确性提升，在代码基准测试中平均提高了7%，在MATH、GSM8K和AIME上分别提高了1到3分。此外，由DataFlow生成的统一的10K样本数据集使基础模型能够超越那些在1M Infinity-Instruct数据上训练的模型。这些结果表明，DataFlow提供了一个实用且高性能的基础，用于可靠、可重复和可扩展的LLM数据准备，并为未来以数据为中心的AI开发奠定了系统级基础。",
        "地址": "https://arxiv.org/pdf/2512.16676.pdf"
    },
    {
        "名称": "2025 [2512.19693] The Prism Hypothesis: Harmonizing Semantic and Pixel Representations via Unified Autoencoding.pdf",
        "作者": "Weichen Fan, Haiwen Diao, Quan Wang, Dahua Lin, Ziwei Liu",
        "摘要": "摘要：深度表示在不同模态之间本质上是相互交织的。在本文中，我们系统地分析了各种语义编码器和像素编码器的光谱特性。有趣的是，我们的研究揭示了编码器特征光谱与其功能作用之间一种高度启发性的且少有研究的对应关系：语义编码器主要捕捉编码抽象意义的低频成分，而像素编码器还保留传达细粒度细节的高频信息。这一启发性发现提供了一种将编码器行为与其底层光谱结构联系起来的统一视角。我们将其定义为棱镜假设，其中每种数据模态都可以看作是自然世界投射到共享特征光谱上的一个投影，就像棱镜一样。基于这一见解，我们提出了统一自编码（UAE），这是一种通过创新的频带调制器来协调语义结构和像素细节的模型，使它们能够无缝共存。在ImageNet和MS-COCO基准测试上的大量实验验证了我们的UAE能够有效地将语义抽象和像素级保真统一到一个单一的潜在空间中，并达到最新的性能水平。",
        "地址": "https://arxiv.org/pdf/2512.19693.pdf"
    },
    {
        "名称": "2025 [2512.17650] Region-Constraint In-Context Generation for Instructional Video Editing.pdf",
        "作者": "Zhongwei Zhang, Fuchen Long, Wei Li, Zhaofan Qiu, Wu Liu, Ting Yao, Tao Mei",
        "摘要": "摘要：最近，情景生成范式在指令图像编辑中展示了在数据效率和合成质量方面的强大能力。然而，将这种情景学习应用于基于指令的视频编辑并非易事。在不指定编辑区域的情况下，结果可能会遭受编辑区域不准确以及在去噪过程中编辑和非编辑区域之间的 token 干扰问题。为了解决这些问题，我们提出了 ReCo，一种新的指令性视频编辑范式，在情景生成过程中新奇地深入研究了编辑和非编辑区域之间的约束建模。从技术上讲，ReCo 通过宽度连接源视频和目标视频进行联合去噪。为了校准视频扩散学习，ReCo 利用两个正则化项，即潜在正则化和注意力正则化，分别在一步向后去噪潜变量和注意力图上进行。前者增加了源视频和目标视频之间编辑区域的潜在差异，同时减少非编辑区域的差异，强调对编辑区域的修改并减轻外部意外内容的生成。后者则抑制了编辑区域中的 tokens 对源视频中对应部分 tokens 的注意力，从而在目标视频中新生成对象时减轻它们的干扰。此外，我们提出了一个大规模高质量的视频编辑数据集，即 ReCo-Data，包括 50 万对指令视频对，以提高模型的训练效果。在四个主要基于指令的视频编辑任务上进行的大量实验表明，我们的提议具有优越性。",
        "地址": "https://arxiv.org/pdf/2512.17650.pdf"
    },
    {
        "名称": "2025 [2512.17040] Infinite-Homography as Robust Conditioning for Camera-Controlled Video Generation.pdf",
        "作者": "Min-Jung Kim, Jeongho Kim, Hoiyeong Jin, Junha Hyung, Jaegul Choo",
        "摘要": "摘要: 最近在视频扩散模型方面的进展激发了对动态场景中基于相机控制的新视角视频生成的兴趣，旨在为创作者在后期制作中提供电影级相机控制能力。相机控制视频生成的一个关键挑战是确保对指定相机姿势的忠实度，同时保持视角一致性并从有限的观察中推理被遮挡的几何形状。为了解决这个问题，现有方法要么在路径-视频对数据集上训练轨迹条件视频生成模型，要么从输入视频中估算深度，以沿目标轨迹重投影并生成未投影的区域。然而，由于两个主要原因，现有方法难以生成相机姿势忠实、高质量的视频：(1) 基于重投影的方法对由不准确深度估计引起的错误高度敏感；(2) 现有数据集中有限的相机轨迹多样性限制了学习模型。为了解决这些局限性，我们提出了InfCam，一个无需深度的、具有高姿势忠实度的相机控制视频生成框架。该框架集成了两个关键组件：(1) 无限单应性扭曲，该组件直接在视频扩散模型的2D潜在空间中编码三维相机旋转。基于这种无噪声的旋转信息，通过端到端训练预测残差视差项，以实现高相机姿势忠实度；(2) 数据增强管道，将现有的合成多视图数据集转换为具有多样化轨迹和焦距的序列。实验结果表明，InfCam在相机姿势准确性和视觉保真度方面优于基线方法，并且能从合成数据很好地推广到真实世界数据。项目页面链接：this https URL\n\n翻译:标题 标题: 无限单应性作为相机控制视频生成的鲁棒条件\n\n年份：2025\n\n作者：金敏贞，金正镐，晋辉泳，亨俊河，朱在鏻",
        "地址": "https://arxiv.org/pdf/2512.17040.pdf"
    },
    {
        "名称": "2025 [2512.19134] QuCo-RAG: Quantifying Uncertainty from the Pre-training Corpus for Dynamic Retrieval-Augmented Generation.pdf",
        "作者": "Dehai Min, Kailin Zhang, Tongtong Wu, Lu Cheng",
        "摘要": "摘要: 动态检索增强生成 (Dynamic Retrieval-Augmented Generation) 在生成过程中自适应地决定何时进行检索，以缓解大型语言模型 (LLMs) 中的幻觉。然而，现有方法依赖于模型内部信号（例如，logits，熵），这些信号本质上是不可靠的，因为LLMs通常校准不佳，且在错误输出上经常表现出高度信心。我们提出了QuCo-RAG，它从主观信心转向从预训练数据计算的客观统计。我们的方法通过两个阶段量化不确定性：(1) 在生成之前，我们识别低频实体，这表明长尾知识的空缺；(2) 在生成过程中，我们验证预训练语料库中的实体共现，零共现通常表示幻觉风险。这两个阶段都利用Infini-gram对40万亿个令牌进行毫秒延迟的查询，当不确定性高时触发检索。在多跳QA基准测试上的实验显示，QuCo-RAG使用OLMo-2模型相对于最先进的基线实现了5到12点的精确匹配（EM）提升，并且有效地转移到使用未公开预训练数据（如Llama、Qwen、GPT）模型中，EM提高了最多14点。在生物医学QA上的领域泛化进一步验证了我们范式的鲁棒性。这些结果确立了基于语料的验证作为一种原则性的、实际的模型无关的动态RAG范式。我们的代码在这个URL公开可用。",
        "地址": "https://arxiv.org/pdf/2512.19134.pdf"
    },
    {
        "名称": "2025 [2512.18880] Can LLMs Estimate Student Struggles? Human-AI Difficulty Alignment with Proficiency Simulation for Item Difficulty Prediction.pdf",
        "作者": "Ming Li, Han Chen, Yunze Xiao, Jian Chen, Hong Jiao, Tianyi Zhou",
        "摘要": "摘要：准确估计题目（问题或任务）的难度对于教育评估至关重要，但却面临冷启动问题。尽管大型语言模型展示了超越人类的解决问题能力，能否感知人类学习者的认知困难仍是一个悬而未决的问题。在这项工作中，我们对超过20个模型在医学知识和数学推理等不同领域进行了大规模的实证分析，以研究人类和人工智能在难度估计上的一致性。研究结果表明，随着模型规模的扩大，这种一致性并未可靠地改善；模型往往趋向于形成机器共识，而不是与人类一致。我们发现，高性能模型在模拟学生能力限制方面存在困难，即使明确提示其采用特定的能力水平进行操作。此外，我们还发现模型缺乏反省能力，无法预测自己的局限性。这些结果表明，通用问题解决能力并不意味着理解人类的认知困难，突显了使用当前模型进行自动难度预测所面临的挑战。",
        "地址": "https://arxiv.org/pdf/2512.18880.pdf"
    },
    {
        "名称": "2025 [2512.19678] WorldWarp: Propagating 3D Geometry with Asynchronous Video Diffusion.pdf",
        "作者": "Hanyang Kong, Xingyi Yang, Xiaoxu Zheng, Xinchao Wang",
        "摘要": "摘要：生成长距离、几何一致的视频提出了一个根本性的难题：尽管一致性要求在像素空间中严格遵守3D几何，最先进的生成模型在摄像机条件下的潜在空间中最为有效。这种不一致性导致当前方法在处理遮挡区域和复杂摄像机轨迹时遇到困难。为了弥合这一差距，我们提出了WorldWarp，一个将3D结构锚与2D生成细化器结合的框架。为了建立几何基础，WorldWarp通过高斯投影（3DGS）维护一个在线的3D几何缓存。通过明确地将历史内容变形到新视图中，这个缓存充当了结构脚手架，确保每个新帧尊重先前的几何。然而，由于遮挡，静态变形不可避免地会留下空洞和伪影。我们使用设计用于“填充和修正”目标的时空扩散（ST-Diff）模型来解决此问题。我们的关键创新是时空变化的噪声计划：空白区域接收完整噪声以触发生成，而变形区域接收部分噪声以实现细化。通过在每一步动态更新3D缓存，WorldWarp在视频段中保持一致性。因此，它通过确保3D逻辑指导结构而扩散逻辑完善纹理，达到了最先进的保真度。项目页面：\\\\href{this https URL}{this https URL}。",
        "地址": "https://arxiv.org/pdf/2512.19678.pdf"
    },
    {
        "名称": "2025 [2512.19629] LoGoPlanner: Localization Grounded Navigation Policy with Metric-aware Visual Geometry.pdf",
        "作者": "Jiaqi Peng, Wenzhe Cai, Yuqiang Yang, Tai Wang, Yuan Shen, Jiangmiao Pang",
        "摘要": "摘要：在非结构化环境中进行轨迹规划是移动机器人所需的基础且具有挑战性的能力。传统的模块化流水线在感知、定位、建图和规划模块中存在延迟和级联错误。近期的端到端学习方法将原始视觉观察直接映射到控制信号或轨迹，在开放世界环境中展示了更佳的性能和效率。然而，大多数之前的端到端方法仍依赖于独立的定位模块，这些模块需要准确的传感器外部校准来进行自状态估计，从而限制了跨模型和环境的泛化能力。我们提出了LoGoPlanner，这是一种基于定位的端到端导航框架，通过以下几方面解决了这些限制：（1）微调长远视角的视觉几何主干网以提供绝对度量尺，从而隐式地进行状态估计以实现准确的定位；（2）从历史观测中重建周围场景几何，提供密集、细粒度的环境感知以确保可靠的避障；（3）将策略建立在通过上述辅助任务引导的隐式几何上，从而减少误差传播。我们在仿真和现实世界环境中评估了LoGoPlanner，其完全端到端的设计减少了累计误差，而度量感知几何记忆增强了规划一致性和避障能力，相较于oracle-localization基线提高了超过27.3%的性能，并且在不同模型和环境中表现出强大的泛化能力。代码和模型已在此链接公开发布。\n\n源文档网址：https://arxiv.org/pdf/2512.19629.pdf",
        "地址": "https://arxiv.org/pdf/2512.19629.pdf"
    },
    {
        "名称": "2025 [2512.17385] UCoder: Unsupervised Code Generation by Internal Probing of Large Language Models.pdf",
        "作者": "Jiajun Wu, Jian Yang, Wei Zhang, Lin Jing, Yuqing Ma, Ensheng Shi, Yuchi Ma, Zhoujun Li, Xianglong Liu",
        "摘要": "摘要：中国大陆模型（LLMs）在代码生成任务中展示了卓越的能力。然而，它们的有效性在很大程度上依赖于广泛的标注数据（如，问答对）或未标注数据（如，代码片段）的监督训练，通常难以大规模获取且成本高昂。为了解决这一限制，本文介绍了一种方法IPC，一个无监督框架，通过对LLMs进行内部探测来生成代码，无需任何外部语料，即使是未标注的代码片段。我们提出了问题空间探测、测试理解探测、解决方案空间探测以及知识巩固和强化，以探测LLMs内部知识和置信模式。此外，IPC通过自一致机制和基于表示的质量评估识别可靠的代码候选，然后训练UCoder（使用无监督学习的编码器）。我们在多种代码基准上验证了该方法，证明无监督方法在减少对标注数据和计算资源依赖的同时，能够实现与监督方法竞争的性能。分析实验表明，内部模型状态包含丰富的代码质量和正确性信号，适当利用这些信号可使代码生成任务的无监督学习有效进行，为资源受限情况下训练代码LLM开启新方向。",
        "地址": "https://arxiv.org/pdf/2512.17385.pdf"
    },
    {
        "名称": "2025 [2512.19682] GenEnv: Difficulty-Aligned Co-Evolution Between LLM Agents and Environment Simulators.pdf",
        "作者": "Jiacheng Guo, Ling Yang, Peter Chen, Qixin Xiao, Yinjie Wang, Xinzhe Juan, Jiahao Qiu, Ke Shen, Mengdi Wang",
        "摘要": "摘要：训练能力强大的大语言模型（LLM）代理受限于现实世界交互数据的高成本和静态性质。为了解决这一问题，我们引入了GenEnv，这是一个在代理和可扩展生成环境模拟器之间建立难度对齐的协同进化游戏的框架。与传统方法在静态数据集上演化模型不同，GenEnv实现了数据演化：模拟器作为动态课程政策，持续生成专门针对代理“最近发展区”的任务。这个过程由一个简单但有效的α-课程奖励指导，它将任务难度与代理的当前能力对齐。我们在包括API-Bank、ALFWorld、BFCL、Bamboogle和TravelPlanner在内的五个基准上评估GenEnv。在这些任务中，GenEnv将代理性能提高了最高达+40.3%，超过了7B基线，并达到或超过了更大模型的平均性能。与基于Gemini 2.5 Pro的离线数据增强相比，GenEnv使用了3.3倍更少的数据，且性能更好。通过从静态监督转向自适应模拟，GenEnv为扩展代理能力提供了一条数据高效的途径。\n\n作者：Jiacheng Guo, Ling Yang, Peter Chen, Qixin Xiao, Yinjie Wang, Xinzhe Juan, Jiahao Qiu, Ke Shen, Mengdi Wang",
        "地址": "https://arxiv.org/pdf/2512.19682.pdf"
    },
    {
        "名称": "2025 [2512.19539] StoryMem: Multi-shot Long Video Storytelling with Memory.pdf",
        "作者": "Kaiwen Zhang, Liming Jiang, Angtian Wang, Jacob Zhiyuan Fang, Tiancheng Zhi, Qing Yan, Hao Kang, Xin Lu, Xingang Pan",
        "摘要": "摘要：视觉故事叙述需要生成具有电影质量和长远一致性的多镜头视频。受人类记忆的启发，我们提出了StoryMem，一种将长篇视频故事叙述重新表述为基于显式视觉记忆的迭代镜头合成的新范式，它将预训练的单镜头视频扩散模型转变为多镜头故事讲述者。通过一种新颖的记忆到视频（Memory-to-Video, M2V）设计，StoryMem维护一个紧凑且动态更新的关键帧记忆库，用于生成的历史镜头。存储的记忆通过潜在连接和负RoPE位移注入到单镜头视频扩散模型中，仅需LoRA微调。一种语义关键帧选择策略，结合美学偏好过滤，进一步确保了生成过程中信息丰富且稳定的记忆。此外，所提出的框架自然地适应平滑镜头过渡和定制的故事生成应用。为了便于评估，我们引入了ST-Bench，一个多样的多镜头视频故事叙述基准。大量实验表明，StoryMem在保持高美学质量和提示贴合度的同时，实现了优于以往方法的跨镜头一致性，标志着在连贯的分钟级视频故事叙述方面迈出了重要一步。",
        "地址": "https://arxiv.org/pdf/2512.19539.pdf"
    },
    {
        "名称": "2025 [2512.16229] LoPA: Scaling dLLM Inference via Lookahead Parallel Decoding.pdf",
        "作者": "Chenkai Xu, Yijie Jin, Jiajun Li, Yi Tu, Guoping Long, Dandan Tu, Mingcong Song, Hongjie Si, Tianqi Hou, Junchi Yan, Zhijie Deng",
        "摘要": "摘要: 扩散大型语言模型（dLLMs）在高速推理方面显示出显著潜力。然而，目前的置信度驱动的解码策略受限于有限的并行性，通常每次前向传递（TPF）只能获得1-3个标记（token）。在这项工作中，我们发现dLLM推理期间的并行度对标记填充顺序（TFO）非常敏感。因此，我们引入了预见并行解码算法LoPA，这是一种无需训练、即插即用的算法，用于识别优越的TFO，从而加速推理。LoPA通过并行分支同时探索不同的候选TFO，并根据分支置信度选择未来并行性潜力最高的一个。我们将LoPA应用于最先进的D2F模型，观察到解码效率显著提高。特别是，LoPA将D2F-Dream的TPF在GSM8K上的值提高到10.1，同时性能优于Dream基准。此外，为了促进这种前所未有的并行度，我们开发了一个专门的多设备推理系统，具有分支并行性（BP），在多GPU部署下实现了每秒1073.9个标记的单样本吞吐量。代码见此URL链接。",
        "地址": "https://arxiv.org/pdf/2512.16229.pdf"
    },
    {
        "名称": "2025 [2512.17206] Reasoning Palette: Modulating Reasoning via Latent Contextualization for Controllable Exploration for (V)LMs.pdf",
        "作者": "Rujiao Long, Yang Li, Xingyao Zhang, Weixun Wang, Tianqianjin Lin, Xi Zhao, Yuchi Xu, Wenbo Su, Junchi Yan, Bo Zheng",
        "摘要": "摘要：探索能力会影响大型（视觉）语言模型在推理时的表现和强化学习（RL）训练，因为随机采样通常会生成冗余的推理路径，高层次多样性较少。本文提出了Reasoning Palette，一种新的潜在调制框架，它通过随机潜在变量进行策略性上下文化，在生成标记之前指导其内部规划。这个潜在上下文是在一个变分自编码器（VAE）中从问答对的均值池化嵌入中推断出来的，每个采样的潜在变量可能编码一个不同的推理上下文。在推理过程中，采样的潜在变量被解码为可学习的标记前缀，并添加到输入提示的前面，调制模型的内部推理轨迹。通过这种方式，模型在生成输出之前对推理策略进行内部采样，从而塑造整个响应序列的风格和结构。一段简短的监督微调（SFT）热身阶段允许模型适应这种潜在条件。在RL优化中，Reasoning Palette通过按需注入多样化的推理模式，促进结构化探索，显著提高了探索效率和持续学习能力。跨多个推理基准的实验表明，我们的方法能够对（视觉）语言模型的策略行为进行可解释和可控的控制，从而在标准RL方法上实现了一致的性能提升。",
        "地址": "https://arxiv.org/pdf/2512.17206.pdf"
    },
    {
        "名称": "2025 [2512.19432] MobileWorld: Benchmarking Autonomous Mobile Agents in Agent-User Interactive, and MCP-Augmented Environments.pdf",
        "作者": "Quyu Kong, Xu Zhang, Zhenyu Yang, Nolan Gao, Chen Liu, Panrong Tong, Chenglin Cai, Hanzhang Zhou, Jianan Zhang, Liangyu Chen, Zhidan Liu, Steven Hoi, Yue Wang",
        "摘要": "摘要：在现有的在线移动使用基准中，AndroidWorld因其可重现的环境和确定性评估而成为主要基准；然而，近期超过90%成功率的代理表明其已经达到饱和状态，激发了对更具挑战性基准的需求。此外，其环境缺乏关键的应用类别，如电子商务和企业通信，并且未能反映出以模糊用户指令和混合工具使用为特点的现实移动使用场景。为弥补这一差距，我们引入了MobileWorld，这是一个设计更具挑战性的基准，以更好地反映现实世界的移动使用情况，包括20个应用程序的201个任务，同时保持与AndroidWorld相同级别的可重现评估。MobileWorld的困难有两个方面。首先，它强调具有跨应用交互的长期任务：MobileWorld平均任务完成步骤几乎是AndroidWorld的两倍（27.8 vs. 14.3），并且包含更多多应用任务（62.2% vs. 9.5%）。其次，MobileWorld不仅仅局限于标准的GUI操作，还引入了新的任务类别，包括代理用户互动和MCP增强任务。为了确保稳健评估，我们提供基于快照的容器环境和精确的功能验证，包括后端数据库检查和任务回调API。我们进一步开发了一个具有扩展动作空间的计划执行代理框架，以支持用户交互和MCP调用。我们的结果显示，与AndroidWorld相比，性能显著下降，最好的代理框架和端到端模型分别取得了51.7%和20.9%的成功率。我们的分析表明，当前模型在用户交互和MCP调用中存在重大挑战，这为实现更稳健的下一代移动智能提供了战略路线图。",
        "地址": "https://arxiv.org/pdf/2512.19432.pdf"
    },
    {
        "名称": "2025 [2512.18658] Does It Tie Out? Towards Autonomous Legal Agents in Venture Capital.pdf",
        "作者": "Pierre Colombo, Malik Boudiaf, Allyn Sweet, Michael Desa, Hongxi Wang, Kevin Candra, Syméon del Marmol",
        "摘要": "摘要：在闭合风险投资融资回合之前，律师会进行尽职调查，其中包括核实资本结构表：验证每个证券（例如股票、期权、认股权证）和发行条款（例如归属时间表、加速触发器、转让限制）都有大型的基础法律文件支持。尽管大语言模型在法律基准测试中不断改进，但专业的法律工作流程，如资本结构核准，即使是强大的代理系统也难以实现。这项任务需要多文档推理、严格的证据可追溯性和确定性的输出，而当前的方法无法可靠地实现这些要求。我们将资本结构核准表征为法律人工智能的现实世界基准实例，分析并比较现有代理系统的性能，并提出一种面向核准流程自动化的世界模型架构，更广泛地作为应用法律智能的基础。\n\n作者：Pierre Colombo, Malik Boudiaf, Allyn Sweet, Michael Desa, Hongxi Wang, Kevin Candra, Syméon del Marmol\n\n网址：https://arxiv.org/pdf/2512.18658.pdf\n\n标题：2025 [2512.18658] 它能核准吗？迈向风险投资中的自动化法律代理系统",
        "地址": "https://arxiv.org/pdf/2512.18658.pdf"
    },
    {
        "名称": "2025 [2512.19402] Real2Edit2Real: Generating Robotic Demonstrations via a 3D Control Interface.pdf",
        "作者": "Yujie Zhao, Hongwei Fan, Di Chen, Shengcong Chen, Liliang Chen, Xiaoqi Li, Guanghui Ren, Hao Dong",
        "摘要": "摘要: 最近机器人学习的进展受益于大规模数据集和强大的视觉运动策略架构，但策略的鲁棒性仍受限于收集多样化示范数据的高昂成本，尤其是在操作任务的空间泛化方面。为减少重复数据收集，我们提出了Real2Edit2Real框架，通过3D控制界面将3D编辑与2D视觉数据桥接，生成新的示范。我们的方法首先利用尺度级3D重建模型，根据多视角RGB观察重建场景几何。在重建的几何基础上，我们在点云上执行深度可靠的3D编辑，生成新的操作轨迹，同时在几何上校正机器人姿态以恢复物理一致的深度，作为合成新示范的可靠条件。最后，我们提出了一种多条件视频生成模型，以深度作为主要控制信号，结合动作、边缘和光线图，生成空间增强的多视角操作视频。对四个真实操作任务的实验表明，仅通过1-5个源示范生成的数据训练的策略，可以匹敌或超过通过50个真实示范训练的策略，将数据效率提高了最多10-50倍。此外，高度和纹理编辑的实验结果展示了该框架的灵活性和可扩展性，表明其有望作为统一的数据生成框架。",
        "地址": "https://arxiv.org/pdf/2512.19402.pdf"
    },
    {
        "名称": "2025 [2512.19535] CASA: Cross-Attention via Self-Attention for Efficient Vision-Language Fusion.pdf",
        "作者": "Moritz Böhle, Amélie Royer, Juliette Marrie, Edouard Grave, Patrick Pérez",
        "摘要": "摘要：视觉-语言模型(VLMs)通常通过将来自预训练视觉编码器的图像标记插入语言模型的文本流中进行训练。这使得文本和图像信息在模型中能够完全互相关注，但对于高分辨率图像、长对话或流视频来说，这在内存和计算上变得极其昂贵。利用交叉注意力的VLMs是标记插入的一种高效替代方案，但在涉及细粒度视觉细节的任务上表现出明显的性能差距。我们发现，提高此类模型性能的关键在于在专用的交叉注意力层中也启用局部文本到文本的交互。在此基础上，我们提出了CASA（通过自注意力的交叉注意力），这是一种简单且高效的范式，在常见的图像理解基准测试中大大缩小了与完全标记插入的差距，同时在应用于长上下文多模态任务（如流视频字幕）时享有与交叉注意力模型相同的可扩展性。有关示例和代码，请参阅我们的项目页面：https://arxiv.org/pdf/2512.19535.pdf。\n\n作者：Moritz Böhle, Amélie Royer, Juliette Marrie, Edouard Grave, Patrick Pérez\n\n标题：2025 [2512.19535] CASA：通过自注意力的交叉注意力实现高效的视觉-语言融合",
        "地址": "https://arxiv.org/pdf/2512.19535.pdf"
    },
    {
        "名称": "2025 [2512.18003] Name That Part: 3D Part Segmentation and Naming.pdf",
        "作者": "Soumava Paul, Prakhar Kaushik, Ankit Vaidya, Anand Bhattad, Alan Yuille",
        "摘要": "摘要：我们研究语义3D部件分割：将物体分解成具有有意义名称的部件。虽然存在具有部件标注的数据集，但数据集之间的定义不一致，限制了稳健训练。之前的方法生成未标注的分解或检索单个部件而没有完整的形状标注。我们提出了ALIGN-Parts，将部件命名任务表述为直接集对齐任务。我们的方法将形状分解成部件——隐含的3D部件表示——通过二分匹配与部件描述匹配。我们结合3D部件场的几何信息、多视角视觉特征的外观以及语言模型生成的便利描述的语义知识。文本对齐损失确保部件共享嵌入空间与文本，使得理论上开放词汇匹配设置成为可能，前提是有足够的数据。我们高效且新颖的一次性3D部件分割和命名方法在多个后续任务中找到应用，包括作为可扩展的标注引擎。由于我们的模型支持零样本匹配到任意描述及为已知类别提供信心校准预测，通过人工验证，我们创建了一个统一的本体，将PartNet, 3DCoMPaT++, 和 Find3D对齐，包含1794个独特的3D部件。我们还展示了我们新创建的Tex-Parts数据集中的示例。我们还介绍了两个适合命名3D部件分割任务的新指标。",
        "地址": "https://arxiv.org/pdf/2512.18003.pdf"
    },
    {
        "名称": "2025 [2512.18314] MatSpray: Fusing 2D Material World Knowledge on 3D Geometry.pdf",
        "作者": "Philipp Langsteiner, Jan-Niklas Dihlmann, Hendrik P.A. Lensch",
        "摘要": "摘要：手动建模材质参数和3D几何形状在游戏和电影行业中是一个耗时但必不可少的任务。尽管最近在3D重建方面的进展已经能够准确地近似场景几何和外观，但由于缺乏精确的、空间变化的材质参数，这些方法在重新曝光场景中往往表现不足。同时，在2D图像上的扩散模型在预测基于物理渲染（PBR）属性如反照率、粗糙度和金属度方面表现出色。然而，将这些2D材质图映射到重建的3D几何模型上仍然是一个重大挑战。我们提出了一种结合新颖的基于学习和基于投影的方法，将2D材质数据融合到3D几何中。我们首先通过高斯散点图重建场景几何。从输入图像中，扩散模型生成反照率、粗糙度和金属参数的2D图。任何能够将图像或视频转换为PBR材质的现有扩散模型都可以应用。预测结果通过优化基于图像的损失，或通过使用高斯射线追踪直接将材质参数投影到高斯点上进一步集成到3D表示中。为了增强精细刻画的准确性和多视角一致性，我们进一步引入一个轻量化的神经细化步骤（Neural Merger），该步骤以光线追踪的材质特征为输入，并进行细化调整。我们的结果表明，所提出的方法在定量指标和感知视觉真实感方面均优于现有技术。这使得从重建场景中实现更准确、可重新曝光和照片级真实感渲染，显著提高了内容制作流水线中资产创建工作的真实感和效率。",
        "地址": "https://arxiv.org/pdf/2512.18314.pdf"
    },
    {
        "名称": "2025 [2512.12620] Understanding Syllogistic Reasoning in LLMs from Formal and Natural Language Perspectives.pdf",
        "作者": "Aheli Poddar (1), Saptarshi Sahoo (2), Sujata Ghosh (2) ((1) Institute of Engineering & Management, Kolkata, (2) Indian Statistical Institute, Chennai)",
        "摘要": "摘要：我们从逻辑和自然语言的角度研究了大型语言模型（LLMs）的三段论推理。在此过程中，我们探讨了LLMs的基本推理能力及这一研究方向的发展。为了辅助我们的研究，我们使用了14种大型语言模型，调查了它们在符号推理和自然语言理解方面的三段论推理能力。尽管这种推理机制在不同的LLMs之间并不是一种统一的突现属性，但某些模型在符号推理方面的完美表现让我们不禁怀疑，LLMs是否正在越来越多地成为形式推理机制，而不是明确体现人类推理的细微差异。",
        "地址": "https://arxiv.org/pdf/2512.12620.pdf"
    },
    {
        "名称": "2025 [2512.19661] Over++: Generative Video Compositing for Layer Interaction Effects.pdf",
        "作者": "Luchao Qi, Jiaye Wu, Jun Myeong Choi, Cary Phillips, Roni Sengupta, Dan B Goldman",
        "摘要": "摘要：在专业的视频合成工作流程中，艺术家必须手动创建前景主体和背景层之间的环境互动效果，如阴影、反射、灰尘和飞溅等。现有的视频生成模型难以在添加此类效果的同时保持原始视频，而当前的视频修复方法要么需要高成本的逐帧掩膜，要么产生不可信的结果。我们引入了增强合成这一新任务，该任务在保持原始场景的同时，基于文本提示和输入视频层合成真实的半透明环境效果。为了解决这一任务，我们提出了Over++，一个视频效果生成框架，它不对摄像机姿态、场景稳定性或深度监督做出假设。我们构建了一个为此任务量身定制的成对效果数据集，并介绍了一种不成对的增强策略，保持了文本驱动的可编辑性。我们的方法还支持可选的掩膜控制和关键帧指导，无需密集标注。尽管在有限的数据上进行训练，Over++产生了多样且真实的环境效果，并在效果生成和场景保存方面均优于现有基准。\n\n作者：Luchao Qi, Jiaye Wu, Jun Myeong Choi, Cary Phillips, Roni Sengupta, Dan B Goldman\n\n评论：项目页面: [此处为URL链接]\n\n链接: [此处为PDF下载链接]\n\n标题：2025 [2512.19661] Over++: 用于层交互效果的生成性视频合成",
        "地址": "https://arxiv.org/pdf/2512.19661.pdf"
    },
    {
        "名称": "2025 [2512.19399] Brain-Grounded Axes for Reading and Steering LLM States.pdf",
        "作者": "Sandro Andric",
        "摘要": "摘要： 大型语言模型（LLMs）的可解释性方法通常从文本监督中得出方向，但这种方法可能缺乏外部基础。我们建议使用人类脑活动作为读取和引导LLM状态的坐标系而非训练信号。利用SMN4Lang MEG数据集，我们构建了一个基于相位锁定值（PLV）模式的单词级脑图谱，并通过ICA提取潜在轴。我们用独立词典和基于NER的标签（POS/日志频率用作理智检查）验证了这些轴，然后训练轻量级适配器，将LLM隐藏状态映射到这些脑轴，而无需微调LLM。沿着由此产生的脑衍生方向进行引导，在TinyLlama的一个中层产生了稳定的词汇（频率关联）轴，其在困惑度匹配的对照中保持不变，且脑轴与文本探针的比较显示，脑轴具有更低的困惑度和更大的日志频率变化（相对于文本探针）。在TinyLlama、Qwen2-0.5B和GPT-2中，功能/内容轴（轴13）显示出一致的引导效果，并在文本级别得到了困惑度匹配的证实。TinyLlama第4层的效果显著但不一致，因此我们将其视为次要（见附录）。当不使用GPT嵌入变化特征或使用word2vec嵌入重新构建图谱时，轴结构是稳定的（匹配轴的|r|=0.64-0.95），减少了循环性问题。探索性fMRI锚定表明嵌入变化和日志频率可能对齐，但效果对血流动力学建模假设敏感，仅作为群体级别证据处理。这些结果支持一个新界面：以神经生理学为基础的轴为LLM行为提供了可解释和可控的手柄。",
        "地址": "https://arxiv.org/pdf/2512.19399.pdf"
    },
    {
        "名称": "2025 [2512.18542] SecureCode v2.0: A Production-Grade Dataset for Training Security-Aware Code Generation Models.pdf",
        "作者": "Scott Thornton",
        "摘要": "摘要：\n\n人工智能助手在45%的安全相关场景中会生成脆弱代码，从而在大规模的生产系统中引入漏洞。然而，现有的安全编码数据集无法满足要求。它们缺乏事故背景，没有提供现代训练所需的规模，并且缺乏开发者在生产部署中需要的操作安全上下文。我们发布了SecureCode v2.0，这是一套通过结构验证和专业安全审核的生产级数据集，包含1215个安全性编码示例。每个示例都与实际记录的安全事件相关，提供了脆弱和安全的实现，展示了具体攻击，并包括深入防御的操作指导。该数据集涵盖了11种漏洞类别（完整的OWASP Top 10:2025加上AI/ML安全威胁），涉及11种语言（Python、JavaScript、Java、Go、PHP、C#、TypeScript、Ruby、Rust、Kotlin以及用于基础设施即代码的YAML）。\n\n我们的质量保证框架确保了完整的事故背景。每个示例都包括SIEM集成策略、基础设施加固建议（Docker、AppArmor、WAF配置），以及使用适合语言的框架进行测试的方法。数据集采用了4轮对话结构，模拟了实际开发者与人工智能的互动，从基本实现逐步升级到高级安全考虑和深入防御指导。\n\n我们的贡献：(1)1215个经过严格验证的示例，分为989个训练集，122个验证集和104个测试集，(2)一个自动化验证框架，以确保数据集的一致性，(3)捕捉真实安全工作流程的4轮对话结构，(4)全面的操作安全指导，包括SIEM集成策略，(5)完整的特定语言实现保真度，(6)数据、验证工具和基准协议的开源发布。",
        "地址": "https://arxiv.org/pdf/2512.18542.pdf"
    }
]