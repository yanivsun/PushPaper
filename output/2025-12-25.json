[
    {
        "名称": "2025 [2512.16093] TurboDiffusion: Accelerating Video Diffusion Models by 100-200 Times.pdf",
        "作者": "Jintao Zhang, Kaiwen Zheng, Kai Jiang, Haoxu Wang, Ion Stoica, Joseph E. Gonzalez, Jianfei Chen, Jun Zhu",
        "摘要": "摘要: 我们介绍了TurboDiffusion，这是一个能够加速端到端扩散生成100-200倍的视频生成加速框架，同时保持视频质量。TurboDiffusion 主要依赖于几个组件进行加速：(1) 注意力加速：TurboDiffusion 使用低位SageAttention和可训练的稀疏线性注意力(SLA)来加速注意力计算。(2) 步骤蒸馏：TurboDiffusion 采用rCM进行高效的步骤蒸馏。(3) W8A8量化：TurboDiffusion 将模型参数和激活量化为8位，以加速线性层并压缩模型。此外，TurboDiffusion 还结合了其他一些工程优化。我们在Wan2.2-I2V-14B-720P、Wan2.1-T2V-1.3B-480P、Wan2.1-T2V-14B-720P和Wan2.1-T2V-14B-480P模型上进行了实验。实验结果表明，TurboDiffusion 即使在单个RTX 5090 GPU上也能实现视频生成的100-200倍加速，同时保持可比的视频质量。包含模型检查点和易于使用代码的GitHub 仓库可在此链接找到。",
        "地址": "https://arxiv.org/pdf/2512.16093.pdf"
    },
    {
        "名称": "2025 [2512.20557] Learning to Reason in 4D: Dynamic Spatial Understanding for Vision Language Models.pdf",
        "作者": "Shengchao Zhou, Yuxin Chen, Yuying Ge, Wei Huang, Jiehong Lin, Ying Shan, Xiaojuan Qi",
        "摘要": "摘要: 视觉-语言模型（VLM）在一般理解方面表现出色，但在动态空间推理（DSR）方面仍较弱，即难以推理物体几何形状和关系随时间在三维空间中的演变，这主要是由于缺乏可扩展的4D意识训练资源。为了弥补数据集、基准测试和模型各方面的这一差距，我们引入了DSR套件。首先，我们提出了一种自动化流水线，用于从野外视频中生成DSR的多选问答对。通过利用现代视觉基础模型，流水线提取了丰富的几何和运动信息，包括相机姿态、局部点云、物体掩模、方向和三维轨迹。这些几何线索使得可以构建DSR-Train进行学习，并进一步由人类改进DSR-Bench用于评估。与先前的工作相比，我们的数据强调（i）野外视频来源，（ii）物体和场景级别的三维要求，（iii）视点转换，（iv）多物体交互，以及（v）细粒度的过程性答案。除了数据外，我们提出了一个轻量级几何选择模块（GSM），以无缝地将几何先验整合到VLM中，该模块将问题语义凝练并从预训练的4D重建先验中提取与问题相关的知识，压缩成一组紧凑的几何标记。这种有针对性的提取避免了模型被无关知识所淹没。实验表明，将DSR-Train和GSM集成到Qwen2.5-VL-7B中显著增强了其动态空间推理能力，同时保持了在一般视频理解基准测试中的准确性。",
        "地址": "https://arxiv.org/pdf/2512.20557.pdf"
    },
    {
        "名称": "2025 [2512.21252] DreaMontage: Arbitrary Frame-Guided One-Shot Video Generation.pdf",
        "作者": "Jiawei Liu, Junqiao Li, Jiangfan Deng, Gen Li, Siyu Zhou, Zetao Fang, Shanshan Lao, Zengde Deng, Jianing Zhu, Tingting Ma, Jiayi Li, Yunqiu Wang, Qian He, Xinglong Wu",
        "摘要": "摘要：'一镜到底'技术代表了一种独特且复杂的电影美学。然而，其实际实现往往受到高昂成本和现实环境复杂性的阻碍。尽管新兴的视频生成模型提供了虚拟替代方案，但现有方法通常依赖于简单的剪辑拼接，这往往无法保持视觉的平滑性和时间连贯性。在本文中，我们介绍了DreaMontage这一全面框架，旨在实现任意帧引导生成，能够从各种用户提供的输入中合成无缝、富有表现力和长时间的一镜到底视频。为实现这一目标，我们从三个主要维度应对挑战。(i) 我们在DiT架构中集成了一种轻量级的中间调控机制。通过采用有效利用基础训练数据的自适应调优策略，我们解锁了强大的任意帧控制能力。(ii) 为了提高视觉保真度和电影表现力，我们策划了一个高质量的数据集并实施了视觉表现SFT阶段。针对主体运动合理性和过渡平滑性等关键问题，我们应用了量身定制的DPO方案，显著提高了生成内容的成功率和可用性。(iii) 为了便于延长序列的生成，我们设计了一种内存高效的分段自回归推理策略。大量实验表明，我们的方法在保持计算效率的同时，成功实现了视觉上引人注目和无缝连贯的一镜到底效果，赋予用户将零散视觉材料转化为生动、连贯的一镜到底电影体验的能力。",
        "地址": "https://arxiv.org/pdf/2512.21252.pdf"
    },
    {
        "名称": "2025 [2512.21094] T2AV-Compass: Towards Unified Evaluation for Text-to-Audio-Video Generation.pdf",
        "作者": "Zhe Cao, Tao Wang, Jiaming Wang, Yanghai Wang, Yuanxing Zhang, Jialu Chen, Miao Deng, Jiahao Wang, Yubin Guo, Chenxi Liao, Yize Zhang, Zhaoxiang Zhang, Jiaheng Liu",
        "摘要": "摘要：文本到音视频生成（T2AV）旨在从自然语言合成时间上连贯的视频和语义上同步的音频，但其评估仍然零散，通常依赖单模态指标或范围狭窄的基准，无法捕捉跨模态对齐、指令遵循和在复杂提示下的感知现实主义。为了应对这一限制，我们提出了T2AV-Compass，一种用于全面评估T2AV系统的统一基准，由通过分类驱动的流程构建的500个多样且复杂的提示组成，以确保语义丰富性和物理合理性。此外，T2AV-Compass引入了一个双层评估框架，将视频质量、音频质量和跨模态对齐的客观信号级指标与主观的MLLM-评审协议相结合，以评估指令遵循和现实主义。对11个代表性T2AV系统的广泛评估表明，即使是最强的模型也远远达不到人类水平的现实主义和跨模态一致性，存在音频现实主义、细粒度同步、指令遵循等持续性缺陷。这些结果表明未来模型有显著的改进空间，并强调T2AV-Compass作为推动文本到音视频生成的挑战性和诊断测试床的价值。",
        "地址": "https://arxiv.org/pdf/2512.21094.pdf"
    },
    {
        "名称": "2025 [2512.21337] Beyond Memorization: A Multi-Modal Ordinal Regression Benchmark to Expose Popularity Bias in Vision-Language Models.pdf",
        "作者": "Li-Zhong Szu-Tu, Ting-Lin Wu, Chia-Jui Chang, He Syu, Yu-Lun Liu",
        "摘要": "摘要：我们揭示了最先进的视觉-语言模型（Vision-Language Models, VLMs）中的显著流行度偏倚，这些模型在识别著名建筑物时的准确率比普通建筑物高出多达34%，表明它们依赖于记忆而非可推广的理解。为系统地研究这个问题，我们引入了该任务的最大公开基准：YearGuessr数据集。此数据集包含来自157个国家的55,546张建筑图片，具有多模态属性，并附有建筑年份（1001-2024）、GPS数据和页面浏览次数作为流行度的代理。使用该数据集，我们将建筑年份预测任务建模为序数回归，并引入流行度感知的区间准确度指标来量化这种偏倚。我们对30多个模型（包括我们的YearCLIP模型）进行基准测试，结果证实VLMs在识别流行、记忆中的项目上表现优异，但在识别不知名对象时表现出显著困难，揭示了它们推理能力中的关键缺陷。项目页面：本https URL",
        "地址": "https://arxiv.org/pdf/2512.21337.pdf"
    },
    {
        "名称": "2025 [2512.21338] HiStream: Efficient High-Resolution Video Generation via Redundancy-Eliminated Streaming.pdf",
        "作者": "Haonan Qiu, Shikun Liu, Zijian Zhou, Zhaochong An, Weiming Ren, Zhiheng Liu, Jonas Schult, Sen He, Shoufa Chen, Yuren Cong, Tao Xiang, Ziwei Liu, Juan-Manuel Perez-Rua",
        "摘要": "摘要：高分辨率视频生成对数字媒体和电影至关重要，但扩散模型的二次复杂性使得实际推理不可行，因此在计算上成为瓶颈。为了解决这个问题，我们引入HiStream，这是一种高效的自回归框架，通过三个轴系统地减少冗余：i) 空间压缩：在低分辨率下去噪，然后通过缓存特征在高分辨率下进行细化；ii) 时间压缩：通过固定大小的锚缓存，以块为单位策略，确保稳定的推理速度；以及iii) 时间步压缩：对后续的、缓存调节的块应用较少的去噪步骤。在1080p基准测试中，我们的主要HiStream模型（i+ii）在视觉质量方面达到了最先进的水平，同时与Wan2.1基线相比，实现了高达76.2倍的去噪速度提升，并且质量损失微乎其微。我们的更快速变体HiStream+应用了所有三种优化（i+ii+iii），相对于基线实现了107.5倍的加速，提供了速度和质量之间的极具吸引力的权衡，从而使高分辨率视频生成变得既实用又可扩展。",
        "地址": "https://arxiv.org/pdf/2512.21338.pdf"
    },
    {
        "名称": "2025 [2512.20848] Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning.pdf",
        "作者": "NVIDIA: Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Faisal Ladhak, Fay Wang, Fei Jia, Felipe Soares, Feng Chen, Ferenc Galko, Frankie Siino, Gal Hubara Agam, Ganesh Ajjanagadde, Gantavya Bhatt\n\n\n        , Gargi Prasad, George Armstrong, Gerald Shen, Gorkem Batmaz, Grigor Nalbandyan, Haifeng Qian, Harsh Sharma, Hayley Ross, Helen Ngo, Herman Sahota, Hexin Wang, Himanshu Soni, Hiren Upadhyay, Huizi Mao, Huy C Nguyen, Huy Q Nguyen, Iain Cunningham, Ido Shahaf, Igor Gitman, Ilya Loshchilov, Ivan Moshkov, Izzy Putterman, Jan Kautz, Jane Polak Scowcroft, Jared Casper, Jatin Mitra, Jeffrey Glick, Jenny Chen, Jesse Oliver, Jian Zhang, Jiaqi Zeng, Jie Lou, Jimmy Zhang, Jining Huang, Joey Conway, Joey Guman, John Kamalu, Johnny Greco, Jonathan Cohen, Joseph Jennings, Joyjit Daw, Julien Veron Vialard, Junkeun Yi, Jupinder Parmar, Kai Xu, Kan Zhu, Kari Briski, Katherine Cheung, Katherine Luna, Keshav Santhanam, Kevin Shih, Kezhi Kong, Khushi Bhardwaj, Krishna C. Puvvada, Krzysztof Pawelec, Kumar Anik, Lawrence McAfee, Laya Sleiman, Leon Derczynski, Li Ding, Lucas Liebenwein, Luis Vega, Maanu Grover, Maarten Van Segbroeck, Maer Rodrigues de Melo, Makesh Narsimhan Sreedhar, Manoj Kilaru, Maor Ashkenazi, Marc Romeijn, Mark Cai, Markus Kliegl, Maryam Moosaei, Matvei Novikov, Mehrzad Samadi, Melissa Corpuz, Mengru Wang, Meredith Price, Michael Boone, Michael Evans, Miguel Martinez, Mike Chrzanowski, Mohammad Shoeybi, Mostofa Patwary, Nabin Mulepati, Natalie Hereth, Nave Assaf, Negar Habibi, Neta Zmora, Netanel Haber, Nicola Sessions, Nidhi Bhatia, Nikhil Jukar, Nikki Pope, Nikolai Ludwig, Nima Tajbakhsh, Nirmal Juluru, Oleksii Hrinchuk, Oleksii Kuchaiev, Olivier Delalleau, Oluwatobi Olabiyi, Omer Ullman Argov, Ouye Xie, Parth Chadha, Pasha Shamis, Pavlo Molchanov, Pawel Morkisz, Peter Dykas, Peter Jin, Pinky Xu, Piotr Januszewski, Pranav Prashant Thombre, Prasoon Varshney, Pritam Gundecha, Qing Miao, Rabeeh Karimi Mahabadi, Ran El-Yaniv, Ran Zilberstein, Rasoul Shafipour, Rich Harang, Rick Izzo, Rima Shahbazyan, Rishabh Garg, Ritika Borkar, Ritu Gala, Riyad Islam, Roger Waleffe, Rohit Watve, Roi Koren, Ruoxi Zhang, Russell J. Hewett, Ryan Prenger, Ryan Timbrook, Sadegh Mahdavi, Sahil Modi, Samuel Kriman, Sanjay Kariyappa, Sanjeev Satheesh, Saori Kaji, Satish Pasumarthi, Sean Narentharen, Sean Narenthiran, Seonmyeong Bak, Sergey Kashirsky, Seth Poulos, Shahar Mor, Shanmugam Ramasamy, Shantanu Acharya, Shaona Ghosh, Sharath Turuvekere Sreenivas, Shelby Thomas, Shiqing Fan, Shreya Gopal, Shrimai Prabhumoye, Shubham Pachori, Shubham Toshniwal, Shuoyang Ding, Siddharth Singh, Simeng Sun, Smita Ithape, Somshubra Majumdar, Soumye Singhal, Stefania Alborghetti, Stephen Ge, Sugam Dipak Devare, Sumeet Kumar Barua, Suseella Panguluri, Suyog Gupta, Sweta Priyadarshi, Syeda Nahida Akter, Tan Bui, Teodor-Dumitru Ene, Terry Kong, Thanh Do, Tijmen Blankevoort, Tom Balough, Tomer Asida, Tomer Bar Natan, Tugrul Konuk, Twinkle Vashishth, Udi Karpas, Ushnish De, Vahid Noorozi, Vahid Noroozi, Venkat Srinivasan, Venmugil Elango, Vijay Korthikanti, Vitaly Kurin, Vitaly Lavrukhin, Wanli Jiang, Wasi Uddin Ahmad, Wei Du, Wei Ping, Wenfei Zhou, Will Jennings, William Zhang, Wojciech Prazuch, Xiaowei Ren, Yashaswi Karnati, Yejin Choi, Yev Meyer, Yi-Fu Wu, Yian Zhang, Ying Lin, Yonatan Geifman, Yonggan Fu, Yoshi Subara, Yoshi Suhara, Yubo Gao, Zach Moshe, Zhen Dong, Zihan Liu, Zijia Chen, Zijie Yan\n\n\n    et al. (213 additional authors not shown)\n You must enable JavaScript to view entire author list.",
        "摘要": "摘要：本文介绍了Nemotron 3 Nano 30B-A3B，这是一种混合的Mamba-Transformer语言模型。Nemotron 3 Nano在超过25万亿个文本标记上进行了预训练，其中包括比Nemotron 2多出3万亿的新独特标记，随后进行了有监督的微调和在多样化环境中的大规模强化学习。Nemotron 3 Nano的准确性优于上一代Nemotron 2 Nano，同时每次前向传递的参数激活数量不到其一半。与类似规模的开放模型（如GPT-OSS-20B和Qwen3-30B-A3B-Thinking-2507）相比，它的推理吞吐量高达3.3倍，并且在流行基准测试中的表现更加准确。Nemotron 3 Nano展现了出色的代理性、推理和聊天能力，并支持长度高达1百万个标记的上下文。我们在Hugging Face上发布了预训练的Nemotron 3 Nano 30B-A3B Base和后训练的Nemotron 3 Nano 30B-A3B检验点。",
        "地址": "https://arxiv.org/pdf/2512.20848.pdf"
    },
    {
        "名称": "2025 [2512.20856] NVIDIA Nemotron 3: Efficient and Open Intelligence.pdf",
        "作者": "NVIDIA: Aaron Blakeman, Aaron Grattafiori, Aarti Basant, Abhibha Gupta, Abhinav Khattar, Adi Renduchintala, Aditya Vavre, Akanksha Shukla, Akhiad Bercovich, Aleksander Ficek, Aleksandr Shaposhnikov, Alex Kondratenko, Alexander Bukharin, Alexandre Milesi, Ali Taghibakhshi, Alisa Liu, Amelia Barton, Ameya Sunil Mahabaleshwarkar, Amir Klein, Amit Zuker, Amnon Geifman, Amy Shen, Anahita Bhiwandiwalla, Andrew Tao, Anjulie Agrusa, Ankur Verma, Ann Guan, Anubhav Mandarwal, Arham Mehta, Ashwath Aithal, Ashwin Poojary, Asif Ahamed, Asit Mishra, Asma Kuriparambil Thekkumpate, Ayush Dattagupta, Banghua Zhu, Bardiya Sadeghi, Barnaby Simkin, Ben Lanir, Benedikt Schifferer, Besmira Nushi, Bilal Kartal, Bita Darvish Rouhani, Boris Ginsburg, Brandon Norick, Brandon Soubasis, Branislav Kisacanin, Brian Yu, Bryan Catanzaro, Carlo del Mundo, Chantal Hwang, Charles Wang, Cheng-Ping Hsieh, Chenghao Zhang, Chenhan Yu, Chetan Mungekar, Chintan Patel, Chris Alexiuk, Christopher Parisien, Collin Neale, Cyril Meurillon, Damon Mosk-Aoyama, Dan Su, Dane Corneil, Daniel Afrimi, Daniel Lo, Daniel Rohrer, Daniel Serebrenik, Daria Gitman, Daria Levy, Darko Stosic, David Mosallanezhad, Deepak Narayanan, Dhruv Nathawani, Dima Rekesh, Dina Yared, Divyanshu Kakwani, Dong Ahn, Duncan Riach, Dusan Stosic, Edgar Minasyan, Edward Lin, Eileen Long, Eileen Peters Long, Elad Segal, Elena Lantz, Ellie Evans, Elliott Ning, Eric Chung, Eric Harper, Eric Tramel, Erick Galinkin, Erik Pounds, Evan Briones, Evelina Bakhturina, Evgeny Tsykunov, Faisal Ladhak, Fay Wang, Fei Jia\n\n\n        , Felipe Soares, Feng Chen, Ferenc Galko, Frank Sun, Frankie Siino, Gal Hubara Agam, Ganesh Ajjanagadde, Gantavya Bhatt, Gargi Prasad, George Armstrong, Gerald Shen, Gorkem Batmaz, Grigor Nalbandyan, Haifeng Qian, Harsh Sharma, Hayley Ross, Helen Ngo, Herbert Hum, Herman Sahota, Hexin Wang, Himanshu Soni, Hiren Upadhyay, Huizi Mao, Huy C Nguyen, Huy Q Nguyen, Iain Cunningham, Ido Galil, Ido Shahaf, Igor Gitman, Ilya Loshchilov, Itamar Schen, Itay Levy, Ivan Moshkov, Izik Golan, Izzy Putterman, Jan Kautz, Jane Polak Scowcroft, Jared Casper, Jatin Mitra, Jeffrey Glick, Jenny Chen, Jesse Oliver, Jian Zhang, Jiaqi Zeng, Jie Lou, Jimmy Zhang, Jinhang Choi, Jining Huang, Joey Conway, Joey Guman, John Kamalu, Johnny Greco, Jonathan Cohen, Joseph Jennings, Joyjit Daw, Julien Veron Vialard, Junkeun Yi, Jupinder Parmar, Kai Xu, Kan Zhu, Kari Briski, Katherine Cheung, Katherine Luna, Keith Wyss, Keshav Santhanam, Kevin Shih, Kezhi Kong, Khushi Bhardwaj, Kirthi Shankar, Krishna C. Puvvada, Krzysztof Pawelec, Kumar Anik, Lawrence McAfee, Laya Sleiman, Leon Derczynski, Li Ding, Lizzie Wei, Lucas Liebenwein, Luis Vega, Maanu Grover, Maarten Van Segbroeck, Maer Rodrigues de Melo, Mahdi Nazemi, Makesh Narsimhan Sreedhar, Manoj Kilaru, Maor Ashkenazi, Marc Romeijn, Marcin Chochowski, Mark Cai, Markus Kliegl, Maryam Moosaei, Matt Kulka, Matvei Novikov, Mehrzad Samadi, Melissa Corpuz, Mengru Wang, Meredith Price, Michael Andersch, Michael Boone, Michael Evans, Miguel Martinez, Mikail Khona, Mike Chrzanowski, Minseok Lee, Mohammad Dabbah, Mohammad Shoeybi, Mostofa Patwary, Nabin Mulepati, Najeeb Nabwani, Natalie Hereth, Nave Assaf, Negar Habibi, Neta Zmora, Netanel Haber, Nicola Sessions, Nidhi Bhatia, Nikhil Jukar, Nikki Pope, Nikolai Ludwig, Nima Tajbakhsh, Nir Ailon, Nirmal Juluru, Nishant Sharma, Oleksii Hrinchuk, Oleksii Kuchaiev, Olivier Delalleau, Oluwatobi Olabiyi, Omer Ullman Argov, Omri Puny, Oren Tropp, Ouye Xie, Parth Chadha, Pasha Shamis, Paul Gibbons, Pavlo Molchanov, Pawel Morkisz, Peter Dykas, Peter Jin, Pinky Xu, Piotr Januszewski, Pranav Prashant Thombre, Prasoon Varshney, Pritam Gundecha, Przemek Tredak, Qing Miao, Qiyu Wan, Rabeeh Karimi Mahabadi, Rachit Garg, Ran El-Yaniv, Ran Zilberstein, Rasoul Shafipour, Rich Harang, Rick Izzo, Rima Shahbazyan, Rishabh Garg, Ritika Borkar, Ritu Gala, Riyad Islam, Robert Hesse, Roger Waleffe, Rohit Watve, Roi Koren, Ruoxi Zhang, Russell Hewett, Russell J. Hewett, Ryan Prenger, Ryan Timbrook, Sadegh Mahdavi, Sahil Modi, Samuel Kriman, Sangkug Lim, Sanjay Kariyappa, Sanjeev Satheesh, Saori Kaji, Satish Pasumarthi, Saurav Muralidharan, Sean Narentharen, Sean Narenthiran, Seonmyeong Bak, Sergey Kashirsky, Seth Poulos, Shahar Mor, Shanmugam Ramasamy, Shantanu Acharya, Shaona Ghosh, Sharath Turuvekere Sreenivas, Shelby Thomas, Shiqing Fan, Shreya Gopal, Shrimai Prabhumoye, Shubham Pachori, Shubham Toshniwal, Shuoyang Ding, Siddharth Singh, Simeng Sun, Smita Ithape, Somshubra Majumdar, Soumye Singhal, Stas Sergienko, Stefania Alborghetti, Stephen Ge, Sugam Dipak Devare, Sumeet Kumar Barua, Suseella Panguluri, Suyog Gupta, Sweta Priyadarshi, Syeda Nahida Akter, Tan Bui, Teodor-Dumitru Ene, Terry Kong, Thanh Do, Tijmen Blankevoort, Tim Moon, Tom Balough, Tomer Asida, Tomer Bar Natan, Tomer Ronen, Tugrul Konuk, Twinkle Vashishth, Udi Karpas, Ushnish De, Vahid Noorozi, Vahid Noroozi, Venkat Srinivasan, Venmugil Elango, Victor Cui, Vijay Korthikanti, Vinay Rao, Vitaly Kurin, Vitaly Lavrukhin, Vladimir Anisimov, Wanli Jiang, Wasi Uddin Ahmad, Wei Du, Wei Ping, Wenfei Zhou, Will Jennings, William Zhang, Wojciech Prazuch, Xiaowei Ren, Yashaswi Karnati, Yejin Choi, Yev Meyer, Yi-Fu Wu, Yian Zhang, Yigong Qin, Ying Lin, Yonatan Geifman, Yonggan Fu, Yoshi Subara, Yoshi Suhara, Yubo Gao, Zach Moshe, Zhen Dong, Zhongbo Zhu, Zihan Liu, Zijia Chen, Zijie Yan\n\n\n    et al. (258 additional authors not shown)\n You must enable JavaScript to view entire author list.",
        "摘要": "摘要：我们介绍了Nemotron 3系列的模型 - Nano、Super和Ultra。这些模型提供了强大的代理性、推理和对话能力。Nemotron 3系列使用一种Mixture-of-Experts混合Mamba-Transformer架构，提供一流的吞吐量和长达1M个token的上下文长度。Super和Ultra模型经过NVFP4训练，结合LatentMoE，这是一种提升模型质量的新方法。这两个更大的模型还包括MTP层，从而加快文本生成速度。所有Nemotron 3模型都经过多环境强化学习后训练，能够进行推理、使用多步骤工具和支持细化推理预算控制。Nano是最小的模型，在准确性方面优于同类模型，同时在推断方面保持极高的成本效益。Super优化用于协同代理和大批量工作负载，例如IT票务自动化。Ultra是最大的模型，提供最先进的准确性和推理性能。Nano与其技术报告和白皮书一起发布，而Super和Ultra将在未来几个月推出。我们将公开发布模型权重、训练前和训练后的软件、配方，以及所有我们拥有再分发权的数据。\n\n网址：https://arxiv.org/pdf/2512.20856.pdf\n题目：2025 [2512.20856] NVIDIA Nemotron 3: Efficient and Open Intelligence.pdf\n作者：NVIDIA团队 et al. (258 additional authors not shown)",
        "地址": "https://arxiv.org/pdf/2512.20856.pdf"
    },
    {
        "名称": "2025 [2512.20757] TokSuite: Measuring the Impact of Tokenizer Choice on Language Model Behavior.pdf",
        "作者": "Gül Sena Altıntaş, Malikeh Ehghaghi, Brian Lester, Fengyuan Liu, Wanru Zhao, Marco Ciccone, Colin Raffel",
        "摘要": "摘要: 分词器为语言模型 (LMs) 表示和处理文本提供了基本基础。尽管分词非常重要，但由于难以孤立地测量分词的影响，它在 LM 性能和行为中的作用仍然知之甚少。为了解决这一需求，我们提出了 TokSuite，这是一套支持研究分词对 LMs 影响的模型和基准测试。具体来说，我们训练了十四种使用不同分词器但在其他方面完全相同的模型，采用相同的架构、数据集、训练预算和初始化。此外，我们策划并发布了一个新的基准测试，该测试专门测量模型在受实际扰动影响时的性能，这些扰动可能会影响分词。TokSuite 这一整套工具允许稳健地剥离模型分词器的影响，支持一系列新发现，阐明了广泛流行的分词器各自的优点和缺点。",
        "地址": "https://arxiv.org/pdf/2512.20757.pdf"
    },
    {
        "名称": "2025 [2512.21004] Learning from Next-Frame Prediction: Autoregressive Video Modeling Encodes Effective Representations.pdf",
        "作者": "Jinghan Li, Yang Jin, Hao Jiang, Yadong Mu, Yang Song, Kun Xu",
        "摘要": "摘要：近期在预训练通用基础模型方面的进展显著提升了各种下游任务的表现。尽管GPT等自回归（AR）生成模型革新了自然语言处理（NLP），大多数视觉生成预训练方法仍依赖于BERT风格的掩码建模，这通常忽视了对视频分析至关重要的时间信息。现有的少数自回归视觉预训练方法存在语义定位不准确和生成质量差的问题，导致语义效果不佳。在这项工作中，我们提出了NExT-Vid，一种利用掩码下一帧预测来联合建模图像和视频的新颖自回归视觉生成预训练框架。NExT-Vid引入了一个上下文隔离的自回归预测器来将语义表示与目标解码分离，和一个条件流匹配解码器来增强生成质量和多样性。通过上下文隔离的流匹配预训练，我们的方法实现了强大的表示。在大规模预训练模型上的广泛实验表明，我们提出的方法在通过下游分类中的注意探测方面，持续优于以前的视觉表示学习生成预训练方法。",
        "地址": "https://arxiv.org/pdf/2512.21004.pdf"
    },
    {
        "名称": "2025 [2512.18832] From Word to World: Can Large Language Models be Implicit Text-based World Models?.pdf",
        "作者": "Yixia Li, Hongru Wang, Jiahao Qiu, Zhenfei Yin, Dongdong Zhang, Cheng Qian, Zeping Li, Pony Ma, Guanhua Chen, Heng Ji, Mengdi Wang",
        "摘要": "摘要：代理强化学习日益依赖于基于经验的扩展，然而现实世界环境仍然是非自适应的，覆盖范围有限且难以扩展。世界模型提供了一种通过模拟经验来提高学习效率的潜在方法，但尚不清楚大规模语言模型能否可靠地发挥这一作用，以及在何种条件下它们能为代理带来实质性的好处。我们在文本环境中研究这些问题，这些环境提供了一个受控的环境，将语言建模重新诠释为交互下的下一个状态预测。我们引入了一个三层框架来评估基于LLM的世界模型：(i) 保真度和一致性，(ii) 可扩展性和鲁棒性，(iii) 代理的实用性。在五个代表性环境中，我们发现经过充分训练的世界模型能够维持一致的潜在状态，随着数据和模型规模的扩大可预测性地扩展，并通过行动验证、合成轨迹生成和温启动强化学习来提高代理的表现。同时，这些收益在很大程度上依赖于行为覆盖和环境复杂性，明确了世界建模有效支持代理学习的边界。\n\n翻译后的中文摘要如下：\n代理强化学习日益依赖基于经验的扩展，然而现实世界环境仍然是非自适应的、覆盖范围有限且难以扩展。世界模型提供了一种通过模拟经验来提高学习效率的潜在方法，但大规模语言模型是否能可靠地发挥这一作用以及在什么条件下能为代理带来实质性收益仍不清楚。我们在文本环境中研究了这些问题，这些环境提供了一个受控的环境，将语言建模重新解释为交互下的下一个状态预测。我们引入了一个三层框架来评估基于LLM的世界模型：（i）保真度和一致性，（ii）可扩展性和鲁棒性，（iii）代理的实用性。在五个具有代表性的环境中，我们发现经过充分训练的世界模型能够维持连贯的潜在状态，随着数据和模型规模的扩展具有可预测性，并通过行动验证、合成轨迹生成和温启动强化学习提升代理表现。同时，这些收益在很大程度上依赖于行为覆盖和环境复杂性，明确了世界建模有效支持代理学习的界限。",
        "地址": "https://arxiv.org/pdf/2512.18832.pdf"
    },
    {
        "名称": "2025 [2512.19012] DramaBench: A Six-Dimensional Evaluation Framework for Drama Script Continuation.pdf",
        "作者": "Shijian Ma, Yunqi Huang, Yan Lin",
        "摘要": "摘要：戏剧剧本续写需要模型保持角色一致性、合理推进剧情并保留戏剧结构，这些能力现有基准无法全面评估。我们提出了DramaBench，这是第一个用于评估戏剧剧本续写的六个独立维度的大规模基准：格式标准、叙事效率、角色一致性、情感深度、逻辑一致性和冲突处理。我们的框架结合了基于规则的分析与基于大型语言模型（LLM）的标记和统计指标，确保客观和可重复的评价。我们对8个最先进的语言模型进行了全面评估，涉及1103份剧本（总计8824次评估），并进行了严格的统计显著性测试（252次成对比较，其中65.9%显著）和人工验证（188份剧本，在5个维度中有3个达成重大共识）。我们的消融研究证实所有六个维度均捕捉到独立的质量方面（平均|r|=0.020）。DramaBench为模型改进提供了可操作的、特定维度的反馈，并为创意写作评估建立了严格的标准。",
        "地址": "https://arxiv.org/pdf/2512.19012.pdf"
    },
    {
        "名称": "2025 [2512.21334] Streaming Video Instruction Tuning.pdf",
        "作者": "Jiaer Xia, Peixian Chen, Mengdan Zhang, Xing Sun, Kaiyang Zhou",
        "摘要": "摘要: 我们介绍了Streamo，这是一款实时流媒体视频的LLM，被设计为通用互动助手。与现有的在线视频模型仅限于问答或字幕生成不同，Streamo能够执行广泛的流视频任务，包括实时讲解、动作理解、事件字幕、时间事件定位以及时间敏感问答。为了开发这样的多功能性，我们构建了Streamo-Instruct-465K，这是一个专门为流视频理解设计的大规模指令遵循数据集。该数据集涵盖了多种时间上下文和多任务监督，允许在不同的流媒体任务中统一训练。经过端到端地在指令遵循数据集上进行简化流水线训练后，Streamo表现出强大的时间推理、响应式互动以及在多种流媒体基准测试中的广泛泛化能力。大量实验显示Streamo弥合了离线视频感知模型和实时多模态助手之间的差距，迈向连续视频流中统一智能视频理解的目标。",
        "地址": "https://arxiv.org/pdf/2512.21334.pdf"
    },
    {
        "名称": "2025 [2512.20144] Multi-hop Reasoning via Early Knowledge Alignment.pdf",
        "作者": "Yuxin Wang, Shicheng Fang, Bo Wang, Qi Luo, Xuanjing Huang, Yining Zheng, Xipeng Qiu",
        "摘要": "摘要：检索增强生成（Retrieval-Augmented Generation, RAG）技术逐渐成为大型语言模型（Large Language Models, LLMs）处理需要领域特定或最新信息的知识密集型查询的强大范式。为了处理单步检索困难的复杂多跳问题，提出了结合强化学习的迭代RAG方法。然而，现有的迭代RAG系统通常在不利用可用检索语料信息的情况下计划分解问题，导致低效的检索和推理链，进而导致次优性能。在本文中，我们引入了早期知识对齐（Early Knowledge Alignment, EKA）模块，这是一种简单有效的模块，在迭代RAG系统中规划前，与上下文相关检索知识对LLMs进行对齐。对六个标准RAG数据集的广泛实验表明，通过建立强大的推理基础，EKA显著提高了检索精度，减少了层叠错误，并增强了性能和效率。从熵的角度进行的分析表明，早期知识的引入减少了推理过程中不必要的探索，使模型能更有效地聚焦于相关信息子集。此外，EKA作为一种通用的、无需训练的推理策略，能够无缝扩展到大型模型。各类数据集和检索语料的泛化测试验证了我们方法的稳健性。总体而言，EKA推进了迭代RAG系统的最新水平，同时揭示了在强化学习增强框架中结构化推理与高效探索之间的重要相互作用。代码已发布于\\\\href{this https URL}{Github}。",
        "地址": "https://arxiv.org/pdf/2512.20144.pdf"
    },
    {
        "名称": "2025 [2512.18470] SWE-EVO: Benchmarking Coding Agents in Long-Horizon Software Evolution Scenarios.pdf",
        "作者": "Minh V. T. Thai, Tue Le, Dung Nguyen Manh, Huy Phan Nhat, Nghi D. Q. Bui",
        "摘要": "摘要：现有的AI编程代理基准测试专注于孤立的单一任务，例如修复一个错误或实现一个小功能。然而，现实世界的软件工程从根本上来说是一个长远的过程：开发人员必须解释高级需求，计划在多文件之间协调更改，并在多次迭代中演变代码库，同时保留现有功能。我们引入了SWE-EVO，这是一个评估代理在这种长远软件进化挑战下的基准。SWE-EVO基于七个成熟的开源Python项目的发布说明和版本历史构建，包含48个进化任务，要求代理实现跨平均21个文件的多步骤修改，并通过覆盖平均874个测试的全面测试套件进行验证。实验结果显示，即使是最先进的模型（例如搭载OpenHands的GPT-5）在SWE-EVO上的解决率仅为21%，而在单一任务的SWE-Bench上的验证率为65%。这表明当前的代理在持续的多文件推理方面存在显著的能力差距。我们还提出了修复率，一个细粒度的指标，用于捕捉这些复杂的长期任务部分解决的进展。",
        "地址": "https://arxiv.org/pdf/2512.18470.pdf"
    },
    {
        "名称": "2025 [2512.21227] PhononBench:A Large-Scale Phonon-Based Benchmark for Dynamical Stability in Crystal Generation.pdf",
        "作者": "Xiao-Qi Han, Ze-Feng Gao, Peng-Jie Guo, Zhong-Yi Lu",
        "摘要": "摘要：在这项工作中，我们介绍了PhononBench，这是第一个针对AI生成晶体动态稳定性的大规模基准。借助最近开发的MatterSim原子间势，它在超过10,000种材料的声子预测中达到了DFT级精度，PhononBench使得对108,843个由六个主要晶体生成模型生成的晶体结构进行大规模声子计算和动态稳定性分析变得高效。PhononBench揭示了当前生成模型在确保动态稳定性方面的普遍限制：所有生成结构的平均动态稳定性率仅为25.83%，表现最好的模型MatterGen仅达到41.0%。进一步的案例研究表明，在特性定向生成中，例如通过MatterGen进行带隙条件化生成，在最佳带隙条件0.5 eV情况下，动态稳定性率仍然低至23.5%。在空间组控制生成中，高对称性晶体表现出更好的稳定性（例如，立方系统实现率高达49.2%），但所有控制生成的平均稳定性仍然只有34.4%。这项研究的另一个重要成果是识别出28,119个在整个布里渊区都具有声子稳定性的晶体结构，为未来的材料探索提供了大量可靠候选。通过建立第一个大规模动态稳定性基准，这项工作系统地凸显了晶体生成模型的当前局限性，并为其未来朝着物理上可行的材料的设计和发现提供了必要的评估标准和指导。所有模型生成的晶体结构、声子计算结果以及PhononBench中开发的高通量评估工作流将在此https URL公开发布。",
        "地址": "https://arxiv.org/pdf/2512.21227.pdf"
    },
    {
        "名称": "2025 [2512.21010] LLM Swiss Round: Aggregating Multi-Benchmark Performance via Competitive Swiss-System Dynamics.pdf",
        "作者": "Jiashuo Liu, Jiayun Wu, Chunjie Wu, Jingkai Liu, Zaiyuan Wang, Huan Zhou, Wenhao Huang, Hongseok Namkoong",
        "摘要": "摘要: 大型语言模型（LLMs）和多样化的专用基准测试的快速普及，要求从分散的、特定任务的指标转向一种能够有效整合多种能力维度的整体竞争排名系统。目前主要使用静态评分的评价方法在根本上是有限的。它们难以确定跨越不同基准测试的适当混合比率，且在面对连续的高风险任务时，无法有效捕捉一个模型的动态竞争适应性或其脆弱性。为了解决这些问题，我们提出了新的竞争瑞士系统动力学（CSD）框架。CSD模拟了一个多轮次、连续的竞赛，模型根据其累积的胜负记录在精心挑选的基准测试序列中进行动态配对。蒙特卡洛模拟（$N=100,000$ 次迭代）被用来近似统计稳健的预期胜分（$E[S_m]$），消除了随机配对和早期回合运气带来的噪音。此外，我们通过参数化每回合淘汰数量（$T_k$）实施了失效敏感性分析，这使我们能够根据模型的风险偏好对其进行分析——区分强健的通才和激进的专家。我们展示了CSD提供了一种比传统聚合评分和静态成对模型更为细腻且符合语境的排名方式，代表了朝着风险知情的下一代LLM评价迈出的重要一步。",
        "地址": "https://arxiv.org/pdf/2512.21010.pdf"
    }
]