[
    {
        "名称": "2025 [2512.21218] Latent Implicit Visual Reasoning.pdf",
        "作者": "Kelvin Li, Chuyi Shang, Leonid Karlinsky, Rogerio Feris, Trevor Darrell, Roei Herzig",
        "摘要": "摘要: 尽管大型多模态模型（LMMs）取得了显著进展，但它们仍然主要以文本为中心，依赖语言作为其核心推理方式。因此，它们在处理主要依赖视觉的推理任务时能力有限。最近的一些方法试图通过使用辅助图像、深度图或图像裁剪来监督中间视觉步骤，以解决这一问题。然而，这些策略对“有用”的视觉抽象表现施加了限制性先验，增加了繁重的标注成本，并难以跨任务推广。为了解决这一关键限制，我们提出了一种无需显式监督，训练LMMs发现和使用视觉推理标记的任务无关机制。这些标记可以全局关注并以任务自适应的方式重新编码图像，使模型能够在没有手工监督的情况下提取相关的视觉信息。我们的方法优于直接微调，并在各种以视觉为中心的任务上取得了最先进的结果——包括那些中间抽象难以定义的任务——同时也推广到多任务指令调整。",
        "地址": "https://arxiv.org/pdf/2512.21218.pdf"
    },
    {
        "名称": "2025 [2512.20605] Emergent temporal abstractions in autoregressive models enable hierarchical reinforcement learning.pdf",
        "作者": "Seijin Kobayashi, Yanick Schimpf, Maximilian Schlegel, Angelika Steger, Maciej Wolczyk, Johannes von Oswald, Nino Scherrer, Kaitlin Maile, Guillaume Lajoie, Blake A. Richards, Rif A. Saurous, James Manyika, Blaise Agüera y Arcas, Alexander Meulemans, João Sacramento",
        "摘要": "摘要: 通过下一个标记预测预训练并通过强化学习（RL）微调的大规模自回归模型在许多问题领域取得了前所未有的成功。在RL期间，这些模型通过一次生成一个新输出标记来进行探索。然而，逐个标记采样动作可能导致学习效率极低，特别是在奖励稀疏的情况下。在这里，我们展示了可以通过在自回归模型的内部表示中进行动作和探索来克服这个问题。具体来说，为了发现时间抽象动作，我们引入了一个高阶非因果序列模型，其输出控制基础自回归模型的残差流激活。在具有层次结构的网格世界和基于MuJoCo的任务中，我们发现高阶模型学会将长激活序列块压缩到内部控制器上。关键是，每个控制器执行一系列行为上有意义的动作，这些动作在长时间尺度上展开，并伴随学习到的终止条件，因此随着时间的推移组合多个控制器能够在新任务上进行高效探索。我们表明直接内部控制器强化（一种我们称为“内部RL”的过程）能够在标准RL微调失败的情况下从稀疏奖励中学习。我们的结果展示了在自回归模型中生成潜在动作和强化的好处，建议内部RL作为在基础模型内实现层次RL的一个有前景的途径。",
        "地址": "https://arxiv.org/pdf/2512.20605.pdf"
    },
    {
        "名称": "2025 [2512.15716] Spatia: Video Generation with Updatable Spatial Memory.pdf",
        "作者": "Jinjing Zhao, Fangyun Wei, Zhening Liu, Hongyang Zhang, Chang Xu, Yan Lu",
        "摘要": "摘要：现有的视频生成模型由于视频信号的密集、高维特性，在维持长期的空间和时间一致性方面面临挑战。为了克服这一局限性，我们提出了Spatia，这是一种空间记忆感知的视频生成框架，它明确地将3D场景点云作为持久的空间记忆进行保存。Spatia在此空间记忆的条件下迭代生成视频片段，并通过视觉SLAM不断更新它。这种动态-静态分离设计在整个生成过程中增强了空间一致性，同时保持了模型生成真实动态实体的能力。此外，Spatia实现了诸如显式的摄像机控制和3D感知交互编辑等应用，提供了一个几何上有基础、可扩展的记忆驱动的视频生成框架。",
        "地址": "https://arxiv.org/pdf/2512.15716.pdf"
    },
    {
        "名称": "2025 [2512.19995] Schoenfeld's Anatomy of Mathematical Reasoning by Language Models.pdf",
        "作者": "Ming Li, Chenrui Fan, Yize Cheng, Soheil Feizi, Tianyi Zhou",
        "摘要": "摘要：大型语言模型越来越多地展示出推理轨迹，但它们的底层认知结构和步骤仍然难以识别和分析，仅限于表面级别的统计数据。我们采用Schoenfeld的情节理论作为一个归纳的、中尺度的视角，并引入ThinkARM（模型推理剖析），这是一个可扩展的框架，将推理轨迹明确抽象为类似分析、探索、实施、验证等功能性推理步骤。当应用于不同模型的数学问题求解时，这种抽象揭示了推理模型和非推理模型之间的重复思维动态和结构差异，而这些差异在标记级别视图中并不明显。我们进一步展示了两个诊断案例研究，表明探索作为与正确性相关的关键分支步骤，而效率导向的方法选择性地抑制评估反馈步骤，而不是统一地缩短响应。综上所述，我们的研究结果表明，情节级别表示使推理步骤明确化，能够系统地分析现代语言模型中推理的结构、稳定性和变化。\n\n翻译：\t        \n大型语言模型越来越多地展示出推理轨迹，但其底层认知结构和步骤仍然难以辨识和分析，超过了表面级别的统计数据。我们采用 Schoenfeld 的情节理论作为归纳的、中尺度的视角，并引入 ThinkARM（模型推理的解剖结构），这是一个可扩展的框架，将推理轨迹明确抽象为例如分析、探索、实现、验证等功能性推理步骤。当应用于不同模型解决数学问题时，这种抽象揭示了推理模型与非推理模型之间的可复现思维动态和结构差异，这些差异在标记级别的视图中并不明显。我们进一步展示了两个诊断案例研究，表明探索是与正确性相关的关键分支步骤，而效率导向的方法选择性地抑制评估反馈步骤，而非统一地缩短响应。总的来说，我们的结果表明，情节级别的表示使推理步骤明确化，从而能够系统地分析现代语言模型中推理的结构、稳定性和变化。",
        "地址": "https://arxiv.org/pdf/2512.19995.pdf"
    },
    {
        "名称": "2025 [2512.19949] How Much 3D Do Video Foundation Models Encode?.pdf",
        "作者": "Zixuan Huang, Xiang Li, Zhaoyang Lv, James M. Rehg",
        "摘要": "摘要：视频是3D世界的连续2D投影。在对大量视频数据进行训练后，是否会自然产生全球3D理解？我们通过量化现有视频基础模型（VidFMs）在大量视频数据上预训练后的3D理解来研究这一点。我们提出了首个与模型无关的框架，通过浅层读取从其特征中估算多个3D属性来衡量各种VidFMs的3D意识。我们的研究在多维度上展示了关于VidFMs 3D意识的重要发现。特别是，我们表明，尽管最先进的视频生成模型并未在任何3D数据上进行训练，但它们对3D对象和场景表现出了较强的理解。这种理解甚至可以超越专门为3D任务训练的大型专家模型。我们的发现以及主要VidFMs的3D基准测试，为构建可扩展的3D模型提供了宝贵的观察结果。\n\n作者: 黄子轩, 李翔, 吕朝阳, James M. Rehg\n\n评论: 项目页面: 该https URL",
        "地址": "https://arxiv.org/pdf/2512.19949.pdf"
    },
    {
        "名称": "2025 [2512.19680] VA-$π$: Variational Policy Alignment for Pixel-Aware Autoregressive Generation.pdf",
        "作者": "Xinyao Liao, Qiyuan He, Kai Xu, Xiaoye Qu, Yicong Li, Wei Wei, Angela Yao",
        "摘要": "摘要：自回归（AR）视觉生成依赖于标记器将图像映射到离散序列并进行相应的反映。然而，标记器的训练目的是从真实标记中重构清晰图像，而AR生成器则仅优化标记的似然性。这种不一致性导致生成的标记序列可能解码为低质量图像，而没有像素空间的直接监督。我们提出了VA-$π$，一个轻量级的后训练框架，直接通过有原则的像素空间目标优化AR模型。VA-$π$将生成器和标记器的对齐表示为变分优化，推导出统一像素重构和自回归建模的证据下界（ELBO）。为了在离散标记空间下进行优化，VA-$π$引入了一种基于强化的对齐策略，将AR生成器视为策略，使用像素空间重构质量作为其内在奖励。这种奖励通过教师强制（teacher forcing）来测量预测的标记序列在多大程度上能重构原始图像，为模型提供直接的像素级指导，而无需耗费大量资源进行自由采样。ELBO的正则项作为自然的正则器，保持标记的分布一致性。VA-$π$使现有AR生成器能够快速适应，无需重新训练标记器或外部奖励模型。仅用1%的ImageNet-1K数据和25分钟的调整时间，它将LlamaGen-XXL的FID从14.36降至7.65，将IS从86.55提升至116.70，同时在GenEval上的文本生成任务中，视觉生成模型（LlamaGen：从0.306到0.339）和统一多模态模型（Janus-Pro：从0.725到0.744）也有显著提升。代码可在此https URL获取。\n\n作者：廖欣瑶、何启元、徐凯、曲小叶、李义聪、魏薇、姚安琪\n\n备注：21页，24幅图\n\n链接：https://arxiv.org/pdf/2512.19680.pdf\n\n标题：2025 [2512.19680] VA-$π$：像素感知的自回归生成的变分策略对齐。",
        "地址": "https://arxiv.org/pdf/2512.19680.pdf"
    },
    {
        "名称": "2025 [2512.13043] GTR-Turbo: Merged Checkpoint is Secretly a Free Teacher for Agentic VLM Training.pdf",
        "作者": "Tong Wei, Yijun Yang, Changhao Zhang, Junliang Xing, Yuanchun Shi, Zongqing Lu, Deheng Ye",
        "摘要": "摘要：多轮强化学习（RL）在基于视觉-语言模型（VLMs）的多模态代理中受限于稀疏的奖励和长时间的信用分配。最近的方法通过查询提供步骤级反馈的教师模型来增加奖励密度，例如指导思想强化学习（GTR）和策略内蒸馏，但依赖于昂贵且常常拥有特权的模型作为教师，限制了其实用性和可重复性。我们引入了GTR-Turbo，这是GTR的高效升级版，其性能匹配无需训练或查询昂贵的教师模型。具体而言，GTR-Turbo合并了正在进行的RL训练期间产生的检查点的权重，然后使用这个合并的模型作为“免费”教师通过监督微调或软逻辑蒸馏来指导后续的RL。这种设计消除了对特权VLMs（例如GPT或Gemini）的依赖，缓解了先前工作中观察到的“熵崩塌”问题，并保持训练的稳定性。在各种视觉代理任务中，GTR-Turbo在提高基线模型准确率10-30%的同时，相较于GTR减少了50%的实际训练时间和60%的计算成本。\n\n作者：魏通，杨宜君，张昌浩，邢俊良，石元春，卢宗庆，叶德恒\n\nURL：https://arxiv.org/pdf/2512.13043.pdf\n\n标题：2025年 [2512.13043] GTR-Turbo：合并检查点秘密地成为代理VLM训练的免费教师",
        "地址": "https://arxiv.org/pdf/2512.13043.pdf"
    }
]