[
    {
        "名称": "2025 [2512.24880] mHC: Manifold-Constrained Hyper-Connections.pdf",
        "作者": "Zhenda Xie, Yixuan Wei, Huanqi Cao, Chenggang Zhao, Chengqi Deng, Jiashi Li, Damai Dai, Huazuo Gao, Jiang Chang, Liang Zhao, Shangyan Zhou, Zhean Xu, Zhengyan Zhang, Wangding Zeng, Shengding Hu, Yuqing Wang, Jingyang Yuan, Lean Wang, Wenfeng Liang",
        "摘要": "摘要：近年来，以超连接（Hyper-Connections, HC）为代表的研究，通过扩展残差流宽度和多样化连接模式，拓展了过去十年间建立的无处不在的残差连接范式。尽管这种多样化带来了显著的性能提升，但从根本上破坏了残差连接固有的恒等映射属性，导致训练不稳定性和可扩展性受限，并且额外带来了显著的内存访问开销。为应对此类挑战，我们提出了流形约束超连接（Manifold-Constrained Hyper-Connections, mHC），这是一个通用框架，通过将HC的残差连接空间投射到特定流形上以恢复恒等映射属性，同时结合严谨的基础设施优化以确保效率。实验证明，mHC在大规模训练中是有效的，提供了可观的性能改进和优越的可扩展性。我们预计，作为对HC的灵活实用的扩展，mHC将有助于更深入地理解拓扑架构设计，并为基础模型的演进提出了有前景的方向。",
        "地址": "https://arxiv.org/pdf/2512.24880.pdf"
    },
    {
        "名称": "2025 [2512.24618] Youtu-LLM: Unlocking the Native Agentic Potential for Lightweight Large Language Models.pdf",
        "作者": "Junru Lu, Jiarui Qin, Lingfeng Qiao, Yinghui Li, Xinyi Dai, Bo Ke, Jianfeng He, Ruizhi Qiao, Di Yin, Xing Sun, Yunsheng Wu, Yinsong Liu, Shuangyin Liu, Mingkong Tang, Haodong Lin, Jiayi Kuang, Fanxu Meng, Xiaojuan Tang, Yunjia Xi, Junjie Huang, Haotong Yang, Zhenyi Shen, Yangning Li, Qianwen Zhang, Yifei Yu, Siyu An, Junnan Dong, Qiufeng Wang, Jie Wang, Keyu Chen, Wei Wen, Taian Guo, Zhifeng Shen, Daohai Yu, Jiahao Li, Ke Li, Zongyi Li, Xiaoyu Tan",
        "摘要": "摘要：我们介绍了Youtu-LLM，这是一种轻量级但功能强大的语言模型，结合了高计算效率与本土代理智能。与依赖蒸馏的小模型不同，Youtu-LLM（1.96B）从头开始预训练，以系统培养推理和规划能力。其关键技术进步如下：(1) 具有长上下文支持的紧凑架构：基于一个密集的多潜在注意（MLA）架构，采用新颖的面向STEM的词汇，Youtu-LLM支持128k上下文窗口。该设计在最小内存占用的情况下，实现了强大的长上下文推理和状态跟踪，非常适合长时任务和推理任务。(2) 原则性的“常识-STEM-代理”课程：我们策划了一个大约11T标记的庞大语料库，并实施了多阶段训练策略。通过逐步将预训练数据分布从一般常识转向复杂的STEM和代理任务，确保模型获得深层认知能力，而非表面对齐。(3) 可扩展的代理中期训练：专门针对中期训练，我们采用了多样的数据构造方案，在数学、编码和工具使用领域生成丰富多样的轨迹。这些高质量数据使得模型能够有效地内化计划和反思行为。广泛的评估显示，Youtu-LLM为亚2B LLMs设定了新的行业标准。在一般基准上，它表现出与较大型模型的竞争力，而在特定的代理任务上，它显著超越了现有的最先进基线，表明轻量级模型也可以具备强大的内在代理能力。",
        "地址": "https://arxiv.org/pdf/2512.24618.pdf"
    },
    {
        "名称": "2025 [2512.24873] Let It Flow: Agentic Crafting on Rock and Roll, Building the ROME Model within an Open Agentic Learning Ecosystem.pdf",
        "作者": "Weixun Wang, XiaoXiao Xu, Wanhe An, Fangwen Dai, Wei Gao, Yancheng He, Ju Huang, Qiang Ji, Hanqi Jin, Xiaoyang Li, Yang Li, Zhongwen Li, Shirong Lin, Jiashun Liu, Zenan Liu, Tao Luo, Dilxat Muhtar, Yuanbin Qu, Jiaqiang Shi, Qinghui Sun, Yingshui Tan, Hao Tang, Runze Wang, Yi Wang, Zhaoguo Wang, Yanan Wu, Shaopan Xiong, Binchen Xu, Xander Xu, Yuchi Xu, Qipeng Zhang, Xixia Zhang, Haizhou Zhao, Jie Zhao, Shuaibing Zhao, Baihui Zheng, Jianhui Zheng, Suhang Zheng, Yanni Zhu, Mengze Cai, Kerui Cao, Xitong Chen, Yue Dai, Lifan Du, Tao Feng, Tao He, Jin Hu, Yijie Hu, Ziyu Jiang, Cheng Li, Xiang Li, Jing Liang, Chonghuan Liu, ZhenDong Liu, Haodong Mi, Yanhu Mo, Junjia Ni, Shixin Pei, Jingyu Shen, XiaoShuai Song, Cecilia Wang, Chaofan Wang, Kangyu Wang, Pei Wang, Tao Wang, Wei Wang, Ke Xiao, Mingyu Xu, Tiange Xu, Nan Ya, Siran Yang, Jianan Ye, Yaxing Zang, Duo Zhang, Junbo Zhang, Boren Zheng, Wanxi Deng, Ling Pan, Lin Qu, Wenbo Su, Jiamang Wang, Wei Wang, Hu Wei, Minggang Wu, Cheng Yu, Bing Zhao, Zhicheng Zheng, Bo Zheng",
        "摘要": "摘要：代理性设计要求大型语言模型（LLMs）在现实环境中通过多次回合操作，通过采取行动、观察结果并迭代精炼作品来进行操作。尽管重要，但开源社区缺乏一个系统性的端到端生态系统来简化代理开发。我们介绍了代理性学习生态系统（ALE），这是一个优化代理LLMs生产管道的基础设施。ALE由三个组件组成：ROLL，一个用于权重优化的后训练框架；ROCK，一个用于轨迹生成的沙盒环境管理器；以及iFlow CLI，一个用于高效上下文工程的代理框架。我们发布了ROME（ROME明显是一个代理模型），这是一个由ALE支撑并基于超过一百万轨迹训练的开源代理。我们的方法包括用于综合复杂行为的数据组成协议以及一种新颖的策略优化算法——基于交互的策略对齐（IPA），该算法分配信用到语义交互块而不是单个标记，从而提高长时间训练的稳定性。从经验上看，我们在结构化环境中评估了ROME，并介绍了Terminal Bench Pro，一个具有改进规模和污染控制的基准。ROME在诸如SWE-bench Verified和Terminal Bench的基准中表现强劲，证明了ALE基础设施的有效性。\n\n翻译为中文：代理性设计要求大型语言模型（LLMs）在现实环境中通过多次回合操作，通过采取行动、观察结果并迭代精炼作品来进行操作。尽管重要，但开源社区缺乏一个系统性的端到端生态系统来简化代理开发。我们介绍了代理性学习生态系统（ALE），这是一个优化代理LLMs生产管道的基础设施。ALE由三个组件组成：ROLL，一个用于权重优化的后训练框架；ROCK，一个用于轨迹生成的沙盒环境管理器；以及iFlow CLI，一个用于高效上下文工程的代理框架。我们发布了ROME（ROME明显是一个代理模型），这是一个由ALE支撑并基于超过一百万轨迹训练的开源代理。我们的方法包括用于综合复杂行为的数据组成协议以及一种新颖的策略优化算法——基于交互的策略对齐（IPA），该算法分配信用到语义交互块而不是单个标记，从而提高长时间训练的稳定性。从经验上看，我们在结构化环境中评估了ROME，并介绍了Terminal Bench Pro，一个具有改进规模和污染控制的基准。ROME在诸如SWE-bench Verified和Terminal Bench的基准中表现强劲，证明了ALE基础设施的有效性。",
        "地址": "https://arxiv.org/pdf/2512.24873.pdf"
    },
    {
        "名称": "2025 [2512.25073] GaMO: Geometry-aware Multi-view Diffusion Outpainting for Sparse-View 3D Reconstruction.pdf",
        "作者": "Yi-Chuan Huang, Hao-Jen Chien, Chin-Yang Lin, Ying-Huan Chen, Yu-Lun Liu",
        "摘要": "摘要：近年来，3D重建在利用密集多视图图像进行高质量场景捕捉方面取得了显著进展，但在输入视角有限的情况下仍存在困难。为了解决这一挑战，各种方法包括正则化技术、语义先验和几何约束已被实施。最新的基于扩散的方法通过从新的摄像机位置生成新的视角以增加训练数据，显示出显着改进，超越了早期的正则化和先验技术。尽管取得了进展，我们发现这些最先进方法存在三个关键限制：已知视角外围之外的覆盖不足、生成视角之间的几何不一致性，以及计算代价高昂的流程。我们介绍了GaMO（GaMO Geometry-aware Multi-view Outpainter），一个通过多视图外绘重新构造稀疏视图重建的框架。GaMO不是生成新的视点，而是从现有摄像机位置扩展视野，从而本质上保持几何一致性，同时提供更广泛的场景覆盖。我们的方法在不需训练的情况下采用多视图调理和几何感知去噪策略进行了零样本的实验。Replica和ScanNet++上的广泛实验表明，在3、6和9个输入视图的情况下，重建质量达到最先进水平，在PSNR和LPIPS方面超过了先前的方法，同时在处理时间上比最先进的基于扩散的方法快25倍，处理时间在10分钟以内。项目页面：这个https网址。",
        "地址": "https://arxiv.org/pdf/2512.25073.pdf"
    },
    {
        "名称": "2025 [2512.23380] A unified framework for detecting point and collective anomalies in operating system logs via collaborative transformers.pdf",
        "作者": "Mohammad Nasirzadeh, Jafar Tahmoresnezhad, Parviz Rashidi-Khazaee",
        "摘要": "摘要：日志异常检测对于维护操作系统的安全至关重要。根据日志数据收集的来源，各种信息记录在日志中，可以视为日志模态。鉴于这种直觉，单模态方法常常忽略日志数据的不同模态，遇到困难。同时，多模态方法无法处理这些模态之间的互动。我们针对日志异常检测提出了 CoLog 这一框架，利用多种模态协同编码日志。CoLog 采用协同变压器和多头注意力机制学习多个模态之间的互动，确保全面的异常检测。为了处理因这些互动引起的异质性，CoLog 导入了模态适应层，它能够调整来自不同日志模态的表示。这种方法使 CoLog 能够学习数据中的复杂模式和依赖性，提升其异常检测能力。大量实验证实了 CoLog 相对于现有最先进方法的优越性。此外，在检测点异常和集合异常方面，CoLog在七个日志异常检测基准数据集上取得了99.63%的平均精度、99.59%的平均召回率和99.61%的平均F1值。CoLog 出色的检测能力使其非常适用于网络安全、系统监控和运营效率。CoLog 代表了日志异常检测的重要进步，通过统一框架为点异常和集合异常检测提供了一种复杂且有效的解决方案，解决了自动日志数据分析带来的复杂挑战。我们也在此提供了 CoLog 的实现。",
        "地址": "https://arxiv.org/pdf/2512.23380.pdf"
    },
    {
        "名称": "2025 [2512.25070] Scaling Open-Ended Reasoning to Predict the Future.pdf",
        "作者": "Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping",
        "摘要": "摘要: 高风险决策涉及在对未来存在不确定性时进行推理。在本研究中，我们训练语言模型在开放式预测问题上进行预测。为了扩展训练数据，我们从每日新闻报道的全球事件中合成了新颖的预测问题，使用了一个完全自动化、精心策划的流程。我们在我们的数据集OpenForesight上训练了Qwen3思维模型。为了在训练和评估期间防止未来信息泄漏，我们使用了一个离线新闻语料库，用于预测系统中的数据生成和检索。在一个小型验证集的指导下，我们展示了检索的益处以及改进的强化学习（RL）奖励函数。一旦获得最终的预测系统，我们在2025年5月至8月期间进行了保留测试。我们专门化的模型OpenForecaster 8B与规模更大的专有模型相匹配，通过我们的训练提高了预测的准确性、校准和一致性。我们发现，通过预测训练改善的校准在流行基准上具有广泛适用性。我们开源了所有模型、代码和数据，以使语言模型预测的研究能够广泛获得。\n\n作者: Nikhil Chandak, Shashwat Goel, Ameya Prabhu, Moritz Hardt, Jonas Geiping\n\n页面数: 45页\n\n链接: [https://arxiv.org/pdf/2512.25070.pdf](https://arxiv.org/pdf/2512.25070.pdf)\n\n标题: 2025 [2512.25070] 将开放式推理扩展到预测未来",
        "地址": "https://arxiv.org/pdf/2512.25070.pdf"
    },
    {
        "名称": "2025 [2512.24551] PhyGDPO: Physics-Aware Groupwise Direct Preference Optimization for Physically Consistent Text-to-Video Generation.pdf",
        "作者": "Yuanhao Cai, Kunpeng Li, Menglin Jia, Jialiang Wang, Junzhe Sun, Feng Liang, Weifeng Chen, Felix Juefei-Xu, Chu Wang, Ali Thabet, Xiaoliang Dai, Xuan Ju, Alan Yuille, Ji Hou",
        "摘要": "摘要：近期文本生成视频（T2V）的研究取得了良好的视觉质量，但生成严格遵循物理规律的视频仍然是一个未解的挑战。现有的方法主要基于图形或提示扩展，难以超越简单的模拟环境或学习隐含的物理推理。此外，含有丰富物理交互和现象的训练数据也比较匮乏。在本文中，我们首先介绍了一种物理增强的视频数据构建流程（PhyAugPipe），它利用链式思维推理的视觉语言模型（VLM）来收集大规模训练数据集PhVidGen-135K。然后我们提出了一个有原则的物理感知组内直接偏好优化（PhyGDPO）框架，该框架建立在群体Plackett-Luce概率模型的基础上，以捕获超越成对比较的整体偏好。在PhyGDPO中，我们设计了一种物理引导奖励（PGR）机制，将基于VLM的物理奖励嵌入优化过程，以引导物理一致性。此外，我们还提出了一种LoRA-切换参考（LoRA-SR）方案，通过消除内存密集型的参考重复来提高训练效率。实验表明，我们的方法在PhyGenBench和VideoPhy2上显著优于最先进的开源方法。请访问我们的项目页面查看更多视频结果。我们的代码、模型和数据将发布在此HTTPS URL。",
        "地址": "https://arxiv.org/pdf/2512.24551.pdf"
    },
    {
        "名称": "2025 [2512.23343] AI Meets Brain: Memory Systems from Cognitive Neuroscience to Autonomous Agents.pdf",
        "作者": "Jiafeng Liang, Hao Li, Chang Li, Jiaqi Zhou, Shixin Jiang, Zekun Wang, Changkai Ji, Zhihao Zhu, Runxuan Liu, Tao Ren, Jinlan Fu, See-Kiong Ng, Xia Liang, Ming Liu, Bing Qin",
        "摘要": "摘要：记忆是连接过去与未来的关键枢纽，为人类和人工智能系统提供了宝贵的概念和经验，以应对复杂任务。近期关于自主代理的研究越来越关注通过借鉴认知神经科学设计高效的记忆工作流。然而，由于跨学科障碍，现有工作难以吸收人类记忆机制的精髓。为弥合这一差距，我们系统地综合了记忆的跨学科知识，将认知神经科学的见解与大语言模型（LLM）驱动的代理结合起来。具体而言，我们首先沿着从认知神经科学到大语言模型再到代理的递进轨迹，阐明了记忆的定义和功能。然后，我们从生物学和人工角度，提供了记忆分类、存储机制和完整管理生命周期的比较分析。随后，我们回顾了评估代理记忆的主流基准。此外，我们还从攻击和防御的双重视角探讨了记忆安全性。最后，我们展望了未来的研究方向，重点关注多模态记忆系统和技能获取。",
        "地址": "https://arxiv.org/pdf/2512.23343.pdf"
    },
    {
        "名称": "2025 [2512.24210] GR-Dexter Technical Report.pdf",
        "作者": "Ruoshi Wen, Guangzeng Chen, Zhongren Cui, Min Du, Yang Gou, Zhigang Han, Liqun Huang, Mingyu Lei, Yunfei Li, Zhuohang Li, Wenlei Liu, Yuxiao Liu, Xiao Ma, Hao Niu, Yutao Ouyang, Zeyu Ren, Haixin Shi, Wei Xu, Haoxiang Zhang, Jiajun Zhang, Xiao Zhang, Liwei Zheng, Weiheng Zhong, Yifei Zhou, Zhengming Zhu, Hang Li",
        "摘要": "摘要：视觉-语言-动作（VLA）模型已经实现了基于语言控制的长时视界机器人操作，但现有的大多数系统仅限于使用抓手。将VLA策略扩展到具有高自由度（DoF）灵巧手的双手机器人仍然具有挑战性，这是由于其扩展的动作空间、频繁的手-物体遮挡以及收集真实机器人数据的成本问题。我们提出了一种基于VLA的全方位硬件-模型-数据框架，名为GR-Dexter，用于双手灵巧手机器人的通用操作。我们的方法结合了紧凑的21自由度机器人手设计、用于采集真实机器人数据的直观双手遥操作系统，以及一种利用遥操作机器人轨迹的大规模视觉语言和精心策划的跨体数据集的训练配方。在针对长时视界日常操作和具备广泛适应性的拾放任务的现实世界评估中，GR-Dexter在域内表现强劲，并对未知物体和未知指令表现出较好的鲁棒性。我们希望GR-Dexter能成为实现通用灵巧手机器人操作的切实一步。",
        "地址": "https://arxiv.org/pdf/2512.24210.pdf"
    },
    {
        "名称": "2025 [2512.23988] Fantastic Reasoning Behaviors and Where to Find Them: Unsupervised Discovery of the Reasoning Process.pdf",
        "作者": "Zhenyu Zhang, Shujian Zhang, John Lambert, Wenxuan Zhou, Zhangyang Wang, Mingqing Chen, Andrew Hard, Rajiv Mathews, Lun Wang",
        "摘要": "摘要：尽管近期的大型语言模型（LLMs）日益增强了推理能力，但其在推理过程中的内部机制仍未被充分探索。先前的方法通常依赖于由人为定义的概念（例如，过度思考、反思）在单词层面进行监督式分析。然而，这些方法存在局限性，因为无法全面捕捉潜在推理行为的全部光谱，其中许多行为在词元空间内难以定义。在本研究中，我们提出了一种无监督框架（即RISE：通过稀疏自编码器解析推理行为），用于发现推理向量，我们将其定义为在激活空间中编码不同推理行为的方向。通过将思维链迹段分为句子级“步骤”并在步骤级激活上训练稀疏自编码器（SAEs），我们揭示了与可解释行为（如反思和回溯）相对应的解缠特征。可视化和聚类分析显示，这些行为占据了解码器列空间中的可分离区域。此外，对SAE派生向量的定向干预可以可控地放大或抑制特定的推理行为，而无需重新训练。除了特定行为的解缠外，SAEs还捕捉到诸如响应长度等结构属性，揭示了长与短推理轨迹的聚类。更有趣的是，SAEs能够发现超越人工监督的新行为。我们通过在SAE解码器空间中识别与置信度相关的向量，展示了控制响应置信度的能力。这些发现强调了无监督潜在发现对解释和可控引导LLMs推理的潜力。",
        "地址": "https://arxiv.org/pdf/2512.23988.pdf"
    },
    {
        "名称": "2025 [2512.23851] Pretraining Frame Preservation in Autoregressive Video Memory Compression.pdf",
        "作者": "Lvmin Zhang, Shengqu Cai, Muyang Li, Chong Zeng, Beijia Lu, Anyi Rao, Song Han, Gordon Wetzstein, Maneesh Agrawala",
        "摘要": "摘要：我们提出了一种神经网络结构PFP，用于将长视频压缩成短上下文，该结构具有显式预训练目标，以在任意时间位置保留单个帧的高频细节。基线模型可以将20秒的视频压缩成约5k长度的上下文，并且可以随意检索帧并保持感知上的逼真性。这类预训练模型可以直接微调作为自回归视频模型的记忆编码器，从而在保持低上下文成本和相对较低的保真度损失的情况下，实现长历史记忆。我们通过消融实验评估了该框架，并讨论了可能的神经架构设计的权衡取舍。",
        "地址": "https://arxiv.org/pdf/2512.23851.pdf"
    },
    {
        "名称": "2025 [2512.25075] SpaceTimePilot: Generative Rendering of Dynamic Scenes Across Space and Time.pdf",
        "作者": "Zhening Huang, Hyeonho Jeong, Xuelin Chen, Yulia Gryaditskaya, Tuanfeng Y. Wang, Joan Lasenby, Chun-Hao Huang",
        "摘要": "摘要：我们介绍了SpaceTimePilot，这是一种视频扩散模型，可以在空间和时间上解耦，实现可控生成渲染。给定单目视频，SpaceTimePilot可以在生成过程中独立改变相机视角和运动序列，重新渲染场景，以便在空间和时间上进行连续和任意的探索。为此，我们在扩散过程中引入了一种有效的动画时间嵌入机制，允许对输出视频的运动序列进行显式控制，以匹配源视频的运动序列。由于没有数据集提供具有连续时间变化的同一动态场景的配对视频，我们提出了一种简单但有效的时间扭曲训练方案，重新利用现有的多视角数据集来模拟时间差异。这一策略有效地监督模型学习时间控制，实现在空间和时间上的强健解耦。为了进一步提高双重控制的精度，我们引入了两个额外的组件：一种改进的相机条件机制，可以从第一帧开始改变相机，以及CamxTime，这是第一个提供场景内完全自由的时空视频轨迹的合成时空全覆盖渲染数据集。在时间扭曲方案和CamxTime数据集上进行联合训练可以获得更精确的时间控制。我们在真实数据和合成数据上对SpaceTimePilot进行评估，结果显示与以往工作相比，空间和时间解耦更加明显，效果更好。\n\n作者：黄贞宁、韩宪浩、陈雪琳、尤利娅·格里亚迪茨卡娅、王团峰、琼·拉森比、黄俊豪\n\n评论：项目页面: [链接] 代码: [链接]\n\n网址：https://arxiv.org/pdf/2512.25075.pdf\n\n标题：SpaceTimePilot：跨空间和时间的动态场景生成渲染",
        "地址": "https://arxiv.org/pdf/2512.25075.pdf"
    },
    {
        "名称": "2025 [2512.22905] JavisGPT: A Unified Multi-modal LLM for Sounding-Video Comprehension and Generation.pdf",
        "作者": "Kai Liu, Jungang Li, Yuchong Sun, Shengqiong Wu, Jianzhang Gao, Daoan Zhang, Wei Zhang, Sheng Jin, Sicheng Yu, Geng Zhan, Jiayi Ji, Fan Zhou, Liang Zheng, Shuicheng Yan, Hao Fei, Tat-Seng Chua",
        "摘要": "摘要：本文介绍了JavisGPT，这是第一个用于音频-视频联合理解和生成的统一多模态大语言模型（MLLM）。JavisGPT采用简洁的编码器-LLM-解码器架构，具有一个用于时空音视频融合的SyncFusion模块和同步感知可学习查询，以连接预训练的JAV-DiT生成器。该设计能够根据多模态指令实现时间上连贯的视频-音频理解和生成。我们设计了一个有效的三阶段训练管道，包括多模态预训练、音视频微调和大规模指令微调，从现有的视觉-语言模型逐步建立多模态理解和生成。为支持这一点，我们进一步构建了JavisInst-Omni，这是一个高质量的指令数据集，包含超过20万个GPT-4o编排的音频-视频-文本对话，涵盖多样且多层次的理解和生成场景。在JAV理解和生成基准上的广泛实验表明，JavisGPT在复杂和时间同步设置中特别优于现有的MLLMs。\n\n作者：刘凯、李俊刚、孙宇冲、吴胜琼、高建章、张道安、张伟、金胜、于思成、詹耕、季加怡、周梵、郑亮、严水城、费浩、蔡达成\n\n评论：已被NeurIPS接受为重点论文。代码：https://arxiv.org/pdf/2512.22905.pdf",
        "地址": "https://arxiv.org/pdf/2512.22905.pdf"
    },
    {
        "名称": "2025 [2512.22564] Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers.pdf",
        "作者": "Atakan Işık, Selin Vulga Işık, Ahmet Feridun Işık, Mahşuk Taylan",
        "摘要": "摘要：呼吸声音分类受到如ICBHI 2017这样基准数据集的有限规模、高噪声水平和严重类别不平衡问题的阻碍。尽管基于Transformer的模型提供了强大的特征提取能力，但在训练这种受限的医学数据时，它们容易过拟合，并且通常会在损失曲面中收敛到较尖锐的最小值。为了解决这个问题，我们引入了一个框架，使用Sharpness-Aware Minimization (SAM) 来增强音频频谱Transformer (AST)。我们的方法不仅仅最小化训练损失，而是优化损失表面的几何形状，引导模型趋向于那些对未见患者泛化更好的平缓最小值。我们还实施了一种加权采样策略以有效处理类别不平衡问题。我们的方法在ICBHI 2017数据集上取得了68.10%的最新成绩，超过了现有的CNN和混合基线模型。更重要的是，它达到了68.31%的敏感度，为可靠的临床筛查提供了重要的改进。通过t-SNE和注意力图的进一步分析证实，该模型学习了鲁棒且具有辨识性的特征，而不是记住了背景噪声。 \n\n作者：Atakan Işık, Selin Vulga Işık, Ahmet Feridun Işık, Mahşuk Taylan\n\n备注：10页，3个图，2个表\n\n链接：https://arxiv.org/pdf/2512.22564.pdf\n\n标题：Geometry-Aware Optimization for Respiratory Sound Classification: Enhancing Sensitivity with SAM-Optimized Audio Spectrogram Transformers",
        "地址": "https://arxiv.org/pdf/2512.22564.pdf"
    },
    {
        "名称": "2025 [2512.24885] BEDA: Belief Estimation as Probabilistic Constraints for Performing Strategic Dialogue Acts.pdf",
        "作者": "Hengli Li, Zhaoxin Yu, Qi Shen, Chenxi Li, Mengmeng Wang, Tinglang Wu, Yipeng Kang, Yuxuan Wang, Song-Chun Zhu, Zixia Jia, Zilong Zheng",
        "摘要": "摘要：战略对话需要智能体执行不同的对话行为，而信念估计对此至关重要。尽管以往的研究通常能够准确地估计信念，但缺乏在生成对话过程中利用这些信念的原则性机制。我们通过首先形式化两个核心行为：对抗性行为和对齐性行为，并通过对智能体生成内容施加概率约束将其操作化，填补了这一空白。我们在BEDA框架中实例化了这一理念，该框架包括世界集、用于信念估计的信念估计器以及用于选择行为并生成与推断信念一致的语句的条件生成器。在三个设置中：Conditional Keeper Burglar（CKBG，对抗性）、Mutual Friends（MF，合作性）和CaSiNo（谈判性），BEDA均明显优于现有的强基准模型：在CKBG中，跨不同基础模型的成功率至少提高了5.0个百分点，相对GPT-4.1-nano提升20.6个百分点；在Mutual Friends中平均提升了9.3个百分点；在CaSiNo中相对于所有基准模型达成了最优交易。这些结果表明，将信念估计视为约束条件提供了一种简单且通用的机制来实现可靠的战略对话。",
        "地址": "https://arxiv.org/pdf/2512.24885.pdf"
    },
    {
        "名称": "2025 [2512.24385] Forging Spatial Intelligence: A Roadmap of Multi-Modal Data Pre-Training for Autonomous Systems.pdf",
        "作者": "Song Wang, Lingdong Kong, Xiaolu Liu, Hao Shi, Wentong Li, Jianke Zhu, Steven C. H. Hoi",
        "摘要": "摘要：自动驾驶汽车和无人机等自主系统的快速发展加剧了从多模态传感器数据中构建真正空间智能的需求。尽管基础模型在单一模态背景下表现出色，但在不同传感器（如摄像头和LiDAR）之间整合其能力以创建统一理解仍是一个巨大挑战。本文提出了一个全面的多模态预训练框架，识别出推动这一目标进展的核心技术集。我们剖析了基础传感器特性与学习策略之间的相互作用，评估了特定平台数据集在推动这些进展中的作用。我们的主要贡献是制定了预训练范式的统一分类法：从单一模态基线到复杂的统一框架，它们学习面向高级任务（如3D物体检测和语义占用预测）的整体表示。此外，我们还研究了文本输入和占用表示的整合，以促进开放世界感知和规划。最后，我们确定了计算效率和模型可扩展性等关键瓶颈，并提出了一条通向多用途多模态基础模型的路线图，这些模型能够实现现实世界应用中的强大空间智能。",
        "地址": "https://arxiv.org/pdf/2512.24385.pdf"
    },
    {
        "名称": "2025 [2512.24297] Figure It Out: Improving the Frontier of Reasoning with Active Visual Thinking.pdf",
        "作者": "Meiqi Chen, Fandong Meng, Jie Zhou",
        "摘要": "摘要：复杂的推理问题通常涉及文本中未被明确编码的隐含空间、几何和结构关系。虽然最近的推理模型在许多领域都表现出色，但纯文本推理在复杂环境下难以表示全局结构约束。在本文中，我们介绍了FIGR，通过端到端强化学习将主动视觉思维整合到多轮推理中。FIGR通过在解决问题过程中构建视觉表示来外化中间结构假设。通过自适应调节何时以及如何进行视觉推理，FIGR能够更稳定和连贯地理解文本难以捕捉的全局结构特性。在具有挑战性的数学推理基准测试中，FIGR优于强大的纯文本思维链基线。特别是，FIGR在AIME 2025上将基线模型提升了13.12％，在BeyondAIME上提升了11.00％，突显了图形引导的多模态推理在增强复杂推理的稳定性和可靠性方面的有效性。",
        "地址": "https://arxiv.org/pdf/2512.24297.pdf"
    },
    {
        "名称": "2025 [2512.24176] Guiding a Diffusion Transformer with the Internal Dynamics of Itself.pdf",
        "作者": "Xingyu Zhou, Qifan Li, Xiaobin Hu, Hai Chen, Shuhang Gu",
        "摘要": "摘要：扩散模型在捕捉整个（条件）数据分布方面展现了强大的能力。然而，由于缺乏足够的训练和数据来学习覆盖低概率区域，该模型在生成与这些区域相对应的高质量图像时将受到惩罚。为了实现更好的生成质量，诸如无分类器指导（CFG）之类的指导策略可以在采样阶段将样本引导到高概率区域。然而，标准的CFG往往会导致过于简化或失真的样本。另一方面，用其劣化版本引导扩散模型的替代方法则受限于精心设计的降级策略、额外的训练和额外的采样步骤。在本文中，我们提出了一种简单而有效的策略——内部指导（IG），通过训练过程中在中间层引入辅助监督，并在采样过程中外推中间层和深层的输出以获得生成结果。这种简单的策略在各种基线模型上显著提高了训练效率和生成质量。在ImageNet 256x256上，SiT-XL/2+IG在80和800个周期的FID分别达到5.31和1.75。更令人印象深刻的是，LightningDiT-XL/1+IG的FID达到1.34，与所有方法相比有很大的优势。结合CFG，LightningDiT-XL/1+IG实现了当前最先进的FID 1.19。\n\n翻译：摘要：扩散模型在捕捉整个（有条件的）数据分布方面表现出了强大的能力。然而，由于缺乏足够的训练和数据来学习覆盖低概率区域，模型在生成这些区域的高质量图像时会受到惩罚。为了实现更好的生成质量，诸如无分类器指导（CFG）等指导策略可以在采样阶段将样本引导到高概率区域。然而，标准的CFG经常导致生成的样本过于简化或失真。另一方面，使用其劣化版本来指导扩散模型的替代方法受到精心设计的降级策略、额外训练和附加采样步骤的限制。本文提出了一个简单但有效的策略——内部指导（IG），该策略在训练过程中在中间层引入辅助监督，并在采样过程中外推中间层和深层的输出以获得生成结果。这种简单的策略在各种基线上显著提高了训练效率和生成质量。在ImageNet 256x256数据集上，SiT-XL/2+IG在80和800个周期的FID分别达到5.31和1.75。更令人印象深刻的是，LightningDiT-XL/1+IG的FID达到了1.34，与所有这些方法相比有很大优势。结合CFG，LightningDiT-XL/1+IG实现了当前最先进的FID 1.19。",
        "地址": "https://arxiv.org/pdf/2512.24176.pdf"
    },
    {
        "名称": "2025 [2512.24097] Factorized Learning for Temporally Grounded Video-Language Models.pdf",
        "作者": "Wenzheng Zeng, Difei Gao, Mike Zheng Shou, Hwee Tou Ng",
        "摘要": "摘要：最新的视频语言模型在视频理解方面展现了巨大潜力，但在事件级感知的精确时间定位上仍然存在困难。我们观察到视频理解的两个主要因素（即时间定位和文本响应）形成了一个逻辑层次结构：精确的时间证据定位为可靠的文本响应奠定了基础。然而，现有作品通常以一种耦合的方式处理这两个任务，缺乏明确的逻辑结构，导致目标次优。我们从因子化学习的角度来解决这个问题。我们首先提出了D^2VLM，一个将这两个任务的学习解耦同时强调其固有依赖关系的框架。我们采用“先定位再回答并参照证据”的范式，并引入证据标记进行证据定位，强调事件级视觉语义捕获，而不仅仅是现有作品中的时间戳表示。为了进一步促进这两个任务的学习，我们引入了一种新颖的因子化偏好优化（FPO）算法。与标准的偏好优化不同，FPO在优化目标中明确包含了概率时间定位建模，使得时间定位和文本响应的偏好学习成为可能。我们还构建了一个合成数据集，以解决缺乏适合因子化偏好学习的明确时间定位数据集的问题。各种任务的实验展示了我们方法的明显优势。我们的源代码可在以下网址获取：https://arxiv.org/pdf/2512.24097.pdf。",
        "地址": "https://arxiv.org/pdf/2512.24097.pdf"
    },
    {
        "名称": "2025 [2512.22280] Valori: A Deterministic Memory Substrate for AI Systems.pdf",
        "作者": "Varshith Gudur",
        "摘要": "摘要: 现代AI系统依赖于使用浮点运算存储和搜索的向量嵌入。虽然这种设计对于近似相似性搜索有效，但也引入了根本上的不确定性：相同的模型、输入和代码在不同的硬件架构（例如x86与ARM）上会产生不同的内存状态和检索结果。这阻碍了重现性和安全部署，导致默默的数据分歧，阻止事后验证，并在监管领域中破坏审计跟踪。我们提出了Valori，一种使用定点运算（Q16.16）替代浮点内存操作，并将内存建模为可重放状态机的确定性AI内存底层结构。Valori保证跨平台的位相同内存状态、快照和搜索结果。我们演示了这种不确定性在索引或检索之前产生，并展示了Valori如何在内存边界强制执行确定性。我们的结果表明，确定性内存是值得信赖的AI系统的必要原语。参考实现是开源的，可在此https URL（归档于此https URL）获取。",
        "地址": "https://arxiv.org/pdf/2512.22280.pdf"
    }
]