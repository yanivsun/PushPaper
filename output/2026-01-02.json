[
    {
        "名称": "2025 [2512.23959] Improving Multi-step RAG with Hypergraph-based Memory for Long-Context Complex Relational Modeling.pdf",
        "作者": "Chulun Zhou, Chunkang Zhang, Guoxin Yu, Fandong Meng, Jie Zhou, Wai Lam, Mo Yu",
        "摘要": "摘要:\n\n多步检索增强生成（RAG）已成为提高大型语言模型（LLMs）在需要全局理解和密集推理的任务上的常用策略。许多RAG系统包含一个工作记忆模块来整合检索到的信息。然而，现有的记忆设计主要是作为被动存储，积累孤立事实，以便通过推理缩短输入长度和生成新的子查询。这种静态性质忽视了原始事实之间的高阶关联，这些事实的组合通常可以为后续步骤提供更强的指导。因此，在多步推理和知识演进中的表现力和影响力有限，导致在扩展上下文中的推理碎片化，缺乏全局理解能力。我们介绍了HGMem，一种基于超图的记忆机制，将记忆的概念从简单存储扩展到复杂推理和全局理解的动态、表达结构。在我们的方法中，记忆表示为一个超图，其超边对应于不同的记忆单元，允许在记忆中逐步形成高阶互动。这种机制围绕中心问题连接事实和思维，演变成综合的、情景化的知识结构，为后续步骤中的深度推理提供了强有力的命题。我们在多个旨在进行全局理解的挑战性数据集上评估HGMem。广泛的实验和深入的分析表明，我们的方法不断改进多步RAG，并在各种任务上显著优于强大的基线系统。\n\n翻译结果:",
        "地址": "https://arxiv.org/pdf/2512.23959.pdf"
    },
    {
        "名称": "2025 [2512.24617] Dynamic Large Concept Models: Latent Reasoning in an Adaptive Semantic Space.pdf",
        "作者": "Xingwei Qu, Shaowen Wang, Zihao Huang, Kai Hua, Fan Yin, Rui-Jie Zhu, Jundong Zhou, Qiyang Min, Zihao Wang, Yizhi Li, Tianyu Zhang, He Xing, Zheng Zhang, Yuxuan Song, Tianyu Zheng, Zhiyuan Zeng, Chenghua Lin, Ge Zhang, Wenhao Huang",
        "摘要": "摘要：大型语言模型（LLMs）对所有的词元（tokens）应用统一计算，尽管语言表现出高度非均匀的信息密度。这种词元统一的计算方式在局部可预测范围内浪费了容量，同时在语义关键的过渡上分配的计算量不足。我们提出了动态大概念模型（DLCM），这是一个层次化的语言建模框架，通过从潜在表示中学习语义边界，将计算从词元转移到压缩的概念空间，在那里推理更加高效。DLCM可以端到端地发现变长的概念，而无需依赖预定义的语言单位。层次化压缩从根本上改变了扩展行为。我们引入了首个压缩感知扩展定律，它解开了词元级容量、概念级推理容量和压缩比之间的关系，在固定的浮点操作次数（FLOPs）下实现了有原则的计算分配。为了稳定地训练这种异构架构，我们进一步开发了分离的μP参数化，它支持跨宽度和压缩情况的零样本超参数转移。在实际设置下（R=4，对应于每个概念平均包含四个词元），DLCM重新分配大约三分之一的推理计算到高容量推理主干上，在相同的推理FLOPs下，在12个零样本基准测试中平均取得了+2.69%的改进。\n\n翻译：“大型语言模型（LLMs）对所有的词元（tokens）应用统一计算，尽管语言表现出高度非均匀的信息密度。这种词元统一的计算方式在局部可预测范围内浪费了容量，同时在语义关键的过渡上分配的计算量不足。我们提出了动态大概念模型（DLCM），这是一个层次化的语言建模框架，通过从潜在表示中学习语义边界，将计算从词元转移到压缩的概念空间，在那里推理更加高效。DLCM可以端到端地发现变长的概念，而无需依赖预定义的语言单位。层次化压缩从根本上改变了扩展行为。我们引入了首个压缩感知扩展定律，它解开了词元级容量、概念级推理容量和压缩比之间的关系，在固定的浮点操作次数（FLOPs）下实现了有原则的计算分配。为了稳定地训练这种异构架构，我们进一步开发了分离的μP参数化，它支持跨宽度和压缩情况的零样本超参数转移。在实际设置下（R=4，对应于每个概念平均包含四个词元），DLCM重新分配大约三分之一的推理计算到高容量推理主干上，在相同的推理FLOPs下，在12个零样本基准测试中平均取得了+2.69%的改进。”\n\n来源:\nhttps://arxiv.org/pdf/2512.24617.pdf\n标题:2025 [2512.24617] 动态大概念模型：自适应语义空间中的潜在推理",
        "地址": "https://arxiv.org/pdf/2512.24617.pdf"
    },
    {
        "名称": "2025 [2512.24165] DiffThinker: Towards Generative Multimodal Reasoning with Diffusion Models.pdf",
        "作者": "Zefeng He, Xiaoye Qu, Yafu Li, Tong Zhu, Siyuan Huang, Yu Cheng",
        "摘要": "摘要：尽管近期多模态大型语言模型（MLLMs）在多模态推理方面取得了显著进展，但其推理过程仍主要以文本为中心，导致在复杂且具有远景的视觉任务中表现不佳。本文建立了一种新颖的生成多模态推理范式，并引入了DiffThinker，一种基于扩散的推理框架。从概念上讲，DiffThinker将多模态推理重新定义为一种原生的生成图像到图像任务，在以视觉为中心的任务中实现了较高的逻辑一致性和空间精度。我们对DiffThinker和MLLMs进行了系统性比较，首次深入调查了这一范式的内在特性，揭示了四个核心属性：效率、可控性、原生并行性和协作性。通过在四个领域（顺序规划、组合优化、约束满足和空间配置）进行大量实验，结果表明DifThinker显著优于领先的闭源模型，包括GPT-5（+314.2%）和Gemini-3-Flash（+111.6%），以及微调的Qwen3-VL-32B基线（+39.0%），突显出生成多模态推理作为视觉中心推理的一种有前景的方法。\n\n作者：何泽锋，曲小叶，李亚夫，朱彤，黄思远，程宇\n\n备注：项目页面：此https URL\n\n链接：https://arxiv.org/pdf/2512.24165.pdf\n\n标题：2025 [2512.24165] DiffThinker：迈向基于扩散模型的生成多模态推理",
        "地址": "https://arxiv.org/pdf/2512.24165.pdf"
    },
    {
        "名称": "2025 [2512.22630] On the Role of Discreteness in Diffusion LLMs.pdf",
        "作者": "Ziqi Jin, Bin Wang, Xiang Lin, Lidong Bing, Aixin Sun",
        "摘要": "摘要：扩散模型为语言生成提供了有吸引力的特性，如并行解码和迭代优化，但文本的离散性和高度结构化特性使得扩散原则的直接应用充满挑战。本文我们从扩散过程和语言建模的角度重新审视了扩散语言建模，并概述了区分扩散机制与特定语言需求的五个特性。我们首先将现有方法分为嵌入空间中的连续扩散和基于标记的离散扩散。然后我们展示了每种方法仅满足五个基本特性中的部分特性，因此表现出结构上的权衡。通过对最近大型扩散语言模型的分析，我们确定了两个核心问题：（i）均匀破坏没有尊重信息在各位置上的分布，（ii）基于标记的边际训练无法在并行解码过程中捕捉多个标记的依赖关系。这些发现促使我们提出更符合文本结构的扩散过程，并鼓励未来工作朝着更连贯的扩散语言模型方向发展。\n\n作者：Ziqi Jin, Bin Wang, Xiang Lin, Lidong Bing, Aixin Sun\n\n链接： [https://arxiv.org/pdf/2512.22630.pdf](https://arxiv.org/pdf/2512.22630.pdf)",
        "地址": "https://arxiv.org/pdf/2512.22630.pdf"
    },
    {
        "名称": "2025 [2512.24724] FlowBlending: Stage-Aware Multi-Model Sampling for Fast and High-Fidelity Video Generation.pdf",
        "作者": "Jibin Song, Mingi Kwon, Jaeseok Jeong, Youngjung Uh",
        "摘要": "摘要：在这项工作中，我们展示了模型容量的影响在不同时间步上有所不同：模型容量对于早期和晚期阶段至关重要，但在中间阶段基本上可以忽略不计。因此，我们提出了FlowBlending，一种阶段感知的多模型抽样策略，在容量敏感阶段和中间阶段分别使用大模型和小模型。我们进一步介绍了选择阶段边界的简单准则，并提供了一种有效的近似方法，即速度发散分析，用于识别容量敏感区域。在LTX-Video (2B/13B)和WAN 2.1 (1.3B/14B)的实验中，FlowBlending在保持大模型的视觉保真度、时间一致性和语义对齐的同时，实现了最多1.65倍的推理加速，并减少了57.35%的浮点运算次数（FLOPs）。FlowBlending还兼容现有的抽样加速技术，能够额外加速最多2倍。项目页面可访问：this https URL。",
        "地址": "https://arxiv.org/pdf/2512.24724.pdf"
    },
    {
        "名称": "2025 [2512.24766] Dream2Flow: Bridging Video Generation and Open-World Manipulation with 3D Object Flow.pdf",
        "作者": "Karthik Dharmarajan, Wenlong Huang, Jiajun Wu, Li Fei-Fei, Ruohan Zhang",
        "摘要": "摘要: 生成视频建模作为一个有力的工具，能够在开放环境下对合理的物理交互进行零样本推理。然而，将这些人主导的运动转化为机器人系统所需的低层次动作仍然是一个挑战。我们观察到，给定初始图像和任务指令，这些模型在生成合理的物体运动方面表现出色。因此，我们引入了Dream2Flow，一个通过3D物体流动作为中介表示，桥接视频生成和机器人控制的框架。我们的方法从生成的视频中重建3D物体运动，并将操控任务形式化为物体轨迹跟踪。通过将状态变化与实现这些变化的执行器分离，Dream2Flow克服了体现差距，实现了从预训练视频模型到操控不同类别物体（包括刚性、关节型、可变形和粒状）的零样本指导。通过轨迹优化或强化学习，Dream2Flow将重建的3D物体流动转换为可执行的低层次命令，而无需特定任务的示范。仿真和现实世界实验突出了3D物体流动作为适应视频生成模型到开放世界机器人操控的通用且可扩展的界面。视频和可视化内容可在上述网址找到.",
        "地址": "https://arxiv.org/pdf/2512.24766.pdf"
    },
    {
        "名称": "2025 [2512.24007] TESO Tabu Enhanced Simulation Optimization for Noisy Black Box Problems.pdf",
        "作者": "Bulent Soykan, Sean Mondesire, Ghaith Rabadi",
        "摘要": "摘要: 仿真优化（SO）常常受到噪声评估、高计算成本和复杂多模搜索环境的挑战。本文介绍了一种名为Tabu增强仿真优化（TESO）的新型元启发式框架，该框架结合了自适应搜索与基于记忆的策略。TESO利用短期禁忌表防止循环并促进多样化，同时通过扰动高性能解来引导精化，从而实现长期的精英记忆。一个渴望准则允许为特殊候选者覆盖禁忌限制。这种组合在随机环境中促进了探索与开发之间的动态平衡。我们通过一个排队优化问题展示了TESO的有效性和可靠性，结果表明其性能优于基准模型，并验证了其记忆组件的贡献。源代码和数据可在此网址获取：this https URL。\n\n作者: Bulent Soykan, Sean Mondesire, Ghaith Rabadi\n\n备注: 11页, 2个图，在2025年12月于华盛顿西雅图召开的冬季仿真会议上展示。\n\n链接: https://arxiv.org/pdf/2512.24007.pdf",
        "地址": "https://arxiv.org/pdf/2512.24007.pdf"
    }
]